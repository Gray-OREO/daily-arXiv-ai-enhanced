<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 94]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.LG](#cs.LG) [Total: 59]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 研究了Artcode的检测问题，提出了一种新的形状方向直方图特征描述符，实验验证了其在拓扑结构表示和Artcode检测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机和VR/AR技术的普及，环境中可能充满与虚拟元素连接的物体，Artcode作为一种伪装成自由形态的标记，其检测是触发交互的第一步。

Method: 提出了一种称为形状方向直方图的新特征描述符，用于描述Artcode的通用拓扑结构，并构建了检测系统进行实验评估。

Result: 实验结果表明，所提出的特征向量能够有效表示拓扑结构，系统在Artcode检测中表现良好。

Conclusion: 尽管这是第一次尝试开发基于特征的拓扑物体检测系统，但它为拓扑物体检测的应用和交互提供了新的可能性。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [2] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: 本文综述了如何利用外部工具增强多模态大语言模型（MLLM）的性能，探讨了四个关键维度。


<details>
  <summary>Details</summary>
Motivation: MLLMs尽管在多种任务中表现出色，但受限于数据质量、复杂任务表现和评估方法，需外部工具补充以提升可靠性和适用性。

Method: 通过外部工具（如API、专家模型和知识库）改进数据获取、任务性能、模型评估。

Result: 总结了工具增强MLLM的潜力，为未来发展方向提供前瞻性观点。

Conclusion: 外部工具对MLLM能力提升具有变革潜力，未来研究和应用前景广阔。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [3] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: MV-ScanQA和TripAlign数据集的引入，解决了现有3D视觉语言数据集中多视图推理和多对象对齐的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D视觉语言数据集在远距离多对象推理和多视图场景理解上表现不足，限制了模型的深度发展。

Method: 提出MV-ScanQA数据集和TripAlign预训练语料库，结合LEGO方法将2D预训练知识迁移到3D领域。

Result: LEGO方法在MV-ScanQA和现有3D密集描述与问答基准上达到最先进性能。

Conclusion: MV-ScanQA和TripAlign为3D视觉语言学习提供了更丰富的多视图和多对象对齐信号，推动了该领域的进一步发展。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [4] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 提出了一个隐私增强机制，通过潜在噪声自编码器保护用户凝视信号，防止未经同意的重新识别，同时保留数据的可用性。


<details>
  <summary>Details</summary>
Motivation: 保护凝视数据的隐私，防止用户被重新识别，同时确保数据的可用性。

Method: 使用潜在噪声自编码器技术，在保留生理可信凝视模式的前提下，降低生物可识别性。

Result: 显著减少了生物可识别性，且对数据的实用性影响最小，优于现有方法。

Conclusion: 该机制为凝视数据提供了有效且实用的隐私保护方案。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [5] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 论文介绍了LogicBench基准测试和LogicCLIP框架，用于提升视觉语言模型的逻辑理解能力，结果显示现有模型在逻辑任务上表现不佳，而LogicCLIP显著改善了这一点。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（如CLIP）在多模态智能中具有重要地位，但其逻辑理解能力未被充分探索，导致实际应用中存在“逻辑盲点”。

Method: 论文提出LogicBench（含50,000+视觉语言对）和LogicCLIP框架，采用逻辑感知数据生成和对比学习策略（包括粗粒度对齐、细粒度多目标选择及逻辑结构感知目标）。

Result: 实验显示LogicCLIP在所有LogicBench任务中显著提升逻辑理解能力，同时保持甚至超越通用视觉语言任务的性能。

Conclusion: LogicBench和LogicCLIP是提升视觉语言模型逻辑能力的重要资源，且不会影响其通用对齐性能。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [6] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: 本文综述了基于多模态大语言模型（MLLMs）的视频时间定位（VTG-MLLMs）研究现状，通过三维分类法系统梳理了当前成果，并讨论了数据集、评估协议及未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有综述多关注通用视频语言理解，而专门针对VTG-MLLMs的综合研究较少，本文旨在填补这一空白。

Method: 采用三维分类法：1) MLLMs的功能角色；2) 训练范式；3) 视频特征处理技术，并分析数据集与评估协议。

Result: VTG-MLLMs在性能和多任务泛化能力上超越传统方法，展现了优越的多模态理解与推理能力。

Conclusion: 本文总结了VTG-MLLMs的研究进展，指出当前局限并提出了未来研究方向。

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [7] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF是一种通过翻转负提示的注意力值符号来动态抑制不想要内容的高效方法，适用于少步扩散和流匹配图像生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法如CFG、NASA和NAG在负提示引导上存在不足，VSF旨在以低计算成本提供高效解决方案。

Method: VSF通过翻转负提示的注意力值符号来动态抑制不想要的内容，适用于多种架构。

Result: VSF在复杂提示对的数据集和视频生成任务中表现出色，显著优于现有方法。

Conclusion: VSF在保持图像质量的同时，显著提高了负提示的遵循效果，具有广泛的应用潜力。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [8] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: 本文提出了一种基于相机姿态自编码器（PAEs）的相对姿态回归（RPR）方法，用于提高零售环境中相机定位的准确性，并通过PAE-based RPR精炼绝对姿态回归（APR）预测，减少了数据收集的负担。


<details>
  <summary>Details</summary>
Motivation: 现代零售环境中，精准的相机定位对提升客户体验、优化库存管理和实现自主操作至关重要。尽管单图像的绝对姿态回归（APR）提供了可行的解决方案，但结合视觉和空间场景先验的方法通常能实现更高的精度。

Method: 本文扩展了相机姿态自编码器（PAEs）到相对姿态回归（RPR）任务，并提出了一种新的重新定位方案，利用PAE-based RPR精炼APR预测，无需额外存储图像或姿态数据。

Result: 实验表明，PAE-based RPR优于等效架构的图像基RPR模型，且精炼策略显著提升了室内基准测试中的定位精度。值得注意的是，该方法在仅使用30%数据训练时仍表现优异。

Conclusion: 本文的方法不仅提高了相机定位的准确性，还显著减少了零售场景部署中的数据收集需求，为实际应用提供了高效且经济的解决方案。

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [9] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE是一种高效视频处理引擎，用于从未标注视频中估计相机参数和深度图，性能优于现有方法并支持多种场景和相机模型。


<details>
  <summary>Details</summary>
Motivation: 解决从未标注视频中获取一致且精确的3D注释的挑战，推动空间AI系统的发展。

Method: ViPE通过高效算法估计相机内参、运动和稠密深度图，支持多样场景和相机模型。

Result: 在TUM/KITTI基准上性能提升18%/50%，运行速度3-5FPS，并用于标注大规模视频数据集。

Conclusion: ViPE为3D感知提供了高效工具，开源数据集将进一步加速空间AI系统的研究。

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [10] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: 论文提出了一种高质量开放词汇3D检测框架（HQ-OV3D），通过改进几何质量来解决现有开放词汇3D检测方法中边界框精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的封闭集3D检测方法无法满足自动驾驶等开放世界应用的需求，现有开放词汇3D检测方法在几何质量（尤其是边界框精度）上表现不佳。

Method: HQ-OV3D包含两个关键组件：跨模态几何一致性的提案生成器（IMCV）和基于DDIM去噪机制的提案优化器（ACA），用于生成和优化高质量的伪标签。

Result: 实验显示，使用该框架生成的伪标签训练模型，在新类上的mAP提升了7.37%。

Conclusion: HQ-OV3D不仅是一个强力的开放词汇3D检测器，还可作为现有检测或标注流程的高质量伪标签生成插件。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [11] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: 论文提出了一种基于稀疏3D语义高斯泼溅的协作3D语义占用预测方法，避免了传统密集3D体素或2D特征的问题，通过高斯原语共享与融合提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉方法在3D语义占用预测中因高通信成本或依赖精确深度估计而受限的问题。

Method: 采用稀疏3D语义高斯泼溅技术，通过高斯原语的共享与融合，实现交叉代理融合、几何与语义的联合编码，并减少通信量。

Result: 实验显示，该方法在mIoU和IoU上显著优于单代理和基线协作方法，且在低通信量下仍保持高性能。

Conclusion: 该方法通过稀疏高斯原语融合，有效提升了协作感知的性能与通信效率。

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [12] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: 论文提出了一种新的面部超分辨率方法（IDFSR），通过身份解耦和拟合技术，在极端降级情况下显著提升了身份一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在极端降级场景（如缩放比例>8×）下，常因严重丢失身份信息而生成虚假或不一致的面部图像。

Method: IDFSR通过掩蔽低分辨率图像中的面部区域、对齐参考图像以提供风格指导，并利用真实图像的ID嵌入进行细粒度建模，从而优化身份恢复。

Result: IDFSR在极端降级条件下显著优于现有方法，尤其在身份一致性方面表现优异。

Conclusion: IDFSR通过解耦风格与身份，以及引入细粒度ID嵌入，有效解决了极端降级下的面部超分辨率问题。

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [13] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: 研究探索了深度学习在木材分类中的应用，通过评估五种CNN架构，发现ShuffleNetV2在性能和效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统木材分类方法费时且依赖专家知识，需自动化解决方案以支持生态监测和森林管理。

Method: 构建自定义图像数据集，评估五种CNN架构（ResNet50等），以分类越南常见十种木材。

Result: ShuffleNetV2表现最优，平均准确率99.29%，F1分数99.35%。

Conclusion: 轻量级深度学习模型适用于资源有限环境的高精度实时木材分类。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [14] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: 这篇论文提出了NIRMAL Pooling，一种结合自适应最大池化和非线性激活函数的CNN新池化层，用于图像分类任务，表现优于标准最大池化。


<details>
  <summary>Details</summary>
Motivation: 传统池化方法在特征表达和鲁棒性上有限，希望提出一种更灵活可靠的池化层以提升CNN性能。

Method: NIRMAL Pooling动态调整池化参数，结合ReLU激活函数，实现自适应和非线性特征提取。

Result: 在MNIST Digits、MNIST Fashion和CIFAR-10上，NIRMAL Pooling分别取得99.25%、91.59%和70.49%的测试准确率，优于传统最大池化。

Conclusion: NIRMAL Pooling能显著提升CNN在图像识别任务中的性能，尤其在复杂数据集上表现突出。

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [15] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: 该研究提出了一种通过低分辨率CT量化纺织增强材料在压实过程中嵌套行为的框架，并利用3D-UNet进行语义分割，分析空间结构以提取关键几何特征。


<details>
  <summary>Details</summary>
Motivation: 纺织增强复合材料的力学性能（如刚度、渗透性和损伤容限）受层间嵌套行为影响显著，需量化分析以支持预测建模。

Method: 采用低分辨率CT扫描和3D-UNet语义分割技术，结合两点相关函数分析空间结构，提取平均层厚度和嵌套程度。

Result: 模型分割性能优异（IoU 0.822，F1 0.902），结果与显微图像验证高度一致，为工业CT数据提供了可靠分析方法。

Conclusion: 该方法为复合材料预制件的逆向建模和描述符基结构分析奠定了基础。

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [16] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: 论文介绍了一个名为iWatchRoad的端到端系统，用于自动化检测道路坑洼、GPS标记和实时地图绘制。


<details>
  <summary>Details</summary>
Motivation: 道路坑洼对安全和车辆寿命构成威胁，尤其在印度等道路维护不善的地区。

Method: 利用自标注数据集和YOLO模型进行实时坑洼检测，结合OCR提取时间戳并与GPS同步。

Result: 系统在复杂条件下提高了检测准确性，并提供了用于道路评估的政府兼容输出。

Conclusion: iWatchRoad是低成本、高效的解决方案，适用于发展中国家的道路管理。

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [17] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: 本文提出了增量补丁生成（IPG）方法，能比现有方法高效11.1倍地生成对抗补丁，同时保持攻击性能，为AI安全生态系统提供了强大的知识基础。


<details>
  <summary>Details</summary>
Motivation: 对抗补丁对AI模型鲁棒性构成挑战，尤其影响计算机视觉任务如目标检测，需开发更高效的方法应对。

Method: 采用增量补丁生成（IPG）方法，通过实验和消融研究验证其高效性和攻击性能。

Result: IPG生成的补丁能广泛覆盖模型漏洞，并可作为构建鲁棒模型的基础。

Conclusion: IPG在对抗补丁防御和实际应用（如自动驾驶）中具有潜力，能提升AI模型在动态高风险环境中的鲁棒性。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [18] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas是一个新的基准框架，旨在通过多模态医学图像交互和多轮对话来评估大型语言模型在真实医疗推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态基准通常局限于单图像、单轮任务，无法模拟临床实践中多模态和纵向交互的复杂性。

Method: MedAtlas设计了四个核心任务：多轮开放式和封闭式问答、多图像联合推理和综合疾病诊断，并引入了新的评估指标。

Result: 基准测试显示现有多模态模型在多阶段临床推理中存在显著性能差距。

Conclusion: MedAtlas为推进稳健可信的医疗AI提供了具有挑战性的评估平台。

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [19] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: FastFOD-Net是一种深度学习框架，用于增强纤维取向分布（FOD），并在健康人群和六种神经系统疾病中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要在健康人群中测试，限制了临床应用。FastFOD-Net旨在解决这一问题，提升临床扩散MRI数据的可靠性和效率。

Method: FastFOD-Net是一种加速的端到端深度学习框架，能高效增强FOD，比前代快60倍。

Result: FastFOD-Net在临床评估中表现优异，能降低测量误差、区分疾病，并提高连接组应用的可解释性。

Conclusion: FastFOD-Net有望推动临床神经科学研究，增强对基于深度学习的扩散MRI增强方法的信任。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [20] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: 本文提出一个名为ORBIT的多层次视觉问答（VQA）基准，专注于对象属性推理，揭示了现有视觉语言模型（VLMs）在复杂推理任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前VQA基准在对象属性推理方面存在不足，感知与推理混杂，且缺乏多样化的图像类别和推理层级。本文旨在填补这一空白，通过系统化评估框架分析VLMs的表现。

Method: 提出了ORBIT基准，涵盖三种代表性图像类型、三种复杂性递增的推理层级和四个对象属性维度，包含360张图像和1,080个计数问题，并在零样本设置下测试12个先进VLMs。

Result: 实验显示VLMs在复杂推理任务中表现显著低于人类，最佳模型准确率仅40%，尤其在真实性图像、反事实推理和高计数任务中表现不佳。

Conclusion: ORBIT基准揭示了VLMs在对象属性推理中的局限性，呼吁开发可扩展的基准方法、通用标注指南及更强大的推理模型。

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [21] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 该论文研究了利用高光谱成像技术解决RGB图像中材料外观相似性（即同色异谱现象）的问题，通过信息理论和图像质量指标选择最具信息量的波段，提高了脆弱道路使用者的可区分性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶感知系统中由于RGB图像中的同色异谱现象导致脆弱道路使用者（VRU）辨识困难的安全挑战。

Method: 提出了一种波段选择策略，结合信息理论（联合互信息最大化、相关性分析）和图像质量指标（对比信噪比），从高光谱数据中选择最具信息量的波段，并在H-City数据集上验证。

Result: 选出三个波段（497 nm, 607 nm, 895 nm），在对比RGB图像时表现出更高的可区分性和感知可分性，各项指标提升显著（70.24%至1206.83%）。

Conclusion: 通过光谱优化的方法显著减少了同色异谱混淆，为高级驾驶辅助系统（ADAS）和自动驾驶（AD）的感知任务提供了更可靠的基础，有助于提升道路安全。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [22] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种轻量级插件EVCtrl，通过时空双缓存策略减少冗余计算，提升图像和视频生成效率，保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有ControlNet虽然能提供精确控制，但计算冗余高且延迟大，影响了生成效率。

Method: 提出时空双缓存策略：空间上分区处理，仅在有需求的局部区域进行计算；时间上选择性跳过冗余去噪步骤。

Result: 在多个基准测试中，EVCtrl显著提升了速度（最高2.16倍），且生成质量几乎无损失。

Conclusion: EVCtrl是一种无需训练的轻量级方案，能高效实现图像和视频的精确控制生成。

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [23] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: 本文研究了视觉语言模型（VLMs）在模拟低视力人群视觉感知方面的能力，发现结合视觉信息和示例图像响应可以显著提高模拟效果。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs在无障碍领域的模拟能力，填补此前研究空白。

Method: 通过40名低视力参与者的调查数据构建仿真代理，测试不同提示信息对VLMs模拟效果的影响。

Result: 结合视觉信息和示例图像响应显著提高了VLMs与参与者回答的一致性（0.70）。

Conclusion: VLMs在低视力模拟中需结合多类型信息，但额外示例效果有限。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [24] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: 论文提出了一个名为ConstructionSite 10k的开源数据集，包含10,000张建筑工地图像及标注，用于评估和改进视觉语言模型（VLMs）在工地安全检查中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开放的、全面的数据集来评估和微调VLMs在建筑安全检查任务中的应用，现有数据集规模小且限制性高。

Method: 提出ConstructionSite 10k数据集，支持三项任务：图像描述生成、安全规则违反视觉问答（VQA）和建筑元素视觉定位。

Result: 对现有VLMs的评估显示其在零样本和小样本设置中有显著泛化能力，但需进一步训练以适应实际工地场景。

Conclusion: 该数据集为研究人员提供了训练和评估新VLMs架构与技术的基准，推动了建筑安全检查技术的发展。

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [25] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: 研究评估多模态大语言模型（LLMs）在检测伪造文件方面的效能，发现某些模型在零样本泛化上表现优异，但模型规模与效果关联有限，强调任务针对性调优的重要性。


<details>
  <summary>Details</summary>
Motivation: 伪造文件对依赖安全文档的行业构成重大威胁，需要高效的检测方法。

Method: 通过提示优化和分析模型推理过程，评估多模态LLMs在识别伪造文件中的表现，使用标准数据集进行基准测试。

Result: 表现最佳的多模态LLMs在零样本泛化上优于传统方法，但部分视觉LLMs表现不一致或较差。模型规模与检测准确性关联有限。

Conclusion: 多模态LLMs在增强伪造文件检测系统方面具有潜力，未来需研究可解释和可扩展的欺诈缓解策略。

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [26] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: MedSAMix是一种无需训练的方法，整合通用与专用模型的优势，用于医学图像分割，显著提升了性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型（如MedSAM）因数据限制和异质性导致泛化能力不足，需要一种更优的解决方案。

Method: 提出MedSAMix，通过零阶优化自动寻找最优层合并策略，并针对临床需求设计了单任务和多目标优化方案。

Result: 在25个任务上的评估表明，MedSAMix显著提升了性能：在专用任务上提高6.67%，在多任务评估上提高4.37%。

Conclusion: MedSAMix通过融合通用与专用模型的优势，有效解决了医学图像分割中的性能与泛化问题。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [27] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: 研究通过AI分析3D影像，揭示了腹部体组成特征与2型糖尿病的关联，发现不同体重人群中存在一致的糖尿病标志。


<details>
  <summary>Details</summary>
Motivation: 尽管BMI是2型糖尿病的已知风险因素，但瘦人和肥胖人群中的疾病差异表明，详细体组成可能揭示腹部表型与糖尿病的关系。

Method: 利用3D影像提取腹部结构特征，通过随机森林分类和SHAP分析确定糖尿病风险或保护标志，并在不同BMI亚组中进行验证。

Result: 随机森林AUC为0.72-0.74，发现脂肪肌肉、内脏脂肪和胰腺脂肪等标志在多个亚组中一致预测糖尿病风险。

Conclusion: 腹部体组成特征可能在不同体重人群中一致驱动2型糖尿病。

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [28] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: 论文提出了一种名为HierOctFusion的3D内容生成方法，通过多尺度八叉树扩散模型和语义部分层次结构，解决了现有方法的局限性，并显著提升了生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D对象视为整体，忽略了语义部分层次结构，且高分辨率建模计算成本高昂。论文旨在通过分层生成和部分感知建模解决这些问题。

Method: 提出了HierOctFusion，一种基于多尺度八叉树扩散模型的生成方法，结合了跨注意力条件机制和部分级信息注入。

Result: 实验表明，该方法在形状质量和效率上优于现有方法。

Conclusion: HierOctFusion通过语义部分层次结构和多尺度建模，实现了高效的3D内容生成，为未来研究提供了新方向。

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [29] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: 提出一种基于超宽带（UWB）的无接触坐姿监测系统UWB-PostureGuard，解决传统方法在隐私和舒适性上的问题，并实现高精度监测。


<details>
  <summary>Details</summary>
Motivation: 长时间使用电脑时的不良坐姿已成为公共卫生问题，传统监测方法存在隐私侵犯和用户不适的局限性。

Method: 利用商用UWB设备，通过特征工程提取坐姿特征，开发PoseGBDT模型以捕捉时间依赖性。

Result: 在10名参与者和19种不同姿势的测试中，系统达到99.11%的准确率，且对环境变化鲁棒。

Conclusion: UWB-PostureGuard提供了一种低成本、高可扩展性的隐私保护健康管理方案。

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [30] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 本文提出了一种残差双向扩散模型（RBDM），可实现雾图与无雾图之间的双向转换，性能优于或与现有方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有深度去雾方法仅关注去雾，无法实现雾图与无雾图之间的双向转换。

Method: 设计双马尔可夫链处理残差，通过噪声预测学习条件分布，并引入基于图像块的统一评分函数以降低计算成本。

Result: RBDM仅需15次采样即可实现双向转换，在合成和真实数据集上性能优异。

Conclusion: RBDM解决了去雾与生成雾图的双向问题，高效且性能优越。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [31] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的跨模态谣言检测方法MICC，通过结合多尺度图像和文本语义，显著提升了谣言检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有谣言检测方法常忽略图像内容及上下文与图像之间的关系，导致关键信息丢失，因此需要新的方法来解决这一问题。

Method: 设计了SCLIP编码器和跨模态多尺度对齐模块，通过对比学习和互信息最大化，融合多尺度图像特征与全局文本特征。

Result: 在两个真实数据集上的实验结果表明，该方法在谣言检测任务中显著优于现有最优方法。

Conclusion: MICC方法有效解决了跨模态信息融合问题，具有实际应用潜力。

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [32] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: LEARN是一个布局感知的扩散框架，旨在为STEM教育生成教学对齐的插图，通过布局条件生成和视觉语义训练提高语义对齐。


<details>
  <summary>Details</summary>
Motivation: 解决STEM教育中抽象科学概念的视觉化问题，减少认知负担并提升学习效果。

Method: 利用BookCover数据集，结合布局条件生成、对比视觉语义训练和提示调制。

Result: 生成连贯的视觉序列，支持中高层次的推理，并降低认知负荷。

Conclusion: LEARN为生成式AI在教育中的应用提供了新方向，未来可集成多模态系统和知识图谱。

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [33] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 提出了一种基于EM和双向布朗桥扩散模型的半监督图像去雾方法，并通过两阶段学习方案提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法处理真实世界厚雾场景效果不佳，主要原因是缺乏配对的真实数据和强健的先验知识。

Method: 采用两阶段学习，第一阶段用EM算法解耦联合分布并通过布朗桥扩散模型建模，第二阶段利用预训练模型和大规模未配对数据优化性能。

Result: 实验表明EM-B3DM在合成和真实数据集上优于或媲美现有最佳方法。

Conclusion: EM-B3DM是一种高效的去雾方法，尤其在真实场景中表现优异。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [34] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉基础模型的源自由目标检测方法VG-DETR，通过半监督框架和伪标签优化，解决了源数据不可用时的领域适应问题。


<details>
  <summary>Details</summary>
Motivation: 针对遥感图像中源数据不可用的实际问题，现有的源自由目标检测方法因伪标签噪声导致训练崩溃，需要一种更鲁棒的解决方案。

Method: VG-DETR结合了视觉基础模型（VFM），通过伪标签挖掘策略和双级对齐方法优化伪标签质量与特征提取能力。

Result: 实验表明VG-DETR在源自由遥感检测任务中表现优异。

Conclusion: VG-DETR通过利用视觉基础模型和半监督学习，显著提升源自由目标检测的性能，为实际应用提供了有效方案。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [35] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: IOVQA是一种针对视觉语言模型的微调方法，通过整数标签和针对性损失计算机制，显著提升了视频质量评估任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频质量评估中存在结果不精确和损失计算效率低的问题，限制了模型对关键评价指标的关注。

Method: 提出IOVQA，通过约束模型输出为整数标签和引入目标掩码策略优化损失计算，强制模型学习数值评估的关键部分。

Result: 实验结果表明，该方法显著提升了模型在VQA任务中的准确性和一致性，在VQualA 2025竞赛中排名第三。

Conclusion: 仅使用整数标签微调对优化视觉语言模型在定量评估场景中表现有效，提供了一种新思路。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [36] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: IDOD方法通过独立多样性增强、联合新颖性发现和正交性增量模块解决了连续类别发现中的错误累积和遗忘问题，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有连续类别发现方法难以平衡新类发现与分类，且易累积错误和占用存储空间。

Method: IDOD包含独立多样性增强模块、联合新颖性发现模块和正交性增量模块，通过对比损失和正交原型减少错误累积和存储开销。

Result: 在细粒度数据集上的实验表明，IDOD优于现有技术。

Conclusion: IDOD有效解决了连续类别发现中的关键问题，性能显著提升。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [37] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: LatHAdapter 是一种新型适配器，用于在少样本分类任务中微调视觉语言模型。它通过潜在语义层次结构和双曲空间投影，解决了现有方法在类别与图像关联上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有适配器方法在少样本分类任务中难以捕获类别与图像之间的一对多关联，且对未知类别适应能力差。

Method: 引入可学习的属性提示作为桥梁，将类别、属性提示和图像投影到双曲空间，利用层次正则化学习潜在语义层次。

Result: 在四个少样本任务上，LatHAdapter 表现优于其他微调方法，尤其在已知类别适应和未知类别泛化方面。

Conclusion: LatHAdapter 通过潜在语义层次结构和双曲空间学习，显著提升了少样本分类任务的性能。

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [38] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于高斯视频变换器（GVT）的视频标记化方法，通过生成2D高斯分布增强空间适应性和时间通用性，显著提升了视频重建质量和其他任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视频标记化方法通常采用固定网格和补丁标记，导致在低信息区域过编码，且在时间冗余减少方面缺乏对静态与动态内容的显式区分。

Method: GVT采用生成2D高斯泼溅（2DGS）策略，通过时空高斯嵌入（STGE）生成2D高斯表示，并引入高斯集合划分（GSP）策略区分静态与动态内容。

Result: GVT在视频重建任务中达到最新水平，在动作识别上优于MAGVIT-v2，并在压缩任务中表现可比。

Conclusion: GVT通过生成高斯分布和显式区分静态与动态内容，提供了一种更具适应性和通用性的视频标记化方法。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [39] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种名为CHARM3R的单目3D物体检测器，通过平均回归深度和基于地面的深度估计，显著提升了对未知相机高度的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D物体检测器在不同相机高度下表现不佳，本文旨在解决这一未充分研究的问题。

Method: 系统分析了相机高度变化对模型性能的影响，提出了一种结合回归深度和基于地面深度估计的方法。

Result: CHARM3R在CARLA数据集上对未知相机高度的泛化能力提升了45%以上，达到SOTA性能。

Conclusion: CHARM3R通过改进深度估计，有效解决了相机高度变化对单目3D检测的影响。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [40] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: 提出了一种自动将单人教学视频转换为任务指导对话的方法，构建了大规模数据集HowToDIV，为未来研究提供基准。


<details>
  <summary>Details</summary>
Motivation: 针对真实世界任务辅助中对话-视频数据集的稀缺问题，提出高效的数据生成方案。

Method: 利用大型语言模型自动将单人教学视频转换为两方对话，并与视频片段对齐。

Result: 构建了包含507个对话、6636对问答和24小时视频的HowToDIV数据集，并提供了基线性能评估。

Conclusion: 该方法为任务辅助对话研究提供了高效的数据生成工具和新基准。

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [41] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: 该论文提出了UAV-VL-R1，一种专为无人机航拍图像设计的轻量级视觉语言模型，通过混合监督微调和多阶段强化学习方法，显著提升了在航拍任务中的零样本准确率，同时支持资源受限设备的实时部署。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型在航拍图像任务中性能下降，主要因为航拍图像的高分辨率、复杂空间语义和实时性需求，限制了其应用。

Method: 采用监督微调（SFT）与多阶段强化学习（RL）结合的混合方法，利用GRPO算法通过规则引导奖励和组内策略对齐提升结构化推理能力。

Result: UAV-VL-R1在零样本准确率上比基线模型提升48.17%，甚至在部分任务上超越了大36倍的模型变体，内存占用低至3.9GB（FP16）或2.5GB（INT8）。

Conclusion: UAV-VL-R1通过结合SFT和GRPO强化学习，显著提升了航拍图像任务的性能，同时满足了资源受限设备的实时部署需求。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [42] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的从粗到细的两阶段知识蒸馏框架，用于轻量化且准确的人体姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态估计方法需要大量计算资源，而传统的知识蒸馏未能充分挖掘人体关节的上下文信息。

Method: 该方法分两阶段：第一阶段通过结构损失挖掘关节间信息；第二阶段利用IGP-GCN逐步优化姿态。

Result: 在COCO keypoint和CrowdPose数据集上表现优于现有方法，尤其在复杂场景下改进显著。

Conclusion: 提出的框架有效提升了轻量化姿态估计的精度和鲁棒性。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [43] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级不确定性模态建模（UMM）框架，用于解决自动驾驶中行人重识别（ReID）任务中模态不确定或缺失的问题。UMM通过多模态令牌映射器、合成模态增强策略和跨模态交互学习器，实现了统一的特征表示，并利用CLIP的视觉-语言对齐能力高效融合多模态输入。实验表明，UMM在模态不确定条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，行人重识别（ReID）因输入模态（如RGB、红外等）的不确定或缺失而面临挑战。现有大规模预训练模型虽然强大，但计算开销大，难以在资源受限的环境中部署。为了解决这些问题，作者提出了UMM框架。

Method: UMM框架包含三个关键组件：多模态令牌映射器、合成模态增强策略和跨模态交互学习器。此外，UMM还利用了CLIP的视觉-语言对齐能力，无需大量微调即可高效融合多模态输入。

Result: 实验结果表明，UMM在模态不确定条件下具有强大的鲁棒性、泛化能力和计算效率，为自动驾驶场景中的行人重识别提供了实用解决方案。

Conclusion: UMM框架通过轻量级设计和跨模态交互学习，有效解决了行人重识别中的模态不确定性挑战，为自动驾驶提供了高效且可扩展的技术支持。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [44] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 这篇论文提出了Talking-Critic模型和TLPO框架，解决了音频驱动肖像动画在多个维度上的细粒度人类偏好对齐问题，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在多维度（如动作自然度、唇形同步准确性和视觉质量）上对齐人类偏好，且缺乏高质量的多维偏好标注数据集。

Method: 作者引入Talking-Critic学习人类对齐的奖励函数，构建Talking-NSQ数据集，并提出TLPO框架，通过分步分层的多专家模块优化多维度偏好。

Result: 实验表明，Talking-Critic在人类偏好评分上显著优于现有方法，TLPO在唇形同步、动作自然度和视觉质量上均有明显提升。

Conclusion: 论文提出的方法在多维度人类偏好对齐方面表现出色，为音频驱动肖像动画提供了有效解决方案。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [45] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP提出了一种新框架，通过解耦CLIP的自注意力模块来分别获取“内容”和“上下文”特征，从而提升密集视觉感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集视觉感知任务受限于预定义类别，而CLIP等视觉语言模型在开放词汇任务中表现不佳，主要是局部特征表示不足。

Method: DeCLIP解耦自注意力模块，分别优化内容和上下文特征，利用视觉基础模型和扩散模型增强语义关联和空间一致性。

Result: 实验表明，DeCLIP在多项任务（如2D检测、3D实例分割等）中均取得了最先进性能。

Conclusion: DeCLIP为开放词汇密集感知任务提供了坚实基础，显著提升了性能。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [46] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 该研究揭示对比视觉语言编码器在嵌入空间中可能隐含性别偏见，并提出了一种评估框架来衡量这些偏见。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探究视觉语言模型（VLM）在共享表示空间中是否无意中编码和放大了性别刻板印象。

Method: 通过计算面部图像与职业和活动描述的短句之间的余弦相似性差异，结合性别分组和标签交换空模型进行分析。

Result: 研究发现对比视觉语言空间中存在性别关联模式，并提供了类别和单语句层面的偏见分布。

Conclusion: 该研究为视觉语言模型的性别偏见评估提供了新框架，并揭示了模型潜在的刻板印象问题。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [47] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: 提出了一个类别级几何学习框架，用于领域泛化的3D语义分割，通过类别级几何嵌入和几何一致性学习提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法通过增强点云数据分布来缓解领域偏移，但忽视了类别级分布和对齐，导致模型泛化能力不足。

Method: 提出类别级几何嵌入（CGE）感知点云特征的细粒度几何属性，并通过几何一致性学习（GCL）模拟潜在3D分布并对齐类别级几何嵌入。

Result: 实验结果表明，该方法在领域泛化3D语义分割任务中表现优异，与最先进方法具有竞争力。

Conclusion: 该方法通过聚焦几何不变信息，显著提升了模型在未见环境中的泛化能力。

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [48] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: 论文提出了一种名为PMTFR的框架，用于解决组合图像检索（CIR）任务中的挑战，通过金字塔匹配模型和无训练优化的方法提升了性能，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决CIR任务中需要联合理解参考图像和文本指令的挑战，避免额外训练排序模型的成本，并探索Chain-of-Thought技术在CIR中的应用。

Method: 提出PMTFR框架，包括金字塔匹配模型和基于表示工程的无训练优化模块，通过Pyramid Patcher增强视觉信息的理解。

Result: 在CIR基准测试中，PMTFR在监督任务中超越了现有方法，表现出更高的性能。

Conclusion: PMTFR为CIR任务提供了一种高效且免训练的优化方案，展示了Chain-of-Thought技术在视觉任务中的潜力。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [49] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: 论文研究了稀疏自编码器（SAEs）在视觉模型中的应用，发现SAE特征在语义理解、泛化能力和可控生成方面表现优异，并为视觉模型的可解释性提供了基础支持。


<details>
  <summary>Details</summary>
Motivation: 尽管SAEs在语言模型中广泛应用，但其在视觉领域的研究仍不足，本文旨在填补这一空白，评估SAEs在视觉模型中的表现。

Method: 通过多种图像任务评估SAEs在三种视觉模型架构（视觉嵌入模型、多模态LMMs和扩散模型）中的代表性能力。

Result: SAE特征具有语义意义，能提升分布外泛化能力，并支持可控生成；在视觉嵌入模型中可用于OOD检测，扩散模型中支持语义引导，多模态LLMs中揭示了跨模态共享表示。

Conclusion: SAEs在视觉模型中展现出显著潜力，为提升可解释性、泛化能力和可控性提供了新方向。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [50] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: 该论文提出了一个统一框架，用于单目内窥镜组织3D重建，结合了尺度感知深度预测和时间约束的感知细化，解决了深度模糊和组织变形等挑战。


<details>
  <summary>Details</summary>
Motivation: 单目内窥镜姿态估计和组织重建在实际应用中面临深度模糊、组织变形等问题，亟需一种鲁棒且高效的方法。

Method: 提出了包含MAPIS-Depth和WEMA-RTDL模块的框架，结合深度预测、光流计算和感知细化，最终通过体积融合生成3D表面网格。

Result: 在HEVD和SCARED数据集上的测试表明，该方法在鲁棒性和准确性上优于现有技术。

Conclusion: 该方法为单目内窥镜组织重建提供了有效解决方案，显著提升了导航和空间感知能力。

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [51] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: TimeMachine是一种基于扩散模型的框架，用于精确编辑面部年龄，同时保持身份特征不变。它通过高精度年龄信息注入和多交叉注意力模块实现细粒度年龄编辑，并通过Age Classifier Guidance模块提高准确性。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在面部图像编辑方面已有显著进展，但在细粒度年龄编辑同时保持个人身份不变方面仍具挑战性。

Method: 提出了TimeMachine框架，采用多交叉注意力模块显式分离年龄和身份特征，并设计Age Classifier Guidance模块直接在潜在空间预测年龄。此外，构建了HFFA数据集。

Result: 实验证明，TimeMachine在细粒度年龄编辑和身份一致性保持方面达到了最先进的性能。

Conclusion: TimeMachine通过创新的设计解决了年龄编辑中的身份保持问题，并在性能上表现出色。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [52] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: HSI通过优化波段选择显著提升行人分割性能，优于标准RGB方法。


<details>
  <summary>Details</summary>
Motivation: 解决RGB成像中因视觉不可区分性导致的行人分割安全问题。

Method: 比较RGB与两种HSI降维方法（PCA和CSNR-JMIM），评估三种语义分割模型（U-Net、DeepLabV3+、SegFormer）。

Result: CSNR-JMIM在IoU和F1-score上平均提升1.44%和2.18%，显著减少假阳性。

Conclusion: 优化HSI波段选择可提升汽车感知系统的行人分割性能，适用于安全关键应用。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [53] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出了一种先降噪再检索的范式（DRNet），通过过滤文本无关的视频片段提升多模态对齐，从而优化视频时刻检索的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理视频时刻检索时，编码所有视频片段（包括无关片段）会破坏多模态对齐，影响优化效果。因此，希望通过显式过滤无关片段提升检索准确性。

Method: 采用TCD模块动态识别噪声片段并生成噪声掩码，TRF模块进一步蒸馏查询嵌入并与文本嵌入对齐。

Result: 在Charades-STA和QVHighlights数据集上，DRNet在所有指标上超越现有方法。

Conclusion: 提出的降噪检索范式不仅性能优越，还可轻松集成到其他先进模型中提升效果。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [54] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: 提出了基于动态场景线索一致性的3D多目标跟踪方法DSC-Track，通过空间模式匹配提升跟踪效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在拥挤场景或不精确检测中表现不佳，忽略了几何关系，需利用空间线索提升跟踪。

Method: 设计时空编码器学习轨迹嵌入，引入线索一致性变换模块对齐特征，动态更新保持信息。

Result: 在nuScenes和Waymo数据集上验证了方法的有效性和鲁棒性，nuScenes上达到73.2%和70.3% AMOTA。

Conclusion: DSC-Track通过空间线索一致性设计显著提升了3D多目标跟踪性能。

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [55] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为NoOp的噪声优化方法，旨在解决扩散分类器（DC）中噪声不稳定性的问题，通过学习匹配的噪声来提升分类性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散分类器（DC）因噪声不稳定而需要大量噪声采样以稳定性能，这显著降低了分类速度。本文旨在通过学习“好噪声”来缓解这一问题。

Method: 提出NoOp方法，通过频率匹配和空间匹配原则优化噪声：优化数据集特定的噪声参数，并训练元网络生成图像特定的噪声偏移。

Result: 在多个数据集上的广泛实验证明了NoOp的有效性，显著提升了扩散分类器的性能。

Conclusion: NoOp通过学习匹配噪声，克服了DC的噪声不稳定性，为快速稳定的图像分类提供了一种新方法。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [56] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: GANDiff FR 是一种合成框架，通过精确控制人口统计学和环境因素来测量、解释和减少偏见，结合了 StyleGAN3 和扩散模型的优势。


<details>
  <summary>Details</summary>
Motivation: 旨在解决人脸识别系统中的偏见问题，并提供可复现的公平性评估标准。

Method: 结合 StyleGAN3 的身份保留生成和扩散模型的属性控制，生成 10,000 张平衡人脸，用于量化偏见。

Result: AdaFace 减少了 60% 的组间 TPR 差异，证实了合成数据与现实数据的强相关性（r 0.85）。

Conclusion: GANDiff FR 为公平性审计提供了可扩展的工具，符合欧盟 AI 法案要求。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [57] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: 增量目标检测（IOD）中，基于Transformer的检测模型容易发生灾难性遗忘。本文提出了一种新的蒸馏方法（IAQD），通过索引对齐和部分查询蒸馏来有效缓解遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer-based检测模型在增量学习任务中因匈牙利匹配导致的灾难性遗忘问题。

Method: 提出索引对齐查询蒸馏（IAQD），通过固定索引匹配查询，并仅对关键查询进行蒸馏。

Result: IAQD在多个基准测试中有效缓解了知识遗忘，实现了最先进的性能。

Conclusion: IAQD通过优化蒸馏策略，显著提升了Transformer-based IOD模型的性能。

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [58] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: 论文提出了一种名为“主动标注”的新方法，旨在通过高效利用未标注宫颈细胞图像的不确定性，构建具有代表性的训练数据集，从而降低人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有宫颈细胞分类方法需要大量人工标注数据，成本高昂。本文旨在开发一种成本效益高的方法，通过主动选择最有价值的图像进行标注，减少人工成本。

Method: 提出“主动标注”算法，利用分类器对未标注图像的不确定性，选择最有价值的图像进行标注，以高效构建代表性训练数据集。

Result: 实验结果表明，该方法能显著提升训练数据集的代表性，并有效降低人工标注成本。

Conclusion: 主动标注方法为宫颈细胞分类提供了一种数据高效且成本效益高的解决方案，有望推动该领域的发展。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [59] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 论文提出了一种基于语义指导的对抗目标选择框架，利用预训练语言和视觉语言模型的跨模态知识转移，提高了攻击的成功率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击中的目标标签选择通常依赖于随机性、模型预测或静态语义资源，缺乏解释性和灵活性。

Method: 使用BERT、TinyLLAMA和CLIP等预训练模型作为相似性来源，选择与真实标签语义最相关和最不相关的标签，构建最佳和最差对抗场景。

Result: 实验表明，预训练模型能有效选择对抗目标，在远距离类别关系上优于静态语义资源（如WordNet）。

Conclusion: 预训练模型适用于构建可解释、标准化和可扩展的对抗基准测试。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [60] [HOID-R1: Reinforcement Learning for Open-World Human-Object Interaction Detection Reasoning with Multimodal Large Language Model](https://arxiv.org/abs/2508.11350)
*Zhenhao Zhang,Hanqing Wang,Xiangyu Zeng,Ziyu Cheng,Jiaxin Liu,Haoyu Yan,Zhirui Liu,Kaiyang Ji,Tianxiang Gui,Ke Hu,Kangyi Chen,Yahao Fan,Mokai Pan*

Main category: cs.CV

TL;DR: 本文介绍了HOID-R1框架，通过结合链式思维（CoT）引导的监督微调（SFT）和群体相对策略优化（GRPO）来解决开放词汇人机交互检测中的3D空间理解不足问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前开放词汇人机交互检测方法依赖大型语言模型但缺乏3D空间理解能力，HOID-R1旨在解决这一问题。

Method: HOID-R1结合了CoT引导的SFT和GRPO强化学习，并引入“MLLM作为裁判”机制以减少思维链推理中的幻觉。

Result: 实验显示HOID-R1在人机交互检测基准测试中表现领先，并在新场景开放世界泛化中优于现有方法。

Conclusion: HOID-R1通过多模态对齐和推理能力提升，成为人机交互检测领域的先进方法。

Abstract: Understanding and recognizing human-object interaction (HOI) is a pivotal
application in AR/VR and robotics. Recent open-vocabulary HOI detection
approaches depend exclusively on large language models for richer textual
prompts, neglecting their inherent 3D spatial understanding capabilities. To
address this shortcoming, we introduce HOID-R1, the first HOI detection
framework that integrates chain-of-thought (CoT) guided supervised fine-tuning
(SFT) with group relative policy optimization (GRPO) within a reinforcement
learning (RL) paradigm. Specifically, we initially apply SFT to imbue the model
with essential reasoning capabilities, forcing the model to articulate its
thought process in the output. Subsequently, we integrate GRPO to leverage
multi-reward signals for policy optimization, thereby enhancing alignment
across diverse modalities. To mitigate hallucinations in the CoT reasoning, we
introduce an "MLLM-as-a-judge" mechanism that supervises the CoT outputs,
further improving generalization. Extensive experiments show that HOID-R1
achieves state-of-the-art performance on HOI detection benchmarks and
outperforms existing methods in open-world generalization to novel scenarios.

</details>


### [61] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: RETFound是一个用于眼底相机和光学相干断层扫描图像的基座模型，首次被应用于视盘分割任务，并在多个数据集中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探索RETFound模型在视盘分割任务中的适用性，验证基座模型是否可替代任务特定架构。

Method: 通过微调头部网络，仅用少量任务特定样本训练，将RETFound模型应用于视盘分割。

Result: 在多个公开和私有数据集上达到约96%的Dice分数，性能优于现有最佳分割网络。

Conclusion: RETFound在视盘分割任务中表现出色，支持基座模型作为任务特定架构的替代方案。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [62] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: 本文对基于拓扑保持的损失函数（如SRL）在图像分割中的效果进行了理论和实证分析，发现其性能并未超越传统基准模型，为复杂管状结构的分割提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 研究拓扑保持损失函数（如SRL）在管状结构图像分割中的实际效果，验证其在基准数据集上的表现是否如宣称的那样优于传统方法。

Method: 通过理论分析SRL损失的梯度，并在多种管状数据集上进行实验，比较SRL与传统模型的性能。

Result: 实验表明，基于SRL的分割模型在性能上并未优于传统基准模型。

Conclusion: 拓扑保持损失函数（如SRL）在复杂管状结构分割中存在局限性，需进一步改进。

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [63] [Unified Knowledge Distillation Framework: Fine-Grained Alignment and Geometric Relationship Preservation for Deep Face Recognition](https://arxiv.org/abs/2508.11376)
*Durgesh Mishra,Rishabh Uikey*

Main category: cs.CV

TL;DR: 提出了一种结合实例级嵌入蒸馏和关系对相似性蒸馏的统一知识蒸馏框架，显著提升了轻量级人脸识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法难以同时捕捉细粒度实例细节和复杂关系结构，导致性能不佳。为此，提出了一种统一框架来解决这一问题。

Method: 提出了两种新损失函数：实例级嵌入蒸馏（动态硬挖掘策略）和关系对相似性蒸馏（记忆库机制和样本挖掘策略）。

Result: 在多个基准数据集上优于现有方法，甚至能使学生在某些情况下超越教师的准确率。

Conclusion: 统一框架通过同时优化实例级对齐和几何关系保留，实现了更全面的知识蒸馏。

Abstract: Knowledge Distillation is crucial for optimizing face recognition models for
deployment in computationally limited settings, such as edge devices.
Traditional KD methods, such as Raw L2 Feature Distillation or Feature
Consistency loss, often fail to capture both fine-grained instance-level
details and complex relational structures, leading to suboptimal performance.
We propose a unified approach that integrates two novel loss functions,
Instance-Level Embedding Distillation and Relation-Based Pairwise Similarity
Distillation. Instance-Level Embedding Distillation focuses on aligning
individual feature embeddings by leveraging a dynamic hard mining strategy,
thereby enhancing learning from challenging examples. Relation-Based Pairwise
Similarity Distillation captures relational information through pairwise
similarity relationships, employing a memory bank mechanism and a sample mining
strategy. This unified framework ensures both effective instance-level
alignment and preservation of geometric relationships between samples, leading
to a more comprehensive distillation process. Our unified framework outperforms
state-of-the-art distillation methods across multiple benchmark face
recognition datasets, as demonstrated by extensive experimental evaluations.
Interestingly, when using strong teacher networks compared to the student, our
unified KD enables the student to even surpass the teacher's accuracy.

</details>


### [64] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: G-CUT3R是一种新型的前馈方法，通过整合先验信息增强3D场景重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖输入图像，而G-CUT3R利用深度、相机校准等辅助数据来提高重建效果。

Method: 对CUT3R进行轻量级改进，为每种数据模态设计专用编码器，通过零卷积与RGB图像特征融合。

Result: 在多个基准测试中表现优异，显著提升了3D重建和其他多视图任务的性能。

Conclusion: G-CUT3R能灵活整合多种先验信息，兼容不同输入模态，效果显著。

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [65] [RMFAT: Recurrent Multi-scale Feature Atmospheric Turbulence Mitigator](https://arxiv.org/abs/2508.11409)
*Zhiming Liu,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: RMFAT是一种轻量级循环框架，通过减少输入帧数和多尺度特征编码，高效恢复因大气湍流而退化的视频质量，显著提升了清晰度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 大气湍流导致视频质量下降，现有方法计算成本高且难以实时应用，亟需高效解决方案。

Method: 采用循环框架，仅需两帧输入，结合多尺度特征编码和时间扭曲模块，提升细节和时间一致性。

Result: 在SSIM上提升近9%，运行时间减少四倍以上，实现高效实时恢复。

Conclusion: RMFAT在清晰度和速度上均优于现有方法，适合实时大气湍流抑制任务。

Abstract: Atmospheric turbulence severely degrades video quality by introducing
distortions such as geometric warping, blur, and temporal flickering, posing
significant challenges to both visual clarity and temporal consistency. Current
state-of-the-art methods are based on transformer and 3D architectures and
require multi-frame input, but their large computational cost and memory usage
limit real-time deployment, especially in resource-constrained scenarios. In
this work, we propose RMFAT: Recurrent Multi-scale Feature Atmospheric
Turbulence Mitigator, designed for efficient and temporally consistent video
restoration under AT conditions. RMFAT adopts a lightweight recurrent framework
that restores each frame using only two inputs at a time, significantly
reducing temporal window size and computational burden. It further integrates
multi-scale feature encoding and decoding with temporal warping modules at both
encoder and decoder stages to enhance spatial detail and temporal coherence.
Extensive experiments on synthetic and real-world atmospheric turbulence
datasets demonstrate that RMFAT not only outperforms existing methods in terms
of clarity restoration (with nearly a 9\% improvement in SSIM) but also
achieves significantly improved inference speed (more than a fourfold reduction
in runtime), making it particularly suitable for real-time atmospheric
turbulence suppression tasks.

</details>


### [66] [SelfAdapt: Unsupervised Domain Adaptation of Cell Segmentation Models](https://arxiv.org/abs/2508.11411)
*Fabian H. Reith,Jannik Franzen,Dinesh R. Palli,J. Lorenz Rumberger,Dagmar Kainmueller*

Main category: cs.CV

TL;DR: 提出了一种名为SelfAdapt的无标签自适应方法，用于改进预训练细胞分割模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有通用模型（如Cellpose）在跨域数据上性能下降，而监督微调需要标注数据，不总是可用。

Method: 基于师生增强一致性训练，结合L2-SP正则化和无标签停止准则。

Result: 在LiveCell和TissueNet数据集上，AP0.5相对提升29.64%优于基线Cellpose，且能进一步提升监督微调模型。

Conclusion: SelfAdapt作为一种简单扩展方法，有效解决了无标签适应问题，代码已开源。

Abstract: Deep neural networks have become the go-to method for biomedical instance
segmentation. Generalist models like Cellpose demonstrate state-of-the-art
performance across diverse cellular data, though their effectiveness often
degrades on domains that differ from their training data. While supervised
fine-tuning can address this limitation, it requires annotated data that may
not be readily available. We propose SelfAdapt, a method that enables the
adaptation of pre-trained cell segmentation models without the need for labels.
Our approach builds upon student-teacher augmentation consistency training,
introducing L2-SP regularization and label-free stopping criteria. We evaluate
our method on the LiveCell and TissueNet datasets, demonstrating relative
improvements in AP0.5 of up to 29.64% over baseline Cellpose. Additionally, we
show that our unsupervised adaptation can further improve models that were
previously fine-tuned with supervision. We release SelfAdapt as an easy-to-use
extension of the Cellpose framework. The code for our method is publicly
available at https: //github.com/Kainmueller-Lab/self_adapt.

</details>


### [67] [Training-free Dimensionality Reduction via Feature Truncation: Enhancing Efficiency in Privacy-preserving Multi-Biometric Systems](https://arxiv.org/abs/2508.11419)
*Florian Bayer,Maximilian Russo,Christian Rathgeb*

Main category: cs.CV

TL;DR: 通过多模态生物特征融合，模板大小可减少67%，同时保持与最佳单模态相当的识别性能。


<details>
  <summary>Details</summary>
Motivation: 生物识别中模板保护和计算效率是重要问题，多模态融合可提升安全性和效率。

Method: 利用深度神经网络提取特征，并对特征向量进行降维处理，结合同态加密技术。

Result: 实验显示多模态融合可显著减少模板大小，且不影响识别性能（EER不变）。

Conclusion: 多模态特征降维和同态加密结合，能高效保护生物模板安全且不影响识别准确性。

Abstract: Biometric recognition is widely used, making the privacy and security of
extracted templates a critical concern. Biometric Template Protection schemes,
especially those utilizing Homomorphic Encryption, introduce significant
computational challenges due to increased workload. Recent advances in deep
neural networks have enabled state-of-the-art feature extraction for face,
fingerprint, and iris modalities. The ubiquity and affordability of biometric
sensors further facilitate multi-modal fusion, which can enhance security by
combining features from different modalities. This work investigates the
biometric performance of reduced multi-biometric template sizes. Experiments
are conducted on an in-house virtual multi-biometric database, derived from
DNN-extracted features for face, fingerprint, and iris, using the FRGC, MCYT,
and CASIA databases. The evaluated approaches are (i) explainable and
straightforward to implement under encryption, (ii) training-free, and (iii)
capable of generalization. Dimensionality reduction of feature vectors leads to
fewer operations in the Homomorphic Encryption (HE) domain, enabling more
efficient encrypted processing while maintaining biometric accuracy and
security at a level equivalent to or exceeding single-biometric recognition.
Our results demonstrate that, by fusing feature vectors from multiple
modalities, template size can be reduced by 67 % with no loss in Equal Error
Rate (EER) compared to the best-performing single modality.

</details>


### [68] [ImagiDrive: A Unified Imagination-and-Planning Framework for Autonomous Driving](https://arxiv.org/abs/2508.11428)
*Jingyu Li,Bozhou Zhang,Xin Jin,Jiankang Deng,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: 提出了ImagiDrive框架，整合VLM和DWM以提升自动驾驶的预测和规划能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要结合上下文理解和预测推理，VLM和DWM各有优势但缺乏整合。

Method: 通过VLM-DWM联合框架，形成想象-规划循环，引入早期停止和轨迹选择策略。

Result: 在nuScenes和NAVSIM数据集上验证了优于现有方法的性能。

Conclusion: ImagiDrive为自动驾驶提供了一种高效的联合预测与规划方案。

Abstract: Autonomous driving requires rich contextual comprehension and precise
predictive reasoning to navigate dynamic and complex environments safely.
Vision-Language Models (VLMs) and Driving World Models (DWMs) have
independently emerged as powerful recipes addressing different aspects of this
challenge. VLMs provide interpretability and robust action prediction through
their ability to understand multi-modal context, while DWMs excel in generating
detailed and plausible future driving scenarios essential for proactive
planning. Integrating VLMs with DWMs is an intuitive, promising, yet
understudied strategy to exploit the complementary strengths of accurate
behavioral prediction and realistic scene generation. Nevertheless, this
integration presents notable challenges, particularly in effectively connecting
action-level decisions with high-fidelity pixel-level predictions and
maintaining computational efficiency. In this paper, we propose ImagiDrive, a
novel end-to-end autonomous driving framework that integrates a VLM-based
driving agent with a DWM-based scene imaginer to form a unified
imagination-and-planning loop. The driving agent predicts initial driving
trajectories based on multi-modal inputs, guiding the scene imaginer to
generate corresponding future scenarios. These imagined scenarios are
subsequently utilized to iteratively refine the driving agent's planning
decisions. To address efficiency and predictive accuracy challenges inherent in
this integration, we introduce an early stopping mechanism and a trajectory
selection strategy. Extensive experimental validation on the nuScenes and
NAVSIM datasets demonstrates the robustness and superiority of ImagiDrive over
previous alternatives under both open-loop and closed-loop conditions.

</details>


### [69] [Remove360: Benchmarking Residuals After Object Removal in 3D Gaussian Splatting](https://arxiv.org/abs/2508.11431)
*Simona Kocour,Assia Benbihi,Torsten Sattler*

Main category: cs.CV

TL;DR: 论文提出了一个新基准和评估框架，用于测量3D高斯泼溅中的对象移除后遗留的语义残余信息，并发布了Remove360数据集。研究发现当前方法在复杂场景中仍有局限性。


<details>
  <summary>Details</summary>
Motivation: 研究3D对象移除后遗留的语义信息对隐私保护和可编辑场景表示的重要性。

Method: 引入新基准和评估框架，使用Remove360数据集进行实验，评估对象移除后的语义残余情况。

Result: 当前方法在视觉几何缺失时仍能保留语义信息，但在复杂场景中表现有限。

Conclusion: 需要更鲁棒的解决方案来处理真实世界的复杂性。

Abstract: Understanding what semantic information persists after object removal is
critical for privacy-preserving 3D reconstruction and editable scene
representations. In this work, we introduce a novel benchmark and evaluation
framework to measure semantic residuals, the unintended semantic traces left
behind, after object removal in 3D Gaussian Splatting. We conduct experiments
across a diverse set of indoor and outdoor scenes, showing that current methods
can preserve semantic information despite the absence of visual geometry. We
also release Remove360, a dataset of pre/post-removal RGB images and
object-level masks captured in real-world environments. While prior datasets
have focused on isolated object instances, Remove360 covers a broader and more
complex range of indoor and outdoor scenes, enabling evaluation of object
removal in the context of full-scene representations. Given ground truth images
of a scene before and after object removal, we assess whether we can truly
eliminate semantic presence, and if downstream models can still infer what was
removed. Our findings reveal critical limitations in current 3D object removal
techniques and underscore the need for more robust solutions capable of
handling real-world complexity. The evaluation framework is available at
github.com/spatial-intelligence-ai/Remove360.git. Data are available at
huggingface.co/datasets/simkoc/Remove360.

</details>


### [70] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

TL;DR: 该研究针对16世纪拉丁手稿的识别问题，采用TrOCR模型，结合图像预处理和新型数据增强方法，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 解决历史手写文本识别中因稀缺转录、语言变体和多样书写风格导致的数字化难题。

Method: 应用TrOCR模型，设计四种针对历史手写特征的数据增强方法，并评估集成学习策略。

Result: 最佳单模型增强方法（Elastic）的字符错误率（CER）为1.86，集成方法降至1.60，相对改进显著。

Conclusion: 领域特定的数据增强和集成策略对提升历史手稿识别性能具有重要影响。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


### [71] [MM-R1: Unleashing the Power of Unified Multimodal Large Language Models for Personalized Image Generation](https://arxiv.org/abs/2508.11433)
*Qian Liang,Yujia Wu,Kuncheng Li,Jiwei Wei,Shiyuan He,Jinyu Guo,Ning Xie*

Main category: cs.CV

TL;DR: MM-R1框架通过跨模态Chain-of-Thought推理策略，实现了统一多模态大型语言模型在个性化图像生成中的应用，零样本生成高保真度图像。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs方法多为特定主题设计，需数据密集微调，扩展性受限。旨在解锁统一MLLMs在个性化图像生成中的潜力。

Method: 结合视觉推理与生成：1）通过用户图像及上下文线索理解主题；2）基于主题表征及用户提示生成图像。采用GRPO优化推理对齐。

Result: 实验显示MM-R1能零样本生成高主题保真度和文本对齐的个性化图像。

Conclusion: MM-R1为统一MLLMs的个性化图像生成提供了高效、可扩展的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) with unified architectures excel
across a wide range of vision-language tasks, yet aligning them with
personalized image generation remains a significant challenge. Existing methods
for MLLMs are frequently subject-specific, demanding a data-intensive
fine-tuning process for every new subject, which limits their scalability. In
this paper, we introduce MM-R1, a framework that integrates a cross-modal
Chain-of-Thought (X-CoT) reasoning strategy to unlock the inherent potential of
unified MLLMs for personalized image generation. Specifically, we structure
personalization as an integrated visual reasoning and generation process: (1)
grounding subject concepts by interpreting and understanding user-provided
images and contextual cues, and (2) generating personalized images conditioned
on both the extracted subject representations and user prompts. To further
enhance the reasoning capability, we adopt Grouped Reward Proximal Policy
Optimization (GRPO) to explicitly align the generation. Experiments demonstrate
that MM-R1 unleashes the personalization capability of unified MLLMs to
generate images with high subject fidelity and strong text alignment in a
zero-shot manner.

</details>


### [72] [An Efficient Medical Image Classification Method Based on a Lightweight Improved ConvNeXt-Tiny Architecture](https://arxiv.org/abs/2508.11532)
*Jingsong Xia,Yue Yin,Xiuhan Li*

Main category: cs.CV

TL;DR: 改进ConvNeXt-Tiny架构的医学图像分类方法，通过双全局池化和轻量级SEVector模块提升性能，资源受限环境下达到89.10%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决资源有限环境中高效高精度医学图像分类的难题。

Method: 改进ConvNeXt-Tiny架构，引入双全局池化特征融合策略和SEVector模块，结合特征平滑损失函数。

Result: 在CPU环境下，10个训练周期内测试集准确率最高达89.10%。

Conclusion: 为资源受限的医学图像分析提供高效可行解决方案。

Abstract: Intelligent analysis of medical imaging plays a crucial role in assisting
clinical diagnosis. However, achieving efficient and high-accuracy image
classification in resource-constrained computational environments remains
challenging. This study proposes a medical image classification method based on
an improved ConvNeXt-Tiny architecture. Through structural optimization and
loss function design, the proposed method enhances feature extraction
capability and classification performance while reducing computational
complexity. Specifically, the method introduces a dual global pooling (Global
Average Pooling and Global Max Pooling) feature fusion strategy into the
ConvNeXt-Tiny backbone to simultaneously preserve global statistical features
and salient response information. A lightweight channel attention module,
termed Squeeze-and-Excitation Vector (SEVector), is designed to improve the
adaptive allocation of channel weights while minimizing parameter overhead.
Additionally, a Feature Smoothing Loss is incorporated into the loss function
to enhance intra-class feature consistency and suppress intra-class variance.
Under CPU-only conditions (8 threads), the method achieves a maximum
classification accuracy of 89.10% on the test set within 10 training epochs,
exhibiting a stable convergence trend in loss values. Experimental results
demonstrate that the proposed method effectively improves medical image
classification performance in resource-limited settings, providing a feasible
and efficient solution for the deployment and promotion of medical imaging
analysis models.

</details>


### [73] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉输入的实时室内导航深度学习方法，避免了传统方案对GPS、特殊传感器或地图的依赖，并提供了大规模数据集和易用的安卓应用。


<details>
  <summary>Details</summary>
Motivation: 室内导航因GPS信号差而困难，现有方案因复杂性和额外需求难以部署，需要更高效且易用的解决方案。

Method: 采用基于视觉的深度学习，结合图路径生成、可解释数据增强和课程学习，简化数据收集和训练过程。

Result: 提出了一个大型商场视频数据集，每帧标注了目标方向，开发了安卓应用，无需特殊设备或网络。

Conclusion: 该方案高效、易部署，仅依赖视觉输入，为室内导航提供了新思路。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [74] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 本文提出了一种通过奖励引导解码来适应多模态大语言模型（MLLMs）的方法，用于改善其视觉基础，并在对象幻觉基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的广泛应用，适应多样化用户需求变得尤为重要。本文旨在通过可控解码来优化MLLMs的视觉基础能力。

Method: 构建了两个独立的奖励模型，分别控制对象精确度和召回率，并在解码过程中动态调整其权重，同时允许用户控制搜索的广度。

Result: 在标准对象幻觉基准测试中，该方法显著提升了MLLMs的可控性，并优于现有的幻觉缓解方法。

Conclusion: 本文的方法为MLLMs提供了动态可控的解码能力，有效提升了视觉基础的性能，同时展示了广泛的适用性。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [75] [Data-Driven Deepfake Image Detection Method -- The 2024 Global Deepfake Image Detection Challenge](https://arxiv.org/abs/2508.11464)
*Xiaoya Zhu,Yibing Nan,Shiguo Lian*

Main category: cs.CV

TL;DR: 该论文探讨了基于Swin Transformer V2-B分类网络的深度伪造图像检测方法，通过在线数据增强和离线样本生成技术提升模型泛化能力，并在竞赛中获奖。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，深度伪造技术成为双刃剑，既生成大量AI内容，也对数字安全构成挑战。研究旨在检测人脸图像是否为深度伪造图像并输出概率得分。

Method: 采用Swin Transformer V2-B分类网络，结合在线数据增强和离线样本生成方法，提升训练样本多样性和模型泛化能力。

Result: 在深度伪造图像检测竞赛中获得卓越奖。

Conclusion: 该方法有效提升了深度伪造图像检测的准确性，为数字安全领域提供了实用工具。

Abstract: With the rapid development of technology in the field of AI, deepfake
technology has emerged as a double-edged sword. It has not only created a large
amount of AI-generated content but also posed unprecedented challenges to
digital security. The task of the competition is to determine whether a face
image is a Deepfake image and output its probability score of being a Deepfake
image. In the image track competition, our approach is based on the Swin
Transformer V2-B classification network. And online data augmentation and
offline sample generation methods are employed to enrich the diversity of
training samples and increase the generalization ability of the model. Finally,
we got the award of excellence in Deepfake image detection.

</details>


### [76] [CoFi: A Fast Coarse-to-Fine Few-Shot Pipeline for Glomerular Basement Membrane Segmentation](https://arxiv.org/abs/2508.11469)
*Hongjin Fang,Daniel Reisenbüchler,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: CoFi是一种快速高效的粗到粗细分的少样本分割管道，用于电子显微镜图像中的肾小球基底膜（GBM）分割，减轻标注和计算负担，同时实现高精度分割。


<details>
  <summary>Details</summary>
Motivation: GBM的准确分割对肾脏疾病诊断至关重要，但传统深度学习方法依赖大量标注，临床实用性受限。少样本学习虽减轻标注负担，但难以捕捉细微结构细节。

Method: CoFi通过轻量级神经网络生成粗略分割掩码，再利用形态学修剪生成高质量点提示，指导SAM细化分割。

Result: CoFi的Dice系数达74.54%，推理速度为1.9 FPS，表现出色。

Conclusion: CoFi兼顾高效与精准，适合研究和临床应用，潜力巨大。

Abstract: Accurate segmentation of the glomerular basement membrane (GBM) in electron
microscopy (EM) images is fundamental for quantifying membrane thickness and
supporting the diagnosis of various kidney diseases. While supervised deep
learning approaches achieve high segmentation accuracy, their reliance on
extensive pixel-level annotation renders them impractical for clinical
workflows. Few-shot learning can reduce this annotation burden but often
struggles to capture the fine structural details necessary for GBM analysis. In
this study, we introduce CoFi, a fast and efficient coarse-to-fine few-shot
segmentation pipeline designed for GBM delineation in EM images. CoFi first
trains a lightweight neural network using only three annotated images to
produce an initial coarse segmentation mask. This mask is then automatically
processed to generate high-quality point prompts with morphology-aware pruning,
which are subsequently used to guide SAM in refining the segmentation. The
proposed method achieved exceptional GBM segmentation performance, with a Dice
coefficient of 74.54% and an inference speed of 1.9 FPS. We demonstrate that
CoFi not only alleviates the annotation and computational burdens associated
with conventional methods, but also achieves accurate and reliable segmentation
results. The pipeline's speed and annotation efficiency make it well-suited for
research and hold strong potential for clinical applications in renal
pathology. The pipeline is publicly available at:
https://github.com/ddrrnn123/CoFi.

</details>


### [77] [TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations](https://arxiv.org/abs/2508.11478)
*Xinyi Yin,Wenbo Yuan,Xuecheng Wu,Liangyu Fu,Danlei Huang*

Main category: cs.CV

TL;DR: TACR-YOLO 是一种新型实时框架，用于特殊场景下的异常行为检测，通过引入坐标注意力模块、任务感知注意力模块和强化颈部网络，提升了小目标检测、任务冲突处理和多尺度融合能力。


<details>
  <summary>Details</summary>
Motivation: 特殊场景下的异常行为检测需求日益增长，但现有 YOLO 方法在小目标检测、任务冲突和多尺度融合方面存在不足，需要改进。

Method: 提出 TACR-YOLO 框架，包括坐标注意力模块（提升小目标检测）、任务感知注意力模块（解决分类-回归冲突）、强化颈部网络（优化多尺度融合），并结合 K-means 聚类优化锚框及 DIoU-Loss。

Result: 在 PABD 数据集上达到 91.92% mAP，速度和鲁棒性表现优异。

Conclusion: TACR-YOLO 为特殊场景下的异常行为检测提供了新思路，推动了该领域的进展。

Abstract: Abnormal Human Behavior Detection (AHBD) under special scenarios is becoming
increasingly crucial. While YOLO-based detection methods excel in real-time
tasks, they remain hindered by challenges including small objects, task
conflicts, and multi-scale fusion in AHBD. To tackle them, we propose
TACR-YOLO, a new real-time framework for AHBD. We introduce a Coordinate
Attention Module to enhance small object detection, a Task-Aware Attention
Module to deal with classification-regression conflicts, and a Strengthen Neck
Network for refined multi-scale fusion, respectively. In addition, we optimize
Anchor Box sizes using K-means clustering and deploy DIoU-Loss to improve
bounding box regression. The Personnel Anomalous Behavior Detection (PABD)
dataset, which includes 8,529 samples across four behavior categories, is also
presented. Extensive experimental results indicate that TACR-YOLO achieves
91.92% mAP on PABD, with competitive speed and robustness. Ablation studies
highlight the contribution of each improvement. This work provides new insights
for abnormal behavior detection under special scenarios, advancing its
progress.

</details>


### [78] [OpenConstruction: A Systematic Synthesis of Open Visual Datasets for Data-Centric Artificial Intelligence in Construction Monitoring](https://arxiv.org/abs/2508.11482)
*Ruoxin Xiong,Yanyu Wang,Jiannan Cai,Kaijian Liu,Yuansheng Zhu,Pingbo Tang,Nora El-Gohary*

Main category: cs.CV

TL;DR: 论文探讨了建筑行业视觉数据集的重要性及其现状，提出了一种分类框架和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 建筑行业依赖视觉数据支持AI应用，但现有数据集在规模、质量和代表性上存在差异，缺乏系统性分类与分析。

Method: 通过系统检索学术数据库和开放数据平台，收集并分类了51个公开视觉数据集。

Result: 制定了OpenConstruction开放目录，提出了基于FAIR原则的未来数据基础设施路线图。

Conclusion: 研究为建筑行业数据驱动解决方案的发展提供了系统性支持和建议。

Abstract: The construction industry increasingly relies on visual data to support
Artificial Intelligence (AI) and Machine Learning (ML) applications for site
monitoring. High-quality, domain-specific datasets, comprising images, videos,
and point clouds, capture site geometry and spatiotemporal dynamics, including
the location and interaction of objects, workers, and materials. However,
despite growing interest in leveraging visual datasets, existing resources vary
widely in sizes, data modalities, annotation quality, and representativeness of
real-world construction conditions. A systematic review to categorize their
data characteristics and application contexts is still lacking, limiting the
community's ability to fully understand the dataset landscape, identify
critical gaps, and guide future directions toward more effective, reliable, and
scalable AI applications in construction. To address this gap, this study
conducts an extensive search of academic databases and open-data platforms,
yielding 51 publicly available visual datasets that span the 2005-2024 period.
These datasets are categorized using a structured data schema covering (i) data
fundamentals (e.g., size and license), (ii) data modalities (e.g., RGB and
point cloud), (iii) annotation frameworks (e.g., bounding boxes), and (iv)
downstream application domains (e.g., progress tracking). This study
synthesizes these findings into an open-source catalog, OpenConstruction,
supporting data-driven method development. Furthermore, the study discusses
several critical limitations in the existing construction dataset landscape and
presents a roadmap for future data infrastructure anchored in the Findability,
Accessibility, Interoperability, and Reusability (FAIR) principles. By
reviewing the current landscape and outlining strategic priorities, this study
supports the advancement of data-centric solutions in the construction sector.

</details>


### [79] [CineTrans: Learning to Generate Videos with Cinematic Transitions via Masked Diffusion Models](https://arxiv.org/abs/2508.11484)
*Xiaoxue Wu,Bingjie Gao,Yu Qiao,Yaohui Wang,Xinyuan Chen*

Main category: cs.CV

TL;DR: 本文提出CineTrans框架，用于生成具有电影风格过渡的多镜头视频，通过构建Cine250K数据集和改进扩散模型的注意力机制，显著提升了多镜头视频生成的质量和连贯性。


<details>
  <summary>Details</summary>
Motivation: 当前多镜头视频生成技术尚不成熟，生成的视频多为单镜头序列，过渡效果粗糙且不稳定。

Method: 构建Cine250K数据集，分析扩散模型注意力图与镜头边界的对应关系，设计基于掩码的控制机制以实现任意位置的过渡。

Result: 经过微调的CineTrans能生成电影风格的多镜头序列，避免了不稳定或简单的拼接。

Conclusion: 实验表明，CineTrans在所有评估标准上显著优于现有基线。

Abstract: Despite significant advances in video synthesis, research into multi-shot
video generation remains in its infancy. Even with scaled-up models and massive
datasets, the shot transition capabilities remain rudimentary and unstable,
largely confining generated videos to single-shot sequences. In this work, we
introduce CineTrans, a novel framework for generating coherent multi-shot
videos with cinematic, film-style transitions. To facilitate insights into the
film editing style, we construct a multi-shot video-text dataset Cine250K with
detailed shot annotations. Furthermore, our analysis of existing video
diffusion models uncovers a correspondence between attention maps in the
diffusion model and shot boundaries, which we leverage to design a mask-based
control mechanism that enables transitions at arbitrary positions and transfers
effectively in a training-free setting. After fine-tuning on our dataset with
the mask mechanism, CineTrans produces cinematic multi-shot sequences while
adhering to the film editing style, avoiding unstable transitions or naive
concatenations. Finally, we propose specialized evaluation metrics for
transition control, temporal consistency and overall quality, and demonstrate
through extensive experiments that CineTrans significantly outperforms existing
baselines across all criteria.

</details>


### [80] [Automated Building Heritage Assessment Using Street-Level Imagery](https://arxiv.org/abs/2508.11486)
*Kristina Dabrock,Tim Johansson,Anna Donarelli,Mikael Mangold,Noah Pflugradt,Jann Michael Weinand,Jochen Linßen*

Main category: cs.CV

TL;DR: 该研究使用GPT和机器学习模型识别建筑文化遗产价值，以支持能源效率改造。


<details>
  <summary>Details</summary>
Motivation: 通过AI工具提高文化遗产识别的效率，避免传统方法的高成本和耗时问题。

Method: 利用GPT从建筑立面图像中提取文化遗产特征，结合建筑登记数据训练机器学习模型。

Result: 模型验证显示，结合登记数据和GPT特征的F1得分为0.71，仅用GPT数据为0.60。

Conclusion: 该方法可提升数据库质量，支持兼顾文化遗产价值的大规模能源改造。

Abstract: Detailed data is required to quantify energy conservation measures in
buildings, such as envelop retrofits, without compromising cultural heritage.
Novel artificial intelligence tools may improve efficiency in identifying
heritage values in buildings compared to costly and time-consuming traditional
inventories. In this study, the large language model GPT was used to detect
various aspects of cultural heritage value in fa\c{c}ade images. Using this
data and building register data as features, machine learning models were
trained to classify multi-family and non-residential buildings in Stockholm,
Sweden. Validation against an expert-created inventory shows a macro F1-score
of 0.71 using a combination of register data and features retrieved from GPT,
and a score of 0.60 using only GPT-derived data. The presented methodology can
contribute to a higher-quality database and thus support careful energy
efficiency measures and integrated consideration of heritage value in
large-scale energetic refurbishment scenarios.

</details>


### [81] [Perception in Plan: Coupled Perception and Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.11488)
*Bozhou Zhang,Jingyu Li,Nan Song,Li Zhang*

Main category: cs.CV

TL;DR: VeteranAD提出了一种感知与规划耦合的端到端自动驾驶框架，通过将感知融入规划过程，实现了基于规划目标的定向感知，显著提升了规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶方法采用感知-规划分离的范式，限制了规划优化的潜力。VeteranAD旨在通过感知与规划的深度融合，提升自动驾驶行为的准确性和可靠性。

Method: VeteranAD通过多模锚定轨迹作为规划先验，设计感知模块收集相关交通元素，并采用自回归策略逐步预测未来轨迹，实现定向感知。

Result: 在NAVSIM和Bench2Drive数据集上的实验表明，VeteranAD达到了最先进的性能。

Conclusion: VeteranAD通过感知与规划的紧密耦合，释放了规划导向端到端方法的潜力，为自动驾驶提供了更优的解决方案。

Abstract: End-to-end autonomous driving has achieved remarkable advancements in recent
years. Existing methods primarily follow a perception-planning paradigm, where
perception and planning are executed sequentially within a fully differentiable
framework for planning-oriented optimization. We further advance this paradigm
through a perception-in-plan framework design, which integrates perception into
the planning process. This design facilitates targeted perception guided by
evolving planning objectives over time, ultimately enhancing planning
performance. Building on this insight, we introduce VeteranAD, a coupled
perception and planning framework for end-to-end autonomous driving. By
incorporating multi-mode anchored trajectories as planning priors, the
perception module is specifically designed to gather traffic elements along
these trajectories, enabling comprehensive and targeted perception. Planning
trajectories are then generated based on both the perception results and the
planning priors. To make perception fully serve planning, we adopt an
autoregressive strategy that progressively predicts future trajectories while
focusing on relevant regions for targeted perception at each step. With this
simple yet effective design, VeteranAD fully unleashes the potential of
planning-oriented end-to-end methods, leading to more accurate and reliable
driving behavior. Extensive experiments on the NAVSIM and Bench2Drive datasets
demonstrate that our VeteranAD achieves state-of-the-art performance.

</details>


### [82] [Hierarchical Graph Feature Enhancement with Adaptive Frequency Modulation for Visual Recognition](https://arxiv.org/abs/2508.11497)
*Feiyue Zhao,Zhichao Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为HGFE的新框架，通过将图推理结合到CNN中，增强结构感知和特征表示。


<details>
  <summary>Details</summary>
Motivation: 传统的CNN依赖规则网格结构，难以建模复杂的拓扑关系和非局部语义。

Method: HGFE构建了局部和全局图结构，并引入自适应频率调制模块。

Result: 实验表明HGFE在多个任务上提高了结构表示和整体性能。

Conclusion: HGFE是一种轻量级、端到端可训练的方法，可无缝集成到标准CNN中。

Abstract: Convolutional neural networks (CNNs) have
  demonstrated strong performance in visual recognition tasks,
  but their inherent reliance on regular grid structures limits
  their capacity to model complex topological relationships and
  non-local semantics within images. To address this limita tion, we propose
the hierarchical graph feature enhancement
  (HGFE), a novel framework that integrates graph-based rea soning into CNNs to
enhance both structural awareness and
  feature representation. HGFE builds two complementary levels
  of graph structures: intra-window graph convolution to cap ture local spatial
dependencies and inter-window supernode
  interactions to model global semantic relationships. Moreover,
  we introduce an adaptive frequency modulation module that
  dynamically balances low-frequency and high-frequency signal
  propagation, preserving critical edge and texture information
  while mitigating over-smoothing. The proposed HGFE module
  is lightweight, end-to-end trainable, and can be seamlessly
  integrated into standard CNN backbone networks. Extensive
  experiments on CIFAR-100 (classification), PASCAL VOC,
  and VisDrone (detection), as well as CrackSeg and CarParts
  (segmentation), validated the effectiveness of the HGFE in
  improving structural representation and enhancing overall
  recognition performance.

</details>


### [83] [AIM: Amending Inherent Interpretability via Self-Supervised Masking](https://arxiv.org/abs/2508.11502)
*Eyad Alshami,Shashank Agnihotri,Bernt Schiele,Margret Keuper*

Main category: cs.CV

TL;DR: AIM是一种自监督掩码方法，通过促进DNN使用真实特征而非虚假特征，提升模型的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决DNN中真实特征与虚假特征共存的问题，无需额外标注即可提升模型可解释性和泛化能力。

Method: AIM通过多阶段编码特征引导自监督的样本特定掩码过程，利用真实特征训练模型。

Result: 在多种数据集（如ImageNet100和CUB-200）上验证，AIM显著提升EPG分数和准确率。

Conclusion: AIM能有效促进真实特征的使用，提升模型的可解释性和泛化性能，具有广泛适用性。

Abstract: It has been observed that deep neural networks (DNNs) often use both genuine
as well as spurious features. In this work, we propose "Amending Inherent
Interpretability via Self-Supervised Masking" (AIM), a simple yet interestingly
effective method that promotes the network's utilization of genuine features
over spurious alternatives without requiring additional annotations. In
particular, AIM uses features at multiple encoding stages to guide a
self-supervised, sample-specific feature-masking process. As a result, AIM
enables the training of well-performing and inherently interpretable models
that faithfully summarize the decision process. We validate AIM across a
diverse range of challenging datasets that test both out-of-distribution
generalization and fine-grained visual understanding. These include
general-purpose classification benchmarks such as ImageNet100, HardImageNet,
and ImageWoof, as well as fine-grained classification datasets such as
Waterbirds, TravelingBirds, and CUB-200. AIM demonstrates significant dual
benefits: interpretability improvements, as measured by the Energy Pointing
Game (EPG) score, and accuracy gains over strong baselines. These consistent
gains across domains and architectures provide compelling evidence that AIM
promotes the use of genuine and meaningful features that directly contribute to
improved generalization and human-aligned interpretability.

</details>


### [84] [A Real-time Concrete Crack Detection and Segmentation Model Based on YOLOv11](https://arxiv.org/abs/2508.11517)
*Shaoze Huang,Qi Liu,Chao Chen,Yuhang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于YOLOv11n架构的多任务混凝土裂缝检测与分割模型YOLOv11-KW-TA-FP，通过动态KernelWarehouse卷积、三重注意力机制和FP-IoU损失函数优化，显著提升了检测性能，具有实际工程价值。


<details>
  <summary>Details</summary>
Motivation: 快速发展的长江三角洲地区基础设施老化问题严重，传统人工检测效率低下，现有深度学习模型对小目标裂缝检测效果欠佳，亟需高效解决方案。

Method: 提出YOLOv11-KW-TA-FP模型，包含动态KernelWarehouse卷积增强特征表示、三重注意力机制强化通道-空间交互建模、FP-IoU损失函数优化边界框回归。

Result: 实验结果表明，优化后的模型性能显著提升，达到91.3%精确率、76.6%召回率和86.4% mAP@50，且在数据稀缺和噪声干扰下表现稳定。

Conclusion: 该研究为自动化基础设施检测提供了高效的计算机视觉解决方案，具有重要工程应用价值。

Abstract: Accelerated aging of transportation infrastructure in the rapidly developing
Yangtze River Delta region necessitates efficient concrete crack detection, as
crack deterioration critically compromises structural integrity and regional
economic growth. To overcome the limitations of inefficient manual inspection
and the suboptimal performance of existing deep learning models, particularly
for small-target crack detection within complex backgrounds, this paper
proposes YOLOv11-KW-TA-FP, a multi-task concrete crack detection and
segmentation model based on the YOLOv11n architecture. The proposed model
integrates a three-stage optimization framework: (1) Embedding dynamic
KernelWarehouse convolution (KWConv) within the backbone network to enhance
feature representation through a dynamic kernel sharing mechanism; (2)
Incorporating a triple attention mechanism (TA) into the feature pyramid to
strengthen channel-spatial interaction modeling; and (3) Designing an FP-IoU
loss function to facilitate adaptive bounding box regression penalization.
Experimental validation demonstrates that the enhanced model achieves
significant performance improvements over the baseline, attaining 91.3%
precision, 76.6% recall, and 86.4% mAP@50. Ablation studies confirm the
synergistic efficacy of the proposed modules. Furthermore, robustness tests
indicate stable performance under conditions of data scarcity and noise
interference. This research delivers an efficient computer vision solution for
automated infrastructure inspection, exhibiting substantial practical
engineering value.

</details>


### [85] [Multi-State Tracker: Enhancing Efficient Object Tracking via Multi-State Specialization and Interaction](https://arxiv.org/abs/2508.11531)
*Shilei Wang,Gong Cheng,Pujian Lai,Dong Gao,Junwei Han*

Main category: cs.CV

TL;DR: 提出了一种多状态跟踪器（MST），通过轻量级的状态增强模块（SSE）和跨状态交互（CSI）提升了特征表示能力，同时保持了低计算开销，显著提高了跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统高效跟踪器通过降低计算复杂度和模型参数牺牲了特征表示能力，限制了其在复杂环境中的跟踪准确性。

Method: MST采用多状态生成（MSG）产生多阶段特征，通过SSE模块增强目标特征，并利用CSI模块交互和整合多状态信息，采用轻量化的HSA-SSD设计。

Result: MST在多个数据集上优于所有现有高效跟踪器，跟踪准确性和鲁棒性显著提升，AO得分在GOT-10K数据集上提高了4.5%。

Conclusion: MST通过高效的特征增强和交互机制，显著提升了跟踪性能，且计算开销极低，适用于复杂环境。

Abstract: Efficient trackers achieve faster runtime by reducing computational
complexity and model parameters. However, this efficiency often compromises the
expense of weakened feature representation capacity, thus limiting their
ability to accurately capture target states using single-layer features. To
overcome this limitation, we propose Multi-State Tracker (MST), which utilizes
highly lightweight state-specific enhancement (SSE) to perform specialized
enhancement on multi-state features produced by multi-state generation (MSG)
and aggregates them in an interactive and adaptive manner using cross-state
interaction (CSI). This design greatly enhances feature representation while
incurring minimal computational overhead, leading to improved tracking
robustness in complex environments. Specifically, the MSG generates multiple
state representations at multiple stages during feature extraction, while SSE
refines them to highlight target-specific features. The CSI module facilitates
information exchange between these states and ensures the integration of
complementary features. Notably, the introduced SSE and CSI modules adopt a
highly lightweight hidden state adaptation-based state space duality (HSA-SSD)
design, incurring only 0.1 GFLOPs in computation and 0.66 M in parameters.
Experimental results demonstrate that MST outperforms all previous efficient
trackers across multiple datasets, significantly improving tracking accuracy
and robustness. In particular, it shows excellent runtime performance, with an
AO score improvement of 4.5\% over the previous SOTA efficient tracker HCAT on
the GOT-10K dataset. The code is available at https://github.com/wsumel/MST.

</details>


### [86] [Reinforcing Video Reasoning Segmentation to Think Before It Segments](https://arxiv.org/abs/2508.11538)
*Sitong Gong,Lu Zhang,Yunzhi Zhuge,Xu Jia,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Veason-R1的视频推理分割模型，通过结构化推理和强化学习优化，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频推理分割方法因缺乏时空推理能力和解释性不足而表现不佳。

Method: Veason-R1结合了Group Relative Policy Optimization（GRPO）和Chain-of-Thought（CoT）初始化，通过结构化推理轨迹和奖励机制优化推理链条。

Result: 模型在多个基准测试中取得最优性能（如ReVOS提升1.3 J&F，ReasonVOS提升10.0 J&F），且对幻觉现象更具鲁棒性（+8.8 R）。

Conclusion: Veason-R1通过强化学习的结构化推理显著提升了视频推理分割的性能和鲁棒性。

Abstract: Video reasoning segmentation (VRS) endeavors to delineate referred objects in
videos guided by implicit instructions that encapsulate human intent and
temporal logic. Previous approaches leverage large vision language models
(LVLMs) to encode object semantics into <SEG> tokens for mask prediction.
However, this paradigm suffers from limited interpretability during inference
and suboptimal performance due to inadequate spatiotemporal reasoning. Drawing
inspiration from seminal breakthroughs in reinforcement learning, we introduce
Veason-R1, a specialized LVLM for VRS that emphasizes structured reasoning in
segmentation. Veason-R1 is trained through Group Relative Policy Optimization
(GRPO) augmented with Chain-of-Thought (CoT) initialization. To begin with, we
curate high-quality CoT training data to instill structured reasoning
trajectories, bridging video-level semantics and frame-level spatial grounding,
yielding the supervised fine-tuned model Veason-SFT. Subsequently, GRPO
fine-tuning encourages efficient exploration of the reasoning space by
optimizing reasoning chains. To this end, we incorporate a holistic reward
mechanism that synergistically enhances spatial alignment and temporal
consistency, bolstering keyframe localization and fine-grained grounding.
Comprehensive empirical evaluations demonstrate that Veason-R1 achieves
state-of-the-art performance on multiple benchmarks, surpassing prior art by
significant margins (e.g., +1.3 J &F in ReVOS and +10.0 J &F in ReasonVOS),
while exhibiting robustness to hallucinations (+8.8 R). Our code and model
weights will be available at Veason-R1.

</details>


### [87] [Training-Free Anomaly Generation via Dual-Attention Enhancement in Diffusion Model](https://arxiv.org/abs/2508.11550)
*Zuo Zuo,Jiahao Dong,Yanyun Qu,Zongze Wu*

Main category: cs.CV

TL;DR: 提出了一种无需训练的异常生成框架AAG，基于Stable Diffusion，通过改进的交叉注意力和自注意力机制生成高质量异常图像，提升下游异常检测任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决工业异常检测中数据稀缺问题，现有方法存在保真度不足或需额外训练的问题。

Method: AAG框架结合Stable Diffusion，引入交叉注意力增强（CAE）和自注意力增强（SAE），通过文本提示和掩码生成逼真异常。

Result: 在MVTec AD和VisA数据集上验证了AAG的有效性，生成图像能提升异常检测任务表现。

Conclusion: AAG为数据稀缺问题提供了高效解决方案，生成的异常图像对下游任务有实际帮助。

Abstract: Industrial anomaly detection (AD) plays a significant role in manufacturing
where a long-standing challenge is data scarcity. A growing body of works have
emerged to address insufficient anomaly data via anomaly generation. However,
these anomaly generation methods suffer from lack of fidelity or need to be
trained with extra data. To this end, we propose a training-free anomaly
generation framework dubbed AAG, which is based on Stable Diffusion (SD)'s
strong generation ability for effective anomaly image generation. Given a
normal image, mask and a simple text prompt, AAG can generate realistic and
natural anomalies in the specific regions and simultaneously keep contents in
other regions unchanged. In particular, we propose Cross-Attention Enhancement
(CAE) to re-engineer the cross-attention mechanism within Stable Diffusion
based on the given mask. CAE increases the similarity between visual tokens in
specific regions and text embeddings, which guides these generated visual
tokens in accordance with the text description. Besides, generated anomalies
need to be more natural and plausible with object in given image. We propose
Self-Attention Enhancement (SAE) which improves similarity between each normal
visual token and anomaly visual tokens. SAE ensures that generated anomalies
are coherent with original pattern. Extensive experiments on MVTec AD and VisA
datasets demonstrate effectiveness of AAG in anomaly generation and its
utility. Furthermore, anomaly images generated by AAG can bolster performance
of various downstream anomaly inspection tasks.

</details>


### [88] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

TL;DR: TrajSV是一种基于轨迹的运动分析框架，通过数据预处理、CRNet和VRNet组件，解决了数据不可用、缺乏有效轨迹框架和标签不足的问题，在运动视频检索、动作识别和视频字幕任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决运动分析领域中的数据不可用、缺乏轨迹框架和标签不足等问题，提出一种高效的轨迹驱动方法。

Method: TrajSV框架包含数据预处理、CRNet（轨迹增强Transformer模块）和VRNet（编码器-解码器架构），并引入三重对比损失进行无监督优化。

Result: 在足球、篮球和排球三种运动视频数据集中，TrajSV在检索任务上提升70%，动作识别任务在17类中9类领先，视频字幕任务提升20%。

Conclusion: TrajSV在运动视频分析中表现出色，并通过部署系统验证了其实际应用价值。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [89] [Causality Matters: How Temporal Information Emerges in Video Language Models](https://arxiv.org/abs/2508.11576)
*Yumeng Shi,Quanyu Long,Yin Wu,Wenya Wang*

Main category: cs.CV

TL;DR: 研究发现，视频语言模型中时间理解的关键在于帧间注意力而非位置编码，并提出两种效率优化策略。


<details>
  <summary>Details</summary>
Motivation: 探索视频语言模型中时间理解的机制，尤其是如何通过注意力机制编码时间结构。

Method: 通过分析实验揭示时间信息的传递路径，并提出分阶段跨模态注意力和时间退出机制以优化效率。

Result: 实验在两大基准测试中验证了所提策略的有效性，证明时间理解主要依赖于帧间注意力。

Conclusion: 研究为视频语言模型的时间理解提供了新见解，并提出高效优化方法。

Abstract: Video language models (VideoLMs) have made significant progress in multimodal
understanding. However, temporal understanding, which involves identifying
event order, duration, and relationships across time, still remains a core
challenge. Prior works emphasize positional encodings (PEs) as a key mechanism
for encoding temporal structure. Surprisingly, we find that removing or
modifying PEs in video inputs yields minimal degradation in the performance of
temporal understanding. In contrast, reversing the frame sequence while
preserving the original PEs causes a substantial drop. To explain this
behavior, we conduct substantial analysis experiments to trace how temporal
information is integrated within the model. We uncover a causal information
pathway: temporal cues are progressively synthesized through inter-frame
attention, aggregated in the final frame, and subsequently integrated into the
query tokens. This emergent mechanism shows that temporal reasoning emerges
from inter-visual token interactions under the constraints of causal attention,
which implicitly encodes temporal structure. Based on these insights, we
propose two efficiency-oriented strategies: staged cross-modal attention and a
temporal exit mechanism for early token truncation. Experiments on two
benchmarks validate the effectiveness of both approaches. To the best of our
knowledge, this is the first work to systematically investigate video temporal
understanding in VideoLMs, offering insights for future model improvement.

</details>


### [90] [DashCam Video: A complementary low-cost data stream for on-demand forest-infrastructure system monitoring](https://arxiv.org/abs/2508.11591)
*Durga Joshi,Chandi Witharana,Robert Fahey,Thomas Worthley,Zhe Zhu,Diego Cerrai*

Main category: cs.CV

TL;DR: 论文提出了一种基于普通车载摄像头的低成本、可重复的框架，用于实时评估和地理定位路边植被和基础设施。通过深度估计、误差校正和几何三角测量，生成准确的空间和结构数据。


<details>
  <summary>Details</summary>
Motivation: 传统遥感方法（如LiDAR）成本高且不易实时更新。本研究旨在利用普通车载摄像头数据，提供一种快速、实时且低成本的对象级监测方案。

Method: 结合单目深度估计、深度误差校正和几何三角测量，构建端到端管道。深度图通过梯度提升回归框架校正，再基于GPS三角测量和相机几何计算对象位置和高度。

Result: 方法在低速车辆和内部摄像头条件下表现最佳，平均地理定位误差2.83米，树木和高杆的高度估计误差分别为2.09米和0.88米。

Conclusion: 该框架为城市植被和基础设施监测提供了实时、低成本且可扩展的解决方案，适合公用事业公司和城市规划者使用。

Abstract: Our study introduces a novel, low-cost, and reproducible framework for
real-time, object-level structural assessment and geolocation of roadside
vegetation and infrastructure with commonly available but underutilized
dashboard camera (dashcam) video data. We developed an end-to-end pipeline that
combines monocular depth estimation, depth error correction, and geometric
triangulation to generate accurate spatial and structural data from
street-level video streams from vehicle-mounted dashcams. Depth maps were first
estimated using a state-of-the-art monocular depth model, then refined via a
gradient-boosted regression framework to correct underestimations, particularly
for distant objects. The depth correction model achieved strong predictive
performance (R2 = 0.92, MAE = 0.31 on transformed scale), significantly
reducing bias beyond 15 m. Further, object locations were estimated using
GPS-based triangulation, while object heights were calculated using pin hole
camera geometry. Our method was evaluated under varying conditions of camera
placement and vehicle speed. Low-speed vehicle with inside camera gave the
highest accuracy, with mean geolocation error of 2.83 m, and mean absolute
error (MAE) in height estimation of 2.09 m for trees and 0.88 m for poles. To
the best of our knowledge, it is the first framework to combine monocular depth
modeling, triangulated GPS-based geolocation, and real-time structural
assessment for urban vegetation and infrastructure using consumer-grade video
data. Our approach complements conventional RS methods, such as LiDAR and image
by offering a fast, real-time, and cost-effective solution for object-level
monitoring of vegetation risks and infrastructure exposure, making it
especially valuable for utility companies, and urban planners aiming for
scalable and frequent assessments in dynamic urban environments.

</details>


### [91] [CoreEditor: Consistent 3D Editing via Correspondence-constrained Diffusion](https://arxiv.org/abs/2508.11603)
*Zhe Zhu,Honghua Chen,Peng Li,Mingqiang Wei*

Main category: cs.CV

TL;DR: CoreEditor通过引入对应约束注意力机制和语义相似性，显著提升了文本驱动的3D编辑质量和多视图一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本驱动的3D编辑中缺乏对多视图信息交换的显式控制，导致编辑不足和细节模糊。

Method: CoreEditor采用对应约束注意力机制，结合几何对齐和语义相似性，确保多视图一致性，并提供选择性编辑管道。

Result: 实验表明，CoreEditor能够生成高质量、3D一致的编辑结果，细节更清晰，优于现有方法。

Conclusion: CoreEditor通过新技术提升了3D编辑的准确性和用户体验。

Abstract: Text-driven 3D editing seeks to modify 3D scenes according to textual
descriptions, and most existing approaches tackle this by adapting pre-trained
2D image editors to multi-view inputs. However, without explicit control over
multi-view information exchange, they often fail to maintain cross-view
consistency, leading to insufficient edits and blurry details. We introduce
CoreEditor, a novel framework for consistent text-to-3D editing. The key
innovation is a correspondence-constrained attention mechanism that enforces
precise interactions between pixels expected to remain consistent throughout
the diffusion denoising process. Beyond relying solely on geometric alignment,
we further incorporate semantic similarity estimated during denoising, enabling
more reliable correspondence modeling and robust multi-view editing. In
addition, we design a selective editing pipeline that allows users to choose
preferred results from multiple candidates, offering greater flexibility and
user control. Extensive experiments show that CoreEditor produces high-quality,
3D-consistent edits with sharper details, significantly outperforming prior
methods.

</details>


### [92] [LoRAtorio: An intrinsic approach to LoRA Skill Composition](https://arxiv.org/abs/2508.11624)
*Niki Foteinopoulou,Ignas Budvytis,Stephan Liwicki*

Main category: cs.CV

TL;DR: LoRAtorio是一个创新的无训练框架，通过利用内在模型行为实现多LoRA适配器的有效组合，解决了现有方法在开放环境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA适配器在多任务组合中表现不佳，尤其是在开放环境中。

Method: 利用LoRA输出与基础模型的差异，通过潜在空间分区和余弦相似性构建空间感知权重矩阵，结合分类器无指导方法。

Result: LoRAtorio在ClipScore上提升1.3%，GPT-4V评估获胜率达72.43%，并在多种潜在扩散模型中表现良好。

Conclusion: LoRAtorio展示了在多LoRA组合任务中的卓越性能和泛化能力。

Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted technique in
text-to-image diffusion models, enabling the personalisation of visual concepts
such as characters, styles, and objects. However, existing approaches struggle
to effectively compose multiple LoRA adapters, particularly in open-ended
settings where the number and nature of required skills are not known in
advance. In this work, we present LoRAtorio, a novel train-free framework for
multi-LoRA composition that leverages intrinsic model behaviour. Our method is
motivated by two key observations: (1) LoRA adapters trained on narrow domains
produce denoised outputs that diverge from the base model, and (2) when
operating out-of-distribution, LoRA outputs show behaviour closer to the base
model than when conditioned in distribution. The balance between these two
observations allows for exceptional performance in the single LoRA scenario,
which nevertheless deteriorates when multiple LoRAs are loaded. Our method
operates in the latent space by dividing it into spatial patches and computing
cosine similarity between each patch's predicted noise and that of the base
model. These similarities are used to construct a spatially-aware weight
matrix, which guides a weighted aggregation of LoRA outputs. To address domain
drift, we further propose a modification to classifier-free guidance that
incorporates the base model's unconditional score into the composition. We
extend this formulation to a dynamic module selection setting, enabling
inference-time selection of relevant LoRA adapters from a large pool. LoRAtorio
achieves state-of-the-art performance, showing up to a 1.3% improvement in
ClipScore and a 72.43% win rate in GPT-4V pairwise evaluations, and generalises
effectively to multiple latent diffusion models.

</details>


### [93] [Is ChatGPT-5 Ready for Mammogram VQA?](https://arxiv.org/abs/2508.11628)
*Qiang Li,Shansong Wang,Mingzhe Hu,Mojtaba Safari,Zachary Eidex,Xiaofeng Yang*

Main category: cs.CV

TL;DR: GPT-5在乳腺X光视觉问答任务中表现优异，但仍不及人类专家和领域专用模型，临床应用中需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-5和GPT-4o在乳腺癌筛查中的潜力，尤其是BI-RADS评估、异常检测和恶性分类任务。

Method: 在四个公开乳腺X光数据集（EMBED、InBreast、CMMD、CBIS-DDSM）上测试GPT-5和GPT-4o的性能。

Result: GPT-5在各任务中优于GPT-4o但落后于人类专家，表现因任务和数据集而异，敏感性和特异性较低。

Conclusion: GPT-5展现了潜力和进步趋势，但需领域适配和优化以胜任高风险临床应用。

Abstract: Mammogram visual question answering (VQA) integrates image interpretation
with clinical reasoning and has potential to support breast cancer screening.
We systematically evaluated the GPT-5 family and GPT-4o model on four public
mammography datasets (EMBED, InBreast, CMMD, CBIS-DDSM) for BI-RADS assessment,
abnormality detection, and malignancy classification tasks. GPT-5 consistently
was the best performing model but lagged behind both human experts and
domain-specific fine-tuned models. On EMBED, GPT-5 achieved the highest scores
among GPT variants in density (56.8%), distortion (52.5%), mass (64.5%),
calcification (63.5%), and malignancy (52.8%) classification. On InBreast, it
attained 36.9% BI-RADS accuracy, 45.9% abnormality detection, and 35.0%
malignancy classification. On CMMD, GPT-5 reached 32.3% abnormality detection
and 55.0% malignancy accuracy. On CBIS-DDSM, it achieved 69.3% BI-RADS
accuracy, 66.0% abnormality detection, and 58.2% malignancy accuracy. Compared
with human expert estimations, GPT-5 exhibited lower sensitivity (63.5%) and
specificity (52.3%). While GPT-5 exhibits promising capabilities for screening
tasks, its performance remains insufficient for high-stakes clinical imaging
applications without targeted domain adaptation and optimization. However, the
tremendous improvements in performance from GPT-4o to GPT-5 show a promising
trend in the potential for general large language models (LLMs) to assist with
mammography VQA tasks.

</details>


### [94] [Thyme: Think Beyond Images](https://arxiv.org/abs/2508.11630)
*Yi-Fan Zhang,Xingyu Lu,Shukang Yin,Chaoyou Fu,Wei Chen,Xiao Hu,Bin Wen,Kaiyu Jiang,Changyi Liu,Tianke Zhang,Haonan Fan,Kaibing Chen,Jiankang Chen,Haojie Ding,Kaiyu Tang,Zhang Zhang,Liang Wang,Fan Yang,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: 本文提出了Thyme框架，通过生成和执行代码来增强多模态大语言模型（MLLMs）的图像处理和逻辑推理能力，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型在图像处理和逻辑推理方面的功能不及专有模型（O3），因此需要一种新方法来丰富功能并提升自主性。

Method: 提出Thyme框架，采用两阶段训练策略（SFT和RL），结合GRPO-ATS算法，平衡代码生成和推理探索。

Result: 在近20个基准测试中，Thyme在感知和复杂推理任务中表现优异。

Conclusion: Thyme通过代码生成和执行显著提升了MLLMs的性能，为未来研究提供了新方向。

Abstract: Following OpenAI's introduction of the ``thinking with images'' concept,
recent efforts have explored stimulating the use of visual information in the
reasoning process to enhance model performance in perception and reasoning
tasks. However, to the best of our knowledge, no open-source work currently
offers a feature set as rich as proprietary models (O3), which can perform
diverse image manipulations and simultaneously enhance logical reasoning
capabilities through code. In this paper, we make a preliminary attempt in this
direction by introducing Thyme (Think Beyond Images), a novel paradigm for
enabling MLLMs to transcend existing ``think with images'' approaches by
autonomously generating and executing diverse image processing and
computational operations via executable code. This approach not only
facilitates a rich, on-the-fly set of image manipulations (e.g., cropping,
rotation, contrast enhancement) but also allows for mathematical computations,
all while maintaining high autonomy in deciding when and how to apply these
operations. We activate this capability through a two-stage training strategy:
an initial SFT on a curated dataset of 500K samples to teach code generation,
followed by a RL phase to refine decision-making. For the RL stage, we manually
collect and design high-resolution question-answer pairs to increase the
learning difficulty, and we propose GRPO-ATS (Group Relative Policy
Optimization with Adaptive Temperature Sampling), an algorithm that applies
distinct temperatures to text and code generation to balance reasoning
exploration with code execution precision. We conduct extensive experimental
analysis and ablation studies. Comprehensive evaluations on nearly 20
benchmarks show that Thyme yields significant and consistent performance gains,
particularly in challenging high-resolution perception and complex reasoning
tasks.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [95] [Failures to Surface Harmful Contents in Video Large Language Models](https://arxiv.org/abs/2508.10974)
*Yuxin Cao,Wei Song,Derui Wang,Jingling Xue,Jin Song Dong*

Main category: cs.MM

TL;DR: 当前视频大语言模型（VideoLLMs）在生成视频摘要时可能忽略有害内容，存在安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 揭示VideoLLMs在生成摘要时忽略有害内容的设计缺陷，并提出改进需求。

Method: 通过根因分析发现三个设计缺陷，并提出三种零查询黑盒攻击方法进行验证。

Result: 实验表明，主流VideoLLMs在90%以上的情况下会忽略有害内容。

Conclusion: VideoLLMs需改进采样策略、令牌压缩和解码机制以确保语义覆盖，而不仅是速度。

Abstract: Video Large Language Models (VideoLLMs) are increasingly deployed on numerous
critical applications, where users rely on auto-generated summaries while
casually skimming the video stream. We show that this interaction hides a
critical safety gap: if harmful content is embedded in a video, either as
full-frame inserts or as small corner patches, state-of-the-art VideoLLMs
rarely mention the harmful content in the output, despite its clear visibility
to human viewers. A root-cause analysis reveals three compounding design flaws:
(1) insufficient temporal coverage resulting from the sparse, uniformly spaced
frame sampling used by most leading VideoLLMs, (2) spatial information loss
introduced by aggressive token downsampling within sampled frames, and (3)
encoder-decoder disconnection, whereby visual cues are only weakly utilized
during text generation. Leveraging these insights, we craft three zero-query
black-box attacks, aligning with these flaws in the processing pipeline. Our
large-scale evaluation across five leading VideoLLMs shows that the harmfulness
omission rate exceeds 90% in most cases. Even when harmful content is clearly
present in all frames, these models consistently fail to identify it. These
results underscore a fundamental vulnerability in current VideoLLMs' designs
and highlight the urgent need for sampling strategies, token compression, and
decoding mechanisms that guarantee semantic coverage rather than speed alone.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [96] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: 论文提出一种基于合作博弈的多准则投票集成方法，以解决现有方法仅考虑单一评价标准的问题，通过同时利用多种预信息，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有集成学习方法在权重分配时仅考虑单一评价标准，无法充分利用多种预信息，限制了模型性能的提升空间。

Method: 提出多准则情境下的合作博弈方法，综合考虑分类器的多种预信息，实现合理的权重分配。

Result: 在Open-ML-CC18数据集上的实验表明，该方法优于其他权重分配方法。

Conclusion: 通过合作博弈多准则集成，能够更全面地利用预信息，有效提升模型性能。

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [97] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: Apriel-Nemotron-15B-Thinker是一个15B参数模型，虽然参数规模仅为同类32B模型的一半，但性能相当甚至更好，同时显著降低了内存和计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码、数学等领域表现出色，但其高昂的内存和计算成本限制了实际企业应用，因此需要更高效的模型。

Method: 采用四阶段训练流程，包括基础模型扩展、持续预训练、监督微调和使用GRPO的强化学习。

Result: Apriel-Nemotron-15B-Thinker在性能上匹配或超越32B参数模型，同时内存占用减少一半。

Conclusion: 该研究表明，通过优化的训练流程，可以设计出高效的小规模模型，满足企业需求。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [98] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: 论文提出了一种基于提示的持续学习方法（PCL），通过统一的提示池和最小扩展策略解决医学领域数据共享受限和分布偏移问题，显著提高了分类精度和F1分数。


<details>
  <summary>Details</summary>
Motivation: 医学领域的数据共享受限于伦理和制度约束，传统集中式学习难以实现。各机构只能利用本地数据逐步更新模型，但易出现过拟合和灾难性遗忘问题。此外，医学数据分布因设备和人群差异而变化，现有持续学习方法多为自然图像设计，医学领域专用方法较少。

Method: 提出了一种基于提示的持续学习方法（PCL），采用统一的提示池和最小扩展策略，通过冻结部分提示减少计算开销，并引入新的正则化项平衡知识保留和适应。

Result: 在三个糖尿病视网膜病变数据集（Aptos2019、LI2019和Diabetic Retinopathy Detection）上的实验表明，PCL模型在分类准确率上提高至少10%，F1分数提高9点，同时降低了推理成本。

Conclusion: PCL方法为医学领域持续学习提供了高效且可持续的解决方案，有望推动分布式医疗中的实时诊断、患者监测和远程医疗应用。代码将在论文接收后公开。

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [99] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: Retro-Expert是一种可解释的逆合成预测框架，结合大语言模型和专用模型的互补推理能力，通过强化学习提供自然语言解释，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有逆合成预测模型依赖静态模式匹配，缺乏有效逻辑决策能力，导致黑箱决策，无法提供可解释的推理路径。

Method: Retro-Expert框架包含三个组件：(1)专用模型进行浅层推理构建化学决策空间，(2)大语言模型驱动关键推理生成预测和解释路径，(3)强化学习优化可解释决策策略。

Result: 实验表明Retro-Expert在多项指标上优于基于大语言模型和专用模型的现有方法，并提供与专家观点一致的解释。

Conclusion: Retro-Expert不仅提升了逆合成预测性能，还通过可解释的推理路径弥合了AI预测与可操作的化学见解之间的差距。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [100] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: BeyondWeb框架生成高质量合成数据用于预训练，优于现有方法，并在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前合成数据质量的影响因素尚不明确，研究旨在探索如何生成高质量的合成数据以提升模型性能。

Method: 提出了BeyondWeb框架，用于生成高质量的合成数据，并分析了影响合成数据质量的关键因素。

Result: BeyondWeb在多个基准评测中优于现有合成数据集，训练速度更快，且小规模模型表现优于大规模模型。

Conclusion: 生成高质量合成数据需多因素联合优化，BeyondWeb展示了该方法的重要性和潜力。

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [101] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 论文提出了第一个文本到图像（T2I）模型选择框架M&C，通过匹配图和预测模型帮助用户高效选择预训练模型。


<details>
  <summary>Details</summary>
Motivation: 当前预训练T2I模型广泛共享，但用户面临如何为特定任务选择最佳模型的问题，缺乏相关研究和方法。

Method: M&C框架构建匹配图（包含模型和数据集节点，以及性能和数据相似性边），提取特征预测最佳微调模型。

Result: 在10个模型和32个数据集上的实验表明，M&C能61.3%准确预测最佳模型，其余选择接近最优。

Conclusion: M&C为T2I模型选择提供了高效解决方案，显著减少用户试错成本。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [102] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: CURE是一种两阶段框架，通过高熵关键令牌重新生成和联合优化轨迹，平衡探索与利用，解决了RLVR中熵崩溃问题，提升数学推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统RLVR方法中静态初始状态采样导致的熵崩溃和低多样性问题。

Method: 提出CURE框架，第一阶段通过高熵关键令牌重新生成和联合优化轨迹增强探索，第二阶段继续使用静态采样加强利用。

Result: 在Qwen-2.5-Math-7B上，CURE在六个数学基准测试中性能提升5%，熵和准确率均达到最优。

Conclusion: CURE有效平衡探索与利用，显著提升数学推理任务的性能和多样性。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [103] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 该论文通过量化设定下的随机子集和问题，扩展了强彩票假设（SLTH）框架，证明了在有限精度网络中，目标离散神经网络可以被精确表示，并给出了初始网络过参数化的最优界限。


<details>
  <summary>Details</summary>
Motivation: 量化是提高神经网络效率的重要技术，但目前对其理论理解有限。先前工作主要集中在连续设定下的SLTH，无法直接扩展到量化设定。

Method: 基于Borgs等人的数分割问题结果，研究量化设定下的随机子集和问题，并将SLTH框架扩展到有限精度网络。

Result: 证明了在量化设定下，目标离散神经网络可被精确表示，并推导了初始网络过参数化的最优界限。

Conclusion: 该研究为量化神经网络的构造提供了新的理论基础，解决了先前框架在量化设定下的局限性。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [104] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: 提出了一种新型的zono-conformal预测方法，通过构建预测zonotopes来提高计算效率和数据利用率，适用于多维度输出和非线性基预测器。


<details>
  <summary>Details</summary>
Motivation: 现有的conformal预测方法计算成本高且数据密集，且预测集以区间形式表示，无法捕捉多维度输出的依赖关系。

Method: 引入zono-conformal预测方法，基于区间预测模型和reachset-conformant识别，通过单一线性程序构建预测zonotopes。

Result: 实验表明，zono-conformal预测比区间预测模型和标准方法更少保守，同时保持相似的测试覆盖率。

Conclusion: zono-conformal预测在多维度输出和非线性场景下更具优势，为不确定性量化提供了高效解决方案。

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [105] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 本文提出并形式化了一种与学习或更新信念相关的“学习者信心”概念，区分了其与概率或似然的不同，并展示了其在多种文献概念中的体现。


<details>
  <summary>Details</summary>
Motivation: 探讨学习过程中信心的角色，明确区分其与概率或似然的不同，为理解信念更新提供新视角。

Method: 通过形式化公理定义信心，提出两种连续的测量方法，证明其普适表示，并在附加假设下推导更简洁的表示形式。

Result: 证明了信心可以通过连续测量方法表示，并衍生出基于向量场和损失函数的紧凑表示，扩展了复合观测的表示语言。

Conclusion: 贝叶斯规则被特化为优化学习者的特殊情况，其损失表示为线性期望，进一步扩展了信心在学习理论中的应用。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [106] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: 论文提出了一种广义非参数正态分布，其精度矩阵可推断变量间的条件独立结构，适用于非高斯分布，并通过算法验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对非高斯分布中协方差矩阵和精度矩阵无法反映变量独立性结构的问题，提出了一类广义非参数正态分布，保留了类似高斯分布的独立性推断能力。

Method: 基于高斯分布的对角变换定义了广义非参数正态分布，并开发了一种计算高效的算法来从其数据中恢复条件独立结构。

Result: 通过合成实验和实际数据应用证明了算法的有效性。

Conclusion: 广义非参数正态分布扩展了精度矩阵在非高斯分布中的应用，为独立性推断提供了新工具。

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [107] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: 该研究探讨了LIME和SHAP等事后解释方法在对抗性操作下的脆弱性，并通过实验评估了改进其鲁棒性的策略。


<details>
  <summary>Details</summary>
Motivation: 由于事后解释方法可能被操纵以掩盖模型偏见，研究旨在验证并改进这些方法的抗偏性。

Method: 通过复制COMPAS实验建立基线，并开发模块化测试框架，系统地评估多种LIME和SHAP增强方法。

Result: 研究发现某些配置能显著提高偏见检测能力，增强高风险机器学习系统的透明度。

Conclusion: 研究提出了改进解释方法鲁棒性的有效策略，对提升机器学习模型的公正性具有重要意义。

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [108] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: 该论文提出了一种基于丰度感知的Set Transformer方法，用于微生物组样本表征，通过加权序列嵌入以考虑物种丰度，提升了分类任务的性能。


<details>
  <summary>Details</summary>
Motivation: 微生物组样本表征对下游任务（如表型预测和环境分类）至关重要。传统方法通常忽视物种丰度的生物学重要性，仅通过简单平均处理序列嵌入。

Method: 作者提出了一种丰度感知的Set Transformer变体，通过将序列嵌入按相对丰度加权，并利用自注意力机制聚合，构建固定大小的样本级嵌入。

Result: 该方法在真实微生物组分类任务中优于平均池化和非加权Set Transformer，某些情况下表现完美。

Conclusion: 丰度感知聚合对构建稳健且符合生物学意义的微生物组表征具有实用价值，是首批将序列丰度整合到基于Transformer的样本嵌入中的方法之一。

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [109] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文提出了一种经济可行的预测编码解决方案，通过数据管理工作流将即时消息分组为日聊天，并结合特征选择和逻辑回归分类器，同时通过降维提高基线模型性能。


<details>
  <summary>Details</summary>
Motivation: 即时消息因其非正式性和较小的规模，给预测编码（文档分类）带来了额外挑战，需要一种经济高效的解决方案。

Method: 使用数据管理工作流将消息分组为日聊天，进行特征选择和逻辑回归分类，并通过降维优化性能。

Result: 在Instant Bloomberg数据集上测试，方法表现良好，并展示了成本节约的示例。

Conclusion: 该方法为即时消息的预测编码提供了一种经济高效的解决方案，并通过降维进一步提升了模型性能。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [110] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: 提出了一个基于相对优势的去偏框架，通过将观看时间与基于用户和视频组的参考分布进行比较，生成量化的偏好信号，显著提升了推荐的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 视频推荐平台通常用观看时间作为用户满意度的代理指标，但原始观看时间受视频时长、流行度和用户行为等混杂因素影响，可能导致推荐模型出现偏差。

Method: 提出相对优势去偏框架，通过将观看时间与用户和视频组的参考分布比较，生成量化偏好信号，并采用两阶段架构分离分布估计和偏好学习。此外，引入分布嵌入参数化观看时间分位数。

Result: 离线和在线实验均显示，该方法在推荐准确性和鲁棒性上显著优于现有基线方法。

Conclusion: 该框架有效解决了因混杂因素导致的推荐偏差问题，为视频推荐提供了一种更可靠的偏好信号生成方法。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [111] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 论文提出了一种基于神经网络的压缩元学习框架，通过优化编码和解码阶段，提高压缩学习的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模快速扩大，传统压缩学习方法因忽略数据结构而效率不足，需要一种更高效且能利用数据结构的解决方案。

Method: 使用神经网络元学习编码和解码阶段，优化压缩学习流程，并在多个应用中验证（如压缩PCA、压缩岭回归等）。

Result: 提出的压缩元学习框架在速度和准确性上优于现有方法，适用于多种任务。

Conclusion: 压缩元学习框架通过神经网络优化编码和解码，显著提升了压缩学习的性能，具有广泛应用潜力。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [112] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 该论文提出了一种多模态系统，用于早期预测ICD代码分配，结合临床记录和电子健康记录中的表格事件，通过预训练编码器、特征池化和跨模态注意力来优化跨模态表示，实验表明该方法优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 早期预测ICD代码分配可帮助识别健康风险、推荐治疗方案和优化资源分配，但现有研究多关注出院后文档分类，本研究旨在解决早期预测的挑战。

Method: 提出多模态系统，融合临床记录和表格事件，采用预训练编码器、特征池化和跨模态注意力技术，并引入加权时间损失函数。

Result: 实验结果表明，所提方法在早期预测任务中优于当前最先进的系统。

Conclusion: 该研究为ICD代码早期预测提供了有效的多模态解决方案，具有实际应用潜力。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [113] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: FGAT框架通过图神经网络和注意力机制，整合视觉与文本特征，同时建模搭配兼容性和用户偏好，显著提升时尚推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 时尚行业快速扩张，产品种类繁多，现有推荐系统难以同时处理搭配兼容性和个性化推荐，且常忽视物品与用户偏好的复杂交互。

Method: 提出FGAT框架，构建用户、搭配、物品三层层次图，利用图注意力机制动态加权节点重要性，融合视觉与文本特征。

Result: 在POG数据集上，FGAT在精度、HR、召回率、NDCG和准确率上优于HFGN等基线模型。

Conclusion: 结合多模态特征和层次图结构，FGAT显著提升了个性化时尚推荐的准确性和效率。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [114] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: 该论文研究了分段仿射正则化（PAR）在监督学习中的理论和应用，证明了在过参数化情况下，PAR损失函数的临界点具有高度量化特性，并提供了多种PAR的近端映射形式及其优化方法，同时分析了PAR在统计上的保证。


<details>
  <summary>Details</summary>
Motivation: 解决离散或量化变量的优化问题在组合搜索空间中的挑战性，提出PAR作为一个灵活的建模和计算框架。

Method: 从优化和统计角度研究PAR的理论基础，提出近端梯度法、加速变体及ADMM等求解方法，并分析线性回归问题的统计保证。

Result: 在过参数化情况下，PAR损失函数的临界点表现出高度量化；提供了多种PAR的近端映射形式及其优化方法；PAR可用于近似经典正则化并保持统计保证。

Conclusion: PAR是一个有效且灵活的量化优化框架，能够通过连续优化实现离散问题的求解，并在统计上具有保证。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [115] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: 论文提出了Clustered Transfer Residual Learning (CTRL)方法，通过结合跨域残差学习和自适应聚类，解决了多源数据中分布偏移和样本量差异的问题，提升了整体精度并保留了源级异质性。


<details>
  <summary>Details</summary>
Motivation: 在多源数据场景中，机器学习任务需要不仅整体精度高，还需保证各源数据的预测可靠性并保留源间差异。然而，数据中存在多源、分布偏移和样本量差异等问题，使得这一目标难以实现。

Method: 论文提出了CTRL方法，结合了跨域残差学习和自适应聚类技术，旨在同时提升整体精度和保留源级异质性。

Result: CTRL在5个大规模数据集（包括瑞士的难民安置项目数据）上表现优于其他先进基准方法，关键指标均有提升。

Conclusion: CTRL通过有效平衡数据数量与质量的权衡，显著提升了多源数据场景下的预测性能。

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [116] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 提出了一种新颖的高阶贝叶斯网络分类器设计范式，通过学习特征值的分布表示，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯网络分类器由于参数爆炸和数据稀疏性问题，难以建模高阶特征依赖关系，限制了其在实际复杂数据中的应用。

Method: 提出NeuralKDB，通过神经网络学习特征值的分布表示，并设计了一种基于随机梯度下降的高效训练算法。

Result: 在60个UCI数据集上的实验表明，NeuralKDB能够有效捕捉高阶特征依赖，性能显著优于传统贝叶斯网络分类器和其他竞争分类器。

Conclusion: 通过学习分布表示，NeuralKDB能够解决传统方法在高阶特征建模中的局限性，为贝叶斯网络分类器设计提供了新思路。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [117] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: 该论文提出了MMO-FL框架下的模态数量与质量不平衡问题，并开发了QQR算法来解决这一问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 物联网设备生成的异构多模态数据在分布式学习中面临模态数量与质量不平衡的问题，影响学习效果。

Method: 提出了基于原型学习的QQR算法，与训练过程并行运行，以平衡模态数量和质量。

Result: 在两种真实多模态数据集上的实验表明，QQR算法在模态不平衡条件下表现优于基准方法。

Conclusion: QQR算法有效解决了MMO-FL中的模态不平衡问题，提升了学习性能。

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [118] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 提出了一种半监督生成模型，用于处理多视图学习中缺失视图和标签的问题，通过结合标记和未标记数据提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视图学习中的缺失视图和标签问题，特别是在标记数据有限的情况下。

Method: 结合标记和未标记数据，通过最大化未标记样本的似然和跨视图互信息来学习共享潜在空间。

Result: 在图像和多组学数据上实现了更好的预测和填补性能。

Conclusion: 该方法在标记数据有限时展示出显著的性能提升，优于现有方法。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [119] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: 论文提出了QBM-VAE，一种量子-经典混合架构，利用量子处理器采样Boltzmann分布作为深度生成模型的先验，显著优于传统高斯先验模型，在单细胞数据任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 传统概率深度学习过度依赖高斯先验，无法准确捕捉复杂自然数据的非高斯特性；量子方法因计算规模和不稳定性受限。

Method: 提出QBM-VAE架构，结合量子处理器高效采样Boltzmann分布，并将其作为深度生成模型的先验。

Result: 在百万级单细胞数据任务中，QBM-VAE优于传统模型（如VAE、SCVI），提升了数据集成、细胞分类和轨迹推断效果。

Conclusion: QBM-VAE展示了量子优势在深度学习中的实际应用，为混合量子AI模型提供了可转移的蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [120] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 该论文提出了一种基于调制元学习的结构保持模型框架，用于解决参数变化的动态系统建模问题，避免了传统方法需要重新训练的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的结构保持模型在动态系统建模中表现优异，但需要为每个系统配置重新训练，限制了其适用性。元学习提供了一种解决方案，但现有方法存在训练不稳定或泛化能力有限的问题。

Method: 引入了基于调制的元学习框架，直接通过紧凑的潜在表示对结构保持模型进行条件化，避免需要显式系统知识或优化过程。

Result: 实验表明，该方法在少样本学习设置下实现了准确的预测，同时保持了物理约束和参数空间的泛化能力。

Conclusion: 调制元学习为解决参数变化动态系统建模问题提供了一种高效且泛化能力强的解决方案。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [121] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: 研究提出了一种名为BFF的方法，通过多模态对比框架，利用后期数据提升早期儿科风险评估的预测性能。


<details>
  <summary>Details</summary>
Motivation: 临床上希望尽早进行可靠的风险评估，但早期评估精度较低，因此研究旨在提高早期阶段的风险预测表现。

Method: 采用多模态对比框架BFF，将每个时间窗口视为独立模态，利用后期数据信息监督早期学习。

Result: 在两项真实儿科预测任务中验证，BFF显著提升了早期风险评估的表现。

Conclusion: BFF框架能够有效利用后期数据提升早期风险预测的准确性，具有临床应用潜力。

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [122] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: 论文探讨了认知行为的计算解释，提出因果抽象理论作为分析框架，并将其应用于深度学习与人工神经网络中，讨论了计算实现与表征的作用。


<details>
  <summary>Details</summary>
Motivation: 研究认知行为的计算解释，并试图通过因果抽象理论分析系统如何实现特定计算与表征。

Method: 提出基于因果抽象的计算实现理论，并结合深度学习与人工神经网络的实例进行说明。

Result: 揭示了计算实现与表征在认知行为中的重要性，并强调其在泛化与预测中的作用。

Conclusion: 因果抽象理论为理解计算与表征提供了有效框架，未来研究应关注泛化与预测方向。

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [123] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: 提出了一种基于CNN-LSTM混合架构的PM2.5浓度预测模型，结合空间特征和时间依赖性，在真实数据中表现优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 全球气候变化加剧，PM2.5浓度预测对环境保护、公共健康和城市管理至关重要。

Method: 使用CNN提取局部空间特征，LSTM建模时间序列的依赖关系，基于北京工业区多元数据集进行预测。

Result: 模型在6小时平均PM2.5浓度预测中，RMSE为5.236，优于传统方法。

Conclusion: 模型在现实应用中潜力巨大，但计算复杂度高，未来需优化多变量处理和扩展性。

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [124] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: 提出了一种改进的基于交互式投票的地图匹配算法，旨在高效处理采样率变化的轨迹，提升GPS轨迹重建精度，适用于不同质量的数据输入。


<details>
  <summary>Details</summary>
Motivation: 为了提高GPS轨迹在不同数据质量下的匹配精度，并扩展算法的适用范围，使其能在更多实际场景中使用。

Method: 在原有算法基础上增加了轨迹插补功能，采用距离有界的交互式投票策略以降低计算复杂度，并改进了对道路网络缺失数据的处理。此外，集成了OpenStreetMap的自定义资源，增强算法的地理适应性。

Result: 改进后的算法保留了核心优势，同时显著提升了其适用性和计算效率，能够广泛应用于不同地区。

Conclusion: 通过集成多种改进措施，该算法在实际应用中表现出色，为GPS轨迹匹配提供了更高效、灵活的解决方案。

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [125] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 该摘要提出了一种名为GODNF的神经网络框架，旨在解决现有扩散图神经网络在适应性、深度限制和理论理解方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应性、深度和收敛行为理论上存在局限，GODNF旨在统一多种意见动态模型，解决这些问题。

Method: 提出GODNF框架，通过节点特定的行为建模和动态邻域影响捕捉异质扩散模式和时态动态。

Result: 理论分析显示GODNF能模拟多样收敛配置，实验验证其在节点分类和影响力估计任务上的优越性。

Conclusion: GODNF在适应性和理论分析上优于现有方法。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [126] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种通过提示从闭源LLMs中提取特征并训练轻量级公平分类器的框架，适用于高风险任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法适用于闭源LLMs的上下文学习场景，需解决群体公平性问题。

Method: 利用LLM作为特征提取器，通过设计提示获取概率预测特征，再用公平算法训练分类器。

Result: 在五个数据集上表现出显著的准确性-公平性平衡，优于传统方法。

Conclusion: 该框架高效且适用于闭源和开源LLMs，为公平分类提供了新思路。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [127] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: 该论文探讨了脉冲神经网络（SNNs）在对抗性扰动下的脆弱性，并提出了一种名为RTE的训练框架以提高其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于SNNs在能效和类脑计算方面的潜力，研究其在对抗性扰动下的鲁棒性至关重要。当前对其脆弱性和时间传播性的理解不足。

Method: 通过时间集成视角重新审视SNNs的鲁棒性，提出RTE框架，结合统一损失函数和随机采样策略优化各子网络的鲁棒性。

Result: 实验显示RTE在多个基准测试中优于现有方法，重塑了SNNs的内部鲁棒性景观。

Conclusion: 研究强调了时间结构在对抗性学习中的重要性，并为构建鲁棒的脉冲模型提供了理论基础。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [128] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为HS-GPPT的新框架，通过谱对齐优化图预训练和提示调整，解决了现有方法无法处理真实图中多样谱分布的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图预训练方法依赖同质性低频知识，无法适应真实图中多样的谱分布和不同同质性水平。

Method: 提出HS-GPPT框架，采用混合谱滤波器主干和局部-全局对比学习，设计提示图以实现谱分布对齐。

Result: 实验验证了该方法在转导和归纳学习设置下的有效性。

Conclusion: HS-GPPT通过谱对齐优化知识转移，解决了现有方法的局限性。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [129] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: RegimeNAS是一个专为加密货币交易设计的可微分架构搜索框架，通过市场状态感知提升性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决静态深度学习模型在动态金融市场中的局限性。

Method: 结合贝叶斯搜索空间、动态激活的神经网络模块和多目标损失函数。

Result: 在真实加密货币数据上，MAE降低80.3%，收敛速度更快（9 vs. 50+ epochs）。

Conclusion: 将领域知识（如市场状态）嵌入NAS过程对金融应用至关重要。

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [130] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: 本文提出了一种名为TACP的方法，用于解决传统CP方法在长尾标签分布下对不同类别覆盖不均衡的问题。通过利用长尾结构和引入重加权机制，TACP及其扩展sTACP显著缩小了头尾类别的覆盖差距。


<details>
  <summary>Details</summary>
Motivation: 传统CP方法虽然在整体覆盖上表现良好，但在长尾标签分布下对尾部类别的覆盖不足，导致预测集对少数类别的可靠性降低。本文旨在解决这一问题。

Method: 提出Tail-Aware Conformal Prediction (TACP)，利用长尾结构缩小头尾类别覆盖差距；进一步引入soft TACP (sTACP)通过重加权机制提升覆盖平衡性。

Result: 理论分析表明，TACP能比传统方法更小化头尾覆盖差距；实验验证了该方法在多个长尾基准数据集上的有效性。

Conclusion: TACP及其扩展sTACP显著改善了长尾标签分布下的覆盖均衡问题，提升了预测集对少数类别的可靠性。

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [131] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: NeMo提出了一种可扩展且通用化的模块化训练方法，适用于Transformer和大规模模型，显著提升了模块分类精度并减少了模块大小。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络模型的构建成本高昂，当前模块化方法难以应对多样化的DNN和大规模模型，尤其是Transformer。需要一种更通用和可扩展的方法。

Method: NeMo在神经元级别进行模块化训练，采用对比学习和复合损失函数，适用于各种架构，包括Transformer。

Result: 实验显示，NeMo在模块分类精度上平均提升1.72%，模块大小减少58.10%，在CNN和Transformer模型上均表现优异。

Conclusion: NeMo为大规模DNN模块化提供了有效解决方案，具有实际应用潜力。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [132] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: 该研究通过整合全球造林和再造林项目的数据，结合卫星影像，开发了一个标准化评估方法（LDIS），发现许多项目的地理数据完整性存在问题。


<details>
  <summary>Details</summary>
Motivation: 由于造林和再造林项目的碳汇效果数据往往依赖项目方的自我报告或缺乏外部验证，导致数据可靠性和项目诚信受到质疑，因此研究旨在通过独立数据验证提升碳市场的透明度和问责制。

Method: 研究使用来自45,628个项目的1,289,068个种植地点的元信息，结合时间序列卫星影像和其他辅助数据，开发了LDIS（Location Data Integrity Score）指标，对地理边界数据的完整性进行标准化评估。

Result: 研究发现，79%的地理参考种植地点至少在一项LDIS指标上失败，15%的项目甚至缺乏机器可读的地理参考数据。

Conclusion: 该数据集不仅有助于提升自愿碳市场的问责制，还可作为计算机视觉任务的训练数据，为相关领域提供支持。

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [133] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: 论文提出了一种名为HGD的新算法，通过调整梯度下降技术来解决数据流中的类别不平衡问题，无需额外参数或先验知识。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据流常因时间累积呈现类别不平衡，现有方法如重采样或重加权存在不足，因此需要一种更高效的梯度下降解决方案。

Method: HGD算法通过平衡不同类别的梯度范数，避免对小类别欠拟合，实现简洁且无需额外存储或参数。

Result: 理论分析和实验验证表明，HGD在多个不平衡数据流场景中表现优异，实现了亚线性遗憾界。

Conclusion: HGD提供了一种有效且通用的解决方案，适用于任何基于梯度下降的学习模型。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [134] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: 论文提出了一种基于熵的机制（ETMR和EAR）来改善测试时强化学习中的探索与利用平衡，显著提升了模型的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在复杂推理任务上有所进步，但仍依赖标注数据且在无监督场景下适应性不足，现有测试时强化学习方法存在高推断成本和估计偏差等问题。

Method: 通过熵分叉树多数展开（ETMR）和基于熵的优势重塑（EAR）两种策略，优化模型的探索与利用平衡。

Result: 在AIME 2024基准测试中，Llama3.1-8B模型实现了68%的相对提升，同时仅消耗60%的标记预算。

Conclusion: 该方法高效平衡了推断效率、多样性和估计鲁棒性，推动了无监督强化学习在开放域推理任务中的应用。

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [135] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: 该论文提出了一种名为PTSM的新框架，用于跨被试的EEG解码，通过双分支掩蔽机制和正交子空间分解实现高度可解释和鲁棒的解码。


<details>
  <summary>Details</summary>
Motivation: 由于被试间差异性和缺乏跨被试共享表征，跨被试EEG解码一直是脑机接口研究中的重大挑战。

Method: PTSM采用双分支掩蔽机制，独立学习个性化和共享的时空模式，并结合信息论约束分解潜在嵌入空间。

Result: 在跨被试运动想象数据集上的实验表明，PTSM在零样本泛化方面优于现有方法，无需特定被试校准。

Conclusion: PTSM通过解耦神经表征，实现了非稳态神经生理学环境下个性化和可迁移的解码。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [136] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: DFA算法融合个体奖励和成对偏好，通过策略对数概率直接建模偏好概率，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在结合个体奖励和偏好反馈，简化强化学习中的偏好建模步骤。

Method: DFA直接使用策略的对数概率建模偏好，支持人工标注或在线合成偏好。

Result: 在6个控制环境中匹配或超越SAC，偏好数据集下优于RLHF基线。

Conclusion: DFA为偏好反馈提供高效解决方案，性能稳定且接近真实奖励。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [137] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: 论文提出了一种通过最小化替代损失的方法，解决了基于梯度的决策聚焦学习中梯度为零的问题，并在实践中取得了与现有方法相当或更好的效果。


<details>
  <summary>Details</summary>
Motivation: 决策聚焦学习（DFL）旨在通过优化问题参数预测直接最小化决策后悔，但许多优化问题（如线性规划）的梯度几乎处处为零，现有方法难以有效解决这一问题。

Method: 提出了通过最小化替代损失的方法，即使在使用可微分优化层时也采用替代损失，实验验证了该方法在高效率和低训练时间下的有效性。

Result: 实验表明，该方法在可微分优化层中使用替代损失，能够实现与现有方法相当或更低的后悔值，同时显著减少训练时间。

Conclusion: 通过替代损失与高效优化技术的结合，论文提供了一种更高效的决策聚焦学习方法，解决了梯度为零的难题。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [138] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: 论文提出了一种基于Forman-Ricci曲率的结构提升策略，以解决图神经网络在长距离信息传递中的信息失真问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的复杂系统（如社交或生物网络）需要更高阶的拓扑表示，而传统图神经网络难以有效处理这些高阶结构。

Method: 通过Forman-Ricci曲率将数据表示从基本图形式提升为更具表达力的拓扑结构，然后应用图神经网络学习。

Result: 该方法通过超边建模网络骨干结构，有效缓解了信息传递中的过度压缩问题。

Conclusion: 提出的曲率提升策略为高阶拓扑深度学习提供了新方法，提升了图神经网络的表达能力。

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [139] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: CHORD框架通过动态权重统一SFT和RL，实现稳定学习。


<details>
  <summary>Details</summary>
Motivation: 解决SFT和RL结合时可能破坏模型模式和过拟合专家数据的风险。

Method: 提出CHORD框架，通过动态权重将SFT作为RL的辅助目标，并引入双控制机制。

Result: 实验显示CHORD在稳定性和效率上显著优于基线。

Conclusion: CHORD有效结合专家数据和探索，为LLM后训练提供了新方法。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [140] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: LEAD是一种基于共享潜在空间的序列-结构协同设计框架，通过优化潜在编码解决了现有方法的局限性，显著降低了查询消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原始数据空间中优化抗体序列，导致搜索效率低下，LEAD旨在通过潜在空间优化提高效率和性能。

Method: 提出LEAD框架，利用共享潜在空间优化序列和结构，并设计黑盒指导策略以适应非可微分属性评估器。

Result: 实验显示LEAD在单目标和多目标优化中表现优异，查询消耗减少一半且性能超越基线方法。

Conclusion: LEAD是一种高效的抗体设计框架，适用于实际场景中的非可微分属性优化。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [141] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: 论文提出使用收缩理论提高卷积神经常微分方程（NODEs）的鲁棒性，通过训练中的正则化或权重正则化，减少输入噪声和对抗攻击的影响。


<details>
  <summary>Details</summary>
Motivation: 神经网络易受输入噪声和对抗攻击的干扰，因此需要提高其鲁棒性。

Method: 利用收缩理论，通过动态系统的Jacobian正则化或特定权重正则化，使NODEs满足收缩性。

Result: 在MNIST和FashionMNIST数据集上测试，证明该方法能有效应对图像噪声和攻击。

Conclusion: 收缩性NODEs可以通过正则化提高鲁棒性，适用于对抗环境下的图像分类任务。

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [142] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: 提出了一种名为mCOCO的新框架，利用储备计算（RC）从BOLD信号中学习群体级别的功能性连接脑模板（CBT），解决了现有方法的黑盒性、计算成本高和忽视认知能力等问题。


<details>
  <summary>Details</summary>
Motivation: 现有CBT学习方法（如传统机器学习和图神经网络）存在解释性差、计算成本高以及忽略认知能力的局限性，需要一种更高效、可解释且能捕捉认知能力的解决方案。

Method: mCOCO框架分为两阶段：(1) 将BOLD信号映射到储备中以提取个体功能连接组，再聚合为群体级CBT；(2) 通过认知储备整合多感官输入，赋予CBT认知能力。

Result: 评估表明，mCOCO在中心性、区分性、拓扑合理性和多感官记忆保留方面显著优于基于GNN的CBT。

Conclusion: mCOCO结合了动态系统特性和多感官输入，提升了CBT的功能性和解释性，为脑连接研究提供了新的工具。

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [143] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: 该研究表明，现有的局部解释算法在复杂模型下的解释性可能不足，并提出了一种基于学习理论的框架来评估解释的有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨现有局部解释算法在复杂机器学习模型中的适用性及其理论保证。

Method: 提出一种基于学习理论的框架，定义了解释的“信息量”，并通过数学分析验证多种流行解释算法的有效性。

Result: 研究发现，许多流行解释算法在复杂模型中并不具备信息量，且需要更强条件才能有效。

Conclusion: 研究为解释算法的改进提供了理论依据，并强调了其在高风险AI应用中的实践意义。

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [144] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 本研究通过近似贝叶斯推断框架和合成数据集，评估了六种概率机器学习算法的不确定度估计能力，发现深度学习算法在分布外数据上的不确定度估计一致性不足。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习等复杂数据模型的应用，不确定度量化变得困难，研究旨在评估不同算法在类概率和不确定度估计上的表现。

Method: 采用近似贝叶斯推断框架，并在合成分类数据集上测试六种算法（如神经网络集成、证据深度学习等），评估其校准性和分布外数据的不确定度表现。

Result: 所有算法均表现良好校准性，但深度学习算法在分布外数据上的不确定度估计不一致。

Conclusion: 研究为开发新的科学数据建模不确定度估计方法提供了参考，揭示了深度学习算法在分布外数据上的局限性。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [145] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: 该研究通过AutoML和可解释AI分析交通事故严重性，提出了一个透明且可复现的方法论，识别出17个关键风险因素。


<details>
  <summary>Details</summary>
Motivation: 交通事故是全球伤害和死亡的主要原因，需要数据驱动的方法来理解和减轻事故严重性。

Method: 结合AutoML和可解释AI（SHAP），构建预测模型并分析特征重要性。

Result: 最终模型在训练集和测试集的AUC-ROC分别达到85.6%和84.9%，识别出17个关键影响因素。

Conclusion: 研究强调方法严谨性和可解释性，为交通政策提供了数据支持的框架。

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [146] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: 提出了GraphOracle框架，用于生成和评估GNN的类级别解释，克服了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 提高GNN的可解释性，确保其安全和公平部署，尤其是类级别解释的有效性。

Method: 联合学习GNN分类器和结构化稀疏子图，提出集成训练方法和掩码评估策略。

Result: GraphOracle在忠诚度、可解释性和扩展性上表现优异，避免了计算瓶颈。

Conclusion: GraphOracle是一个实用且高效的自解释GNN框架。

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [147] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 该论文提出了一种双空间引导的测试框架，通过协调场景参数空间和智能体行为空间，解决了高维场景空间中多样性和关键性的平衡问题，显著提升了测试场景的生成效果。


<details>
  <summary>Details</summary>
Motivation: 由于动态环境中决策智能体的广泛应用，安全验证需求日益增长，但现有方法在高维场景空间中难以有效平衡多样性和关键性，亟需解决这一问题。

Method: 论文提出了一种双空间引导的测试框架，结合层次化表示和多维子空间评估，通过局部扰动和全局探索优化场景生成，并利用智能体行为空间数据形成闭环反馈。

Result: 实验表明，该框架在五种决策智能体上的测试场景生成中，关键场景数量平均提升了56.23%，且多样性优于现有基线方法。

Conclusion: 通过双空间协同和闭环反馈，该框架显著提升了测试场景的多样性和关键性，为决策智能体的安全验证提供了有效工具。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [148] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 介绍了使用费曼图计算神经切线核（NTK）有限宽度修正的方法，简化了代数操作，并验证了无有限宽度修正的结果。


<details>
  <summary>Details</summary>
Motivation: 为了更全面地理解有限宽度下神经网络的训练动态，弥补无限宽度下缺失的特征学习和NTK演化等特性。

Method: 引入费曼图，用于计算NTK统计量的有限宽度修正，推导层间递归关系，并通过数值实验验证。

Result: 证明了深度网络稳定性结果的扩展，以及尺度不变非线性（如ReLU）在NTK矩阵对角线上无有限宽度修正。

Conclusion: 该方法为有限宽度下NTK统计量的计算提供了有效工具，并揭示了某些非线性下修正的缺失。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [149] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: 提出一种基于物理信息扩散模型的无监督异常检测方法，通过加权物理信息损失提升模型性能，实验表明其优于基线方法和现有物理信息模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决多元时间序列数据中无监督异常检测的挑战，结合物理信息扩散模型的优势，提出新的学习方法以提升模型对数据分布的逼近能力。

Method: 采用加权物理信息损失函数，通过静态权重调度在扩散模型训练中结合物理依赖的时间分布。

Result: 实验结果显示，该方法在合成和真实数据集上提高了异常检测的F1分数，生成的数据多样性和对数似然性能更优。

Conclusion: 所提方法在异常检测任务中表现优异，超越了基线方法和现有物理信息模型，同时在多个数据集上保持竞争力。

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [150] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: HXAI是一个用户为中心的可解释人工智能框架，通过将解释嵌入数据分析的每个阶段，并统一六个组件，解决了传统可解释AI方法的局限性，同时结合了多学科理论和实践。


<details>
  <summary>Details</summary>
Motivation: 传统可解释AI方法仅关注单个预测的透明度，但忽略了上游决策和下游质量检查，导致对AI模型的信任不足。HXAI旨在填补这一空白。

Method: HXAI将数据、分析设置、学习过程、模型输出、模型质量和通信通道统一为一个分类法，并结合人类解释理论、人机交互原则和用户研究，生成清晰且可操作的解释。

Result: HXAI提供了一个全面的分类法和问题库，减少了术语歧义，并通过整合大语言模型，实现了多样化的解释方法。

Conclusion: HXAI通过端到端的透明度和多学科融合，推动了负责任AI部署的发展。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [151] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: DFed-SST是一种去中心化的联邦图学习框架，通过自适应通信机制解决现有方法在处理本地子图拓扑信息时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有去中心化联邦学习（DFL）方法在面对图数据时未能有效利用本地子图的拓扑信息，而集中式的联邦图学习（FGL）又无法享受去中心化的优势。

Method: 提出DFed-SST框架，采用双拓扑自适应通信机制，动态构建和优化客户端间通信拓扑。

Result: 在八个真实数据集上的实验表明，DFed-SST能比基线方法平均准确率提升3.26%。

Conclusion: DFed-SST通过自适应通信机制，有效解决了图数据联邦学习中的去中心化和拓扑适应性挑战。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [152] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: 提出了一种数据驱动的嵌套Operator Inference（OpInf）方法，用于从高维动态系统的快照数据中学习物理信息的降阶模型（ROM）。该方法通过利用降阶空间的层次结构，优先考虑主导模式的相互作用，从而构建OpInf学习问题的初始猜测。实验表明，嵌套OpInf算法在立方热传导问题和格陵兰冰盖的大规模参数化模型中表现优异，误差显著降低且计算速度大幅提升。


<details>
  <summary>Details</summary>
Motivation: 高维动态系统的降阶建模是科学计算中的重要问题，尤其是在需要高效模拟复杂系统时。传统的OpInf方法在初始猜测和模型适应性方面存在局限，因此需要一种更高效、更灵活的方法来改进降阶模型的精度和计算效率。

Method: 提出嵌套Operator Inference方法，通过利用降阶空间的层次结构迭代构建初始猜测，优先考虑主导模式的相互作用。算法支持基于先前模型的“热启动”，适用于动态基和模型形式的更新。实验验证包括立方热传导问题和格陵兰冰盖的大规模参数化模型。

Result: 在立方热传导问题中，嵌套OpInf的误差比标准OpInf小四倍，离线时间相近。在格陵兰冰盖模型中，平均误差为3%，计算速度提升超过19,000倍。

Conclusion: 嵌套OpInf方法显著提升了降阶模型的学习效率和精度，尤其适用于复杂系统的动态建模。其通过层次结构利用和“热启动”机制，为高维动态系统的降阶建模提供了新的有效工具。

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [153] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow是一个基于服务器的强化学习框架，解决了工业级RL中的两个核心挑战：训练与复杂执行流解耦，以及最大化GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 工业级强化学习面临训练与复杂执行流程难以解耦和资源利用率低的挑战，需要高效且稳定的解决方案。

Method: SeamlessFlow提出数据平面解耦RL训练与代理实现，并引入标记驱动调度和时空复用管道，动态分配资源。

Result: 框架实现了高吞吐量和稳定性，适合多代理、长期任务等复杂RL场景。

Conclusion: SeamlessFlow为大规模RL部署提供了高效且稳定的解决方案。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [154] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: 通过马尔可夫游戏和强化学习框架，研究多站点碳捕集与封存（CCS）项目中不同联盟结构对利益相关者目标的影响。


<details>
  <summary>Details</summary>
Motivation: CCS项目涉及多个利益相关者，其目标和责任各异，且项目具有复杂性和长期性。需要研究独立最大化利益或通过合作联盟的有效性。

Method: 采用马尔可夫游戏和强化学习框架，结合安全约束，通过代理人学习最优策略。

Result: 提出的框架在多个利益相关者参与的CO2封存管理中表现出有效性。

Conclusion: 该框架为多利益相关者CCS项目的优化管理提供了可行方案。

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>
