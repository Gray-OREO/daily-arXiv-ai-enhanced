<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 66]
- [cs.MM](#cs.MM) [Total: 4]
- [cs.LG](#cs.LG) [Total: 70]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Heatmap Regression without Soft-Argmax for Facial Landmark Detection](https://arxiv.org/abs/2508.14929)
*Chiao-An Yang,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 本文重新审视了面部标志检测中常用的Soft-argmax方法，提出了一种基于经典结构化预测框架的替代训练目标，取得了更优的性能。


<details>
  <summary>Details</summary>
Motivation: Soft-argmax虽然广泛用于面部标志检测，但其局限性促使研究者探索更高效的方法。

Method: 作者提出了一种基于结构化预测框架的替代训练目标，替代Soft-argmax。

Result: 该方法在三个基准测试（WFLW、COFW和300W）上达到了SOTA性能，训练速度提升2.2倍，同时保持高精度。

Conclusion: 结构化预测框架为面部标志检测提供了比Soft-argmax更高效的选择。

Abstract: Facial landmark detection is an important task in computer vision with
numerous applications, such as head pose estimation, expression analysis, face
swapping, etc. Heatmap regression-based methods have been widely used to
achieve state-of-the-art results in this task. These methods involve computing
the argmax over the heatmaps to predict a landmark. Since argmax is not
differentiable, these methods use a differentiable approximation, Soft-argmax,
to enable end-to-end training on deep-nets. In this work, we revisit this
long-standing choice of using Soft-argmax and demonstrate that it is not the
only way to achieve strong performance. Instead, we propose an alternative
training objective based on the classic structured prediction framework.
Empirically, our method achieves state-of-the-art performance on three facial
landmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during
training while maintaining better/competitive accuracy. Our code is available
here: https://github.com/ca-joe-yang/regression-without-softarg.

</details>


### [2] [Fast Graph Neural Network for Image Classification](https://arxiv.org/abs/2508.14958)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 该研究提出了一种结合图卷积网络（GCNs）和Voronoi图的新方法，通过将图像表示为图结构，提高了分类效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 通过GCNs和Voronoi图的结合，增强图像分类的能力，尤其是在处理复杂场景和细粒度分类时。

Method: 将图像表示为图结构，利用Voronoi图和Delaunay三角剖分优化图的表示，结合GCNs进行分类。

Result: 实验表明，该方法在多个基准数据集上显著提升了分类效率和准确性，超越了现有技术。

Conclusion: 该研究不仅为图像分类提供了新视角，还拓展了图学习在计算机视觉和非结构化数据分析中的应用潜力。

Abstract: The rapid progress in image classification has been largely driven by the
adoption of Graph Convolutional Networks (GCNs), which offer a robust framework
for handling complex data structures. This study introduces a novel approach
that integrates GCNs with Voronoi diagrams to enhance image classification by
leveraging their ability to effectively model relational data. Unlike
conventional convolutional neural networks (CNNs), our method represents images
as graphs, where pixels or regions function as vertices. These graphs are then
refined using corresponding Delaunay triangulations, optimizing their
representation. The proposed model achieves significant improvements in both
preprocessing efficiency and classification accuracy across various benchmark
datasets, surpassing state-of-the-art approaches, particularly in challenging
scenarios involving intricate scenes and fine-grained categories. Experimental
results, validated through cross-validation, underscore the effectiveness of
combining GCNs with Voronoi diagrams for advancing image classification. This
research not only presents a novel perspective on image classification but also
expands the potential applications of graph-based learning paradigms in
computer vision and unstructured data analysis.

</details>


### [3] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: 本文提出了一种名为YOPO的单阶段、基于查询的框架，能够仅通过RGB图像和类别级姿态标签，实现高精度的9自由度姿态估计，无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决从单一RGB图像中准确恢复特定类别物体的9自由度姿态的挑战，尤其是减少对伪深度、CAD模型或多阶段级联的依赖。

Method: YOPO通过增强变压器检测器，加入轻量级姿态头、基于边界框的平移模块和6D感知匈牙利匹配成本，实现端到端训练。

Result: 在REAL275数据集上，YOPO实现了79.6%的IoU50和54.1%的10°/10cm指标，超过了现有的RGB-only方法，并缩小了与RGB-D系统的差距。

Conclusion: YOPO通过简化的设计和高性能表现，证明了RGB图像可以实现高质量的9自由度姿态估计，为机器人技术和自动化提供了新思路。

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


### [4] [Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection](https://arxiv.org/abs/2508.14980)
*Andrei Balykin,Anvar Ganiev,Denis Kondranin,Kirill Polevoda,Nikolai Liudkevich,Artem Petrov*

Main category: cs.CV

TL;DR: 论文提出了一种名为Paired-Sampling Contrastive Framework的统一训练方法，用于同时检测物理和数字伪造攻击，降低了系统复杂性和延迟，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的人脸识别系统使用不同的模型分别处理物理和数字伪造攻击，这增加了系统复杂性和延迟。论文旨在开发一种统一的方法以解决这一问题。

Method: 利用自动匹配的真实和攻击自拍对，通过对比学习框架学习模态无关的活体检测特征。

Result: 在基准测试中，平均分类错误率（ACER）为2.10%，优于现有方法，且模型轻量（4.46 GFLOPs），训练时间短于一小时。

Conclusion: 该方法为物理和数字伪造攻击提供了一种高效、统一的解决方案，适用于实际部署。

Abstract: Modern face recognition systems remain vulnerable to spoofing attempts,
including both physical presentation attacks and digital forgeries.
Traditionally, these two attack vectors have been handled by separate models,
each targeting its own artifacts and modalities. However, maintaining distinct
detectors increases system complexity and inference latency and leaves systems
exposed to combined attack vectors. We propose the Paired-Sampling Contrastive
Framework, a unified training approach that leverages automatically matched
pairs of genuine and attack selfies to learn modality-agnostic liveness cues.
Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital
Attack Detection benchmark, our method achieves an average classification error
rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is
lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for
real-world deployment. Code and pretrained models are available at
https://github.com/xPONYx/iccv2025_deepfake_challenge.

</details>


### [5] [TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](https://arxiv.org/abs/2508.15020)
*Susim Roy,Anubhooti Jain,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: TAIGen是一种无需训练的生成对抗图像的黑盒方法，利用无条件扩散模型仅需3-20步采样生成高质量的对抗样本。通过选择性RGB通道策略和部分时间步扰动注入，实现了高效攻击与视觉质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法通常生成低质量图像且计算资源消耗大，扩散模型虽然能生成高质量图像但需要数百步采样。因此，研究一种高效且高质量的对抗攻击方法具有实际意义。

Method: TAIGen通过在混合时间步间隔注入扰动，避免处理所有时间步。采用选择性RGB通道策略，对红色通道应用注意力图，对绿色和蓝色通道使用GradCAM引导的扰动。

Result: 在ImageNet数据集上，TAIGen对ResNet、MNASNet和ShuffleNet的攻击成功率分别为70.6%、80.8%和97.8%。生成速度比现有扩散攻击快10倍，PSNR高于30dB。

Conclusion: TAIGen在高效生成高质量对抗样本的同时，显著提升了攻击成功率，且防御机制对其效果最差，表明其是目前最具破坏力的攻击方法。

Abstract: Adversarial attacks from generative models often produce low-quality images
and require substantial computational resources. Diffusion models, though
capable of high-quality generation, typically need hundreds of sampling steps
for adversarial generation. This paper introduces TAIGen, a training-free
black-box method for efficient adversarial image generation. TAIGen produces
adversarial examples using only 3-20 sampling steps from unconditional
diffusion models. Our key finding is that perturbations injected during the
mixing step interval achieve comparable attack effectiveness without processing
all timesteps. We develop a selective RGB channel strategy that applies
attention maps to the red channel while using GradCAM-guided perturbations on
green and blue channels. This design preserves image structure while maximizing
misclassification in target models. TAIGen maintains visual quality with PSNR
above 30 dB across all tested datasets. On ImageNet with VGGNet as source,
TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%
against ShuffleNet. The method generates adversarial examples 10x faster than
existing diffusion-based attacks. Our method achieves the lowest robust
accuracy, indicating it is the most impactful attack as the defense mechanism
is least successful in purifying the images generated by TAIGen.

</details>


### [6] [Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement](https://arxiv.org/abs/2508.15027)
*Chunming He,Fengyang Xiao,Rihan Zhang,Chengyu Fang,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: 论文提出了一种名为RUN++的可逆展开网络，结合生成细化方法，通过多阶段深度网络解决隐蔽视觉感知问题，利用扩散模型减少不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有隐蔽视觉感知方法多局限于掩膜领域，RGB领域潜力未充分挖掘，RUN++旨在通过可逆建模和扩散模型解决这一问题。

Method: RUN++将CVP任务建模为优化问题，分阶段展开为深度网络，包含CORE、CARE和FINE模块，分别处理掩膜和RGB域的不确定性。

Result: RUN++通过扩散模型细化不确定区域，显著减少误检和漏检，计算效率高，适用于实际退化场景。

Conclusion: RUN++提出了一种新的CVP系统范式，通过可逆建模和扩散模型的结合，提升了隐蔽视觉感知的性能和鲁棒性。

Abstract: Existing methods for concealed visual perception (CVP) often leverage
reversible strategies to decrease uncertainty, yet these are typically confined
to the mask domain, leaving the potential of the RGB domain underexplored. To
address this, we propose a reversible unfolding network with generative
refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as
a mathematical optimization problem and unfolds the iterative solution into a
multi-stage deep network. This approach provides a principled way to apply
reversible modeling across both mask and RGB domains while leveraging a
diffusion model to resolve the resulting uncertainty. Each stage of the network
integrates three purpose-driven modules: a Concealed Object Region Extraction
(CORE) module applies reversible modeling to the mask domain to identify core
object regions; a Context-Aware Region Enhancement (CARE) module extends this
principle to the RGB domain to foster better foreground-background separation;
and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a
final refinement. The FINE module introduces a targeted Bernoulli diffusion
model that refines only the uncertain regions of the segmentation mask,
harnessing the generative power of diffusion for fine-detail restoration
without the prohibitive computational cost of a full-image process. This unique
synergy, where the unfolding network provides a strong uncertainty prior for
the diffusion model, allows RUN++ to efficiently direct its focus toward
ambiguous areas, significantly mitigating false positives and negatives.
Furthermore, we introduce a new paradigm for building robust CVP systems that
remain effective under real-world degradations and extend this concept into a
broader bi-level optimization framework.

</details>


### [7] [GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging](https://arxiv.org/abs/2508.15057)
*Toqi Tahamid Sarker,Mohamed Embaby,Taminul Islam,Amer AbuGhazaleh,Khaled R Ahmed*

Main category: cs.CV

TL;DR: GasTwinFormer是一种混合视觉Transformer，用于实时甲烷排放分割和饮食分类，结合了新型Mix Twin编码器和轻量级LR-ASPP解码器，效果高效。


<details>
  <summary>Details</summary>
Motivation: 畜牧业甲烷排放占人为甲烷排放的32%，需要自动化监测以实现气候减缓策略。

Method: 采用混合视觉Transformer GasTwinFormer，结合Mix Twin编码器（全局和局部注意力机制）和LR-ASPP解码器，实现实时甲烷分割和饮食分类。

Result: 在分割任务上达到74.47% mIoU和83.63% mF1，饮食分类精度100%，模型高效（3.348M参数，114.9 FPS）。

Conclusion: GasTwinFormer是实时监测畜牧排放的实用解决方案，验证了饮食与排放的相关性。

Abstract: Livestock methane emissions represent 32% of human-caused methane production,
making automated monitoring critical for climate mitigation strategies. We
introduce GasTwinFormer, a hybrid vision transformer for real-time methane
emission segmentation and dietary classification in optical gas imaging through
a novel Mix Twin encoder alternating between spatially-reduced global attention
and locally-grouped attention mechanisms. Our architecture incorporates a
lightweight LR-ASPP decoder for multi-scale feature aggregation and enables
simultaneous methane segmentation and dietary classification in a unified
framework. We contribute the first comprehensive beef cattle methane emission
dataset using OGI, containing 11,694 annotated frames across three dietary
treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation
while maintaining exceptional efficiency with only 3.348M parameters, 3.428G
FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect
dietary classification accuracy (100%), demonstrating the effectiveness of
leveraging diet-emission correlations. Extensive ablation studies validate each
architectural component, establishing GasTwinFormer as a practical solution for
real-time livestock emission monitoring. Please see our project page at
gastwinformer.github.io.

</details>


### [8] [CurveFlow: Curvature-Guided Flow Matching for Image Generation](https://arxiv.org/abs/2508.15093)
*Yan Luo,Drake Du,Hao Huang,Yi Fang,Mengyu Wang*

Main category: cs.CV

TL;DR: CurveFlow提出了一种新颖的流匹配框架，通过直接引入曲率指导来学习平滑的非线性轨迹，显著提升了文本到图像生成的语义一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 现有矫正流模型基于数据与噪声分布之间的线性轨迹，这种线性性可能导致图像生成过程穿越数据流形的低概率区域，影响语义对齐。

Method: 引入曲率指导并通过曲率正则化技术惩罚轨迹动态的突变，从而学习非线性轨迹。

Result: 在MS COCO数据集上的实验表明，CurveFlow在语义一致性指标（如BLEU、METEOR等）上优于其他方法，同时保持高图像质量。

Conclusion: 曲率感知建模能显著提升模型在遵循复杂指令时的能力，并保持图像质量，代码已公开。

Abstract: Existing rectified flow models are based on linear trajectories between data
and noise distributions. This linearity enforces zero curvature, which can
inadvertently force the image generation process through low-probability
regions of the data manifold. A key question remains underexplored: how does
the curvature of these trajectories correlate with the semantic alignment
between generated images and their corresponding captions, i.e., instructional
compliance? To address this, we introduce CurveFlow, a novel flow matching
framework designed to learn smooth, non-linear trajectories by directly
incorporating curvature guidance into the flow path. Our method features a
robust curvature regularization technique that penalizes abrupt changes in the
trajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017
demonstrate that CurveFlow achieves state-of-the-art performance in
text-to-image generation, significantly outperforming both standard rectified
flow variants and other non-linear baselines like Rectified Diffusion. The
improvements are especially evident in semantic consistency metrics such as
BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling
substantially enhances the model's ability to faithfully follow complex
instructions while simultaneously maintaining high image quality. The code is
made publicly available at
https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.

</details>


### [9] [HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment](https://arxiv.org/abs/2508.15130)
*Vaishnav Ramesh,Haining Wang,Md Jahidul Islam*

Main category: cs.CV

TL;DR: 提出了一种自监督的HiRQA框架，通过排名和对比学习实现无参考图像质量评估（NR-IQA），并在多种失真条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的NR-IQA方法受限于数据集偏差和主观标签，无法泛化。HiRQA旨在通过自监督和基于排名的学习解决这一问题。

Method: HiRQA结合了排名损失和对比学习损失，通过分层嵌入和结构化文本提示提升表示能力。还提出了轻量级变体HiRQA-S。

Result: HiRQA在合成和真实失真数据集上表现优异，推理速度快（3.5 ms/图），泛化能力强。

Conclusion: HiRQA是NR-IQA领域的新基准，具有高效、泛化和可扩展的特性。

Abstract: Despite significant progress in no-reference image quality assessment
(NR-IQA), dataset biases and reliance on subjective labels continue to hinder
their generalization performance. We propose HiRQA, Hierarchical Ranking and
Quality Alignment), a self-supervised, opinion-unaware framework that offers a
hierarchical, quality-aware embedding through a combination of ranking and
contrastive learning. Unlike prior approaches that depend on pristine
references or auxiliary modalities at inference time, HiRQA predicts quality
scores using only the input image. We introduce a novel higher-order ranking
loss that supervises quality predictions through relational ordering across
distortion pairs, along with an embedding distance loss that enforces
consistency between feature distances and perceptual differences. A
training-time contrastive alignment loss, guided by structured textual prompts,
further enhances the learned representation. Trained only on synthetic
distortions, HiRQA generalizes effectively to authentic degradations, as
demonstrated through evaluation on various distortions such as lens flare,
haze, motion blur, and low-light conditions. For real-time deployment, we
introduce \textbf{HiRQA-S}, a lightweight variant with an inference time of
only 3.5 ms per image. Extensive experiments across synthetic and authentic
benchmarks validate HiRQA's state-of-the-art (SOTA) performance, strong
generalization ability, and scalability.

</details>


### [10] [Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments](https://arxiv.org/abs/2508.15158)
*Md. Nurul Absur,Abhinav Kumar,Swastik Brahma,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 本文提出了一种基于投资组合理论的边缘资源管理策略，用于在多视图3D重建中应对系统中断，确保重建质量。


<details>
  <summary>Details</summary>
Motivation: 在多视图3D重建中，边缘环境的动态性和操作困难可能导致相机中断，进而影响重建质量。

Method: 采用投资组合理论优化相机选择问题，并通过遗传算法快速求解。

Result: 实验表明，该方法在时空中断下显著优于传统基线策略。

Conclusion: 该方法能有效保证3D重建的可靠性，适用于动态边缘环境。

Abstract: Multi-view 3D reconstruction applications are revolutionizing critical use
cases that require rapid situational-awareness, such as emergency response,
tactical scenarios, and public safety. In many cases, their near-real-time
latency requirements and ad-hoc needs for compute resources necessitate
adoption of `Just-in-time' edge environments where the system is set up on the
fly to support the applications during the mission lifetime. However,
reliability issues can arise from the inherent dynamism and operational
adversities of such edge environments, resulting in spatiotemporally correlated
disruptions that impact the camera operations, which can lead to sustained
degradation of reconstruction quality. In this paper, we propose a novel
portfolio theory inspired edge resource management strategy for reliable
multi-view 3D reconstruction against possible system disruptions. Our proposed
methodology can guarantee reconstruction quality satisfaction even when the
cameras are prone to spatiotemporally correlated disruptions. The portfolio
theoretic optimization problem is solved using a genetic algorithm that
converges quickly for realistic system settings. Using publicly available and
customized 3D datasets, we demonstrate the proposed camera selection strategy's
benefits in guaranteeing reliable 3D reconstruction against traditional
baseline strategies, under spatiotemporal disruptions.

</details>


### [11] [XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2508.15168)
*Masato Ito,Kaito Tanaka,Keisuke Matsuda,Aya Nakayama*

Main category: cs.CV

TL;DR: 论文提出XDR-LVLM框架，结合视觉-语言大模型，为糖尿病视网膜病变提供高精度的诊断与自然语言解释，显著提升临床实用性。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球失明的主要原因，深度学习模型因其黑箱特性缺乏透明度和可解释性，阻碍了临床采用。

Method: XDR-LVLM整合医学视觉编码器和LVLM核心，通过多任务提示工程和多阶段微调，生成包含病情分级、关键病理特征识别的诊断报告。

Result: 在DDR数据集上，XDR-LVLM表现优异，疾病诊断平衡准确率达84.55%，F1分数79.92%，概念检测结果也优于同类模型。

Conclusion: XDR-LVLM通过提供可解释的诊断报告，在自动化诊断与临床需求之间搭建桥梁，展示出高流畅性和临床实用性。

Abstract: Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating
early and accurate diagnosis. While deep learning models have shown promise in
DR detection, their black-box nature often hinders clinical adoption due to a
lack of transparency and interpretability. To address this, we propose XDR-LVLM
(eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that
leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis
coupled with natural language-based explanations. XDR-LVLM integrates a
specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt
Engineering and Multi-stage Fine-tuning to deeply understand pathological
features within fundus images and generate comprehensive diagnostic reports.
These reports explicitly include DR severity grading, identification of key
pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and
detailed explanations linking observed features to the diagnosis. Extensive
experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM
achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and
an F1 Score of 79.92% for disease diagnosis, and superior results for concept
detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the
high fluency, accuracy, and clinical utility of the generated explanations,
showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and
clinical needs by providing robust and interpretable insights.

</details>


### [12] [MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion](https://arxiv.org/abs/2508.15169)
*Xuyang Chen,Zhijun Zhai,Kaixuan Zhou,Zengmao Wang,Jianan He,Dong Wang,Yanfeng Zhang,mingwei Sun,Rüdiger Westermann,Konrad Schindler,Liqiu Meng*

Main category: cs.CV

TL;DR: 利用MeSS方法生成高质量、风格一致的户外场景，结合ControlNet增强几何对齐。


<details>
  <summary>Details</summary>
Motivation: 解决城市网格模型缺乏真实纹理的问题，以支持虚拟城市导航和自动驾驶。

Method: 采用三个阶段：生成几何一致稀疏视图、传播更密集中间视图、全局消除视觉不一致。同时重建3D高斯泼溅场景。

Result: 在几何对齐和生成质量上优于现有方法，并支持多样化的风格渲染。

Conclusion: MeSS方法有效提升了3D场景生成的几何一致性和视觉质量，具有广泛的应用潜力。

Abstract: Mesh models have become increasingly accessible for numerous cities; however,
the lack of realistic textures restricts their application in virtual urban
navigation and autonomous driving. To address this, this paper proposes MeSS
(Meshbased Scene Synthesis) for generating high-quality, styleconsistent
outdoor scenes with city mesh models serving as the geometric prior. While
image and video diffusion models can leverage spatial layouts (such as depth
maps or HD maps) as control conditions to generate street-level perspective
views, they are not directly applicable to 3D scene generation. Video diffusion
models excel at synthesizing consistent view sequences that depict scenes but
often struggle to adhere to predefined camera paths or align accurately with
rendered control videos. In contrast, image diffusion models, though unable to
guarantee cross-view visual consistency, can produce more geometry-aligned
results when combined with ControlNet. Building on this insight, our approach
enhances image diffusion models by improving cross-view consistency. The
pipeline comprises three key stages: first, we generate geometrically
consistent sparse views using Cascaded Outpainting ControlNets; second, we
propagate denser intermediate views via a component dubbed AGInpaint; and
third, we globally eliminate visual inconsistencies (e.g., varying exposure)
using the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting
(3DGS) scene is reconstructed by initializing Gaussian balls on the mesh
surface. Our method outperforms existing approaches in both geometric alignment
and generation quality. Once synthesized, the scene can be rendered in diverse
styles through relighting and style transfer techniques.

</details>


### [13] [SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis](https://arxiv.org/abs/2508.15189)
*Jiahao Xu,Changchang Yin,Odysseas Chatzipanagiotou,Diamantis Tsilimigras,Kevin Clear,Bingsheng Yao,Dakuo Wang,Timothy Pawlik,Ping Zhang*

Main category: cs.CV

TL;DR: 该论文提出了首个开源手术伤口数据集SurgWound，并建立了手术伤口诊断基准，同时开发了一个三阶段学习框架WoundQwen，用于个性化伤口护理。


<details>
  <summary>Details</summary>
Motivation: 手术部位感染(SSI)是一个常见且昂贵的临床问题，当前缺乏公开数据集和工具。为解决这一问题，论文旨在填补这一空白。

Method: 论文提出了SurgWound数据集和一个三阶段学习框架WoundQwen，包括特征预测、诊断生成和综合报告生成。

Result: SurgWound数据集包含697张手术伤口图像，WoundQwen框架能够分析伤口特征并提供个性化护理建议。

Conclusion: 该研究为手术伤口筛查提供了开源工具和基准，有望改善患者治疗效果。

Abstract: Surgical site infection (SSI) is one of the most common and costly
healthcare-associated infections and and surgical wound care remains a
significant clinical challenge in preventing SSIs and improving patient
outcomes. While recent studies have explored the use of deep learning for
preliminary surgical wound screening, progress has been hindered by concerns
over data privacy and the high costs associated with expert annotation.
Currently, no publicly available dataset or benchmark encompasses various types
of surgical wounds, resulting in the absence of an open-source Surgical-Wound
screening tool. To address this gap: (1) we present SurgWound, the first
open-source dataset featuring a diverse array of surgical wound types. It
contains 697 surgical wound images annotated by 3 professional surgeons with
eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce
the first benchmark for surgical wound diagnosis, which includes visual
question answering (VQA) and report generation tasks to comprehensively
evaluate model performance. (3) Furthermore, we propose a three-stage learning
framework, WoundQwen, for surgical wound diagnosis. In the first stage, we
employ five independent MLLMs to accurately predict specific surgical wound
characteristics. In the second stage, these predictions serve as additional
knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess
infection risk and guide subsequent interventions. In the third stage, we train
a MLLM that integrates the diagnostic results from the previous two stages to
produce a comprehensive report. This three-stage framework can analyze detailed
surgical wound characteristics and provide subsequent instructions to patients
based on surgical images, paving the way for personalized wound care, timely
intervention, and improved patient outcomes.

</details>


### [14] [Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning](https://arxiv.org/abs/2508.15207)
*Arjun Srinivasan,Anubhav Paras,Aniket Bera*

Main category: cs.CV

TL;DR: 提出一种基于学习的方法，用于为规则驱动的智能体生成对抗行为，以模拟失败场景，并验证其对累积奖励的负面影响。


<details>
  <summary>Details</summary>
Motivation: 在安全关键的自主驾驶等领域，需要正确建模规则驱动的智能体行为，但现有方法对此不足。

Method: 采用学习驱动的对抗智能体技术，针对规则驱动的智能体生成对抗行为。

Result: 对抗智能体有效降低了规则智能体的累积奖励，验证其破坏性。

Conclusion: 通过对抗学习方法可以揭示规则驱动智能体的潜在弱点，对安全应用有重要意义。

Abstract: Existing approaches in reinforcement learning train an agent to learn desired
optimal behavior in an environment with rule based surrounding agents. In
safety critical applications such as autonomous driving it is crucial that the
rule based agents are modelled properly. Several behavior modelling strategies
and IDM models are used currently to model the surrounding agents. We present a
learning based method to derive the adversarial behavior for the rule based
agents to cause failure scenarios. We evaluate our adversarial agent against
all the rule based agents and show the decrease in cumulative reward.

</details>


### [15] [DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology](https://arxiv.org/abs/2508.15208)
*Leiyue Zhao,Yuechen Yang,Yanfan Zhu,Haichun Yang,Yuankai Huo,Paul D. Simonson,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 该论文提出了一种动态、形态学引导的二元至实例分割框架DyMorph-B2I，用于肾脏病理学中的精确实例分割，显著提升了现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有肾脏病理学数据集和自动化方法多仅提供二元（语义）掩码，限制了形态学定量分析的精度，而传统后处理技术在复杂肾脏组织形态和连接性下效果有限。

Method: DyMorph-B2I结合分水岭、骨架化和形态学操作，通过自适应几何优化和可调超参数实现精确实例分割。

Result: 实验表明，该方法优于单一传统技术及其简单组合，显著提升了实例分离效果和形态学分析精度。

Conclusion: DyMorph-B2I为肾脏病理学提供了一个高效的分割工具，开源代码便于实际应用。

Abstract: Accurate morphological quantification of renal pathology functional units
relies on instance-level segmentation, yet most existing datasets and automated
methods provide only binary (semantic) masks, limiting the precision of
downstream analyses. Although classical post-processing techniques such as
watershed, morphological operations, and skeletonization, are often used to
separate semantic masks into instances, their individual effectiveness is
constrained by the diverse morphologies and complex connectivity found in renal
tissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided
binary-to-instance segmentation pipeline tailored for renal pathology. Our
approach integrates watershed, skeletonization, and morphological operations
within a unified framework, complemented by adaptive geometric refinement and
customizable hyperparameter tuning for each class of functional unit. Through
systematic parameter optimization, DyMorph-B2I robustly separates adherent and
heterogeneous structures present in binary masks. Experimental results
demonstrate that our method outperforms individual classical approaches and
na\"ive combinations, enabling superior instance separation and facilitating
more accurate morphometric analysis in renal pathology workflows. The pipeline
is publicly available at: https://github.com/ddrrnn123/DyMorph-B2I.

</details>


### [16] [STAGNet: A Spatio-Temporal Graph and LSTM Framework for Accident Anticipation](https://arxiv.org/abs/2508.15216)
*Vipooshan Vipulananthan,Kumudu Mohottala,Kavindu Chinthana,Nimsara Paramulla,Charith D Chitraranjan*

Main category: cs.CV

TL;DR: 通过改进时空特征并结合循环网络，STAGNet模型在基于行车记录仪视频的事故预测中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提高道路安全，通过预测事故减少人员伤害和财产损失。

Method: 利用改进的时空特征，通过循环网络聚合，优化图神经网络模型。

Result: 在三个公开数据集上，STAGNet的平均精度和碰撞时间预测优于现有方法。

Conclusion: STAGNet在事故预测任务中表现出色，具有更好的泛化能力。

Abstract: Accident prediction and timely warnings play a key role in improving road
safety by reducing the risk of injury to road users and minimizing property
damage. Advanced Driver Assistance Systems (ADAS) are designed to support human
drivers and are especially useful when they can anticipate potential accidents
before they happen. While many existing systems depend on a range of sensors
such as LiDAR, radar, and GPS, relying solely on dash-cam video input presents
a more challenging but a more cost-effective and easily deployable solution. In
this work, we incorporate better spatio-temporal features and aggregate them
through a recurrent network to improve upon state-of-the-art graph neural
networks for predicting accidents from dash-cam videos. Experiments using three
publicly available datasets show that our proposed STAGNet model achieves
higher average precision and mean time-to-collision values than previous
methods, both when cross-validated on a given dataset and when trained and
tested on different datasets.

</details>


### [17] [Collaborative Multi-Modal Coding for High-Quality 3D Generation](https://arxiv.org/abs/2508.15228)
*Ziang Cao,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: TriMM是一种利用多模态数据（如RGB、RGBD和点云）的3D生成模型，通过协作多模态编码和辅助监督信号，提升3D资产的纹理和几何质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型通常局限于单模态数据或3D结构，忽略了多模态数据的互补优势。TriMM旨在通过多模态学习克服这一限制。

Method: 1. 协作多模态编码整合模态特性；2. 引入2D和3D辅助监督提升鲁棒性；3. 使用三平面潜在扩散模型生成高质量3D资产。

Result: TriMM在小规模训练数据下表现出色，实验验证了其性能与更大规模数据集训练的模型相当。

Conclusion: TriMM证明了多模态数据在3D生成中的潜力，并展示了与其他模态数据集结合的可行性。

Abstract: 3D content inherently encompasses multi-modal characteristics and can be
projected into different modalities (e.g., RGB images, RGBD, and point clouds).
Each modality exhibits distinct advantages in 3D asset modeling: RGB images
contain vivid 3D textures, whereas point clouds define fine-grained 3D
geometries. However, most existing 3D-native generative architectures either
operate predominantly within single-modality paradigms-thus overlooking the
complementary benefits of multi-modality data-or restrict themselves to 3D
structures, thereby limiting the scope of available training datasets. To
holistically harness multi-modalities for 3D modeling, we present TriMM, the
first feed-forward 3D-native generative model that learns from basic
multi-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM
first introduces collaborative multi-modal coding, which integrates
modality-specific features while preserving their unique representational
strengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to
raise the robustness and performance of multi-modal coding. 3) Based on the
embedded multi-modal code, TriMM employs a triplane latent diffusion model to
generate 3D assets of superior quality, enhancing both the texture and the
geometric detail. Extensive experiments on multiple well-known datasets
demonstrate that TriMM, by effectively leveraging multi-modality, achieves
competitive performance with models trained on large-scale datasets, despite
utilizing a small amount of training data. Furthermore, we conduct additional
experiments on recent RGB-D datasets, verifying the feasibility of
incorporating other multi-modal datasets into 3D generation.

</details>


### [18] [Center-Oriented Prototype Contrastive Clustering](https://arxiv.org/abs/2508.15231)
*Shihao Dong,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 提出了一种基于软原型对比和双一致学习的聚类框架，解决了类间冲突和原型偏移问题，实验证明效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法在聚类任务中存在类间冲突问题，原型计算方法与真实聚类中心有偏差。

Method: 提出中心导向的原型对比聚类框架，包括软原型对比模块（加权计算原型减少冲突）和双一致学习模块（对齐样本变换与邻居样本）。

Result: 在五个数据集上实验表明，该方法优于现有SOTA方法。

Conclusion: 所提框架有效解决了类间冲突和原型偏移问题，提升了聚类性能。

Abstract: Contrastive learning is widely used in clustering tasks due to its
discriminative representation. However, the conflict problem between classes is
difficult to solve effectively. Existing methods try to solve this problem
through prototype contrast, but there is a deviation between the calculation of
hard prototypes and the true cluster center. To address this problem, we
propose a center-oriented prototype contrastive clustering framework, which
consists of a soft prototype contrastive module and a dual consistency learning
module. In short, the soft prototype contrastive module uses the probability
that the sample belongs to the cluster center as a weight to calculate the
prototype of each category, while avoiding inter-class conflicts and reducing
prototype drift. The dual consistency learning module aligns different
transformations of the same sample and the neighborhoods of different samples
respectively, ensuring that the features have transformation-invariant semantic
information and compact intra-cluster distribution, while providing reliable
guarantees for the calculation of prototypes. Extensive experiments on five
datasets show that the proposed method is effective compared to the SOTA. Our
code is published on https://github.com/LouisDong95/CPCC.

</details>


### [19] [AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation](https://arxiv.org/abs/2508.15232)
*Ruipu Wu,Yige Zhang,Jinyu Chen,Linjiang Huang,Shifeng Zhang,Xu Zhou,Liang Wang,Si Liu*

Main category: cs.CV

TL;DR: 论文提出了一种新的双高度无人机协作视觉与语言导航任务（DuAl-VLN），通过高低空无人机的协作，解决传统无人机-VLN任务中长轨迹和复杂机动性的挑战，并发布了HaL-13k数据集。


<details>
  <summary>Details</summary>
Motivation: 传统无人机-VLN任务中，由于轨迹长和机动性复杂，性能不稳定且依赖人工干预或详细指令。高低空无人机协作可以兼顾大范围环境推理和精确导航。

Method: 提出DuAl-VLN任务，构建HaL-13k数据集；设计双无人机协作框架AeroDuo，高低空无人机分别负责目标推理和导航。

Result: 通过高低空无人机的协作，实现了高效的导航和目标定位，验证了框架的泛化能力。

Conclusion: 双高度无人机协作VLN任务通过高低空分工，显著提升了导航效率和泛化能力，为无人机自主导航提供了新思路。

Abstract: Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables
Unmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural
language instructions and visual cues. However, due to the extended
trajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN
performance is challenging and often requires human intervention or overly
detailed instructions. To harness the advantages of UAVs' high mobility, which
could provide multi-grained perspectives, while maintaining a manageable motion
space for learning, we introduce a novel task called Dual-Altitude UAV
Collaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct
altitudes: a high-altitude UAV responsible for broad environmental reasoning,
and a low-altitude UAV tasked with precise navigation. To support the training
and evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising
13,838 collaborative high-low UAV demonstration trajectories, each paired with
target-oriented language instructions. This dataset includes both unseen maps
and an unseen object validation set to systematically evaluate the model's
generalization capabilities across novel environments and unfamiliar targets.
To consolidate their complementary strengths, we propose a dual-UAV
collaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a
multimodal large language model (Pilot-LLM) for target reasoning, while the
low-altitude UAV employs a lightweight multi-stage policy for navigation and
target grounding. The two UAVs work collaboratively and only exchange minimal
coordinate information to ensure efficiency.

</details>


### [20] [Pretrained Diffusion Models Are Inherently Skipped-Step Samplers](https://arxiv.org/abs/2508.15233)
*Wenju Xu*

Main category: cs.CV

TL;DR: 论文提出了一种跳过步骤采样机制，通过马尔科夫方式加速扩散模型的生成过程，同时保持训练目标不变。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然在各生成任务中表现优异，但其顺序生成过程耗时较长；现有方法（如DDIM）通过非马尔科夫过程减少采样步骤，但缺乏对原始扩散模型能否同样高效的探究。

Method: 提出了跳过步骤采样机制，绕过中间去噪步骤，并通过与DDIM结合进一步优化生成。

Result: 实验表明，该方法在多种预训练扩散模型上显著减少了采样步骤，同时保持高质量的生成结果。

Conclusion: 跳过步骤采样是预训练扩散模型的内在特性，能以马尔科夫方式高效生成，且与DDIM结合效果更佳。

Abstract: Diffusion models have been achieving state-of-the-art results across various
generation tasks. However, a notable drawback is their sequential generation
process, requiring long-sequence step-by-step generation. Existing methods,
such as DDIM, attempt to reduce sampling steps by constructing a class of
non-Markovian diffusion processes that maintain the same training objective.
However, there remains a gap in understanding whether the original diffusion
process can achieve the same efficiency without resorting to non-Markovian
processes. In this paper, we provide a confirmative answer and introduce
skipped-step sampling, a mechanism that bypasses multiple intermediate
denoising steps in the iterative generation process, in contrast with the
traditional step-by-step refinement of standard diffusion inference. Crucially,
we demonstrate that this skipped-step sampling mechanism is derived from the
same training objective as the standard diffusion model, indicating that
accelerated sampling via skipped-step sampling via a Markovian way is an
intrinsic property of pretrained diffusion models. Additionally, we propose an
enhanced generation method by integrating our accelerated sampling technique
with DDIM. Extensive experiments on popular pretrained diffusion models,
including the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our
method achieves high-quality generation with significantly reduced sampling
steps.

</details>


### [21] [Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent](https://arxiv.org/abs/2508.15243)
*Yixin Gao,Xin Li,Xiaohan Pan,Runsen Feng,Bingchen Li,Yunpeng Qi,Yiting Lu,Zhengxue Cheng,Zhibo Chen,Jörn Ostermann*

Main category: cs.CV

TL;DR: Comp-X 是首个基于大型语言模型（LLM）智能交互的图像压缩范式，通过多功能编码框架、交互式编码代理和专用基准测试，实现了高效且用户友好的图像压缩。


<details>
  <summary>Details</summary>
Motivation: 传统图像编解码器依赖工程师手动选择编码模式，对非专业用户不友好。Comp-X旨在通过智能交互提升编码范式，解决这一问题。

Method: 提出三种创新：1）多功能编码框架，统一多种编码模式；2）交互式编码代理，利用上下文学习训练LLM代理；3）IIC-bench基准测试，用于智能交互评估。

Result: 实验表明，Comp-X能高效理解编码需求并实现出色的交互能力，同时保持与传统方法相当的压缩性能。

Conclusion: Comp-X为图像压缩领域的人工通用智能（AGI）提供了有前景的方向。

Abstract: We present Comp-X, the first intelligently interactive image compression
paradigm empowered by the impressive reasoning capability of large language
model (LLM) agent. Notably, commonly used image codecs usually suffer from
limited coding modes and rely on manual mode selection by engineers, making
them unfriendly for unprofessional users. To overcome this, we advance the
evolution of image coding paradigm by introducing three key innovations: (i)
multi-functional coding framework, which unifies different coding modes of
various objective/requirements, including human-machine perception, variable
coding, and spatial bit allocation, into one framework. (ii) interactive coding
agent, where we propose an augmented in-context learning method with coding
expert feedback to teach the LLM agent how to understand the coding request,
mode selection, and the use of the coding tools. (iii) IIC-bench, the first
dedicated benchmark comprising diverse user requests and the corresponding
annotations from coding experts, which is systematically designed for
intelligently interactive image compression evaluation. Extensive experimental
results demonstrate that our proposed Comp-X can understand the coding requests
efficiently and achieve impressive textual interaction capability. Meanwhile,
it can maintain comparable compression performance even with a single coding
framework, providing a promising avenue for artificial general intelligence
(AGI) in image compression.

</details>


### [22] [Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images](https://arxiv.org/abs/2508.15256)
*Jinsol Song,Jiamu Wang,Anh Tien Nguyen,Keunho Byeon,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak*

Main category: cs.CV

TL;DR: Ano-NAViLa 是一种基于预训练视觉语言模型的异常检测方法，通过结合正常和异常病理知识，提高了病理图像中的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有异常检测方法在病理图像中的局限性，如计算限制、组织多样性及缺乏可解释性。

Method: 构建于预训练视觉语言模型上，结合轻量级MLP，整合正常和异常病理知识。

Result: 在两个淋巴结数据集上实现了最先进的异常检测和定位性能。

Conclusion: Ano-NAViLa在病理图像异常检测中表现出优越性能和可解释性。

Abstract: Anomaly detection in computational pathology aims to identify rare and scarce
anomalies where disease-related data are often limited or missing. Existing
anomaly detection methods, primarily designed for industrial settings, face
limitations in pathology due to computational constraints, diverse tissue
structures, and lack of interpretability. To address these challenges, we
propose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented
Vision-Language model for Anomaly detection in pathology images. Ano-NAViLa is
built on a pre-trained vision-language model with a lightweight trainable MLP.
By incorporating both normal and abnormal pathology knowledge, Ano-NAViLa
enhances accuracy and robustness to variability in pathology images and
provides interpretability through image-text associations. Evaluated on two
lymph node datasets from different organs, Ano-NAViLa achieves the
state-of-the-art performance in anomaly detection and localization,
outperforming competing models.

</details>


### [23] [RATopo: Improving Lane Topology Reasoning via Redundancy Assignment](https://arxiv.org/abs/2508.15272)
*Han Li,Shaofei Huang,Longfei Xu,Yulu Gao,Beipeng Mu,Si Liu*

Main category: cs.CV

TL;DR: RATopo是一种冗余分配策略，通过改进Transformer解码器结构，实现多对一的监督，提升车道拓扑推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有车道拓扑推理方法采用一对一分配监督，监督范围有限，导致性能不佳。

Method: 通过交换Transformer解码器的交叉注意力和自注意力层，保留冗余车道预测，并实例化多个并行交叉注意力块提升多样性。

Result: 在OpenLane-V2数据集上，RATopo显著提升了车道间及车道-交通元素的拓扑推理性能。

Conclusion: RATopo模型无关且可无缝集成至现有框架，持续改进拓扑推理效果。

Abstract: Lane topology reasoning plays a critical role in autonomous driving by
modeling the connections among lanes and the topological relationships between
lanes and traffic elements. Most existing methods adopt a
first-detect-then-reason paradigm, where topological relationships are
supervised based on the one-to-one assignment results obtained during the
detection stage. This supervision strategy results in suboptimal topology
reasoning performance due to the limited range of valid supervision. In this
paper, we propose RATopo, a Redundancy Assignment strategy for lane Topology
reasoning that enables quantity-rich and geometry-diverse topology supervision.
Specifically, we restructure the Transformer decoder by swapping the
cross-attention and self-attention layers. This allows redundant lane
predictions to be retained before suppression, enabling effective one-to-many
assignment. We also instantiate multiple parallel cross-attention blocks with
independent parameters, which further enhances the diversity of detected lanes.
Extensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is
model-agnostic and can be seamlessly integrated into existing topology
reasoning frameworks, consistently improving both lane-lane and lane-traffic
topology performance.

</details>


### [24] [DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding](https://arxiv.org/abs/2508.15297)
*Zhu Wang,Homaira Huda Shomee,Sathya N. Ravi,Sourav Medya*

Main category: cs.CV

TL;DR: 论文提出DesignCLIP框架，结合CLIP模型和大规模设计专利数据，改进设计专利分类与检索任务。


<details>
  <summary>Details</summary>
Motivation: 传统设计专利分析依赖图像数据，但专利图像的抽象性导致信息不足，影响评估准确性，本文利用视觉语言模型提升分析可靠性。

Method: 采用CLIP模型构建DesignCLIP框架，结合类感知分类、对比学习、图像多视图学习及生成详细图像描述。

Result: DesignCLIP在专利分类和检索任务中优于基线及SOTA模型，且多模态检索可激发设计创新。

Conclusion: 多模态方法在专利分析中具有潜力，DesignCLIP框架展示了其有效性。

Abstract: In the field of design patent analysis, traditional tasks such as patent
classification and patent image retrieval heavily depend on the image data.
However, patent images -- typically consisting of sketches with abstract and
structural elements of an invention -- often fall short in conveying
comprehensive visual context and semantic information. This inadequacy can lead
to ambiguities in evaluation during prior art searches. Recent advancements in
vision-language models, such as CLIP, offer promising opportunities for more
reliable and accurate AI-driven patent analysis. In this work, we leverage CLIP
models to develop a unified framework DesignCLIP for design patent applications
with a large-scale dataset of U.S. design patents. To address the unique
characteristics of patent data, DesignCLIP incorporates class-aware
classification and contrastive learning, utilizing generated detailed captions
for patent images and multi-views image learning. We validate the effectiveness
of DesignCLIP across various downstream tasks, including patent classification
and patent retrieval. Additionally, we explore multimodal patent retrieval,
which provides the potential to enhance creativity and innovation in design by
offering more diverse sources of inspiration. Our experiments show that
DesignCLIP consistently outperforms baseline and SOTA models in the patent
domain on all tasks. Our findings underscore the promise of multimodal
approaches in advancing patent analysis. The codebase is available here:
https://anonymous.4open.science/r/PATENTCLIP-4661/README.md.

</details>


### [25] [TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification](https://arxiv.org/abs/2508.15298)
*Darya Taratynova,Alya Almsouti,Beknur Kalmakhanbet,Numan Saeed,Mohammad Yaqub*

Main category: cs.CV

TL;DR: 论文提出了一种名为Temporal Prompt Alignment (TPA)的方法，通过结合时间建模、提示感知对比学习和不确定性量化，提高胎儿先天性心脏病（CHD）在超声视频中的分类性能。


<details>
  <summary>Details</summary>
Motivation: 超声视频中CHD检测受图像噪声和探头位置变异性影响，现有机器学习方法常忽略时间信息且仅支持二分类。TPA旨在解决这些问题，提升分类准确性和临床可靠性。

Method: TPA利用基础图像-文本模型和提示感知对比学习，从视频子片段中提取帧特征，通过可训练的时间提取器捕捉心脏运动，并与类特定文本提示对齐。此外，引入CVAESM模块来调制嵌入并量化分类不确定性。

Result: TPA在CHD检测和EchoNet-Dynamic数据集上均取得最佳性能，宏F1分数达85.40%，校准误差显著降低。在三分类任务中，宏F1提升4.73%。

Conclusion: TPA通过整合时间建模和不确定性量化，显著提高了超声视频中CHD分类的准确性和临床可靠性，为自动化诊断提供了有力工具。

Abstract: Congenital heart defect (CHD) detection in ultrasound videos is hindered by
image noise and probe positioning variability. While automated methods can
reduce operator dependence, current machine learning approaches often neglect
temporal information, limit themselves to binary classification, and do not
account for prediction calibration. We propose Temporal Prompt Alignment (TPA),
a method leveraging foundation image-text model and prompt-aware contrastive
learning to classify fetal CHD on cardiac ultrasound videos. TPA extracts
features from each frame of video subclips using an image encoder, aggregates
them with a trainable temporal extractor to capture heart motion, and aligns
the video representation with class-specific text prompts via a margin-hinge
contrastive loss. To enhance calibration for clinical reliability, we introduce
a Conditional Variational Autoencoder Style Modulation (CVAESM) module, which
learns a latent style vector to modulate embeddings and quantifies
classification uncertainty. Evaluated on a private dataset for CHD detection
and on a large public dataset, EchoNet-Dynamic, for systolic dysfunction, TPA
achieves state-of-the-art macro F1 scores of 85.40% for CHD diagnosis, while
also reducing expected calibration error by 5.38% and adaptive ECE by 6.8%. On
EchoNet-Dynamic's three-class task, it boosts macro F1 by 4.73% (from 53.89% to
58.62%). Temporal Prompt Alignment (TPA) is a framework for fetal congenital
heart defect (CHD) classification in ultrasound videos that integrates temporal
modeling, prompt-aware contrastive learning, and uncertainty quantification.

</details>


### [26] [BasketLiDAR: The First LiDAR-Camera Multimodal Dataset for Professional Basketball MOT](https://arxiv.org/abs/2508.15299)
*Ryunosuke Hayashi,Kohei Torimi,Rokuto Nagata,Kazuma Ikeda,Ozora Sako,Taichi Nakamura,Masaki Tani,Yoshimitsu Aoki,Kentaro Yoshioka*

Main category: cs.CV

TL;DR: 本文提出了BasketLiDAR数据集和新MOT框架，结合LiDAR和相机数据，实现实时3D运动员追踪，显著提高了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统多相机系统在实时3D运动员追踪中存在限制，尤其是在篮球比赛中，由于快速运动和遮挡，追踪难度大。

Method: 构建包含LiDAR点云和多视角相机数据的BasketLiDAR数据集，并提出基于LiDAR的实时和多模态追踪算法。

Result: 实验表明，新方法在实时性和遮挡条件下均优于传统相机方法。

Conclusion: BasketLiDAR和提出的框架为体育MOT领域提供了高效且准确的解决方案。

Abstract: Real-time 3D trajectory player tracking in sports plays a crucial role in
tactical analysis, performance evaluation, and enhancing spectator experience.
Traditional systems rely on multi-camera setups, but are constrained by the
inherently two-dimensional nature of video data and the need for complex 3D
reconstruction processing, making real-time analysis challenging. Basketball,
in particular, represents one of the most difficult scenarios in the MOT field,
as ten players move rapidly and complexly within a confined court space, with
frequent occlusions caused by intense physical contact.
  To address these challenges, this paper constructs BasketLiDAR, the first
multimodal dataset in the sports MOT field that combines LiDAR point clouds
with synchronized multi-view camera footage in a professional basketball
environment, and proposes a novel MOT framework that simultaneously achieves
improved tracking accuracy and reduced computational cost. The BasketLiDAR
dataset contains a total of 4,445 frames and 3,105 player IDs, with fully
synchronized IDs between three LiDAR sensors and three multi-view cameras. We
recorded 5-on-5 and 3-on-3 game data from actual professional basketball
players, providing complete 3D positional information and ID annotations for
each player. Based on this dataset, we developed a novel MOT algorithm that
leverages LiDAR's high-precision 3D spatial information. The proposed method
consists of a real-time tracking pipeline using LiDAR alone and a multimodal
tracking pipeline that fuses LiDAR and camera data. Experimental results
demonstrate that our approach achieves real-time operation, which was difficult
with conventional camera-only methods, while achieving superior tracking
performance even under occlusion conditions. The dataset is available upon
request at: https://sites.google.com/keio.jp/keio-csg/projects/basket-lidar

</details>


### [27] [First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection](https://arxiv.org/abs/2508.15313)
*Wutao Liu,YiDan Wang,Pan Gao*

Main category: cs.CV

TL;DR: RAG-SEG是一种无需训练的方法，通过两阶段（RAG生成粗掩码和SAM细化）解决伪装目标检测问题，计算高效且性能优异。


<details>
  <summary>Details</summary>
Motivation: 伪装目标检测（COD）中目标与背景高度相似，现有方法依赖大量计算资源，而基础模型如SAM需要高质量提示且难以直接应用于COD任务。

Method: 提出RAG-SEG，通过检索增强生成（RAG）生成粗掩码作为提示，再使用SAM进行细化，无需训练。

Result: 在多个COD基准数据集上表现优异，计算效率高，仅需个人笔记本电脑即可完成实验。

Conclusion: RAG-SEG提供了一种高效、无需训练的COD解决方案，性能与现有方法相当或更优。

Abstract: Camouflaged object detection (COD) poses a significant challenge in computer
vision due to the high similarity between objects and their backgrounds.
Existing approaches often rely on heavy training and large computational
resources. While foundation models such as the Segment Anything Model (SAM)
offer strong generalization, they still struggle to handle COD tasks without
fine-tuning and require high-quality prompts to yield good performance.
However, generating such prompts manually is costly and inefficient. To address
these challenges, we propose \textbf{First RAG, Second SEG (RAG-SEG)}, a
training-free paradigm that decouples COD into two stages: Retrieval-Augmented
Generation (RAG) for generating coarse masks as prompts, followed by SAM-based
segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval
database via unsupervised clustering, enabling fast and effective feature
retrieval. During inference, the retrieved features produce pseudo-labels that
guide precise mask generation using SAM2. Our method eliminates the need for
conventional training while maintaining competitive performance. Extensive
experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par
with or surpasses state-of-the-art methods. Notably, all experiments are
conducted on a \textbf{personal laptop}, highlighting the computational
efficiency and practicality of our approach. We present further analysis in the
Appendix, covering limitations, salient object detection extension, and
possible improvements.

</details>


### [28] [VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.15314)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Zhi Chen,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CV

TL;DR: VideoEraser是一种无需训练的框架，可防止文本到视频（T2V）扩散模型生成不良内容。


<details>
  <summary>Details</summary>
Motivation: 由于T2V扩散模型可能被滥用生成有害或误导性内容，作者提出VideoEraser以解决隐私、版权和安全隐患。

Method: VideoEraser通过选择性提示嵌入调整（SPEA）和抗干扰噪声引导（ARNG）两阶段方法，作为即插即用模块与现有模型集成。

Result: 实验显示，VideoEraser在四种任务中平均减少46%的不良内容生成，显著优于基线方法。

Conclusion: VideoEraser在抑制T2V生成中的不良内容方面表现出高效性、鲁棒性和普适性。

Abstract: The rapid growth of text-to-video (T2V) diffusion models has raised concerns
about privacy, copyright, and safety due to their potential misuse in
generating harmful or misleading content. These models are often trained on
numerous datasets, including unauthorized personal identities, artistic
creations, and harmful materials, which can lead to uncontrolled production and
distribution of such content. To address this, we propose VideoEraser, a
training-free framework that prevents T2V diffusion models from generating
videos with undesirable concepts, even when explicitly prompted with those
concepts. Designed as a plug-and-play module, VideoEraser can seamlessly
integrate with representative T2V diffusion models via a two-stage process:
Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise
Guidance (ARNG). We conduct extensive evaluations across four tasks, including
object erasure, artistic style erasure, celebrity erasure, and explicit content
erasure. Experimental results show that VideoEraser consistently outperforms
prior methods regarding efficacy, integrity, fidelity, robustness, and
generalizability. Notably, VideoEraser achieves state-of-the-art performance in
suppressing undesirable content during T2V generation, reducing it by 46% on
average across four tasks compared to baselines.

</details>


### [29] [Predicting Road Crossing Behaviour using Pose Detection and Sequence Modelling](https://arxiv.org/abs/2508.15336)
*Subhasis Dasgupta,Preetam Saha,Agniva Roy,Jaydip Sen*

Main category: cs.CV

TL;DR: 摘要研究了基于深度学习的行人过马路意图预测，重点比较了GRU、LSTM和1D CNN模型的性能，发现1D CNN速度最快。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要远距离预测行人是否过马路，以提高安全性。

Method: 结合姿态检测和序列建模（GRU、LSTM、1D CNN），构建端到端深度学习框架。

Result: GRU优于LSTM，1D CNN速度最佳。

Conclusion: 研究为自动驾驶提供了有效的行人意图预测方法。

Abstract: The world is constantly moving towards AI based systems and autonomous
vehicles are now reality in different parts of the world. These vehicles
require sensors and cameras to detect objects and maneuver according to that.
It becomes important to for such vehicles to also predict from a distant if a
person is about to cross a road or not. The current study focused on predicting
the intent of crossing the road by pedestrians in an experimental setup. The
study involved working with deep learning models to predict poses and sequence
modelling for temporal predictions. The study analysed three different sequence
modelling to understand the prediction behaviour and it was found out that GRU
was better in predicting the intent compared to LSTM model but 1D CNN was the
best model in terms of speed. The study involved video analysis, and the output
of pose detection model was integrated later on to sequence modelling
techniques for an end-to-end deep learning framework for predicting road
crossing intents.

</details>


### [30] [RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features](https://arxiv.org/abs/2508.15353)
*Olga Matykina,Dmitry Yudin*

Main category: cs.CV

TL;DR: RCDINO是一种基于多模态Transformer的模型，通过融合DINOv2预训练模型的语义丰富表示，提升了自动驾驶和机器人领域中三维物体检测的性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶和机器人领域，有效的多模态数据融合对三维物体检测至关重要。

Method: RCDINO结合了视觉主干特征和DINOv2预训练模型的语义表示，提升了检测性能。

Result: 在nuScenes数据集上，RCDINO实现了56.4 NDS和48.1 mAP，达到雷达-相机模型的最先进性能。

Conclusion: RCDINO通过融合DINOv2的语义表示，显著提升了检测性能，同时保持了基线架构的兼容性。

Abstract: Three-dimensional object detection is essential for autonomous driving and
robotics, relying on effective fusion of multimodal data from cameras and
radar. This work proposes RCDINO, a multimodal transformer-based model that
enhances visual backbone features by fusing them with semantically rich
representations from the pretrained DINOv2 foundation model. This approach
enriches visual representations and improves the model's detection performance
while preserving compatibility with the baseline architecture. Experiments on
the nuScenes dataset demonstrate that RCDINO achieves state-of-the-art
performance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our
implementation is available at https://github.com/OlgaMatykina/RCDINO.

</details>


### [31] [An Empirical Study on How Video-LLMs Answer Video Questions](https://arxiv.org/abs/2508.15360)
*Chenhui Gou,Ziyu Ma,Zicheng Duan,Haoyu He,Feng Chen,Akide Liu,Bohan Zhuang,Jianfei Cai,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 本文通过注意力敲除方法，系统地研究了视频大型语言模型（Video-LLMs）的内部机制，揭示了信息处理的关键层和空间-时间建模的依赖特性，并提出效率优化方向。


<details>
  <summary>Details</summary>
Motivation: 尽管Video-LLMs在视频问答中表现优异，但其内部机制缺乏深入研究。本文旨在填补这一空白，通过注意力敲除方法揭示其工作原理。

Method: 采用三种注意力敲除变体（视频时间、空间和语言到视频敲除），结合全局和细粒度设置，分析不同层对模型行为的影响。

Result: 发现信息提取集中在早期层，形成感知与推理两阶段；某些中间层是关键异常点；空间-时间建模更依赖语言引导的检索。这些见解可用于减少计算量。

Conclusion: 本研究首次系统揭示了Video-LLMs的内部处理机制，为未来研究提供了可解释性和效率优化的方向。

Abstract: Taking advantage of large-scale data and pretrained language models, Video
Large Language Models (Video-LLMs) have shown strong capabilities in answering
video questions. However, most existing efforts focus on improving performance,
with limited attention to understanding their internal mechanisms. This paper
aims to bridge this gap through a systematic empirical study. To interpret
existing VideoLLMs, we adopt attention knockouts as our primary analytical tool
and design three variants: Video Temporal Knockout, Video Spatial Knockout, and
Language-to-Video Knockout. Then, we apply these three knockouts on different
numbers of layers (window of layers). By carefully controlling the window of
layers and types of knockouts, we provide two settings: a global setting and a
fine-grained setting. Our study reveals three key findings: (1) Global setting
indicates Video information extraction primarily occurs in early layers,
forming a clear two-stage process -- lower layers focus on perceptual encoding,
while higher layers handle abstract reasoning; (2) In the fine-grained setting,
certain intermediate layers exert an outsized impact on video question
answering, acting as critical outliers, whereas most other layers contribute
minimally; (3) In both settings, we observe that spatial-temporal modeling
relies more on language-guided retrieval than on intra- and inter-frame
self-attention among video tokens, despite the latter's high computational
cost. Finally, we demonstrate that these insights can be leveraged to reduce
attention computation in Video-LLMs. To our knowledge, this is the first work
to systematically uncover how Video-LLMs internally process and understand
video content, offering interpretability and efficiency perspectives for future
research.

</details>


### [32] [Transfer learning optimization based on evolutionary selective fine tuning](https://arxiv.org/abs/2508.15367)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune是一种进化自适应微调技术，通过选择性微调层提高迁移学习效率，减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统微调方法更新所有参数导致过拟合和高计算成本的问题。

Method: 使用进化算法选择特定层进行微调，优化目标任务的性能。

Result: 在多个图像分类数据集上表现优于AutoRGN和LoRA，准确率和效率均有提升。

Conclusion: BioTune通过选择性微调层，降低了训练参数数量，提高了迁移学习的效率和适应性。

Abstract: Deep learning has shown substantial progress in image analysis. However, the
computational demands of large, fully trained models remain a consideration.
Transfer learning offers a strategy for adapting pre-trained models to new
tasks. Traditional fine-tuning often involves updating all model parameters,
which can potentially lead to overfitting and higher computational costs. This
paper introduces BioTune, an evolutionary adaptive fine-tuning technique that
selectively fine-tunes layers to enhance transfer learning efficiency. BioTune
employs an evolutionary algorithm to identify a focused set of layers for
fine-tuning, aiming to optimize model performance on a given target task.
Evaluation across nine image classification datasets from various domains
indicates that BioTune achieves competitive or improved accuracy and efficiency
compared to existing fine-tuning methods such as AutoRGN and LoRA. By
concentrating the fine-tuning process on a subset of relevant layers, BioTune
reduces the number of trainable parameters, potentially leading to decreased
computational cost and facilitating more efficient transfer learning across
diverse data characteristics and distributions.

</details>


### [33] [Image-Conditioned 3D Gaussian Splat Quantization](https://arxiv.org/abs/2508.15372)
*Xinshuang Liu,Runfa Blark Li,Keito Suzuki,Truong Nguyen*

Main category: cs.CV

TL;DR: 3DGS压缩方法存在存储和适应性问题，ICGS-Quantizer通过联合利用高斯间和属性间相关性及共享码本，显著提升压缩效率并适应后期场景变化。


<details>
  <summary>Details</summary>
Motivation: 解决3DGS压缩方法在存储限制设备和长期存档中面临的两大问题：压缩效率不足和缺乏对场景变化的适应性。

Method: 提出了ICGS-Quantizer，通过联合利用高斯间和属性间相关性、共享码本以及基于图像的解码条件化，实现高效压缩和场景适应。

Result: ICGS-Quantizer将3DGS存储需求降至千字节级，同时保持视觉保真度，并在压缩效率和场景适应性上优于现有方法。

Conclusion: ICGS-Quantizer显著提升了3DGS的压缩效率和适应能力，适用于大规模场景存储与动态更新。

Abstract: 3D Gaussian Splatting (3DGS) has attracted considerable attention for
enabling high-quality real-time rendering. Although 3DGS compression methods
have been proposed for deployment on storage-constrained devices, two
limitations hinder archival use: (1) they compress medium-scale scenes only to
the megabyte range, which remains impractical for large-scale scenes or
extensive scene collections; and (2) they lack mechanisms to accommodate scene
changes after long-term archival. To address these limitations, we propose an
Image-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially
enhances compression efficiency and provides adaptability to scene changes
after archiving. ICGS-Quantizer improves quantization efficiency by jointly
exploiting inter-Gaussian and inter-attribute correlations and by using shared
codebooks across all training scenes, which are then fixed and applied to
previously unseen test scenes, eliminating the overhead of per-scene codebooks.
This approach effectively reduces the storage requirements for 3DGS to the
kilobyte range while preserving visual fidelity. To enable adaptability to
post-archival scene changes, ICGS-Quantizer conditions scene decoding on images
captured at decoding time. The encoding, quantization, and decoding processes
are trained jointly, ensuring that the codes, which are quantized
representations of the scene, are effective for conditional decoding. We
evaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.
Experimental results show that ICGS-Quantizer consistently outperforms
state-of-the-art methods in compression efficiency and adaptability to scene
changes. Our code, model, and data will be publicly available on GitHub.

</details>


### [34] [DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians](https://arxiv.org/abs/2508.15376)
*Cong Wang,Xianda Guo,Wenbo Xu,Wei Tian,Ruiqi Song,Chenming Zhang,Lingxi Li,Long Chen*

Main category: cs.CV

TL;DR: 本文提出DriveSplat方法，用于解决驾驶场景中3D重建的挑战，通过动态-静态解耦和区域体素初始化提升新颖视角合成的质量。


<details>
  <summary>Details</summary>
Motivation: 驾驶场景中的快速移动物体和静态背景导致现有3D高斯泼溅方法在几何关系和渲染新颖视角时表现不佳。

Method: 采用区域体素初始化解耦动态和静态成分，引入可变形神经高斯建模非刚性物体，并通过深度和法线先验优化几何结构。

Result: 在Waymo和KITTI数据集上验证了方法的高效性，实现新颖视角合成的最优性能。

Conclusion: DriveSplat通过动态-静态解耦和几何优化，显著提升了驾驶场景的3D重建质量。

Abstract: In the realm of driving scenarios, the presence of rapidly moving vehicles,
pedestrians in motion, and large-scale static backgrounds poses significant
challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian
Splatting address the motion blur problem by decoupling dynamic and static
components within the scene. However, these decoupling strategies overlook
background optimization with adequate geometry relationships and rely solely on
fitting each training view by adding Gaussians. Therefore, these models exhibit
limited robustness in rendering novel views and lack an accurate geometric
representation. To address the above issues, we introduce DriveSplat, a
high-quality reconstruction method for driving scenarios based on neural
Gaussian representations with dynamic-static decoupling. To better accommodate
the predominantly linear motion patterns of driving viewpoints, a region-wise
voxel initialization scheme is employed, which partitions the scene into near,
middle, and far regions to enhance close-range detail representation.
Deformable neural Gaussians are introduced to model non-rigid dynamic actors,
whose parameters are temporally adjusted by a learnable deformation network.
The entire framework is further supervised by depth and normal priors from
pre-trained models, improving the accuracy of geometric structures. Our method
has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating
state-of-the-art performance in novel-view synthesis for driving scenarios.

</details>


### [35] [DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability](https://arxiv.org/abs/2508.15387)
*Ruizhuo Song,Beiming Yuan*

Main category: cs.CV

TL;DR: 该论文探讨了如何通过改进深度学习方法来解决Raven渐进矩阵（RPM）问题，以提升机器智能的抽象推理能力。首先基于因果链建模设计了DIO模型，但实验显示其优化目标未能捕捉人类推理逻辑。随后提出了三种改进方法。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在抽象推理方面存在瓶颈，RPM问题被用作评估基准。论文旨在通过解决RPM问题，提升机器智能的抽象推理能力。

Method: 采用因果链建模分析RPM任务，设计了DIO模型。实验发现其优化目标不足，进而提出三种改进方法。

Result: DIO模型未有效捕捉人类推理逻辑，需进一步改进。

Conclusion: 论文通过分析RPM任务的因果链，发现了现有方法的不足，并提出了改进方向。

Abstract: Despite the outstanding performance of current deep learning models across
various domains, their fundamental bottleneck in abstract reasoning remains
unresolved. To address this challenge, the academic community has introduced
Raven's Progressive Matrices (RPM) problems as an authoritative benchmark for
evaluating the abstract reasoning capabilities of deep learning algorithms,
with a focus on core intelligence dimensions such as abstract reasoning,
pattern recognition, and complex problem-solving. Therefore, this paper centers
on solving RPM problems, aiming to contribute to enhancing the abstract
reasoning abilities of machine intelligence. Firstly, this paper adopts a
``causal chain modeling'' perspective to systematically analyze the complete
causal chain in RPM tasks: image $\rightarrow$ abstract attributes
$\rightarrow$ progressive attribute patterns $\rightarrow$ pattern consistency
$\rightarrow$ correct answer. Based on this analysis, the network architecture
of the baseline model DIO is designed. However, experiments reveal that the
optimization objective formulated for DIO, namely maximizing the variational
lower bound of mutual information between the context and the correct option,
fails to enable the model to genuinely acquire the predefined human reasoning
logic. This is attributed to two main reasons: the tightness of the lower bound
significantly impacts the effectiveness of mutual information maximization, and
mutual information, as a statistical measure, does not capture the causal
relationship between subjects and objects. To overcome these limitations, this
paper progressively proposes three improvement methods:

</details>


### [36] [Spiking Variational Graph Representation Inference for Video Summarization](https://arxiv.org/abs/2508.15389)
*Wenrui Li,Wei Han,Liang-Jian Deng,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 提出了一种名为SpiVG的神经网络，用于改进短视频摘要技术，解决了现有方法在全局时间依赖性和语义连贯性上的不足，并通过动态聚合图推理器和变分推断重建模块优化了多通道特征融合中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 短视频内容兴起，现有视频摘要技术难以捕捉全局时间依赖性及语义连贯性，且多通道特征融合中易受噪声影响。

Method: 结合脉冲神经网络（SNN）设计关键帧提取器，引入动态聚合图推理器进行细粒度推理，并使用变分推断重建模块优化特征融合中的不确定性。

Result: SpiVG在多个数据集（SumMe、TVSum、VideoXum、QFVS）上优于现有方法。

Conclusion: SpiVG通过创新设计有效提升视频摘要的信息密度和计算效率，同时减少了噪声干扰。

Abstract: With the rise of short video content, efficient video summarization
techniques for extracting key information have become crucial. However,
existing methods struggle to capture the global temporal dependencies and
maintain the semantic coherence of video content. Additionally, these methods
are also influenced by noise during multi-channel feature fusion. We propose a
Spiking Variational Graph (SpiVG) Network, which enhances information density
and reduces computational complexity. First, we design a keyframe extractor
based on Spiking Neural Networks (SNN), leveraging the event-driven computation
mechanism of SNNs to learn keyframe features autonomously. To enable
fine-grained and adaptable reasoning across video frames, we introduce a
Dynamic Aggregation Graph Reasoner, which decouples contextual object
consistency from semantic perspective coherence. We present a Variational
Inference Reconstruction Module to address uncertainty and noise arising during
multi-channel feature fusion. In this module, we employ Evidence Lower Bound
Optimization (ELBO) to capture the latent structure of multi-channel feature
distributions, using posterior distribution regularization to reduce
overfitting. Experimental results show that SpiVG surpasses existing methods
across multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes
and pre-trained models are available at https://github.com/liwrui/SpiVG.

</details>


### [37] [From Linearity to Non-Linearity: How Masked Autoencoders Capture Spatial Correlations](https://arxiv.org/abs/2508.15404)
*Anthony Bisulco,Rahul Ramesh,Randall Balestriero,Pratik Chaudhari*

Main category: cs.CV

TL;DR: MAEs作为一种视觉基础模型的预训练技术效果显著，但应用于新数据集时需要大量超参数调优。本文探讨了MAE如何学习输入图像的空间相关性，并提出了超参数选择建议。


<details>
  <summary>Details</summary>
Motivation: 针对MAEs在新数据集上需要大量超参数调优的问题，研究其如何学习图像的空间相关性，以优化超参数选择。

Method: 通过分析线性MAE学习的特征，探讨掩码比例和补丁大小如何影响特征捕获短程和长程空间相关性，并推广到非线性MAE。

Result: 发现MAE表征能够适应数据集的空间相关性，而不仅是二阶统计量，并提出了在实践中选择超参数的见解。

Conclusion: MAEs通过学习空间相关性优化表征，为实际中超参数选择提供了理论支持。

Abstract: Masked Autoencoders (MAEs) have emerged as a powerful pretraining technique
for vision foundation models. Despite their effectiveness, they require
extensive hyperparameter tuning (masking ratio, patch size, encoder/decoder
layers) when applied to novel datasets. While prior theoretical works have
analyzed MAEs in terms of their attention patterns and hierarchical latent
variable models, the connection between MAE hyperparameters and performance on
downstream tasks is relatively unexplored. This work investigates how MAEs
learn spatial correlations in the input image. We analytically derive the
features learned by a linear MAE and show that masking ratio and patch size can
be used to select for features that capture short- and long-range spatial
correlations. We extend this analysis to non-linear MAEs to show that MAE
representations adapt to spatial correlations in the dataset, beyond
second-order statistics. Finally, we discuss some insights on how to select MAE
hyper-parameters in practice.

</details>


### [38] [Bidirectional Temporal Information Propagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2508.15415)
*Dengyan Luo,Yanping Xiang,Hu Wang,Luping Ji. Shuai Li,Mao Ye*

Main category: cs.CV

TL;DR: 提出了一种双向时序信息传播方法（BIRD），用于红外小目标检测，结合局部和全局时序信息，提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的多帧方法仅通过滑动窗口聚合相邻帧信息，忽略了全局时序信息，导致冗余计算和次优性能。

Method: 设计双向传播策略，包含局部时序运动融合（LTMF）和全局时序运动融合（GTMF）模块，并引入时空融合（STF）损失联合优化。

Result: 实验表明BIRD方法在性能和推理速度上均达到最优。

Conclusion: BIRD通过双向时序信息传播策略显著提升了红外小目标检测的效果。

Abstract: Moving infrared small target detection is broadly adopted in infrared search
and track systems, and has attracted considerable research focus in recent
years. The existing learning-based multi-frame methods mainly aggregate the
information of adjacent frames in a sliding window fashion to assist the
detection of the current frame. However, the sliding-window-based methods do
not consider joint optimization of the entire video clip and ignore the global
temporal information outside the sliding window, resulting in redundant
computation and sub-optimal performance. In this paper, we propose a
Bidirectional temporal information propagation method for moving InfraRed small
target Detection, dubbed BIRD. The bidirectional propagation strategy
simultaneously utilizes local temporal information of adjacent frames and
global temporal information of past and future frames in a recursive fashion.
Specifically, in the forward and backward propagation branches, we first design
a Local Temporal Motion Fusion (LTMF) module to model local spatio-temporal
dependency between a target frame and its two adjacent frames. Then, a Global
Temporal Motion Fusion (GTMF) module is developed to further aggregate the
global propagation feature with the local fusion feature. Finally, the
bidirectional aggregated features are fused and input into the detection head
for detection. In addition, the entire video clip is jointly optimized by the
traditional detection loss and the additional Spatio-Temporal Fusion (STF)
loss. Extensive experiments demonstrate that the proposed BIRD method not only
achieves the state-of-the-art performance but also shows a fast inference
speed.

</details>


### [39] [A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles](https://arxiv.org/abs/2508.15431)
*Danish Zia Baig,Mohsin Kamal*

Main category: cs.CV

TL;DR: 论文提出了一种基于YOLOv8的深度学习方案，用于自动检测汽车表面的微观凹陷，解决了传统手动检测效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 传统汽车损伤检测方法费时且不可靠，难以检测微小缺陷，因此需要一种快速准确的自动化解决方案。

Method: 采用YOLOv8框架及其定制变体YOLOv8m-t4和YOLOv8m-t42，通过实时数据增强训练，并使用标注数据集提高鲁棒性。

Result: YOLOv8m-t42模型在微观缺陷检测中表现最佳，精度0.86，召回率0.84，F1得分0.85，优于YOLOv8m-t4。

Conclusion: YOLOv8m-t42在检测微小凹陷方面具有更高的准确性和实用性，适用于实时应用如自动化保险评估。

Abstract: Conventional car damage inspection techniques are labor-intensive, manual,
and frequently overlook tiny surface imperfections like microscopic dents.
Machine learning provides an innovative solution to the increasing demand for
quicker and more precise inspection methods. The paper uses the YOLOv8 object
recognition framework to provide a deep learning-based solution for
automatically detecting microscopic surface flaws, notably tiny dents, on car
exteriors. Traditional automotive damage inspection procedures are manual,
time-consuming, and frequently unreliable at detecting tiny flaws. To solve
this, a bespoke dataset containing annotated photos of car surfaces under
various lighting circumstances, angles, and textures was created. To improve
robustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and
YOLOv8m-t42, were trained employing real-time data augmentation approaches.
Experimental results show that the technique has excellent detection accuracy
and low inference latency, making it suited for real-time applications such as
automated insurance evaluations and automobile inspections. Evaluation
parameters such as mean Average Precision (mAP), precision, recall, and
F1-score verified the model's efficacy. With a precision of 0.86, recall of
0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4
model (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying
microscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the
mAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve
area was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82).
YOLOv8m-t42 has greater accuracy and is more appropriate for practical dent
detection applications, even though its convergence is slower.

</details>


### [40] [Aligning Moments in Time using Video Queries](https://arxiv.org/abs/2508.15439)
*Yogesh Kumar,Uday Agarwal,Manish Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: 论文提出了MATR模型，用于视频到视频时刻检索任务，通过双重序列对齐和自监督预训练技术显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决视频到视频时刻检索任务中的语义帧级对齐和复杂依赖关系建模的挑战。

Method: 采用基于Transformer的MATR模型，结合双重序列对齐和自监督预训练技术。

Result: 在ActivityNet-VRL和SportsMoments数据集上分别实现了13.1%和14.7%的R@1性能提升。

Conclusion: MATR通过创新的对齐和预训练方法，显著提升了视频时刻检索的准确性。

Abstract: Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen
events or moments in a target video using a query video. This task poses
several challenges, such as the need for semantic frame-level alignment and
modeling complex dependencies between query and target videos. To tackle this
challenging problem, we introduce MATR (Moment Alignment TRansformer), a
transformer-based model designed to capture semantic context as well as the
temporal details necessary for precise moment localization. MATR conditions
target video representations on query video features using dual-stage sequence
alignment that encodes the required correlations and dependencies. These
representations are then used to guide foreground/background classification and
boundary prediction heads, enabling the model to accurately identify moments in
the target video that semantically match with the query video. Additionally, to
provide a strong task-specific initialization for MATR, we propose a
self-supervised pre-training technique that involves training the model to
localize random clips within videos. Extensive experiments demonstrate that
MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU
on an absolute scale compared to state-of-the-art methods on the popular
ActivityNet-VRL dataset. Additionally, on our newly proposed dataset,
SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an
absolute scale over strong baselines.

</details>


### [41] [Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework](https://arxiv.org/abs/2508.15457)
*Zongqi He,Hanmin Li,Kin-Chung Chan,Yushen Zuo,Hao Xie,Zhe Xiao,Jun Xiao,Kin-Man Lam*

Main category: cs.CV

TL;DR: 提出了一种不依赖SfM的3DGS方法，用于从极稀疏视角输入中联合估计相机姿态并重建3D场景，显著提升了渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS依赖SfM初始化且需要密集多视角输入，现实中难以满足，稀疏视角下性能下降。

Method: 提出稠密立体模块和连贯视角插值模块，结合多尺度拉普拉斯正则化和自适应空间感知几何正则化。

Result: 显著优于其他方法，PSNR提升2.75dB（仅用2个训练视角），图像失真小且细节丰富。

Conclusion: 方法有效解决了稀疏视角下3DGS的性能问题，渲染质量更高。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated remarkable real-time
performance in novel view synthesis, yet its effectiveness relies heavily on
dense multi-view inputs with precisely known camera poses, which are rarely
available in real-world scenarios. When input views become extremely sparse,
the Structure-from-Motion (SfM) method that 3DGS depends on for initialization
fails to accurately reconstruct the 3D geometric structures of scenes,
resulting in degraded rendering quality. In this paper, we propose a novel
SfM-free 3DGS-based method that jointly estimates camera poses and reconstructs
3D scenes from extremely sparse-view inputs. Specifically, instead of SfM, we
propose a dense stereo module to progressively estimates camera pose
information and reconstructs a global dense point cloud for initialization. To
address the inherent problem of information scarcity in extremely sparse-view
settings, we propose a coherent view interpolation module that interpolates
camera poses based on training view pairs and generates viewpoint-consistent
content as additional supervision signals for training. Furthermore, we
introduce multi-scale Laplacian consistent regularization and adaptive
spatial-aware multi-scale geometry regularization to enhance the quality of
geometrical structures and rendered content. Experiments show that our method
significantly outperforms other state-of-the-art 3DGS-based approaches,
achieving a remarkable 2.75dB improvement in PSNR under extremely sparse-view
conditions (using only 2 training views). The images synthesized by our method
exhibit minimal distortion while preserving rich high-frequency details,
resulting in superior visual quality compared to existing techniques.

</details>


### [42] [LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion](https://arxiv.org/abs/2508.15476)
*Chengqi Dong,Fenghe Tang,Rongge Mao,Xinpei Gao,S. Kevin Zhou*

Main category: cs.CV

TL;DR: LGMSNet是一种轻量级医学图像分割框架，结合局部和全局多尺度特征，解决了现有轻量模型性能不足和通道冗余问题。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的临床环境中，急需高效且通用的轻量模型，但现有模型常因追求效率而牺牲性能，且缺乏全局感知能力。

Method: LGMSNet采用异构核提取局部高频信息，并集成稀疏Transformer-卷积混合分支捕获全局低频信息。

Result: 在六个公共数据集上的实验显示，LGMSNet性能优于现有方法，并在零样本泛化测试中表现优异。

Conclusion: LGMSNet在资源有限的医学场景中具有实际部署潜力。

Abstract: Medical image segmentation plays a pivotal role in disease diagnosis and
treatment planning, particularly in resource-constrained clinical settings
where lightweight and generalizable models are urgently needed. However,
existing lightweight models often compromise performance for efficiency and
rarely adopt computationally expensive attention mechanisms, severely
restricting their global contextual perception capabilities. Additionally,
current architectures neglect the channel redundancy issue under the same
convolutional kernels in medical imaging, which hinders effective feature
extraction. To address these challenges, we propose LGMSNet, a novel
lightweight framework based on local and global dual multiscale that achieves
state-of-the-art performance with minimal computational overhead. LGMSNet
employs heterogeneous intra-layer kernels to extract local high-frequency
information while mitigating channel redundancy. In addition, the model
integrates sparse transformer-convolutional hybrid branches to capture
low-frequency global information. Extensive experiments across six public
datasets demonstrate LGMSNet's superiority over existing state-of-the-art
methods. In particular, LGMSNet maintains exceptional performance in zero-shot
generalization tests on four unseen datasets, underscoring its potential for
real-world deployment in resource-limited medical scenarios. The whole project
code is in https://github.com/cq-dong/LGMSNet.

</details>


### [43] [MExECON: Multi-view Extended Explicit Clothed humans Optimized via Normal integration](https://arxiv.org/abs/2508.15500)
*Fulden Ece Uğur,Rafael Redondo,Albert Barreiro,Stefan Hristov,Roger Marí*

Main category: cs.CV

TL;DR: MExECON是一个新管道，用于从稀疏多视角RGB图像中进行3D重建，通过JMBO算法提高几何和姿态估计，无需网络重新训练。


<details>
  <summary>Details</summary>
Motivation: 扩展单视角方法ECON，利用多视角提高重建精度。

Method: 使用JMBO算法联合优化SMPL-X模型，并通过法线图整合细节。

Result: 在多视角下提高重建保真度，与少样本方法竞争。

Conclusion: MExECON通过多视角优化显著提升重建效果。

Abstract: This work presents MExECON, a novel pipeline for 3D reconstruction of clothed
human avatars from sparse multi-view RGB images. Building on the single-view
method ECON, MExECON extends its capabilities to leverage multiple viewpoints,
improving geometry and body pose estimation. At the core of the pipeline is the
proposed Joint Multi-view Body Optimization (JMBO) algorithm, which fits a
single SMPL-X body model jointly across all input views, enforcing multi-view
consistency. The optimized body model serves as a low-frequency prior that
guides the subsequent surface reconstruction, where geometric details are added
via normal map integration. MExECON integrates normal maps from both front and
back views to accurately capture fine-grained surface details such as clothing
folds and hairstyles. All multi-view gains are achieved without requiring any
network re-training. Experimental results show that MExECON consistently
improves fidelity over the single-view baseline and achieves competitive
performance compared to modern few-shot 3D reconstruction methods.

</details>


### [44] [Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion](https://arxiv.org/abs/2508.15505)
*Mengyu Wang,Zhenyu Liu,Kun Li,Yu Wang,Yuwei Wang,Yanyan Wei,Fei Wang*

Main category: cs.CV

TL;DR: AdaSFFuse是一种新型的多模态图像融合框架，通过自适应跨域共融合学习解决模态错位、高频细节丢失等问题，具有高效和低计算成本的优点。


<details>
  <summary>Details</summary>
Motivation: 现有多模态图像融合方法存在模态错位、高频细节破坏等问题，需要一种更通用的解决方案。

Method: 提出AdaSFFuse框架，包含自适应近似小波变换（AdaWAT）和空间-频率Mamba块，实现跨域高效融合。

Result: 在多个任务中表现优异，保持了低计算成本和小网络规模。

Conclusion: AdaSFFuse在多模态图像融合中实现了性能与效率的平衡。

Abstract: Multimodal Image Fusion (MMIF) aims to integrate complementary information
from different imaging modalities to overcome the limitations of individual
sensors. It enhances image quality and facilitates downstream applications such
as remote sensing, medical diagnostics, and robotics. Despite significant
advancements, current MMIF methods still face challenges such as modality
misalignment, high-frequency detail destruction, and task-specific limitations.
To address these challenges, we propose AdaSFFuse, a novel framework for
task-generalized MMIF through adaptive cross-domain co-fusion learning.
AdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet
Transform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba
Blocks for efficient multimodal fusion. AdaWAT adaptively separates the high-
and low-frequency components of multimodal images from different scenes,
enabling fine-grained extraction and alignment of distinct frequency
characteristics for each modality. The Spatial-Frequency Mamba Blocks
facilitate cross-domain fusion in both spatial and frequency domains, enhancing
this process. These blocks dynamically adjust through learnable mappings to
ensure robust fusion across diverse modalities. By combining these components,
AdaSFFuse improves the alignment and integration of multimodal features,
reduces frequency loss, and preserves critical details. Extensive experiments
on four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image
Fusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF)
-- demonstrate AdaSFFuse's superior fusion performance, ensuring both low
computational cost and a compact network, offering a strong balance between
performance and efficiency. The code will be publicly available at
https://github.com/Zhen-yu-Liu/AdaSFFuse.

</details>


### [45] [ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors](https://arxiv.org/abs/2508.15529)
*Kaiyuan Tan,Yingying Shen,Haohui Zhu,Zhiwei Zhan,Shan Zhao,Mingfei Tu,Hongcheng Luo,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye*

Main category: cs.CV

TL;DR: ExtraGS框架通过几何和生成先验结合，提升自动驾驶场景中视图外推的真实性和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的生成先验方法在几何一致性和渲染质量上表现不佳，需改进。

Method: 提出Road Surface Gaussian和Far Field Gaussians表示，并结合自监督不确定性估计框架。

Result: 在多个数据集和设置下验证，ExtraGS显著提升了视图外推的效果。

Conclusion: ExtraGS是一种高效且通用的解决方案，适用于复杂的自动驾驶场景模拟。

Abstract: Synthesizing extrapolated views from recorded driving logs is critical for
simulating driving scenes for autonomous driving vehicles, yet it remains a
challenging task. Recent methods leverage generative priors as pseudo ground
truth, but often lead to poor geometric consistency and over-smoothed
renderings. To address these limitations, we propose ExtraGS, a holistic
framework for trajectory extrapolation that integrates both geometric and
generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG)
representation based on a hybrid Gaussian-Signed Distance Function (SDF)
design, and Far Field Gaussians (FFG) that use learnable scaling factors to
efficiently handle distant objects. Furthermore, we develop a self-supervised
uncertainty estimation framework based on spherical harmonics that enables
selective integration of generative priors only where extrapolation artifacts
occur. Extensive experiments on multiple datasets, diverse multi-camera setups,
and various generative priors demonstrate that ExtraGS significantly enhances
the realism and geometric consistency of extrapolated views, while preserving
high fidelity along the original trajectory.

</details>


### [46] [Multi-Object Sketch Animation with Grouping and Motion Trajectory Priors](https://arxiv.org/abs/2508.15535)
*Guotao Liang,Juncheng Hu,Ximing Xing,Jing Zhang,Qian Yu*

Main category: cs.CV

TL;DR: GroupSketch是一种新颖的矢量草图动画方法，通过两阶段流程（运动初始化和运动细化）解决多对象交互和复杂运动的挑战，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多对象交互和复杂运动时存在单对象限制、时间不一致和泛化能力差的问题。

Method: 两阶段流程：1) 运动初始化（语义分组和关键帧定义）；2) 运动细化（Group-based Displacement Network和Context-conditioned Feature Enhancement模块）。

Result: 实验表明，GroupSketch在生成高质量、时间一致的动画方面显著优于现有方法。

Conclusion: GroupSketch拓展了草图动画的实际应用范围，特别适用于复杂多对象场景。

Abstract: We introduce GroupSketch, a novel method for vector sketch animation that
effectively handles multi-object interactions and complex motions. Existing
approaches struggle with these scenarios, either being limited to single-object
cases or suffering from temporal inconsistency and poor generalization. To
address these limitations, our method adopts a two-stage pipeline comprising
Motion Initialization and Motion Refinement. In the first stage, the input
sketch is interactively divided into semantic groups and key frames are
defined, enabling the generation of a coarse animation via interpolation. In
the second stage, we propose a Group-based Displacement Network (GDN), which
refines the coarse animation by predicting group-specific displacement fields,
leveraging priors from a text-to-video model. GDN further incorporates
specialized modules, such as Context-conditioned Feature Enhancement (CCFE), to
improve temporal consistency. Extensive experiments demonstrate that our
approach significantly outperforms existing methods in generating high-quality,
temporally consistent animations for complex, multi-object sketches, thus
expanding the practical applications of sketch animation.

</details>


### [47] [D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems](https://arxiv.org/abs/2508.15537)
*Chang Liu,Yang Xu,Tamas Sziranyi*

Main category: cs.CV

TL;DR: D3FNet是一种用于高分辨率遥感影像中细粒度道路分割的新型网络，通过差分注意力、双流解码和多尺度膨胀策略提升窄道路的提取效果。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率遥感影像中窄道路提取面临的宽度有限、拓扑断裂和遮挡频繁等问题。

Method: 提出DADE模块增强道路特征，DDFM机制平衡空间精度与语义上下文，以及多尺度膨胀策略减少网格伪影。

Result: 在DeepGlobe和CHN6-CUG基准测试中，D3FNet在挑战性道路区域表现优于现有方法。

Conclusion: D3FNet为复杂遥感场景中的窄道路提取提供了稳健解决方案。

Abstract: Extracting narrow roads from high-resolution remote sensing imagery remains a
significant challenge due to their limited width, fragmented topology, and
frequent occlusions. To address these issues, we propose D3FNet, a Dilated
Dual-Stream Differential Attention Fusion Network designed for fine-grained
road structure segmentation in remote perception systems. Built upon the
encoder-decoder backbone of D-LinkNet, D3FNet introduces three key
innovations:(1) a Differential Attention Dilation Extraction (DADE) module that
enhances subtle road features while suppressing background noise at the
bottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates
original and attention-modulated features to balance spatial precision with
semantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9)
that mitigates gridding artifacts and improves continuity in narrow road
prediction. Unlike conventional models that overfit to generic road widths,
D3FNet specifically targets fine-grained, occluded, and low-contrast road
segments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show
that D3FNet achieves superior IoU and recall on challenging road regions,
outperforming state-of-the-art baselines. Ablation studies further verify the
complementary synergy of attention-guided encoding and dual-path decoding.
These results confirm D3FNet as a robust solution for fine-grained narrow road
extraction in complex remote and cooperative perception scenarios.

</details>


### [48] [Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment](https://arxiv.org/abs/2508.15568)
*Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong*

Main category: cs.CV

TL;DR: 论文提出了ADAPT方法，一种无需反向传播的测试时自适应方法，通过高斯概率推理建模类条件似然，显著提升了分布偏移下的鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有测试时自适应方法依赖反向传播或迭代优化，限制了实时部署的可行性，且缺乏对类条件特征分布的显式建模。ADAPT旨在解决这些问题。

Method: ADAPT将测试时自适应重构为高斯概率推理任务，利用逐步更新的类均值和共享协方差矩阵建模类条件似然。引入基于CLIP先验的轻量级正则化矫正可能的似然偏差。

Result: 在多种基准测试中，ADAPT在广泛的分布偏移下实现了最先进的性能，具有卓越的可扩展性和鲁棒性。

Conclusion: ADAPT是一种无源数据、无梯度更新、无全目标数据访问的高效测试时自适应方法，适用于在线和转导设置。

Abstract: Test-time adaptation (TTA) enhances the zero-shot robustness under
distribution shifts by leveraging unlabeled test data during inference. Despite
notable advances, several challenges still limit its broader applicability.
First, most methods rely on backpropagation or iterative optimization, which
limits scalability and hinders real-time deployment. Second, they lack explicit
modeling of class-conditional feature distributions. This modeling is crucial
for producing reliable decision boundaries and calibrated predictions, but it
remains underexplored due to the lack of both source data and supervision at
test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and
backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian
probabilistic inference task by modeling class-conditional likelihoods using
gradually updated class means and a shared covariance matrix. This enables
closed-form, training-free inference. To correct potential likelihood bias, we
introduce lightweight regularization guided by CLIP priors and a historical
knowledge bank. ADAPT requires no source data, no gradient updates, and no full
access to target data, supporting both online and transductive settings.
Extensive experiments across diverse benchmarks demonstrate that our method
achieves state-of-the-art performance under a wide range of distribution shifts
with superior scalability and robustness.

</details>


### [49] [High-Frequency First: A Two-Stage Approach for Improving Image INR](https://arxiv.org/abs/2508.15582)
*Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong*

Main category: cs.CV

TL;DR: 该论文提出了一种通过两阶段训练策略来缓解隐式神经表示（INRs）中的频谱偏差问题的方法，即通过邻居感知软掩模自适应分配权重，优先学习高频细节，再过渡到全图像训练。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示在捕捉高频细节（如锐边和细纹理）时存在频谱偏差问题，传统方法通过架构修改或特殊激活函数解决，但本文提出直接优化训练过程的新思路。

Method: 采用两阶段训练策略：1）使用邻居感知软掩模自适应分配权重，优先学习局部变化强的像素（高频细节）；2）过渡到全图像训练。

Result: 实验表明，该方法能显著提升重建质量，并与现有INR方法兼容。

Conclusion: 通过频率感知的像素权重分配，本文为缓解频谱偏差问题提供了新方向。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful alternative
to traditional pixel-based formats by modeling images as continuous functions
over spatial coordinates. A key challenge, however, lies in the spectral bias
of neural networks, which tend to favor low-frequency components while
struggling to capture high-frequency (HF) details such as sharp edges and fine
textures. While prior approaches have addressed this limitation through
architectural modifications or specialized activation functions, we propose an
orthogonal direction by directly guiding the training process. Specifically, we
introduce a two-stage training strategy where a neighbor-aware soft mask
adaptively assigns higher weights to pixels with strong local variations,
encouraging early focus on fine details. The model then transitions to
full-image training. Experimental results show that our approach consistently
improves reconstruction quality and complements existing INR methods. As a
pioneering attempt to assign frequency-aware importance to pixels in image INR,
our work offers a new avenue for mitigating the spectral bias problem.

</details>


### [50] [Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis](https://arxiv.org/abs/2508.15613)
*Ivo Ivanov,Carsten Markgraf*

Main category: cs.CV

TL;DR: 本文提出了一种新的线性时间凸松弛方法和收缩算子方法，用于加速分支定界（BnB），能够在半秒内求解100个点的3D点云配准问题，证明全局最优性。


<details>
  <summary>Details</summary>
Motivation: 针对点云配准中高离群率（高达95%）的稳健性问题，现有方法（如SDP松弛）计算耗时，需要一种更高效的全局最优求解方法。

Method: 提出线性时间凸松弛和收缩算子方法，加速分支定界（BnB）求解，适用于旋转轴已知的3D点云配准问题。

Result: 在100个点的3D点云配准中，新方法比现有SDP求解器快两个数量级，且能证明全局最优性。

Conclusion: 该方法在高离群率下显著提升求解效率，但尚未完全解决6DoF问题，未来可扩展至更复杂场景。

Abstract: Recent results showed that point cloud registration with given
correspondences can be made robust to outlier rates of up to 95\% using the
truncated least squares (TLS) formulation. However, solving this combinatorial
optimization problem to global optimality is challenging. Provably globally
optimal approaches using semidefinite programming (SDP) relaxations take
hundreds of seconds for 100 points. In this paper, we propose a novel linear
time convex relaxation as well as a contractor method to speed up Branch and
Bound (BnB). Our solver can register two 3D point clouds with 100 points to
provable global optimality in less than half a second when the axis of rotation
is provided. Although it currently cannot solve the full 6DoF problem, it is
two orders of magnitude faster than the state-of-the-art SDP solver STRIDE when
solving the rotation-only TLS problem. In addition to providing a formal proof
for global optimality, we present empirical evidence of global optimality using
adversarial instances with local minimas close to the global minimum.

</details>


### [51] [Multi-perspective monitoring of wildlife and human activities from camera traps and drones with deep learning models](https://arxiv.org/abs/2508.15629)
*Hao Chen,Fang Qiu,Li An,Douglas Stow,Eve Bohnett,Haitao Lyu,Shuang Tian*

Main category: cs.CV

TL;DR: 摘要探讨了利用相机陷阱和无人机热成像多视角监测野生动物和人类活动，结合深度学习模型分析其空间分布，以评估人兽冲突。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过多视角监测了解野生动物和人类活动的空间分布，评估人兽冲突，并为保护规划提供依据。

Method: 结合相机陷阱和无人机热成像数据，使用YOLOv11s和增强的Faster RCNN模型自动识别目标，并进行空间模式分析。

Result: YOLOv11s在相机陷阱图像中表现最佳，精度达96.2%。热成像无人机为监测提供补充视角。空间分析揭示了野生动物与人类活动的热点区域及其潜在冲突区域。

Conclusion: 多视角监测与自动目标检测相结合，能有效提升野生动物监测和景观管理能力，揭示保护区内的人兽冲突问题。

Abstract: Wildlife and human activities are key components of landscape systems.
Understanding their spatial distribution is essential for evaluating human
wildlife interactions and informing effective conservation planning.
Multiperspective monitoring of wildlife and human activities by combining
camera traps and drone imagery. Capturing the spatial patterns of their
distributions, which allows the identification of the overlap of their activity
zones and the assessment of the degree of human wildlife conflict. The study
was conducted in Chitwan National Park (CNP), Nepal, and adjacent regions.
Images collected by visible and nearinfrared camera traps and thermal infrared
drones from February to July 2022 were processed to create training and testing
datasets, which were used to build deep learning models to automatic identify
wildlife and human activities. Drone collected thermal imagery was used for
detecting targets to provide a multiple monitoring perspective. Spatial pattern
analysis was performed to identify animal and resident activity hotspots and
delineation potential human wildlife conflict zones. Among the deep learning
models tested, YOLOv11s achieved the highest performance with a precision of
96.2%, recall of 92.3%, mAP50 of 96.7%, and mAP50 of 81.3%, making it the most
effective for detecting objects in camera trap imagery. Drone based thermal
imagery, analyzed with an enhanced Faster RCNN model, added a complementary
aerial viewpoint for camera trap detections. Spatial pattern analysis
identified clear hotspots for both wildlife and human activities and their
overlapping patterns within certain areas in the CNP and buffer zones
indicating potential conflict. This study reveals human wildlife conflicts
within the conserved landscape. Integrating multiperspective monitoring with
automated object detection enhances wildlife surveillance and landscape
management.

</details>


### [52] [When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](https://arxiv.org/abs/2508.15641)
*Pengcheng Fang,Yuxia Chen,Rui Guo*

Main category: cs.CV

TL;DR: 论文提出Grounded VideoDiT，通过引入三个创新点（DTL编码器、对象接地表示和混合令牌方案）解决现有Video LLM在时间感知上的不足，实现细粒度时间推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频LLM在时间感知上的局限性，如隐式时间戳编码、帧级特征连续性不足以及语言视觉对齐偏移。

Method: 1. 引入DTL编码器增强边界敏感性和时间一致性；2. 使用对象接地表示显式绑定查询实体与视觉证据；3. 采用混合令牌方案实现显式时间戳建模。

Result: 在Charades STA、NExT GQA和多个VideoQA基准测试中达到最优性能。

Conclusion: Grounded VideoDiT通过创新设计显著提升了视频理解中的时间感知和细粒度推理能力。

Abstract: Understanding videos requires more than answering open ended questions, it
demands the ability to pinpoint when events occur and how entities interact
across time. While recent Video LLMs have achieved remarkable progress in
holistic reasoning, they remain coarse in temporal perception: timestamps are
encoded only implicitly, frame level features are weak in capturing continuity,
and language vision alignment often drifts from the entities of interest. In
this paper, we present Grounded VideoDiT, a Video LLM designed to overcome
these limitations by introducing three key innovations. First, a Diffusion
Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains
temporal consistency. Second, object grounded representations explicitly bind
query entities to localized visual evidence, strengthening alignment. Third, a
mixed token scheme with discrete temporal tokens provides explicit timestamp
modeling, enabling fine grained temporal reasoning. Together, these designs
equip Grounded VideoDiT with robust grounding capabilities, as validated by
state of the art results on Charades STA, NExT GQA, and multiple VideoQA
benchmarks.

</details>


### [53] [Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds](https://arxiv.org/abs/2508.15646)
*Swann Emilien Céleste Destouches,Jesse Lahaye,Laurent Valentin Jospin,Jan Skaloud*

Main category: cs.CV

TL;DR: 论文提出了一种弱监督方法，结合人类操作员的评分，改进ALS数据的树实例分割模型，性能提升了34%。


<details>
  <summary>Details</summary>
Motivation: 由于ALS数据中树实例分割因数据变化和标注成本高而具有挑战性，需要一种高效的弱监督方法。

Method: 使用非微调模型或算法初步分割，人类操作员评分后训练评分模型，再微调分割模型。

Result: 树实例识别率提升34%，非树实例预测显著减少，但在稀疏林区和小树（<2米）区域表现下降。

Conclusion: 弱监督方法有效提升了分割性能，但在复杂场景中仍需改进。

Abstract: Tree instance segmentation of airborne laser scanning (ALS) data is of utmost
importance for forest monitoring, but remains challenging due to variations in
the data caused by factors such as sensor resolution, vegetation state at
acquisition time, terrain characteristics, etc. Moreover, obtaining a
sufficient amount of precisely labeled data to train fully supervised instance
segmentation methods is expensive. To address these challenges, we propose a
weakly supervised approach where labels of an initial segmentation result
obtained either by a non-finetuned model or a closed form algorithm are
provided as a quality rating by a human operator. The labels produced during
the quality assessment are then used to train a rating model, whose task is to
classify a segmentation output into the same classes as specified by the human
operator. Finally, the segmentation model is finetuned using feedback from the
rating model. This in turn improves the original segmentation model by 34\% in
terms of correctly identified tree instances while considerably reducing the
number of non-tree instances predicted. Challenges still remain in data over
sparsely forested regions characterized by small trees (less than two meters in
height) or within complex surroundings containing shrubs, boulders, etc. which
can be confused as trees where the performance of the proposed method is
reduced.

</details>


### [54] [Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance](https://arxiv.org/abs/2508.15650)
*Shuchao Pang,Zhenghan Chen,Shen Zhang,Liming Lu,Siyuan Liang,Anan Du,Yongbin Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于关键特征引导的转移攻击方法CFG，用于生成对抗性点云，无需目标模型信息，且在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实场景中难以获取目标模型信息，因此研究无信息依赖的转移攻击方法，利用不同DNN架构共有的关键特征。

Method: 通过计算提取特征的重要性，优先破坏不同架构共有的关键特征，并在损失函数中约束对抗点云的最大偏差。

Result: 在ModelNet40和ScanObjectNN数据集上的实验表明，CFG方法显著优于现有攻击方法。

Conclusion: CFG通过关键特征引导和偏差约束，有效提升了对抗点云的转移性和隐蔽性。

Abstract: Deep neural networks for 3D point clouds have been demonstrated to be
vulnerable to adversarial examples. Previous 3D adversarial attack methods
often exploit certain information about the target models, such as model
parameters or outputs, to generate adversarial point clouds. However, in
realistic scenarios, it is challenging to obtain any information about the
target models under conditions of absolute security. Therefore, we focus on
transfer-based attacks, where generating adversarial point clouds does not
require any information about the target models. Based on our observation that
the critical features used for point cloud classification are consistent across
different DNN architectures, we propose CFG, a novel transfer-based black-box
attack method that improves the transferability of adversarial point clouds via
the proposed Critical Feature Guidance. Specifically, our method regularizes
the search of adversarial point clouds by computing the importance of the
extracted features, prioritizing the corruption of critical features that are
likely to be adopted by diverse architectures. Further, we explicitly constrain
the maximum deviation extent of the generated adversarial point clouds in the
loss function to ensure their imperceptibility. Extensive experiments conducted
on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the
proposed CFG outperforms the state-of-the-art attack methods by a large margin.

</details>


### [55] [MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction](https://arxiv.org/abs/2508.15653)
*Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu*

Main category: cs.CV

TL;DR: 论文提出了一种名为MapKD的多级跨模态知识蒸馏框架，通过教师-教练-学生范式，将多模态模型的先验知识转移到轻量级的视觉中心学生模型中，显著提升性能并加速推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态离线地图或多模态传感器，导致计算开销大且效率低，因此需要一种轻量级且高效的解决方案。

Method: 采用知识蒸馏策略，提出MapKD框架（包括多模态教师模型、视觉中心教练模型和轻量学生模型），并引入TGPD和MSRD两种蒸馏策略。

Result: 在nuScenes数据集上，学生模型的性能提升了+6.68 mIoU和+10.94 mAP，同时推理速度加快。

Conclusion: MapKD通过知识蒸馏成功实现了轻量级视觉模型的性能提升与加速，为自动驾驶系统提供了一种高效解决方案。

Abstract: Online HD map construction is a fundamental task in autonomous driving
systems, aiming to acquire semantic information of map elements around the ego
vehicle based on real-time sensor inputs. Recently, several approaches have
achieved promising results by incorporating offline priors such as SD maps and
HD maps or by fusing multi-modal data. However, these methods depend on stale
offline maps and multi-modal sensor suites, resulting in avoidable
computational overhead at inference. To address these limitations, we employ a
knowledge distillation strategy to transfer knowledge from multimodal models
with prior knowledge to an efficient, low-cost, and vision-centric student
model. Specifically, we propose MapKD, a novel multi-level cross-modal
knowledge distillation framework with an innovative Teacher-Coach-Student (TCS)
paradigm. This framework consists of: (1) a camera-LiDAR fusion model with
SD/HD map priors serving as the teacher; (2) a vision-centric coach model with
prior knowledge and simulated LiDAR to bridge the cross-modal knowledge
transfer gap; and (3) a lightweight vision-based student model. Additionally,
we introduce two targeted knowledge distillation strategies: Token-Guided 2D
Patch Distillation (TGPD) for bird's eye view feature alignment and Masked
Semantic Response Distillation (MSRD) for semantic learning guidance. Extensive
experiments on the challenging nuScenes dataset demonstrate that MapKD improves
the student model by +6.68 mIoU and +10.94 mAP while simultaneously
accelerating inference speed. The code is available
at:https://github.com/2004yan/MapKD2026.

</details>


### [56] [CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps](https://arxiv.org/abs/2508.15672)
*Franz Hanke,Antonia Bieringer,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: 论文提出了一种名为CM2LoD3的新方法，通过冲突地图（CMs）实现LoD3建筑模型的自动化重建，解决了传统手动建模难以大规模应用的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LoD1和LoD2建筑模型缺乏详细的立面元素，LoD3模型虽能弥补这一不足，但传统手动建模方式难以大规模推广，因此需要自动化方法。

Method: 利用射线到模型先验分析生成的冲突地图（CMs），结合开发的语义冲突地图生成器（SCMG）进行语义分割，并通过置信度评分融合纹理模型，提升分割和重建精度。

Result: 实验结果表明，CM2LoD3方法能有效分割和重建建筑开口，不确定性感知的纹理融合将性能提升至61%。

Conclusion: CM2LoD3方法为自动化LoD3模型重建提供了可行方案，推动了高效、可扩展的3D城市建模发展。

Abstract: Detailed 3D building models are crucial for urban planning, digital twins,
and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2
building models are widely available, they lack detailed facade elements
essential for advanced urban analysis. In contrast, LoD3 models address this
limitation by incorporating facade elements such as windows, doors, and
underpasses. However, their generation has traditionally required manual
modeling, making large-scale adoption challenging. In this contribution,
CM2LoD3, we present a novel method for reconstructing LoD3 building models
leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis.
Unlike previous works, we concentrate on semantically segmenting real-world CMs
with synthetically generated CMs from our developed Semantic Conflict Map
Generator (SCMG). We also observe that additional segmentation of textured
models can be fused with CMs using confidence scores to further increase
segmentation performance and thus increase 3D reconstruction accuracy.
Experimental results demonstrate the effectiveness of our CM2LoD3 method in
segmenting and reconstructing building openings, with the 61% performance with
uncertainty-aware fusion of segmented building textures. This research
contributes to the advancement of automated LoD3 model reconstruction, paving
the way for scalable and efficient 3D city modeling. Our project is available:
https://github.com/InFraHank/CM2LoD3

</details>


### [57] [LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions](https://arxiv.org/abs/2508.15688)
*Yongju Jia,Jiarui Ma,Xiangxian Li,Baiqiao Zhang,Xianhui Cao,Juan Liu,Yulong Bian*

Main category: cs.CV

TL;DR: 论文提出了一种名为MDPR的框架，通过多维动态提示路由来缓解预训练视觉语言模型在类别不平衡场景下的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（如CLIP）在类别不平衡场景中微调时容易产生偏差，且现有方法未能充分考虑预训练阶段的不平衡问题。

Method: MDPR框架构建了一个涵盖五个视觉-语义维度的知识库，并采用动态路由机制对齐视觉类别、检索最优提示并平衡细粒度语义。

Result: 在长尾基准（CIFAR-LT、ImageNet-LT等）上的实验表明，MDPR性能与当前最优方法相当，且动态路由计算开销低。

Conclusion: MDPR是一种灵活高效的VLM微调增强方法，尤其适用于数据不平衡场景。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
impressive capability in visual tasks, but their fine-tuning often suffers from
bias in class-imbalanced scene. Recent works have introduced large language
models (LLMs) to enhance VLM fine-tuning with supplementing semantic
information. However, they often overlook inherent class imbalance in VLMs'
pre-training, which may lead to bias accumulation in downstream tasks. To
address this problem, this paper proposes a Multi-dimensional Dynamic Prompt
Routing (MDPR) framework. MDPR constructs a comprehensive knowledge base for
classes, spanning five visual-semantic dimensions. During fine-tuning, the
dynamic routing mechanism aligns global visual classes, retrieves optimal
prompts, and balances fine-grained semantics, yielding stable predictions
through logits fusion. Extensive experiments on long-tailed benchmarks,
including CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves
comparable results with current SOTA methods. Ablation studies further confirm
the effectiveness of our semantic library for tail classes, and show that our
dynamic routing incurs minimal computational overhead, making MDPR a flexible
and efficient enhancement for VLM fine-tuning under data imbalance.

</details>


### [58] [StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding](https://arxiv.org/abs/2508.15717)
*Yanlai Yang,Zhuokai Zhao,Satya Narayan Shukla,Aashu Singh,Shlok Kumar Mishra,Lizhu Zhang,Mengye Ren*

Main category: cs.CV

TL;DR: StreamMem是一种查询无关的KV缓存内存机制，用于流式视频理解，解决了长视频处理中的内存和计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时存在内存和计算开销大的问题，且需要提前编码或知道问题，实用性有限。

Method: StreamMem以流式方式编码新视频帧，使用视觉标记和通用查询标记之间的注意力分数压缩KV缓存，并保持固定大小的KV内存。

Result: 在三个长视频理解和两个流式视频问答基准测试中，StreamMem在查询无关的KV缓存压缩中表现最优。

Conclusion: StreamMem在长视频理解和多轮对话场景中高效且实用，性能优于现有查询感知压缩方法。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
visual-language reasoning, but their ability to efficiently handle long videos
remains limited. Despite recent advances in long-context MLLMs, storing and
attending to the key-value (KV) cache for long visual contexts incurs
substantial memory and computational overhead. Existing visual compression
methods require either encoding the entire visual context before compression or
having access to the questions in advance, which is impractical for long video
understanding and multi-turn conversational settings. In this work, we propose
StreamMem, a query-agnostic KV cache memory mechanism for streaming video
understanding. Specifically, StreamMem encodes new video frames in a streaming
manner, compressing the KV cache using attention scores between visual tokens
and generic query tokens, while maintaining a fixed-size KV memory to enable
efficient question answering (QA) in memory-constrained, long-video scenarios.
Evaluation on three long video understanding and two streaming video question
answering benchmarks shows that StreamMem achieves state-of-the-art performance
in query-agnostic KV cache compression and is competitive with query-aware
compression approaches.

</details>


### [59] [WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception](https://arxiv.org/abs/2508.15720)
*Zhiheng Liu,Xueqing Deng,Shoufa Chen,Angtian Wang,Qiushan Guo,Mingfei Han,Zeyue Xue,Mengzhao Chen,Ping Luo,Linjie Yang*

Main category: cs.CV

TL;DR: WorldWeaver框架通过联合建模RGB帧和感知条件，结合深度线索和分段噪声调度，显著提升了长视频生成的时间一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长视频生成中因依赖RGB信号而导致的结构和时间一致性问题。

Method: 联合预测感知条件和颜色信息，利用深度线索构建记忆库，采用分段噪声调度。

Result: 有效减少时间漂移，提高生成视频的保真度。

Conclusion: WorldWeaver为长视频生成提供了更鲁棒的解决方案。

Abstract: Generative video modeling has made significant strides, yet ensuring
structural and temporal consistency over long sequences remains a challenge.
Current methods predominantly rely on RGB signals, leading to accumulated
errors in object structure and motion over extended durations. To address these
issues, we introduce WorldWeaver, a robust framework for long video generation
that jointly models RGB frames and perceptual conditions within a unified
long-horizon modeling scheme. Our training framework offers three key
advantages. First, by jointly predicting perceptual conditions and color
information from a unified representation, it significantly enhances temporal
consistency and motion dynamics. Second, by leveraging depth cues, which we
observe to be more resistant to drift than RGB, we construct a memory bank that
preserves clearer contextual information, improving quality in long-horizon
video generation. Third, we employ segmented noise scheduling for training
prediction groups, which further mitigates drift and reduces computational
cost. Extensive experiments on both diffusion- and rectified flow-based models
demonstrate the effectiveness of WorldWeaver in reducing temporal drift and
improving the fidelity of generated videos.

</details>


### [60] [Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model](https://arxiv.org/abs/2508.15751)
*Xueyuan Li,Can Cui,Ruining Deng,Yucheng Tang,Quan Liu,Tianyuan Yao,Shunxing Bao,Naweed Chowdhury,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: All-in-SAM模型利用分子增强学习提升计算病理学中的细胞分类性能，减少标注工作量并提高分割准确性。


<details>
  <summary>Details</summary>
Motivation: 解决通用视觉基础模型在细粒度语义分割中的挑战，如识别特定细胞亚型。

Method: 结合分子增强学习、SAM适配器和分子导向纠正学习（MOCL）的全栈方法。

Result: 在内部和公共数据集上显著提升细胞分类性能，适应不同标注质量。

Conclusion: 降低标注负担，扩展精准生物医学图像分析在资源有限环境中的应用。

Abstract: Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentation through two primary methods:
prompt-based zero-shot segmentation and the use of cell-specific SAM models for
direct segmentation. These approaches enable effective segmentation across a
range of nuclei and cells. However, general vision foundation models often face
challenges with fine-grained semantic segmentation, such as identifying
specific nuclei subtypes or particular cells. Approach: In this paper, we
propose the molecular-empowered All-in-SAM Model to advance computational
pathology by leveraging the capabilities of vision foundation models. This
model incorporates a full-stack approach, focusing on: (1) annotation-engaging
lay annotators through molecular-empowered learning to reduce the need for
detailed pixel-level annotations, (2) learning-adapting the SAM model to
emphasize specific semantics, which utilizes its strong generalizability with
SAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating
Molecular-Oriented Corrective Learning (MOCL). Results: Experimental results
from both in-house and public datasets show that the All-in-SAM model
significantly improves cell classification performance, even when faced with
varying annotation quality. Conclusions: Our approach not only reduces the
workload for annotators but also extends the accessibility of precise
biomedical image analysis to resource-limited settings, thereby advancing
medical diagnostics and automating pathology image analysis.

</details>


### [61] [Waver: Wave Your Way to Lifelike Video Generation](https://arxiv.org/abs/2508.15761)
*Yifu Zhang,Hao Yang,Yuqi Zhang,Yifei Hu,Fengda Zhu,Chuang Lin,Xiaofeng Mei,Yi Jiang,Zehuan Yuan,Bingyue Peng*

Main category: cs.CV

TL;DR: Waver是一个高性能基础模型，支持图像和视频的统一生成，包括文本到视频、图像到视频和文本到图像。采用混合流DiT架构提升模态对齐和训练效率。


<details>
  <summary>Details</summary>
Motivation: 通过统一框架实现高质量视频和图像生成，解决现有模型在复杂运动捕捉和模态对齐上的不足。

Method: 引入混合流DiT架构，优化数据筛选流程，训练MLLM视频质量模型。

Result: 在T2V和I2V任务中排名前三，超越开源模型并媲美商业解决方案。

Conclusion: Waver在视频生成领域表现优异，框架和训练方法可供社区参考。

Abstract: We present Waver, a high-performance foundation model for unified image and
video generation. Waver can directly generate videos with durations ranging
from 5 to 10 seconds at a native resolution of 720p, which are subsequently
upscaled to 1080p. The model simultaneously supports text-to-video (T2V),
image-to-video (I2V), and text-to-image (T2I) generation within a single,
integrated framework. We introduce a Hybrid Stream DiT architecture to enhance
modality alignment and accelerate training convergence. To ensure training data
quality, we establish a comprehensive data curation pipeline and manually
annotate and train an MLLM-based video quality model to filter for the
highest-quality samples. Furthermore, we provide detailed training and
inference recipes to facilitate the generation of high-quality videos. Building
on these contributions, Waver excels at capturing complex motion, achieving
superior motion amplitude and temporal consistency in video synthesis. Notably,
it ranks among the Top 3 on both the T2V and I2V leaderboards at Artificial
Analysis (data as of 2025-07-30 10:00 GMT+8), consistently outperforming
existing open-source models and matching or surpassing state-of-the-art
commercial solutions. We hope this technical report will help the community
more efficiently train high-quality video generation models and accelerate
progress in video generation technologies. Official page:
https://github.com/FoundationVision/Waver.

</details>


### [62] [ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling](https://arxiv.org/abs/2508.15767)
*Jinhyung Park,Javier Romero,Shunsuke Saito,Fabian Prada,Takaaki Shiratori,Yichen Xu,Federica Bogo,Shoou-I Yu,Kris Kitani,Rawal Khirodkar*

Main category: cs.CV

TL;DR: ATLAS是一种高保真人体模型，通过解耦形状和骨骼基础，提升了对多样化姿态和形状的表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的人体网格建模方法在处理多样化的身体姿态和形状时缺乏细节，主要由于训练数据多样性不足和建模假设的限制。

Method: ATLAS基于600K高分辨率扫描数据，通过显式解耦形状和骨骼基础，并利用非线性姿态校正。

Result: ATLAS在拟合未见过的多样化姿态的受试者时表现更优，非线性姿态校正比线性模型更有效。

Conclusion: ATLAS通过解耦骨骼和形状提升了建模的灵活性和准确性，适用于高保真人体建模。

Abstract: Parametric body models offer expressive 3D representation of humans across a
wide range of poses, shapes, and facial expressions, typically derived by
learning a basis over registered 3D meshes. However, existing human mesh
modeling approaches struggle to capture detailed variations across diverse body
poses and shapes, largely due to limited training data diversity and
restrictive modeling assumptions. Moreover, the common paradigm first optimizes
the external body surface using a linear basis, then regresses internal
skeletal joints from surface vertices. This approach introduces problematic
dependencies between internal skeleton and outer soft tissue, limiting direct
control over body height and bone lengths. To address these issues, we present
ATLAS, a high-fidelity body model learned from 600k high-resolution scans
captured using 240 synchronized cameras. Unlike previous methods, we explicitly
decouple the shape and skeleton bases by grounding our mesh representation in
the human skeleton. This decoupling enables enhanced shape expressivity,
fine-grained customization of body attributes, and keypoint fitting independent
of external soft-tissue characteristics. ATLAS outperforms existing methods by
fitting unseen subjects in diverse poses more accurately, and quantitative
evaluations show that our non-linear pose correctives more effectively capture
complex poses compared to linear models.

</details>


### [63] [SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass](https://arxiv.org/abs/2508.15769)
*Yanxu Meng,Haoning Wu,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: 提出了一种名为SceneGen的新框架，用于从单个场景图像生成多个3D资产，无需优化或资产检索。


<details>
  <summary>Details</summary>
Motivation: 解决在VR/AR和具身AI中生成高质量3D内容的需求。

Method: 使用视觉和几何编码器的特征聚合模块，结合位置头，通过单次前向传递生成3D资产及其空间位置。

Result: 实验证明该方法高效且生成能力强，支持多图像输入的扩展。

Conclusion: SceneGen为高质量3D内容生成提供了新解决方案，有望推动下游应用。

Abstract: 3D content generation has recently attracted significant research interest
due to its applications in VR/AR and embodied AI. In this work, we address the
challenging task of synthesizing multiple 3D assets within a single scene
image. Concretely, our contributions are fourfold: (i) we present SceneGen, a
novel framework that takes a scene image and corresponding object masks as
input, simultaneously producing multiple 3D assets with geometry and texture.
Notably, SceneGen operates with no need for optimization or asset retrieval;
(ii) we introduce a novel feature aggregation module that integrates local and
global scene information from visual and geometric encoders within the feature
extraction module. Coupled with a position head, this enables the generation of
3D assets and their relative spatial positions in a single feedforward pass;
(iii) we demonstrate SceneGen's direct extensibility to multi-image input
scenarios. Despite being trained solely on single-image inputs, our
architectural design enables improved generation performance with multi-image
inputs; and (iv) extensive quantitative and qualitative evaluations confirm the
efficiency and robust generation abilities of our approach. We believe this
paradigm offers a novel solution for high-quality 3D content generation,
potentially advancing its practical applications in downstream tasks. The code
and model will be publicly available at: https://mengmouxu.github.io/SceneGen.

</details>


### [64] [Visual Autoregressive Modeling for Instruction-Guided Image Editing](https://arxiv.org/abs/2508.15772)
*Qingyang Mao,Qi Cai,Yehao Li,Yingwei Pan,Mingyue Cheng,Ting Yao,Qi Liu,Tao Mei*

Main category: cs.CV

TL;DR: VAREdit是一种视觉自回归框架，通过重新定义图像编辑为多尺度预测问题，提高了编辑精度和效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在全局去噪过程中会导致编辑区域与整个图像上下文纠缠，导致意外的虚假修改和编辑指令的偏离。自回归模型通过序列化图像合成提供了一种避免这些问题的新方法。

Method: VAREdit通过多尺度目标特征生成实现精确编辑，并引入Scale-Aligned Reference (SAR)模块来解决源图像特征与目标特征尺度不匹配的问题。

Result: VAREdit在标准基准测试中表现出色，比领先的基于扩散的方法高出30%以上的GPT-Balance分数，且编辑速度更快。

Conclusion: VAREdit显著提升了编辑精度和效率，为图像编辑提供了一种更优的解决方案。

Abstract: Recent advances in diffusion models have brought remarkable visual fidelity
to instruction-guided image editing. However, their global denoising process
inherently entangles the edited region with the entire image context, leading
to unintended spurious modifications and compromised adherence to editing
instructions. In contrast, autoregressive models offer a distinct paradigm by
formulating image synthesis as a sequential process over discrete visual
tokens. Their causal and compositional mechanism naturally circumvents the
adherence challenges of diffusion-based methods. In this paper, we present
VAREdit, a visual autoregressive (VAR) framework that reframes image editing as
a next-scale prediction problem. Conditioned on source image features and text
instructions, VAREdit generates multi-scale target features to achieve precise
edits. A core challenge in this paradigm is how to effectively condition the
source image tokens. We observe that finest-scale source features cannot
effectively guide the prediction of coarser target features. To bridge this
gap, we introduce a Scale-Aligned Reference (SAR) module, which injects
scale-matched conditioning information into the first self-attention layer.
VAREdit demonstrates significant advancements in both editing adherence and
efficiency. On standard benchmarks, it outperforms leading diffusion-based
methods by 30\%+ higher GPT-Balance score. Moreover, it completes a
$512\times512$ editing in 1.2 seconds, making it 2.2$\times$ faster than the
similarly sized UltraEdit. The models are available at
https://github.com/HiDream-ai/VAREdit.

</details>


### [65] [Scaling Group Inference for Diverse and High-Quality Generation](https://arxiv.org/abs/2508.15773)
*Gaurav Parmar,Or Patashnik,Daniil Ostashev,Kuan-Chieh Wang,Kfir Aberman,Srinivasa Narasimhan,Jun-Yan Zhu*

Main category: cs.CV

TL;DR: 论文提出了一种通过群体推理方法提升生成模型输出多样性与质量的方法，解决了独立采样导致的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，用户通常需要一组多样的输出以供选择，但传统的独立采样方法容易产生冗余结果，限制了选择范围和创意探索。

Method: 将群体推理建模为二次整数分配问题，通过优化样本质量和多样性，并结合渐进式剪枝方法提升运行效率。

Result: 实验表明，该方法显著提升了输出的多样性和质量，适用于文本到图像、图像到图像等多种生成任务。

Conclusion: 该方法为生成模型提供了一种从独立采样转向群体优化的新思路，提升了实际应用中的用户体验。

Abstract: Generative models typically sample outputs independently, and recent
inference-time guidance and scaling algorithms focus on improving the quality
of individual samples. However, in real-world applications, users are often
presented with a set of multiple images (e.g., 4-8) for each prompt, where
independent sampling tends to lead to redundant results, limiting user choices
and hindering idea exploration. In this work, we introduce a scalable group
inference method that improves both the diversity and quality of a group of
samples. We formulate group inference as a quadratic integer assignment
problem: candidate outputs are modeled as graph nodes, and a subset is selected
to optimize sample quality (unary term) while maximizing group diversity
(binary term). To substantially improve runtime efficiency, we progressively
prune the candidate set using intermediate predictions, allowing our method to
scale up to large candidate sets. Extensive experiments show that our method
significantly improves group diversity and quality compared to independent
sampling baselines and recent inference algorithms. Our framework generalizes
across a wide range of tasks, including text-to-image, image-to-image, image
prompting, and video generation, enabling generative models to treat multiple
outputs as cohesive groups rather than independent samples.

</details>


### [66] [CineScale: Free Lunch in High-Resolution Cinematic Visual Generation](https://arxiv.org/abs/2508.15774)
*Haonan Qiu,Ning Yu,Ziqi Huang,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: CineScale是一种新的推理范式，用于实现更高分辨率的视觉生成，解决了现有方法在超出训练分辨率时产生低质量重复模式的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉扩散模型由于缺乏高分辨率数据和计算资源限制，通常只能在有限分辨率下训练，限制了其生成高保真图像或视频的能力。

Method: 提出CineScale，针对两种视频生成架构设计专用变体，支持更高分辨率的I2V和V2V合成。

Result: 实验表明，CineScale能够在不微调的情况下生成8k图像，仅需少量LoRA微调即可生成4k视频。

Conclusion: CineScale扩展了视觉扩散模型在高分辨率生成方面的能力，显著优于现有基线方法。

Abstract: Visual diffusion models achieve remarkable progress, yet they are typically
trained at limited resolutions due to the lack of high-resolution data and
constrained computation resources, hampering their ability to generate
high-fidelity images or videos at higher resolutions. Recent efforts have
explored tuning-free strategies to exhibit the untapped potential
higher-resolution visual generation of pre-trained models. However, these
methods are still prone to producing low-quality visual content with repetitive
patterns. The key obstacle lies in the inevitable increase in high-frequency
information when the model generates visual content exceeding its training
resolution, leading to undesirable repetitive patterns deriving from the
accumulated errors. In this work, we propose CineScale, a novel inference
paradigm to enable higher-resolution visual generation. To tackle the various
issues introduced by the two types of video generation architectures, we
propose dedicated variants tailored to each. Unlike existing baseline methods
that are confined to high-resolution T2I and T2V generation, CineScale broadens
the scope by enabling high-resolution I2V and V2V synthesis, built atop
state-of-the-art open-source video generation frameworks. Extensive experiments
validate the superiority of our paradigm in extending the capabilities of
higher-resolution visual generation for both image and video models.
Remarkably, our approach enables 8k image generation without any fine-tuning,
and achieves 4k video generation with only minimal LoRA fine-tuning. Generated
video samples are available at our website:
https://eyeline-labs.github.io/CineScale/.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [67] [Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs](https://arxiv.org/abs/2508.14941)
*Yi-Chun Chen*

Main category: cs.MM

TL;DR: 提出了一个语义归一化框架，用于解决视觉叙事图中不一致和冗余的问题，并通过实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉叙事图（如漫画）的结构化表示常因不一致和冗余而受限，影响推理和泛化能力。

Method: 基于认知模型，采用词汇相似性和嵌入聚类方法，对语义相关的动作和事件进行归一化处理。

Result: 在Manga109数据集上的实验表明，归一化能提高叙事推理任务的连贯性和鲁棒性。

Conclusion: 语义归一化是构建可扩展、认知启发的多模态叙事理解模型的关键步骤。

Abstract: Understanding visual narratives such as comics requires structured
representations that capture events, characters, and their relations across
multiple levels of story organization. However, symbolic narrative graphs often
suffer from inconsistency and redundancy, where similar actions or events are
labeled differently across annotations or contexts. Such variance limits the
effectiveness of reasoning and generalization.
  This paper introduces a semantic normalization framework for hierarchical
narrative knowledge graphs. Building on cognitively grounded models of
narrative comprehension, we propose methods that consolidate semantically
related actions and events using lexical similarity and embedding-based
clustering. The normalization process reduces annotation noise, aligns symbolic
categories across narrative levels, and preserves interpretability.
  We demonstrate the framework on annotated manga stories from the Manga109
dataset, applying normalization to panel-, event-, and story-level graphs.
Preliminary evaluations across narrative reasoning tasks, such as action
retrieval, character grounding, and event summarization, show that semantic
normalization improves coherence and robustness, while maintaining symbolic
transparency. These findings suggest that normalization is a key step toward
scalable, cognitively inspired graph models for multimodal narrative
understanding.

</details>


### [68] [Holo-Artisan: A Personalized Multi-User Holographic Experience for Virtual Museums on the Edge Intelligence](https://arxiv.org/abs/2508.14956)
*Nan-Hong Kuo,Hojjat Baghban*

Main category: cs.MM

TL;DR: Holo-Artisan是一套新型系统架构，通过全息显示和个性化边缘智能实现虚拟博物馆的多用户沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 将静态博物馆展品转变为动态的、能与每位访客个性化互动的艺术品，提升文化遗产的互动体验。

Method: 利用边缘计算节点实时处理用户数据，生成式AI模型驱动数字艺术品个性化响应，并通过联邦学习保护隐私。

Result: 实现了高保真、个性化的实时互动体验，同时最小化延迟和带宽占用。

Conclusion: Holo-Artisan为文化遗产互动开创了新范式。

Abstract: We present Holo-Artisan, a novel system architecture enabling immersive
multi-user experiences in virtual museums through true holographic displays and
personalized edge intelligence. In our design, local edge computing nodes
process real-time user data -- including pose, facial expression, and voice --
for multiple visitors concurrently. Generative AI models then drive digital
artworks (e.g., a volumetric Mona Lisa) to respond uniquely to each viewer. For
instance, the Mona Lisa can return a smile to one visitor while engaging in a
spoken Q\&A with another, all in real time. A cloud-assisted collaboration
platform composes these interactions in a shared scene using a universal scene
description, and employs ray tracing to render high-fidelity, personalized
views with a direct pipeline to glasses-free holographic displays. To preserve
user privacy and continuously improve personalization, we integrate federated
learning (FL) -- edge devices locally fine-tune AI models and share only model
updates for aggregation. This edge-centric approach minimizes latency and
bandwidth usage, ensuring a synchronized shared experience with individual
customization. Through Holo-Artisan, static museum exhibits are transformed
into dynamic, living artworks that engage each visitor in a personal dialogue,
heralding a new paradigm of cultural heritage interaction.

</details>


### [69] [\textit{adder-viz}: Real-Time Visualization Software for Transcoding Event Video](https://arxiv.org/abs/2508.14996)
*Andrew C. Freeman,Luke Reinkensmeyer*

Main category: cs.MM

TL;DR: 论文介绍了一种改进的ADΔER表示方法和adder-viz软件，用于实时事件转码和可视化。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机表示方法在灵活性、速度和可压缩性方面的不足。

Method: 提出了统一的ADΔER表示方法，并改进了adder-viz软件。

Result: 实现了实时事件转码和可视化，软件已开源并提供。

Conclusion: 改进的ADΔER表示方法和adder-viz软件为事件视频研究提供了更灵活、高效的解决方案。

Abstract: Recent years have brought about a surge in neuromorphic ``event'' video
research, primarily targeting computer vision applications. Event video eschews
video frames in favor of asynchronous, per-pixel intensity samples. While much
work has focused on a handful of representations for specific event cameras,
these representations have shown limitations in flexibility, speed, and
compressibility. We previously proposed the unified AD{\Delta}ER representation
to address these concerns. This paper introduces numerous improvements to the
\textit{adder-viz} software for visualizing real-time event transcode processes
and applications in-the-loop. The MIT-licensed software is available from a
centralized repository at
\href{https://github.com/ac-freeman/adder-codec-rs}{https://github.com/ac-freeman/adder-codec-rs}.

</details>


### [70] [A Low-Latency 3D Live Remote Visualization System for Tourist Sites Integrating Dynamic and Pre-captured Static Point Clouds](https://arxiv.org/abs/2508.15398)
*Takahiro Matsumoto,Masafumi Suzuki,Mariko Yamaguchi,Masakatsu Aoki,Shunsuke Konagai,Kazuhiko Murasaki*

Main category: cs.MM

TL;DR: 提出了一种结合多LiDAR和摄像头的系统，用于实时动态点云捕获，并与静态点云集成，实现大范围3D可视化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在户外旅游景点的应用中存在维护、美学限制及光照变化等问题。

Method: 结合多LiDAR和摄像头实时捕获动态点云，自动调整静态点云颜色以适应光照变化。

Result: 系统在大范围内保持30 fps，延迟低于100 ms，并在实际景点部署中验证了有效性。

Conclusion: 该系统成功解决了户外景点实时3D捕获中的光照和传感器限制问题。

Abstract: Various real-time methods for capturing and transmitting dynamic 3D spaces
have been proposed, including those based on RGB-D cameras and volumetric
capture. However, applying existing methods to outdoor tourist sites remains
difficult because maintenance and aesthetic constraints limit sensor placement,
and daylight variability complicates processing. We propose a system that
combines multiple LiDARs and cameras for live dynamic point cloud capture, and
integrates them with pre-captured static point clouds for wide-area 3D
visualization. The system sustains 30 fps across wide-area scenes while keeping
latency below 100 ms. To mitigate lighting inconsistencies, static point-cloud
colors are automatically adjusted to current lighting. The effectiveness of our
system is demonstrated through real-world deployment in a tourist site.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [71] [Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving](https://arxiv.org/abs/2508.14926)
*Dianzhao Li,Ostap Okhrin*

Main category: cs.LG

TL;DR: 论文提出了一种结合伦理考量的分层安全强化学习框架，用于自动驾驶车辆的决策与执行，并在真实交通数据中验证了其优于基线方法的表现。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在常规和紧急情况下如何嵌入伦理推理的问题，以降低交通事故死亡率并提高交通效率。

Method: 采用分层结构，决策层通过安全强化学习（Safe RL）结合伦理风险成本生成运动目标；执行层使用多项式路径规划和PID/Stanley控制器实现平滑轨迹。

Result: 在真实交通数据集上验证，该方法在降低伦理风险和保持驾驶性能方面优于基线方法。

Conclusion: 结合形式控制理论和数据驱动学习，为复杂混合交通环境中的自动驾驶伦理决策提供了新思路。

Abstract: Autonomous vehicles hold great promise for reducing traffic fatalities and
improving transportation efficiency, yet their widespread adoption hinges on
embedding robust ethical reasoning into routine and emergency maneuvers. Here,
we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that
explicitly integrates moral considerations with standard driving objectives. At
the decision level, a Safe RL agent is trained using a composite ethical risk
cost, combining collision probability and harm severity, to generate high-level
motion targets. A dynamic Prioritized Experience Replay mechanism amplifies
learning from rare but critical, high-risk events. At the execution level,
polynomial path planning coupled with Proportional-Integral-Derivative (PID)
and Stanley controllers translates these targets into smooth, feasible
trajectories, ensuring both accuracy and comfort. We train and validate our
approach on rich, real-world traffic datasets encompassing diverse vehicles,
cyclists, and pedestrians, and demonstrate that it outperforms baseline methods
in reducing ethical risk and maintaining driving performance. To our knowledge,
this is the first study of ethical decision-making for autonomous vehicles via
Safe RL in real-world scenarios. Our results highlight the potential of
combining formal control theory and data-driven learning to advance ethically
accountable autonomy in complex, human-mixed traffic environments.

</details>


### [72] [Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework](https://arxiv.org/abs/2508.14940)
*Chongyu Qu,Allen J. Luna,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.LG

TL;DR: 提出了一种个性化肺癌风险预测代理，通过动态选择最适合患者的模型，结合队列特定知识和现代检索推理技术，实现精准预测。


<details>
  <summary>Details</summary>
Motivation: 由于患者人群和临床环境的巨大差异，现有的肺癌风险预测模型无法在所有队列中表现最佳，因此需要一种更具个性化的方法。

Method: 代理采用两阶段流程：1）通过FAISS相似性检索从九个真实队列中识别最相关患者群体；2）利用大型语言模型（LLM）基于检索队列和性能指标推荐最优预测算法。

Result: 该方法能够动态选择适合患者特征的模型，实现个性化的肺癌风险评估。

Conclusion: 该代理为肺癌筛查提供了一种灵活且实用的个性化风险评估工具，适用于多样化临床人群。

Abstract: Accurate lung cancer risk prediction remains challenging due to substantial
variability across patient populations and clinical settings -- no single model
performs best for all cohorts. To address this, we propose a personalized lung
cancer risk prediction agent that dynamically selects the most appropriate
model for each patient by combining cohort-specific knowledge with modern
retrieval and reasoning techniques. Given a patient's CT scan and structured
metadata -- including demographic, clinical, and nodule-level features -- the
agent first performs cohort retrieval using FAISS-based similarity search
across nine diverse real-world cohorts to identify the most relevant patient
population from a multi-institutional database. Second, a Large Language Model
(LLM) is prompted with the retrieved cohort and its associated performance
metrics to recommend the optimal prediction algorithm from a pool of eight
representative models, including classical linear risk models (e.g., Mayo,
Brock), temporally-aware models (e.g., TDVIT, DLSTM), and multi-modal computer
vision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent
pipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic,
cohort-aware risk prediction personalized to each patient's profile. Building
on this architecture, the agent supports flexible and cohort-driven model
selection across diverse clinical populations, offering a practical path toward
individualized risk assessment in real-world lung cancer screening.

</details>


### [73] [Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction](https://arxiv.org/abs/2508.14942)
*Jiacheng Hu,Bo Zhang,Ting Xu,Haifeng Yang,Min Gao*

Main category: cs.LG

TL;DR: 为了解决帕金森病进展预测中症状演化复杂性和时间依赖性不足的问题，研究提出了一个结合结构感知和时间建模的统一框架，通过图神经网络和Transformer提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决帕金森病预测中的症状演化复杂性和时间依赖性建模不足问题。

Method: 采用图神经网络和Transformer，结合结构感知门控机制动态融合结构与时间信息。

Result: 在真实数据上表现优于现有方法，尤其在AUC、RMSE和IPW-F1指标上。

Conclusion: 框架具有强泛化和扩展性，为慢性渐进性疾病的智能建模提供支持。

Abstract: This study addresses the challenges of symptom evolution complexity and
insufficient temporal dependency modeling in Parkinson's disease progression
prediction. It proposes a unified prediction framework that integrates
structural perception and temporal modeling. The method leverages graph neural
networks to model the structural relationships among multimodal clinical
symptoms and introduces graph-based representations to capture semantic
dependencies between symptoms. It also incorporates a Transformer architecture
to model dynamic temporal features during disease progression. To fuse
structural and temporal information, a structure-aware gating mechanism is
designed to dynamically adjust the fusion weights between structural encodings
and temporal features, enhancing the model's ability to identify key
progression stages. To improve classification accuracy and stability, the
framework includes a multi-component modeling pipeline, consisting of a graph
construction module, a temporal encoding module, and a prediction output layer.
The model is evaluated on real-world longitudinal Parkinson's disease data. The
experiments involve comparisons with mainstream models, sensitivity analysis of
hyperparameters, and graph connection density control. Results show that the
proposed method outperforms existing approaches in AUC, RMSE, and IPW-F1
metrics. It effectively distinguishes progression stages and improves the
model's ability to capture personalized symptom trajectories. The overall
framework demonstrates strong generalization and structural scalability,
providing reliable support for intelligent modeling of chronic progressive
diseases such as Parkinson's disease.

</details>


### [74] [HHNAS-AM: Hierarchical Hybrid Neural Architecture Search using Adaptive Mutation Policies](https://arxiv.org/abs/2508.14946)
*Anurag Tripathi,Ajeet Kumar Singh,Rajsabi Surya,Aum Gupta,Sahiinii Lemaina Veikho,Dorien Herremans,Sudhir Bisane*

Main category: cs.LG

TL;DR: 提出了一种基于自适应变异策略的分层混合神经架构搜索方法HHNAS-AM，通过结构化搜索空间和动态调整策略提升搜索效率，在Spider数据集上测试准确率提升了8%。


<details>
  <summary>Details</summary>
Motivation: 现有NAS模型在文本分类中缺乏分层结构，搜索空间过大且冗余，导致RL模型难以有效导航。

Method: 引入分层架构模板，基于领域线索设计搜索空间，并通过Q-learning动态调整变异策略。

Result: 在db_id预测任务中表现优异，Spider数据集上测试准确率提升8%。

Conclusion: HHNAS-AM通过结构化搜索空间和自适应策略，显著提升了NAS在文本分类中的效率和性能。

Abstract: Neural Architecture Search (NAS) has garnered significant research interest
due to its capability to discover architectures superior to manually designed
ones. Learning text representation is crucial for text classification and other
language-related tasks. The NAS model used in text classification does not have
a Hybrid hierarchical structure, and there is no restriction on the
architecture structure, due to which the search space becomes very large and
mostly redundant, so the existing RL models are not able to navigate the search
space effectively. Also, doing a flat architecture search leads to an
unorganised search space, which is difficult to traverse. For this purpose, we
propose HHNAS-AM (Hierarchical Hybrid Neural Architecture Search with Adaptive
Mutation Policies), a novel approach that efficiently explores diverse
architectural configurations. We introduce a few architectural templates to
search on which organise the search spaces, where search spaces are designed on
the basis of domain-specific cues. Our method employs mutation strategies that
dynamically adapt based on performance feedback from previous iterations using
Q-learning, enabling a more effective and accelerated traversal of the search
space. The proposed model is fully probabilistic, enabling effective
exploration of the search space. We evaluate our approach on the database id
(db_id) prediction task, where it consistently discovers high-performing
architectures across multiple experiments. On the Spider dataset, our method
achieves an 8% improvement in test accuracy over existing baselines.

</details>


### [75] [Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization](https://arxiv.org/abs/2508.14947)
*Rui Wang,Qianguo Sun,Chao Song,Junlong Wu,Tianrong Chen,Zhiyun Zeng,Yu Li*

Main category: cs.LG

TL;DR: 论文提出了一种新的对齐框架LPO，解决了DPO易过拟合和崩溃的问题，通过梯度解耦、稳定性提升和可控拒绝抑制实现优化。


<details>
  <summary>Details</summary>
Motivation: DPO因其简单性和训练稳定性成为广泛使用的离线偏好优化算法，但容易过拟合和崩溃，因此需要改进。

Method: 引入梯度解耦（绝对差异损失替代log-sigmoid函数）、稳定性提升（偏移约束与正则化项）和可控拒绝抑制（梯度分离与可调系数）。

Result: 实验表明，LPO在多种任务（文本、数学、TTS等）上性能均有提升。

Conclusion: LPO是一种鲁棒且可调的偏好对齐范式，已公开源代码、模型和训练数据。

Abstract: DPO (Direct Preference Optimization) has become a widely used offline
preference optimization algorithm due to its simplicity and training stability.
However, DPO is prone to overfitting and collapse. To address these challenges,
we propose Linear Preference Optimization (LPO), a novel alignment framework
featuring three key innovations. First, we introduce gradient decoupling by
replacing the log-sigmoid function with an absolute difference loss, thereby
isolating the optimization dynamics. Second, we improve stability through an
offset constraint combined with a positive regularization term to preserve the
chosen response quality. Third, we implement controllable rejection suppression
using gradient separation with straightforward estimation and a tunable
coefficient that linearly regulates the descent of the rejection probability.
Through extensive experiments, we demonstrate that LPO consistently improves
performance on various tasks, including general text tasks, math tasks, and
text-to-speech (TTS) tasks. These results establish LPO as a robust and tunable
paradigm for preference alignment, and we release the source code, models, and
training data publicly.

</details>


### [76] [Large Foundation Model for Ads Recommendation](https://arxiv.org/abs/2508.14948)
*Shangyu Zhang,Shijie Quan,Zhongren Wang,Junwei Pan,Tianqu Zhuang,Bo Fu,Yilong Sun,Jieying Lin,Jushuo Chen,Xiaotian Li,Zhixiang Feng,Xian Hu,Huiting Deng,Hua Lu,Jinpeng Wang,Boqi Dai,Xiaoyu Chen,Bin Hu,Lili Huang,Yanwen Wu,Yeshou Cai,Qi Zhou,Huang Tang,Chunfeng Yang,Chengguo Yin,Tingyu Jiang,Lifeng Wang,Shudong Huang,Dapeng Liu,Lei Xiao,Haijie Gu,Shu-Tao Xia,Jie Jiang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为LFM4Ads的广告推荐框架，通过全面迁移用户、物品及用户-物品交叉表示，并采用多粒度机制提升迁移效果，已成功应用于工业级广告平台。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅迁移用户表示，忽略了物品表示和用户-物品交叉表示，且迁移粒度不足，导致推荐效果受限。

Method: 提出LFM4Ads框架，全面迁移用户、物品及用户-物品交叉表示，并通过非线适配器、同构交互模块和独立检索等多粒度机制优化迁移。

Result: 在腾讯广告平台部署后，LFM4Ads实现了2.45%的GMV提升，预计年收入增加数亿美元。

Conclusion: LFM4Ads通过多粒度迁移和全表示利用，显著提升了广告推荐效果，为工业级应用提供了高效解决方案。

Abstract: Online advertising relies on accurate recommendation models, with recent
advances using pre-trained large-scale foundation models (LFMs) to capture
users' general interests across multiple scenarios and tasks. However, existing
methods have critical limitations: they extract and transfer only user
representations (URs), ignoring valuable item representations (IRs) and
user-item cross representations (CRs); and they simply use a UR as a feature in
downstream applications, which fails to bridge upstream-downstream gaps and
overlooks more transfer granularities. In this paper, we propose LFM4Ads, an
All-Representation Multi-Granularity transfer framework for ads recommendation.
It first comprehensively transfers URs, IRs, and CRs, i.e., all available
representations in the pre-trained foundation model. To effectively utilize the
CRs, it identifies the optimal extraction layer and aggregates them into
transferable coarse-grained forms. Furthermore, we enhance the transferability
via multi-granularity mechanisms: non-linear adapters for feature-level
transfer, an Isomorphic Interaction Module for module-level transfer, and
Standalone Retrieval for model-level transfer. LFM4Ads has been successfully
deployed in Tencent's industrial-scale advertising platform, processing tens of
billions of daily samples while maintaining terabyte-scale model parameters
with billions of sparse embedding keys across approximately two thousand
features. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+
successful production launches across various advertising scenarios, including
primary ones like Weixin Moments and Channels. These launches achieve an
overall GMV lift of 2.45% across the entire platform, translating to estimated
annual revenue increases in the hundreds of millions of dollars.

</details>


### [77] [Quantum Long Short-term Memory with Differentiable Architecture Search](https://arxiv.org/abs/2508.14955)
*Samuel Yen-Chi Chen,Prayag Tiwari*

Main category: cs.LG

TL;DR: 提出DiffQAS-QLSTM框架，通过端到端可微分优化量子电路参数和架构选择，提升序列学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决变分量子电路（VQC）设计任务专用且效率低的问题。

Method: 提出DiffQAS-QLSTM框架，结合可微分优化，自动调整VQC参数和架构。

Result: 在多样测试场景中表现优于手工设计基线，损失更低。

Conclusion: 为可扩展和自适应量子序列学习开辟了新途径。

Abstract: Recent advances in quantum computing and machine learning have given rise to
quantum machine learning (QML), with growing interest in learning from
sequential data. Quantum recurrent models like QLSTM are promising for
time-series prediction, NLP, and reinforcement learning. However, designing
effective variational quantum circuits (VQCs) remains challenging and often
task-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end
differentiable framework that optimizes both VQC parameters and architecture
selection during training. Our results show that DiffQAS-QLSTM consistently
outperforms handcrafted baselines, achieving lower loss across diverse test
settings. This approach opens the door to scalable and adaptive quantum
sequence learning.

</details>


### [78] [CuMoLoS-MAE: A Masked Autoencoder for Remote Sensing Data Reconstruction](https://arxiv.org/abs/2508.14957)
*Anurup Naskar,Nathanael Zhixin Wong,Sara Shamekh*

Main category: cs.LG

TL;DR: 本文提出CuMoLoS-MAE模型，用于修复大气遥感数据中的精细特征，并量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统方法会模糊精细结构，而深度学习模型缺乏置信度估计。

Method: 采用课程引导的蒙特卡洛随机集成掩码自编码器，通过训练和蒙特卡洛采样实现高保真重建和不确定性量化。

Result: 模型能修复精细特征，支持对流诊断、实时数据同化和气候再分析。

Conclusion: CuMoLoS-MAE为大气遥感数据提供了一种高保真重建和不确定性量化的新方法。

Abstract: Accurate atmospheric profiles from remote sensing instruments such as Doppler
Lidar, Radar, and radiometers are frequently corrupted by low-SNR (Signal to
Noise Ratio) gates, range folding, and spurious discontinuities. Traditional
gap filling blurs fine-scale structures, whereas deep models lack confidence
estimates. We present CuMoLoS-MAE, a Curriculum-Guided Monte Carlo Stochastic
Ensemble Masked Autoencoder designed to (i) restore fine-scale features such as
updraft and downdraft cores, shear lines, and small vortices, (ii) learn a
data-driven prior over atmospheric fields, and (iii) quantify pixel-wise
uncertainty. During training, CuMoLoS-MAE employs a mask-ratio curriculum that
forces a ViT decoder to reconstruct from progressively sparser context. At
inference, we approximate the posterior predictive by Monte Carlo over random
mask realisations, evaluating the MAE multiple times and aggregating the
outputs to obtain the posterior predictive mean reconstruction together with a
finely resolved per-pixel uncertainty map. Together with high-fidelity
reconstruction, this novel deep learning-based workflow enables enhanced
convection diagnostics, supports real-time data assimilation, and improves
long-term climate reanalysis.

</details>


### [79] [Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System](https://arxiv.org/abs/2508.14976)
*Joydeep Chandra,Prabal Manhas,Ramanjot Kaur,Rashi Sahay*

Main category: cs.LG

TL;DR: Aura-CAPTHA是一种结合GANs、RL和LLMs的多模态CAPTCHA系统，显著提升安全性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决传统CAPTCHA方法容易被AI技术（如OCR）绕过的漏洞。

Method: 集成GANs生成动态图像挑战，RL自适应调整难度，LLMs生成文本和音频提示。

Result: 实际测试中人类成功率92%，机器人绕过率10%，优于现有系统。

Conclusion: 系统提供了强健且可扩展的在线应用保护方案，填补了研究空白。

Abstract: Aura-CAPTCHA was developed as a multi-modal CAPTCHA system to address
vulnerabilities in traditional methods that are increasingly bypassed by AI
technologies, such as Optical Character Recognition (OCR) and adversarial image
processing. The design integrated Generative Adversarial Networks (GANs) for
generating dynamic image challenges, Reinforcement Learning (RL) for adaptive
difficulty tuning, and Large Language Models (LLMs) for creating text and audio
prompts. Visual challenges included 3x3 grid selections with at least three
correct images, while audio challenges combined randomized numbers and words
into a single task. RL adjusted difficulty based on incorrect attempts,
response time, and suspicious user behavior. Evaluations on real-world traffic
demonstrated a 92% human success rate and a 10% bot bypass rate, significantly
outperforming existing CAPTCHA systems. The system provided a robust and
scalable approach for securing online applications while remaining accessible
to users, addressing gaps highlighted in previous research.

</details>


### [80] [Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs](https://arxiv.org/abs/2508.14995)
*Anastasis Kratsios,Ariel Neufeld,Philipp Schmocker*

Main category: cs.LG

TL;DR: 该论文通过生成平衡算子（GEOs）解决了神经网络算子理论中参数需求过大与实际实验结果不符的差距，证明了其在无限维度紧凑集上能够高效逼近优化问题的解。


<details>
  <summary>Details</summary>
Motivation: 针对神经网络算子在理论上需要大量参数与实际应用效果不符的矛盾，研究者提出GEOs，旨在通过有限维深层平衡层解决无限维空间中的凸优化问题。

Method: 使用生成平衡算子（GEOs）和有限维深层平衡层，处理可分离希尔伯特空间中的凸优化问题，输入为光滑凸损失函数，输出为近似解。

Result: 论文证明了GEOs在特定条件下能够以对数级增长的参数复杂度逼近最优解，并在非线性PDE、随机最优控制和金融对冲三个应用中验证了其有效性。

Conclusion: GEOs在理论与实践中架起了桥梁，展示了其在无限维问题中的高效逼近能力，同时在实际应用中表现优异。

Abstract: Neural operators (NOs) are a class of deep learning models designed to
simultaneously solve infinitely many related problems by casting them into an
infinite-dimensional space, whereon these NOs operate. A significant gap
remains between theory and practice: worst-case parameter bounds from universal
approximation theorems suggest that NOs may require an unrealistically large
number of parameters to solve most operator learning problems, which stands in
direct opposition to a slew of experimental evidence. This paper closes that
gap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),
using (realistic) finite-dimensional deep equilibrium layers, when solving
families of convex optimization problems over a separable Hilbert space $X$.
Here, the inputs are smooth, convex loss functions on $X$, and outputs are the
associated (approximate) solutions to the optimization problem defined by each
input loss.
  We show that when the input losses lie in suitable infinite-dimensional
compact sets, our GEO can uniformly approximate the corresponding solutions to
arbitrary precision, with rank, depth, and width growing only logarithmically
in the reciprocal of the approximation error. We then validate both our
theoretical results and the trainability of GEOs on three applications: (1)
nonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging
problems in mathematical finance under liquidity constraints.

</details>


### [81] [Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications](https://arxiv.org/abs/2508.15008)
*Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri*

Main category: cs.LG

TL;DR: 本文综述了量化神经网络（QNN）在资源受限设备上的部署问题，重点介绍了量化技术及硬件与软件框架的优化，探讨了当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 解决在微控制器等资源受限设备上部署QNN时性能、计算复杂度和内存限制的平衡问题。

Method: 通过系统综述量化技术，并结合硬件加速和软件优化，评估现有框架和平台。

Result: 分析了QNN部署中的关键权衡，总结了当前挑战和未来发展方向。

Conclusion: TinyML通过跨领域的优化，为QNN在嵌入式系统上的高效运行提供了可能性。

Abstract: The deployment of Quantized Neural Networks (QNNs) on resource-constrained
devices, such as microcontrollers, has introduced significant challenges in
balancing model performance, computational complexity and memory constraints.
Tiny Machine Learning (TinyML) addresses these issues by integrating
advancements across machine learning algorithms, hardware acceleration, and
software optimization to efficiently run deep neural networks on embedded
systems. This survey presents a hardware-centric introduction to quantization,
systematically reviewing essential quantization techniques employed to
accelerate deep learning models for embedded applications. In particular,
further emphasis is put on critical trade-offs among model performance and
hardware capabilities. The survey further evaluates existing software
frameworks and hardware platforms designed specifically for supporting QNN
execution on microcontrollers. Moreover, we provide an analysis of the current
challenges and an outline of promising future directions in the rapidly
evolving domain of QNN deployment.

</details>


### [82] [TOAST: Fast and scalable auto-partitioning based on principled static analysis](https://arxiv.org/abs/2508.15010)
*Sami Alabed,Dominik Grewe,Norman Alexander Rink,Timur Sitdikov,Agnieszka Swietlik,Dimitrios Vytiniotis,Daniel Belov*

Main category: cs.LG

TL;DR: 论文提出了一种结合静态编译器分析和蒙特卡洛树搜索的系统，用于高效分区大型机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动分区方法在高维搜索空间中的内存和性能问题。

Method: 结合静态编译器分析（识别需一致分区的张量维度和冲突）与蒙特卡洛树搜索。

Result: 在多样硬件和模型架构中显著优于现有工业方法，发现更优解。

Conclusion: 系统能完全自动化处理复杂大型模型，提供高效分区方案。

Abstract: Partitioning large machine learning models across distributed accelerator
systems is a complex process, requiring a series of interdependent decisions
that are further complicated by internal sharding ambiguities. Consequently,
existing auto-partitioners often suffer from out-of-memory errors or are
prohibitively slow when exploring the exponentially large space of possible
partitionings. To mitigate this, they artificially restrict the search space,
but this approach frequently yields infeasible solutions that violate device
memory constraints or lead to sub-optimal performance.
  We propose a system that combines a novel static compiler analysis with a
Monte Carlo Tree Search. Our analysis constructs an efficient decision space by
identifying (i) tensor dimensions requiring identical sharding, and (ii)
partitioning "conflicts" that require resolution.
  Our system significantly outperforms state-of-the-art industrial methods
across diverse hardware platforms and model architectures, discovering
previously unknown, superior solutions, and the process is fully automated even
for complex and large models.

</details>


### [83] [Fragment-Wise Interpretability in Graph Neural Networks via Molecule Decomposition and Contribution Analysis](https://arxiv.org/abs/2508.15015)
*Sebastian Musiał,Bartosz Zieliński,Tomasz Danel*

Main category: cs.LG

TL;DR: SEAL是一种新型可解释的图神经网络，通过归因学习将预测结果归因于有意义的分子子结构，提升了模型的可解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络在预测分子性质方面表现优异，但缺乏可解释性，限制了其在高风险应用如药物发现中的信任度。

Method: SEAL通过将输入图分解为化学相关片段，并估计其对输出的因果影响，同时减少片段间的消息传递以实现明确归因。

Result: SEAL在合成基准和真实分子数据集的评估中表现优于其他解释方法，且用户研究表明其解释更直观可信。

Conclusion: SEAL在预测性能和可解释性之间架起桥梁，为分子建模提供了更透明和可操作的解决方案。

Abstract: Graph neural networks have demonstrated remarkable success in predicting
molecular properties by leveraging the rich structural information encoded in
molecular graphs. However, their black-box nature reduces interpretability,
which limits trust in their predictions for important applications such as drug
discovery and materials design. Furthermore, existing explanation techniques
often fail to reliably quantify the contribution of individual atoms or
substructures due to the entangled message-passing dynamics. We introduce SEAL
(Substructure Explanation via Attribution Learning), a new interpretable graph
neural network that attributes model predictions to meaningful molecular
subgraphs. SEAL decomposes input graphs into chemically relevant fragments and
estimates their causal influence on the output. The strong alignment between
fragment contributions and model predictions is achieved by explicitly reducing
inter-fragment message passing in our proposed model architecture. Extensive
evaluations on synthetic benchmarks and real-world molecular datasets
demonstrate that SEAL outperforms other explainability methods in both
quantitative attribution metrics and human-aligned interpretability. A user
study further confirms that SEAL provides more intuitive and trustworthy
explanations to domain experts. By bridging the gap between predictive
performance and interpretability, SEAL offers a promising direction for more
transparent and actionable molecular modeling.

</details>


### [84] [Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping](https://arxiv.org/abs/2508.15019)
*Carlos Stein Brito*

Main category: cs.LG

TL;DR: 论文提出了一种名为Twin-Bootstrap梯度下降的方法，用于在优化过程中整合不确定性估计，解决传统方法在深度学习中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的梯度下降方法无法提供置信度测量，且在过参数化和低数据量的情况下容易过拟合。而Bootstrap方法在深度学习中直接应用时存在效率低、无法指导学习、假设不符合非凸优化等问题。

Method: 通过训练两个独立Bootstrap样本的相同模型，并定期重置均值以保持轨迹在同一个优化盆地内，从而估计局部不确定性。在训练过程中，利用这种估计自适应地采样权重，提供正则化效果。

Result: 在深度神经网络和高维逆问题中，该方法提高了模型的校准性和泛化能力，并生成了可解释的不确定性图。

Conclusion: Twin-Bootstrap梯度下降方法为优化过程提供了有效的不确定性估计，提升了深度学习模型在复杂任务中的表现。

Abstract: Standard gradient descent methods yield point estimates with no measure of
confidence. This limitation is acute in overparameterized and low-data regimes,
where models have many parameters relative to available data and can easily
overfit. Bootstrapping is a classical statistical framework for uncertainty
estimation based on resampling, but naively applying it to deep learning is
impractical: it requires training many replicas, produces post-hoc estimates
that cannot guide learning, and implicitly assumes comparable optima across
runs - an assumption that fails in non-convex landscapes. We introduce
Twin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training
procedure that integrates uncertainty estimation into optimization. Two
identical models are trained in parallel on independent bootstrap samples, and
a periodic mean-reset keeps both trajectories in the same basin so that their
divergence reflects local (within-basin) uncertainty. During training, we use
this estimate to sample weights in an adaptive, data-driven way, providing
regularization that favors flatter solutions. In deep neural networks and
complex high-dimensional inverse problems, the approach improves calibration
and generalization and yields interpretable uncertainty maps.

</details>


### [85] [Nonlinear Federated System Identification](https://arxiv.org/abs/2508.15025)
*Omkar Tupe,Max Hartman,Lav R. Varshney,Saurav Prakash*

Main category: cs.LG

TL;DR: 论文研究了联邦学习在线性参数化非线性系统中的表现，理论证明了联邦方法的收敛率优于集中式方法，且随着客户端数量增加而提升。实验验证了在物理系统中的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索联邦学习在非线性系统识别中的潜力，比较其与集中式方法的性能，特别是在多客户端场景下的表现。

Method: 利用线性参数化模型处理非线性系统，并在实验中采用独立同分布的控制输入和策略扰动，通过物理系统的轨迹数据验证理论。

Result: 联邦学习显著提升了单个客户端的收敛速度，随着客户端数量增加，收敛性能进一步改善。

Conclusion: 联邦学习在多客户端非线性系统识别中具有优势，可通过选择合适的特征映射进一步提高性能。

Abstract: We consider federated learning of linearly-parameterized nonlinear systems.
We establish theoretical guarantees on the effectiveness of federated nonlinear
system identification compared to centralized approaches, demonstrating that
the convergence rate improves as the number of clients increases. Although the
convergence rates in the linear and nonlinear cases differ only by a constant,
this constant depends on the feature map $\phi$, which can be carefully chosen
in the nonlinear setting to increase excitation and improve performance. We
experimentally validate our theory in physical settings where client devices
are driven by i.i.d. control inputs and control policies exhibiting i.i.d.
random perturbations, ensuring non-active exploration. Experiments use
trajectories from nonlinear dynamical systems characterized by real-analytic
feature functions, including polynomial and trigonometric components,
representative of physical systems including pendulum and quadrotor dynamics.
We analyze the convergence behavior of the proposed method under varying noise
levels and data distributions. Results show that federated learning
consistently improves convergence of any individual client as the number of
participating clients increases.

</details>


### [86] [Rethinking the Potential of Layer Freezing for Efficient DNN Training](https://arxiv.org/abs/2508.15033)
*Chence Yang,Ci Zhang,Lei Lu,Qitao Tan,Sheng Li,Ao Li,Xulong Tang,Shaoyi Huang,Jinzhen Wang,Guoming Li,Jundong Li,Xiaoming Zhai,Jin Lu,Geng Yuan*

Main category: cs.LG

TL;DR: 本文提出了一种新方法来解决传统层冻结技术在减少神经网络训练成本中的局限性，通过缓存特征图和优化数据压缩策略，显著降低了计算和存储开销。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络和数据集的规模增长，训练的计算成本大幅增加。传统层冻结方法虽能减少部分计算成本，但仍需前向传播生成特征图，限制了效率提升。本文旨在解决这一痛点。

Method: 提出相似性感知通道增强和渐进式压缩策略：前者缓存对增强敏感的通道以减少存储成本，后者通过逐步增加压缩率来优化存储效率。

Result: 该方法在保持模型精度的同时，显著降低了训练成本和存储开销，仅引入微小的时间开销。

Conclusion: 通过系统性解决方案和综合分析，本文为高效DNN训练提供了实用见解，并验证了层冻结与压缩策略的优化潜力。

Abstract: With the growing size of deep neural networks and datasets, the computational
costs of training have significantly increased. The layer-freezing technique
has recently attracted great attention as a promising method to effectively
reduce the cost of network training. However, in traditional layer-freezing
methods, frozen layers are still required for forward propagation to generate
feature maps for unfrozen layers, limiting the reduction of computation costs.
To overcome this, prior works proposed a hypothetical solution, which caches
feature maps from frozen layers as a new dataset, allowing later layers to
train directly on stored feature maps. While this approach appears to be
straightforward, it presents several major challenges that are severely
overlooked by prior literature, such as how to effectively apply augmentations
to feature maps and the substantial storage overhead introduced. If these
overlooked challenges are not addressed, the performance of the caching method
will be severely impacted and even make it infeasible. This paper is the first
to comprehensively explore these challenges and provides a systematic solution.
To improve training accuracy, we propose \textit{similarity-aware channel
augmentation}, which caches channels with high augmentation sensitivity with a
minimum additional storage cost. To mitigate storage overhead, we incorporate
lossy data compression into layer freezing and design a \textit{progressive
compression} strategy, which increases compression rates as more layers are
frozen, effectively reducing storage costs. Finally, our solution achieves
significant reductions in training cost while maintaining model accuracy, with
a minor time overhead. Additionally, we conduct a comprehensive evaluation of
freezing and compression strategies, providing insights into optimizing their
application for efficient DNN training.

</details>


### [87] [Robust Estimation Under Heterogeneous Corruption Rates](https://arxiv.org/abs/2508.15051)
*Syomantak Chaudhuri,Jerry Li,Thomas A. Courtade*

Main category: cs.LG

TL;DR: 研究了在异构腐败率下的稳健估计问题，提出了一种适用于多种场景的优化方法。


<details>
  <summary>Details</summary>
Motivation: 现有的稳健估计方法通常假设腐败率均匀或最坏情况，忽视了结构异构性，而该问题在分布式学习、众包和传感器网络等场景中很重要。

Method: 针对多元有界分布和单变量高斯分布，给出了所有异构腐败模式的紧致极小极大率；针对多元高斯均值估计和线性回归，建立了平方误差的极小极大率。

Result: 发现超出一定腐败阈值的样本可能被最优估计器丢弃，这一阈值由腐败率的经验分布决定。

Conclusion: 研究为异构腐败率下的稳健估计提供了理论支持，并为实际应用中的样本选择提供了指导。

Abstract: We study the problem of robust estimation under heterogeneous corruption
rates, where each sample may be independently corrupted with a known but
non-identical probability. This setting arises naturally in distributed and
federated learning, crowdsourcing, and sensor networks, yet existing robust
estimators typically assume uniform or worst-case corruption, ignoring
structural heterogeneity. For mean estimation for multivariate bounded
distributions and univariate gaussian distributions, we give tight minimax
rates for all heterogeneous corruption patterns. For multivariate gaussian mean
estimation and linear regression, we establish the minimax rate for squared
error up to a factor of $\sqrt{d}$, where $d$ is the dimension. Roughly, our
findings suggest that samples beyond a certain corruption threshold may be
discarded by the optimal estimators -- this threshold is determined by the
empirical distribution of the corruption rates given.

</details>


### [88] [Enhancing Optimizer Stability: Momentum Adaptation of The NGN Step-size](https://arxiv.org/abs/2508.15071)
*Rustem Islamov,Niccolo Ajroldi,Antonio Orvieto,Aurelien Lucchi*

Main category: cs.LG

TL;DR: 论文提出了一种结合动量和NGN步长的新型优化算法（NGN-M），提高了对步长超参数选择的稳定性，并在性能上达到或超过现有最优算法。


<details>
  <summary>Details</summary>
Motivation: 现代优化算法在深度学习任务中表现出色，但对超参数（尤其是步长）的调优敏感且耗时，因此需要提高算法的稳定性。

Method: 通过引入动量版本NGN-M，并在NGN步长方法基础上进行创新，算法在不需严格假设条件下实现了标准收敛速率。

Result: NGN-M在步长选择上更稳健，性能优于或与其他最优算法相当，且无需插值条件或有界梯度假设。

Conclusion: 该算法为优化深度学习任务中的超参数调优提供了更稳定和高效的工具。

Abstract: Modern optimization algorithms that incorporate momentum and adaptive
step-size offer improved performance in numerous challenging deep learning
tasks. However, their effectiveness is often highly sensitive to the choice of
hyperparameters, especially the step-size. Tuning these parameters is often
difficult, resource-intensive, and time-consuming. Therefore, recent efforts
have been directed toward enhancing the stability of optimizers across a wide
range of hyperparameter choices [Schaipp et al., 2024]. In this paper, we
introduce an algorithm that matches the performance of state-of-the-art
optimizers while improving stability to the choice of the step-size
hyperparameter through a novel adaptation of the NGN step-size method [Orvieto
and Xiao, 2024]. Specifically, we propose a momentum-based version (NGN-M) that
attains the standard convergence rate of $\mathcal{O}(1/\sqrt{K})$ under less
restrictive assumptions, without the need for interpolation condition or
assumptions of bounded stochastic gradients or iterates, in contrast to
previous approaches. Additionally, we empirically demonstrate that the
combination of the NGN step-size with momentum results in enhanced robustness
to the choice of the step-size hyperparameter while delivering performance that
is comparable to or surpasses other state-of-the-art optimizers.

</details>


### [89] [Wormhole Dynamics in Deep Neural Networks](https://arxiv.org/abs/2508.15086)
*Yen-Lung Lai,Zhe Jin*

Main category: cs.LG

TL;DR: 本文研究了深度神经网络（DNN）的泛化行为，特别是“欺骗性示例”现象，并提出了一种基于最大似然估计的分析框架，揭示了过参数化DNN在输出特征空间的崩溃现象。


<details>
  <summary>Details</summary>
Motivation: 探索DNN的泛化行为及其在处理随机或非结构化输入时的表现，以揭示模型学习的深层机制。

Method: 引入基于最大似然估计的分析框架，避免依赖梯度优化和显式标签的传统数值方法。

Result: 发现过参数化DNN在输出特征空间崩溃，并提出“虫洞解决方案”以绕过退化问题，调和随机输入与有意义的标签。

Conclusion: 研究为DNN泛化提供了新视角，并指出了在无监督学习动态中弥合理论与实践差距的未来研究方向。

Abstract: This work investigates the generalization behavior of deep neural networks
(DNNs), focusing on the phenomenon of "fooling examples," where DNNs
confidently classify inputs that appear random or unstructured to humans. To
explore this phenomenon, we introduce an analytical framework based on maximum
likelihood estimation, without adhering to conventional numerical approaches
that rely on gradient-based optimization and explicit labels. Our analysis
reveals that DNNs operating in an overparameterized regime exhibit a collapse
in the output feature space. While this collapse improves network
generalization, adding more layers eventually leads to a state of degeneracy,
where the model learns trivial solutions by mapping distinct inputs to the same
output, resulting in zero loss. Further investigation demonstrates that this
degeneracy can be bypassed using our newly derived "wormhole" solution. The
wormhole solution, when applied to arbitrary fooling examples, reconciles
meaningful labels with random ones and provides a novel perspective on shortcut
learning. These findings offer deeper insights into DNN generalization and
highlight directions for future research on learning dynamics in unsupervised
settings to bridge the gap between theory and practice.

</details>


### [90] [Evaluating Sparse Autoencoders for Monosemantic Representation](https://arxiv.org/abs/2508.15094)
*Moghis Fereidouni,Muhammad Umair Haider,Peizhong Ju,A. B. Siddique*

Main category: cs.LG

TL;DR: 论文通过系统评估稀疏自编码器（SAEs）与基础模型在单义性上的表现，提出了一种基于Jensen-Shannon距离的概念可分离性评分，发现SAEs能减少多义性并提高概念可分离性，但稀疏性并非总是带来更好的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型中神经元多义性的问题，验证稀疏自编码器（SAEs）在提升单义性方面的效果。

Method: 引入基于Jensen-Shannon距离的概念可分离性评分，使用Gemma-2-2B模型和多种SAE变体进行系统评估，并提出Attenuation via Posterior Probabilities（APP）干预方法。

Result: SAEs能减少多义性并提高概念可分离性，稀疏性并不总是与性能正相关；APP方法在目标概念去除上优于现有方法。

Conclusion: 稀疏自编码器（SAEs）在提升单义性和概念分离方面有效，但需权衡稀疏性；新干预方法APP展示了更强的目标控制能力。

Abstract: A key barrier to interpreting large language models is polysemanticity, where
neurons activate for multiple unrelated concepts. Sparse autoencoders (SAEs)
have been proposed to mitigate this issue by transforming dense activations
into sparse, more interpretable features. While prior work suggests that SAEs
promote monosemanticity, there has been no quantitative comparison with their
base models. This paper provides the first systematic evaluation of SAEs
against base models concerning monosemanticity. We introduce a fine-grained
concept separability score based on the Jensen-Shannon distance, which captures
how distinctly a neuron's activation distributions vary across concepts. Using
Gemma-2-2B and multiple SAE variants across five benchmarks, we show that SAEs
reduce polysemanticity and achieve higher concept separability. However,
greater sparsity of SAEs does not always yield better separability and often
impairs downstream performance. To assess practical utility, we evaluate
concept-level interventions using two strategies: full neuron masking and
partial suppression. We find that, compared to base models, SAEs enable more
precise concept-level control when using partial suppression. Building on this,
we propose Attenuation via Posterior Probabilities (APP), a new intervention
method that uses concept-conditioned activation distributions for targeted
suppression. APP outperforms existing approaches in targeted concept removal.

</details>


### [91] [Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory](https://arxiv.org/abs/2508.15099)
*Siddharth Chaudhary,Bennett Browning*

Main category: cs.LG

TL;DR: Hydra提出了一种混合长上下文语言模型架构，结合条件计算、长上下文记忆机制和稀疏混合专家，旨在实现模块化、输入自适应的长上下文语言模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决长上下文语言模型的效率与扩展性问题，Hydra融合了多种技术，以在1.6B参数规模内实现高效性能。

Method: Hydra架构整合了Mamba风格的状态空间模型（SSM）、稀疏全局注意力、块级MoE路由和双记忆系统（工作记忆与事实记忆）。同时提供透明的参数和复杂度分析。

Result: 通过小规模原型验证了可行性，展示了长上下文吞吐量交叉和可控专家路由等特性，但未进行全规模性能验证。

Conclusion: Hydra是一个蓝图，旨在激发后续实证研究，未来需进一步验证其在大规模任务中的性能增益。

Abstract: We present Hydra as an architectural proposal for hybrid long-context
language models that combine conditional computation, long-context memory
mechanisms, and sparse mixture-of-experts within an approximately 1.6B
parameter design envelope. Hydra integrates a Mamba-style Structured State
Space Model (SSM) backbone with intermittent sparse global attention,
chunk-level MoE feed-forward routing, and dual (workspace plus factual PKM)
memories. We formalize the component interfaces, give transparent parameter and
complexity accounting, and outline a staged curriculum intended to stably
activate the parts. We accompany the specification with illustrative toy-scale
prototype measurements (tens of millions of parameters on synthetic data) whose
sole purpose is to demonstrate implementation feasibility and qualitative
scaling behaviors (for example, long-context throughput crossover and
controllable expert routing), not to claim competitive full-scale performance.
We explicitly delineate assumptions and open risks (training complexity, memory
utilization, specialization dynamics) and position Hydra as a blueprint to
stimulate empirical follow-up rather than a finished system. By combining SSM
efficiency, selective sparse attention, MoE capacity, and learnable memory,
Hydra sketches a path toward modular, input-adaptive long-context language
models; validating end-task gains at target scale remains future work.

</details>


### [92] [Side Effects of Erasing Concepts from Diffusion Models](https://arxiv.org/abs/2508.15124)
*Shaswati Saha,Sourajit Saha,Manas Gaur,Tejas Gokhale*

Main category: cs.LG

TL;DR: 该论文指出概念擦除技术（CETs）易被规避，并通过Side Effect Evaluation（SEE）评估其副作用，包括对邻近概念的影响、目标规避和属性泄漏。


<details>
  <summary>Details</summary>
Motivation: 研究CETs在实际应用中的局限性，揭示其在隐私、版权和安全性方面的潜在问题。

Method: 开发SEE评估框架，使用分层和组合性提示量化CETs的副作用，并通过实验验证其易被规避的特性。

Result: 实验表明，CETs可通过超类-子类层次结构和语义相似提示规避，存在属性泄漏和注意力异常现象。

Conclusion: CETs存在显著缺陷，需要更鲁棒的解决方案；作者将数据集和工具开源以支持未来研究。

Abstract: Concerns about text-to-image (T2I) generative models infringing on privacy,
copyright, and safety have led to the development of Concept Erasure Techniques
(CETs).
  The goal of an effective CET is to prohibit the generation of undesired
``target'' concepts specified by the user, while preserving the ability to
synthesize high-quality images of the remaining concepts.
  In this work, we demonstrate that CETs can be easily circumvented and present
several side effects of concept erasure.
  For a comprehensive measurement of the robustness of CETs, we present Side
Effect Evaluation (\see), an evaluation benchmark that consists of hierarchical
and compositional prompts that describe objects and their attributes.
  This dataset and our automated evaluation pipeline quantify side effects of
CETs across three aspects: impact on neighboring concepts, evasion of targets,
and attribute leakage.
  Our experiments reveal that CETs can be circumvented by using
superclass-subclass hierarchy and semantically similar prompts, such as
compositional variants of the target. We show that CETs suffer from attribute
leakage and counterintuitive phenomena of attention concentration or dispersal.
  We release our dataset, code, and evaluation tools to aid future work on
robust concept erasure.

</details>


### [93] [Towards Source-Free Machine Unlearning](https://arxiv.org/abs/2508.15127)
*Sk Miraj Ahmed,Umit Yigit Basaran,Dripta S. Raychaudhuri,Arindam Dutta,Rohit Kundu,Fahim Faisal Niloy,Basak Guler,Amit K. Roy-Chowdhury*

Main category: cs.LG

TL;DR: 提出了一种源无关的遗忘方法，通过估计剩余训练数据的Hessian矩阵，实现在无需原始训练数据的情况下高效去除特定数据。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习广泛应用和数据隐私法规发展，从训练模型中移除私有或受版权保护信息的需求日益重要。现有方法通常依赖整个训练数据集，但在实际场景中可能无法获取原始数据。

Method: 提出了一种源无关遗忘方法，通过估计剩余训练数据的Hessian矩阵，实现了无需原始数据的零样本遗忘。

Result: 广泛的实验验证了该方法在保持剩余数据性能的同时，高效移除特定数据的有效性。

Conclusion: 该方法为源无关场景下的高效遗忘提供了理论和实践支持。

Abstract: As machine learning becomes more pervasive and data privacy regulations
evolve, the ability to remove private or copyrighted information from trained
models is becoming an increasingly critical requirement. Existing unlearning
methods often rely on the assumption of having access to the entire training
dataset during the forgetting process. However, this assumption may not hold
true in practical scenarios where the original training data may not be
accessible, i.e., the source-free setting. To address this challenge, we focus
on the source-free unlearning scenario, where an unlearning algorithm must be
capable of removing specific data from a trained model without requiring access
to the original training dataset. Building on recent work, we present a method
that can estimate the Hessian of the unknown remaining training data, a crucial
component required for efficient unlearning. Leveraging this estimation
technique, our method enables efficient zero-shot unlearning while providing
robust theoretical guarantees on the unlearning performance, while maintaining
performance on the remaining data. Extensive experiments over a wide range of
datasets verify the efficacy of our method.

</details>


### [94] [Universal Reinforcement Learning in Coalgebras: Asynchronous Stochastic Computation via Conduction](https://arxiv.org/abs/2508.15128)
*Sridhar Mahadevan*

Main category: cs.LG

TL;DR: 本文提出了基于范畴论的通用强化学习（URL），利用非良基集合、拓扑论和异步并行计算等数学抽象扩展了传统强化学习框架。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习（RL）框架在处理复杂动态系统时存在局限性，需要通过更高级的数学工具（如范畴论和联合拓扑理论）进行扩展，以支持更通用的学习和决策模型。

Method: 通过范畴论和函子分析RL，提出了标准异步分布式最小化模型，并将MDPs、POMDPs等动态系统建模为通用联合拓扑。在URL框架中，RL的固定点问题被推广为异步分布式计算联合拓扑的最终态。

Result: 展示了RL算法空间可以表示为函子范畴，扩展了动态系统模型的联合拓扑家族，并提出了分布式计算最终联合拓扑的方法。

Conclusion: URL为RL提供了更强大的数学基础和通用性，能够处理更复杂的动态系统和异步并行计算场景。

Abstract: In this paper, we introduce a categorial generalization of RL, termed
universal reinforcement learning (URL), building on powerful mathematical
abstractions from the study of coinduction on non-well-founded sets and
universal coalgebras, topos theory, and categorial models of asynchronous
parallel distributed computation. In the first half of the paper, we review the
basic RL framework, illustrate the use of categories and functors in RL,
showing how they lead to interesting insights. In particular, we also introduce
a standard model of asynchronous distributed minimization proposed by Bertsekas
and Tsitsiklis, and describe the relationship between metric coinduction and
their proof of the Asynchronous Convergence Theorem. The space of algorithms
for MDPs or PSRs can be modeled as a functor category, where the co-domain
category forms a topos, which admits all (co)limits, possesses a subobject
classifier, and has exponential objects. In the second half of the paper, we
move on to universal coalgebras. Dynamical system models, such as Markov
decision processes (MDPs), partially observed MDPs (POMDPs), a predictive state
representation (PSRs), and linear dynamical systems (LDSs) are all special
types of coalgebras. We describe a broad family of universal coalgebras,
extending the dynamic system models studied previously in RL. The core problem
in finding fixed points in RL to determine the exact or approximate (action)
value function is generalized in URL to determining the final coalgebra
asynchronously in a parallel distributed manner.

</details>


### [95] [Towards Reliable and Generalizable Differentially Private Machine Learning (Extended Version)](https://arxiv.org/abs/2508.15141)
*Wenxuan Bao,Vincent Bindschaedler*

Main category: cs.LG

TL;DR: 本文复现并验证了11种最新的差分隐私机器学习（DPML）技术，发现部分方法在初始实验条件外表现不佳，并探讨了DPML特有的可重复性挑战。


<details>
  <summary>Details</summary>
Motivation: 当前DPML技术缺乏一致的评估标准，不同方法之间的直接比较存在困难，因此需要进行可重复性和可复制性研究。

Method: 对11种现有SoTA DPML技术进行复现实验，分析其在初始实验条件外的表现，并讨论DPML特有的挑战。

Result: 部分DPML方法在严格测试下表现不佳，突显了评估标准和实验一致性的重要性。

Conclusion: 提出了确保DPML技术科学有效性的最佳实践，强调了可重复性研究的重要性。

Abstract: There is a flurry of recent research papers proposing novel differentially
private machine learning (DPML) techniques. These papers claim to achieve new
state-of-the-art (SoTA) results and offer empirical results as validation.
However, there is no consensus on which techniques are most effective or if
they genuinely meet their stated claims. Complicating matters, heterogeneity in
codebases, datasets, methodologies, and model architectures make direct
comparisons of different approaches challenging.
  In this paper, we conduct a reproducibility and replicability (R+R)
experiment on 11 different SoTA DPML techniques from the recent research
literature. Results of our investigation are varied: while some methods stand
up to scrutiny, others falter when tested outside their initial experimental
conditions. We also discuss challenges unique to the reproducibility of DPML,
including additional randomness due to DP noise, and how to address them.
Finally, we derive insights and best practices to obtain scientifically valid
and reliable results.

</details>


### [96] [A Robust BERT-Based Deep Learning Model for Automated Cancer Type Extraction from Unstructured Pathology Reports](https://arxiv.org/abs/2508.15149)
*Minh Tran,Jeffery C. Chan,Min Li Huang,Maya Kansara,John P. Grady,Christine E. Napier,Subotheni Thavaneswaran,Mandy L. Ballinger,David M. Thomas,Frank P. Lin*

Main category: cs.LG

TL;DR: 该研究开发了一种基于RoBERTa模型的系统，用于自动从病理报告中提取癌症类型，支持精准肿瘤学研究，性能显著优于基线模型和Mistral 7B。


<details>
  <summary>Details</summary>
Motivation: 电子病历中临床信息的准确提取对临床研究至关重要，但需要大量专业知识和人工劳动。

Method: 使用微调的RoBERTa模型从病理报告中自动提取特定癌症类型。

Result: 模型性能显著优于基线模型和Mistral 7B，F1_Bertscore为0.98，整体精确匹配率为80.61%。

Conclusion: 微调领域特定模型为精准任务提供了潜力，可能实现更高效准确的临床信息提取。

Abstract: The accurate extraction of clinical information from electronic medical
records is particularly critical to clinical research but require much trained
expertise and manual labor. In this study we developed a robust system for
automated extraction of the specific cancer types for the purpose of supporting
precision oncology research. from pathology reports using a fine-tuned RoBERTa
model. This model significantly outperformed the baseline model and a Large
Language Model, Mistral 7B, achieving F1_Bertscore 0.98 and overall exact match
of 80.61%. This fine-tuning approach demonstrates the potential for scalability
that can integrate seamlessly into the molecular tumour board process.
Fine-tuning domain-specific models for precision tasks in oncology, may pave
the way for more efficient and accurate clinical information extraction.

</details>


### [97] [SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks](https://arxiv.org/abs/2508.15182)
*Xiangman Li,Xiaodong Wu,Qi Li,Jianbing Ni,Rongxing Lu*

Main category: cs.LG

TL;DR: SafeLLM是一种基于遗忘的新防御框架，通过动态检测、有害内容定位和约束优化，有效减少LLM的有害输出，同时保持通用性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM因越狱攻击而生成有害内容的问题，需一种既能消除有害知识又不影响模型通用能力的防御方法。

Method: 采用三阶段流程：动态检测有害输出、通过FFN激活定位有害知识、约束优化以抑制有害行为。

Result: 实验证明SafeLLM显著降低攻击成功率，并在安全性、精确控制和鲁棒性上优于现有方法。

Conclusion: 遗忘是提升LLM安全性的有效方向，SafeLLM在保证性能的同时实现了更强的安全保障。

Abstract: Jailbreak attacks pose a serious threat to the safety of Large Language
Models (LLMs) by crafting adversarial prompts that bypass alignment mechanisms,
causing the models to produce harmful, restricted, or biased content. In this
paper, we propose SafeLLM, a novel unlearning-based defense framework that
unlearn the harmful knowledge from LLMs while preserving linguistic fluency and
general capabilities. SafeLLM employs a three-stage pipeline: (1) dynamic
unsafe output detection using a hybrid approach that integrates external
classifiers with model-internal evaluations; (2) token-level harmful content
tracing through feedforward network (FFN) activations to localize harmful
knowledge; and (3) constrained optimization to suppress unsafe behavior without
degrading overall model quality. SafeLLM achieves targeted and irreversible
forgetting by identifying and neutralizing FFN substructures responsible for
harmful generation pathways. Extensive experiments on prominent LLMs (Vicuna,
LLaMA, and GPT-J) across multiple jailbreak benchmarks show that SafeLLM
substantially reduces attack success rates while maintaining high
general-purpose performance. Compared to standard defense methods such as
supervised fine-tuning and direct preference optimization, SafeLLM offers
stronger safety guarantees, more precise control over harmful behavior, and
greater robustness to unseen attacks. Moreover, SafeLLM maintains the general
performance after the harmful knowledge unlearned. These results highlight
unlearning as a promising direction for scalable and effective LLM safety.

</details>


### [98] [Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework](https://arxiv.org/abs/2508.15193)
*Brodie Oldfield,Ziqi Xu,Sevvandi Kandanaarachchi*

Main category: cs.LG

TL;DR: 论文介绍了FairPrep，一个用于评估表格数据公平性预处理技术的模块化基准框架。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习系统在高风险决策中的作用增加，确保算法公平性成为关键需求。预处理方法因模型无关和隐私合规等优势受到较少关注且缺乏标准化评估工具。

Method: 基于AIF360平台，FairPrep提供可扩展的模块化框架，支持数据集、公平性干预和预测模型的无缝集成，并提供批量处理和自动报告功能。

Result: FairPrep填补了公平性基准测试领域的空白，支持标准化和可重复的评估。

Conclusion: FairPrep为数据级公平性研究提供了实用基础，推动了这一领域的进展。

Abstract: As machine learning systems become increasingly integrated into high-stakes
decision-making processes, ensuring fairness in algorithmic outcomes has become
a critical concern. Methods to mitigate bias typically fall into three
categories: pre-processing, in-processing, and post-processing. While
significant attention has been devoted to the latter two, pre-processing
methods, which operate at the data level and offer advantages such as
model-agnosticism and improved privacy compliance, have received comparatively
less focus and lack standardised evaluation tools. In this work, we introduce
FairPrep, an extensible and modular benchmarking framework designed to evaluate
fairness-aware pre-processing techniques on tabular datasets. Built on the
AIF360 platform, FairPrep allows seamless integration of datasets, fairness
interventions, and predictive models. It features a batch-processing interface
that enables efficient experimentation and automatic reporting of fairness and
utility metrics. By offering standardised pipelines and supporting reproducible
evaluations, FairPrep fills a critical gap in the fairness benchmarking
landscape and provides a practical foundation for advancing data-level fairness
research.

</details>


### [99] [Frequency-adaptive tensor neural networks for high-dimensional multi-scale problems](https://arxiv.org/abs/2508.15198)
*Jizu Huang,Rukang You,Tao Zhou*

Main category: cs.LG

TL;DR: 该论文提出了一种频率自适应的张量神经网络（TNNs）算法，通过随机傅里叶特征和一维分量函数的离散傅里叶变换，增强了TNNs在解决高维多尺度问题中的表达能力。


<details>
  <summary>Details</summary>
Motivation: TNNs在解决高维问题上表现出色，但仍受限于频率原则，难以准确捕捉解的高频特征，因此需要改进其表达能力和适应性。

Method: 通过傅里叶分析TNNs的训练动态，引入随机傅里叶特征，并利用TNNs的张量结构对一维分量函数进行离散傅里叶变换，提取高维函数的频率特征。

Result: 提出的频率自适应TNNs算法显著提升了TNNs在复杂多尺度问题中的求解能力，数值实验验证了其有效性和鲁棒性。

Conclusion: 该研究成功改进了TNNs的频率适应性，为解决高维多尺度问题提供了一种有效方法。

Abstract: Tensor neural networks (TNNs) have demonstrated their superiority in solving
high-dimensional problems. However, similar to conventional neural networks,
TNNs are also influenced by the Frequency Principle, which limits their ability
to accurately capture high-frequency features of the solution. In this work, we
analyze the training dynamics of TNNs by Fourier analysis and enhance their
expressivity for high-dimensional multi-scale problems by incorporating random
Fourier features. Leveraging the inherent tensor structure of TNNs, we further
propose a novel approach to extract frequency features of high-dimensional
functions by performing the Discrete Fourier Transform to one-dimensional
component functions. This strategy effectively mitigates the curse of
dimensionality. Building on this idea, we propose a frequency-adaptive TNNs
algorithm, which significantly improves the ability of TNNs in solving complex
multi-scale problems. Extensive numerical experiments are performed to validate
the effectiveness and robustness of the proposed frequency-adaptive TNNs
algorithm.

</details>


### [100] [SleepDIFFormer: Sleep Stage Classification via Multivariate Differential Transformer](https://arxiv.org/abs/2508.15215)
*Benjamin Wei Hao Chin,Yuin Torng Yew,Haocheng Wu,Lanxin Liang,Chow Khuen Chan,Norita Mohd Zain,Siti Balqis Samdin,Sim Kuan Goh*

Main category: cs.LG

TL;DR: 提出了一种名为SleepDIFFormer的多变量差分变换器方法，用于联合学习EEG和EOG信号表示，以提高睡眠分期分类的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 睡眠分期分类对评估睡眠质量和诊断睡眠障碍至关重要，但手动检查EEG特征耗时且易出错，现有机器学习方法因EEG和EOG信号的非平稳性和变异性泛化能力有限。

Method: 开发了多变量差分变换器架构（MDTA），通过跨域对齐训练处理EEG和EOG信号，减少时空注意力噪声，学习域不变的联合表示。

Result: 在五个睡眠分期数据集上验证，性能优于现有方法，达到state-of-the-art水平，并通过消融分析和注意力权重解释验证了方法的有效性。

Conclusion: SleepDIFFormer在睡眠分期分类中表现出色，其差分注意力权重与睡眠EEG特征相关，推动了自动化睡眠质量评估的应用。

Abstract: Classification of sleep stages is essential for assessing sleep quality and
diagnosing sleep disorders such as insomnia. However, manual inspection of EEG
characteristics for each stage is time-consuming and prone to human error.
Although machine learning and deep learning methods have been actively
developed, they continue to face challenges from the non-stationarity and
variability of electroencephalography (EEG) and electrooculography (EOG)
signals, often leading to poor generalization on unseen datasets. This research
proposed a Sleep Stage Classification method by developing Multivariate
Differential Transformer (SleepDIFFormer) for joint EEG and EOG representation
learning. Specifically, SleepDIFFormer was developed to process EEG and EOG
signals using our Multivariate Differential Transformer Architecture (MDTA) for
time series, trained with cross-domain alignment. Our method mitigated spatial
and temporal attention noise while learning a domain-invariant joint EEG-EOG
representation through feature distribution alignment, thereby enabling
generalization to unseen target datasets. Empirically, we evaluated our method
on five different sleep staging datasets and compared it with existing
approaches, achieving state-of-the-art performance. We also conducted thorough
ablation analyses of SleepDIFFormer and interpreted the differential attention
weights, highlighting their relevance to characteristic sleep EEG patterns.
These findings have implications for advancing automated sleep stage
classification and its application to sleep quality assessment. Our source code
is publicly available at https://github.com/Ben1001409/SleepDIFFormer

</details>


### [101] [See Beyond a Single View: Multi-Attribution Learning Leads to Better Conversion Rate Prediction](https://arxiv.org/abs/2508.15217)
*Sishuo Chen,Zhangming Chan,Xiang-Rong Sheng,Lei Zhang,Sheng Chen,Chenghuan Hou,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 提出了一种多归因学习框架（MAL）来整合不同归因机制的信号，提升CVR预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅使用单一归因机制的标签，忽略了其他归因视角的互补信号，限制了模型的性能。

Method: MAL框架包含归因知识聚合器（AKA）和主目标预测器（PTP），通过多任务学习和Cartesian积训练策略整合多归因信号。

Result: 离线实验显示GAUC提升0.51%，线上实验ROI提升2.6%。

Conclusion: MAL显著提升CVR预测性能，且与工业部署兼容。

Abstract: Conversion rate (CVR) prediction is a core component of online advertising
systems, where the attribution mechanisms-rules for allocating conversion
credit across user touchpoints-fundamentally determine label generation and
model optimization. While many industrial platforms support diverse attribution
mechanisms (e.g., First-Click, Last-Click, Linear, and Data-Driven Multi-Touch
Attribution), conventional approaches restrict model training to labels from a
single production-critical attribution mechanism, discarding complementary
signals in alternative attribution perspectives.
  To address this limitation, we propose a novel Multi-Attribution Learning
(MAL) framework for CVR prediction that integrates signals from multiple
attribution perspectives to better capture the underlying patterns driving user
conversions. Specifically, MAL is a joint learning framework consisting of two
core components: the Attribution Knowledge Aggregator (AKA) and the Primary
Target Predictor (PTP). AKA is implemented as a multi-task learner that
integrates knowledge extracted from diverse attribution labels. PTP, in
contrast, focuses on the task of generating well-calibrated conversion
probabilities that align with the system-optimized attribution metric (e.g.,
CVR under the Last-Click attribution), ensuring direct compatibility with
industrial deployment requirements. Additionally, we propose CAT, a novel
training strategy that leverages the Cartesian product of all attribution label
combinations to generate enriched supervision signals. This design
substantially enhances the performance of the attribution knowledge aggregator.
Empirical evaluations demonstrate the superiority of MAL over
single-attribution learning baselines, achieving +0.51% GAUC improvement on
offline metrics. Online experiments demonstrate that MAL achieved a +2.6%
increase in ROI (Return on Investment).

</details>


### [102] [Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models](https://arxiv.org/abs/2508.15220)
*Aniruddha Joshi,Supratik Chakraborty,S Akshay,Shetal Shah,Hazem Torfah,Sanjit Seshia*

Main category: cs.LG

TL;DR: 提出了一个基于局部最优性保证的框架，用于更高效地合成黑盒机器学习模型的解释，平衡了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为黑盒机器学习模型提供可信解释时，需平衡准确性和可解释性，但现有方法缺乏对Pareto最优性的正式保证或存在可扩展性问题。

Method: 结合多目标学习或搜索技术生成Pareto最优候选解，并通过SAT求解器验证每个解的局部最优性。

Result: 在基准测试中，新方法的解释效果接近具有全局保证的方法。

Conclusion: 新框架在保证局部最优性的同时，提高了可扩展性，适用于实际问题。

Abstract: Creating meaningful interpretations for black-box machine learning models
involves balancing two often conflicting objectives: accuracy and
explainability. Exploring the trade-off between these objectives is essential
for developing trustworthy interpretations. While many techniques for
multi-objective interpretation synthesis have been developed, they typically
lack formal guarantees on the Pareto-optimality of the results. Methods that do
provide such guarantees, on the other hand, often face severe scalability
limitations when exploring the Pareto-optimal space. To address this, we
develop a framework based on local optimality guarantees that enables more
scalable synthesis of interpretations. Specifically, we consider the problem of
synthesizing a set of Pareto-optimal interpretations with local optimality
guarantees, within the immediate neighborhood of each solution. Our approach
begins with a multi-objective learning or search technique, such as
Multi-Objective Monte Carlo Tree Search, to generate a best-effort set of
Pareto-optimal candidates with respect to accuracy and explainability. We then
verify local optimality for each candidate as a Boolean satisfiability problem,
which we solve using a SAT solver. We demonstrate the efficacy of our approach
on a set of benchmarks, comparing it against previous methods for exploring the
Pareto-optimal front of interpretations. In particular, we show that our
approach yields interpretations that closely match those synthesized by methods
offering global guarantees.

</details>


### [103] [Learning ECG Representations via Poly-Window Contrastive Learning](https://arxiv.org/abs/2508.15225)
*Yi Yuan,Joseph Van Duyn,Runze Yan,Zhuoyi Huang,Sulaiman Vesal,Sergey Plis,Xiao Hu,Gloria Hyunjung Kwak,Ran Xiao,Alex Fedorov*

Main category: cs.LG

TL;DR: 提出了一种多窗口对比学习框架，用于从心电图中学习鲁棒表示，显著提升了分类性能并减少了训练时间和计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决当前深度学习方法因标注数据有限而受限的问题，并利用心电图的时间结构改进对比学习。

Method: 通过提取多个时间窗口构建正样本对，并最大化其一致性，同时结合慢特征分析原则学习时间不变的特征。

Result: 在PTB-XL数据集上，多窗口方法在分类任务中表现优于传统方法（AUROC 0.891 vs. 0.888），且训练时间和计算成本显著降低。

Conclusion: 多窗口对比学习是一种高效且可扩展的心电图分析方法，为生物医学时间序列数据的自监督学习提供了通用框架。

Abstract: Electrocardiogram (ECG) analysis is foundational for cardiovascular disease
diagnosis, yet the performance of deep learning models is often constrained by
limited access to annotated data. Self-supervised contrastive learning has
emerged as a powerful approach for learning robust ECG representations from
unlabeled signals. However, most existing methods generate only pairwise
augmented views and fail to leverage the rich temporal structure of ECG
recordings. In this work, we present a poly-window contrastive learning
framework. We extract multiple temporal windows from each ECG instance to
construct positive pairs and maximize their agreement via statistics. Inspired
by the principle of slow feature analysis, our approach explicitly encourages
the model to learn temporally invariant and physiologically meaningful features
that persist across time. We validate our approach through extensive
experiments and ablation studies on the PTB-XL dataset. Our results demonstrate
that poly-window contrastive learning consistently outperforms conventional
two-view methods in multi-label superclass classification, achieving higher
AUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to
four times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock
pre-training time reduction. Despite processing multiple windows per sample, we
achieve a significant reduction in the number of training epochs and total
computation time, making our method practical for training foundational models.
Through extensive ablations, we identify optimal design choices and demonstrate
robustness across various hyperparameters. These findings establish poly-window
contrastive learning as a highly efficient and scalable paradigm for automated
ECG analysis and provide a promising general framework for self-supervised
representation learning in biomedical time-series data.

</details>


### [104] [Deep Think with Confidence](https://arxiv.org/abs/2508.15260)
*Yichao Fu,Xuewei Wang,Yuandong Tian,Jiawei Zhao*

Main category: cs.LG

TL;DR: 提出了一种名为DeepConf的新方法，通过动态过滤低质量推理轨迹来提高大型语言模型在推理任务中的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如自一致性多数投票）在准确性和计算开销上的局限性。

Method: 利用模型内部置信度信号动态过滤低质量推理轨迹，无需额外训练或调参。

Result: 在多个推理任务和开源模型上表现优异，例如在AIME 2025上达到99.9%的准确率，并减少84.7%的生成token。

Conclusion: DeepConf是一种简单高效的方法，可显著提升推理任务的性能，并易于集成到现有框架中。

Abstract: Large Language Models (LLMs) have shown great potential in reasoning tasks
through test-time scaling methods like self-consistency with majority voting.
However, this approach often leads to diminishing returns in accuracy and high
computational overhead. To address these challenges, we introduce Deep Think
with Confidence (DeepConf), a simple yet powerful method that enhances both
reasoning efficiency and performance at test time. DeepConf leverages
model-internal confidence signals to dynamically filter out low-quality
reasoning traces during or after generation. It requires no additional model
training or hyperparameter tuning and can be seamlessly integrated into
existing serving frameworks. We evaluate DeepConf across a variety of reasoning
tasks and the latest open-source models, including Qwen 3 and GPT-OSS series.
Notably, on challenging benchmarks such as AIME 2025, DeepConf@512 achieves up
to 99.9% accuracy and reduces generated tokens by up to 84.7% compared to full
parallel thinking.

</details>


### [105] [Evaluating Knowledge Graph Complexity via Semantic, Spectral, and Structural Metrics for Link Prediction](https://arxiv.org/abs/2508.15291)
*Haji Gul,Abul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.LG

TL;DR: 本文批判性评估了CSG（累积谱梯度）在知识图谱链接预测中的有效性，发现其对参数敏感且与性能指标相关性弱，提出了更稳定的替代指标。


<details>
  <summary>Details</summary>
Motivation: 研究数据复杂度对知识图谱链接预测模型评估的重要性，并检验CSG在此背景下的适用性。

Method: 通过在链接预测中引入语义表示（如Transformer嵌入），并结合新的结构和语义复杂度指标（如关系熵）进行综合评估。

Result: CSG对参数敏感且与性能指标相关性弱，而关系熵等新指标更可靠地反映了任务难度。

Conclusion: CSG在链接预测中稳定性不足，需要更稳定且任务对齐的复杂度指标。

Abstract: Understanding dataset complexity is fundamental to evaluating and comparing
link prediction models on knowledge graphs (KGs). While the Cumulative Spectral
Gradient (CSG) metric, derived from probabilistic divergence between classes
within a spectral clustering framework, has been proposed as a classifier
agnostic complexity metric purportedly scaling with class cardinality and
correlating with downstream performance, it has not been evaluated in KG
settings so far. In this work, we critically examine CSG in the context of
multi relational link prediction, incorporating semantic representations via
transformer derived embeddings. Contrary to prior claims, we find that CSG is
highly sensitive to parametrisation and does not robustly scale with the number
of classes. Moreover, it exhibits weak or inconsistent correlation with
standard performance metrics such as Mean Reciprocal Rank (MRR) and Hit@1. To
deepen the analysis, we introduce and benchmark a set of structural and
semantic KG complexity metrics. Our findings reveal that global and local
relational ambiguity captured via Relation Entropy, node level Maximum Relation
Diversity, and Relation Type Cardinality exhibit strong inverse correlations
with MRR and Hit@1, suggesting these as more faithful indicators of task
difficulty. Conversely, graph connectivity measures such as Average Degree,
Degree Entropy, PageRank, and Eigenvector Centrality correlate positively with
Hit@10. Our results demonstrate that CSGs purported stability and
generalization predictive power fail to hold in link prediction settings and
underscore the need for more stable, interpretable, and task-aligned measures
of dataset complexity in knowledge driven learning.

</details>


### [106] [Saving for the future: Enhancing generalization via partial logic regularization](https://arxiv.org/abs/2508.15317)
*Zhaorui Tan,Yijie Hu,Xi Yang,Qiufeng Wang,Anh Nguyen,Kaizhu Huang*

Main category: cs.LG

TL;DR: 本文提出PL-Reg，一种部分逻辑正则化方法，用于提升视觉分类任务中对未知类别的泛化能力，相较于现有方法更具灵活性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在未知类别泛化上的不足，尤其是逻辑公式完全定义的限制问题。

Method: 引入部分逻辑正则化项（PL-Reg），无需完全定义逻辑公式，保留未来定义的灵活性。

Result: 在多个任务上验证了PL-Reg的有效性，显示出优于现有方法的性能提升。

Conclusion: 部分逻辑显著提升了模型对未知类别的适应性与泛化能力，为未来的逻辑应用提供了新思路。

Abstract: Generalization remains a significant challenge in visual classification
tasks, particularly in handling unknown classes in real-world applications.
Existing research focuses on the class discovery paradigm, which tends to favor
known classes, and the incremental learning paradigm, which suffers from
catastrophic forgetting. Recent approaches such as the L-Reg technique employ
logic-based regularization to enhance generalization but are bound by the
necessity of fully defined logical formulas, limiting flexibility for unknown
classes. This paper introduces PL-Reg, a novel partial-logic regularization
term that allows models to reserve space for undefined logic formulas,
improving adaptability to unknown classes. Specifically, we formally
demonstrate that tasks involving unknown classes can be effectively explained
using partial logic. We also prove that methods based on partial logic lead to
improved generalization. We validate PL-Reg through extensive experiments on
Generalized Category Discovery, Multi-Domain Generalized Category Discovery,
and long-tailed Class Incremental Learning tasks, demonstrating consistent
performance improvements. Our results highlight the effectiveness of partial
logic in tackling challenges related to unknown classes.

</details>


### [107] [ExBigBang: A Dynamic Approach for Explainable Persona Classification through Contextualized Hybrid Transformer Analysis](https://arxiv.org/abs/2508.15364)
*Saleh Afzoon,Amin Beheshti,Nabi Rezvani,Farshad Khunjush,Usman Naseem,John McMahon,Zahra Fathollahi,Mahdieh Labani,Wathiq Mansoor,Xuyun Zhang*

Main category: cs.LG

TL;DR: ExBigBang是一种混合文本-表格方法，利用变压器架构为人物分类建模上下文特征，解决了上下文信息捕捉和模型可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 用户交互复杂性增加，需要更上下文化的设计方法，同时现有模型在捕捉上下文信息和解释性方面存在不足。

Method: 结合元数据、领域知识和用户画像，通过变压器架构动态更新用户行为模型，整合文本和表格数据。

Result: 在基准数据集上验证了模型的鲁棒性，消融实验展示了文本与表格数据结合的优势，可解释AI技术揭示了预测逻辑。

Conclusion: ExBigBang为人物分类提供了上下文丰富且可解释的解决方案，适用于动态用户行为建模。

Abstract: In user-centric design, persona development plays a vital role in
understanding user behaviour, capturing needs, segmenting audiences, and
guiding design decisions. However, the growing complexity of user interactions
calls for a more contextualized approach to ensure designs align with real user
needs. While earlier studies have advanced persona classification by modelling
user behaviour, capturing contextual information, especially by integrating
textual and tabular data, remains a key challenge. These models also often lack
explainability, leaving their predictions difficult to interpret or justify. To
address these limitations, we present ExBigBang (Explainable BigBang), a hybrid
text-tabular approach that uses transformer-based architectures to model rich
contextual features for persona classification. ExBigBang incorporates
metadata, domain knowledge, and user profiling to embed deeper context into
predictions. Through a cyclical process of user profiling and classification,
our approach dynamically updates to reflect evolving user behaviours.
Experiments on a benchmark persona classification dataset demonstrate the
robustness of our model. An ablation study confirms the benefits of combining
text and tabular data, while Explainable AI techniques shed light on the
rationale behind the model's predictions.

</details>


### [108] [Enhancing Forecasting with a 2D Time Series Approach for Cohort-Based Data](https://arxiv.org/abs/2508.15369)
*Yonathan Guttel,Orit Moradov,Nachi Lieder,Asnat Greenstein-Messica*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的二维时间序列预测模型，通过整合时间上的群体行为，解决了小数据环境中的挑战，并在多个真实数据集上展示了其优于基准模型的准确性及适应性。


<details>
  <summary>Details</summary>
Motivation: 解决小数据环境下时间序列预测的挑战，并为面临财务和营销预测问题的行业提供战略决策依据。

Method: 提出了一种整合群体行为的二维时间序列预测模型。

Result: 在多个真实数据集上表现优于基准模型，准确性及适应性更佳。

Conclusion: 该模型为小数据环境下的预测问题提供了有效的解决方案，并在实际应用中展现出广泛的应用潜力。

Abstract: This paper introduces a novel two-dimensional (2D) time series forecasting
model that integrates cohort behavior over time, addressing challenges in small
data environments. We demonstrate its efficacy using multiple real-world
datasets, showcasing superior performance in accuracy and adaptability compared
to reference models. The approach offers valuable insights for strategic
decision-making across industries facing financial and marketing forecasting
challenges.

</details>


### [109] [Fairness for the People, by the People: Minority Collective Action](https://arxiv.org/abs/2508.15374)
*Omri Ben-Dov,Samira Samadi,Amartya Sanyal,Alexandru Ţifrea*

Main category: cs.LG

TL;DR: 论文提出了一种通过“算法集体行动”框架，让少数群体通过重新标记数据来提升公平性，而不改变公司训练过程的方法，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有偏向缓解技术通常需要组织支持且可能牺牲模型性能，而用户贡献数据的模式为少数群体提供了通过数据重新标记实现公平的可能性。

Method: 提出了三种模型无关的方法，少数群体通过协调行动重新标记数据，以近似理想的公平性调整。

Result: 实验表明，少数群体的一小部分可以通过重新标记数据显著减少不公平性，同时对整体预测误差影响较小。

Conclusion: 通过算法集体行动，少数群体可以在不依赖公司干预的情况下，有效提升模型的公平性。

Abstract: Machine learning models often preserve biases present in training data,
leading to unfair treatment of certain minority groups. Despite an array of
existing firm-side bias mitigation techniques, they typically incur utility
costs and require organizational buy-in. Recognizing that many models rely on
user-contributed data, end-users can induce fairness through the framework of
Algorithmic Collective Action, where a coordinated minority group strategically
relabels its own data to enhance fairness, without altering the firm's training
process. We propose three practical, model-agnostic methods to approximate
ideal relabeling and validate them on real-world datasets. Our findings show
that a subgroup of the minority can substantially reduce unfairness with a
small impact on the overall prediction error.

</details>


### [110] [EvoFormer: Learning Dynamic Graph-Level Representations with Structural and Temporal Bias Correction](https://arxiv.org/abs/2508.15378)
*Haodi Zhong,Liuxin Zou,Di Wang,Bo Wang,Zhenxing Niu,Quan Wang*

Main category: cs.LG

TL;DR: 这篇论文提出了EvoFormer框架，用于动态图级别嵌入学习。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中存在的结构访问偏见和突变演化盲点问题。

Method: 结合了结构感知Transformer模块和演化敏感时间模块，通过三步策略建模时间演化。

Result: 在多个基准数据集上表现优异，验证了其有效性。

Conclusion: EvoFormer能有效纠正结构和时间偏见，具有应用潜力。

Abstract: Dynamic graph-level embedding aims to capture structural evolution in
networks, which is essential for modeling real-world scenarios. However,
existing methods face two critical yet under-explored issues: Structural Visit
Bias, where random walk sampling disproportionately emphasizes high-degree
nodes, leading to redundant and noisy structural representations; and Abrupt
Evolution Blindness, the failure to effectively detect sudden structural
changes due to rigid or overly simplistic temporal modeling strategies,
resulting in inconsistent temporal embeddings. To overcome these challenges, we
propose EvoFormer, an evolution-aware Transformer framework tailored for
dynamic graph-level representation learning. To mitigate Structural Visit Bias,
EvoFormer introduces a Structure-Aware Transformer Module that incorporates
positional encoding based on node structural roles, allowing the model to
globally differentiate and accurately represent node structures. To overcome
Abrupt Evolution Blindness, EvoFormer employs an Evolution-Sensitive Temporal
Module, which explicitly models temporal evolution through a sequential
three-step strategy: (I) Random Walk Timestamp Classification, generating
initial timestamp-aware graph-level embeddings; (II) Graph-Level Temporal
Segmentation, partitioning the graph stream into segments reflecting
structurally coherent periods; and (III) Segment-Aware Temporal Self-Attention
combined with an Edge Evolution Prediction task, enabling the model to
precisely capture segment boundaries and perceive structural evolution trends,
effectively adapting to rapid temporal shifts. Extensive evaluations on five
benchmark datasets confirm that EvoFormer achieves state-of-the-art performance
in graph similarity ranking, temporal anomaly detection, and temporal
segmentation tasks, validating its effectiveness in correcting structural and
temporal biases.

</details>


### [111] [CITE: A Comprehensive Benchmark for Heterogeneous Text-Attributed Graphs on Catalytic Materials](https://arxiv.org/abs/2508.15392)
*Chenghao Zhang,Qingqing Long,Ludi Wang,Wenjuan Cui,Jianjun Yu,Yi Du*

Main category: cs.LG

TL;DR: 该论文介绍了CITE数据集，这是第一个针对催化材料的大规模异构文本属性图基准数据集，并提供了标准化评估方法和多种学习范式的基线实验。


<details>
  <summary>Details</summary>
Motivation: 解决异构文本属性图（TAG）缺乏大规模基准数据集的问题，推动表示学习方法的发展与公平比较。

Method: 建立CITE数据集（438K节点，1.2M边，四种关系类型），设计标准化评估流程，并对多种模型范式（同构图模型、异构图模型、LLM中心模型、LLM+图模型）进行基准测试和消融实验。

Result: 提供了CITE数据集的详细描述、评估协议以及不同建模范式的实验结果，为异构文本属性图研究提供了基础。

Conclusion: CITE填补了异构文本属性图基准数据集的空白，为未来研究提供了可靠的数据支持和评估标准。

Abstract: Text-attributed graphs(TAGs) are pervasive in real-world systems,where each
node carries its own textual features. In many cases these graphs are
inherently heterogeneous, containing multiple node types and diverse edge
types. Despite the ubiquity of such heterogeneous TAGs, there remains a lack of
large-scale benchmark datasets. This shortage has become a critical bottleneck,
hindering the development and fair comparison of representation learning
methods on heterogeneous text-attributed graphs. In this paper, we introduce
CITE - Catalytic Information Textual Entities Graph, the first and largest
heterogeneous text-attributed citation graph benchmark for catalytic materials.
CITE comprises over 438K nodes and 1.2M edges, spanning four relation types. In
addition, we establish standardized evaluation procedures and conduct extensive
benchmarking on the node classification task, as well as ablation experiments
on the heterogeneous and textual properties of CITE. We compare four classes of
learning paradigms, including homogeneous graph models, heterogeneous graph
models, LLM(Large Language Model)-centric models, and LLM+Graph models. In a
nutshell, we provide (i) an overview of the CITE dataset, (ii) standardized
evaluation protocols, and (iii) baseline and ablation experiments across
diverse modeling paradigms.

</details>


### [112] [Federated Learning based on Self-Evolving Gaussian Clustering](https://arxiv.org/abs/2508.15393)
*Miha Ožbot,Igor Škrjanc*

Main category: cs.LG

TL;DR: 提出了一种在联邦学习框架下动态适应新聚类的模糊系统，无需预先设定聚类数量。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法中需要预先确定聚类数量的问题，同时利用联邦学习保护数据隐私。

Method: 采用PyTorch实现，动态添加新聚类，通过联邦学习在客户端本地训练模型，仅共享模型参数。

Result: 在UCI数据集上的聚类和分类任务中表现优于传统方法。

Conclusion: 尽管计算密集，但该方法在分散数据处理中展现出显著优势。

Abstract: In this study, we present an Evolving Fuzzy System within the context of
Federated Learning, which adapts dynamically with the addition of new clusters
and therefore does not require the number of clusters to be selected apriori.
Unlike traditional methods, Federated Learning allows models to be trained
locally on clients' devices, sharing only the model parameters with a central
server instead of the data. Our method, implemented using PyTorch, was tested
on clustering and classification tasks. The results show that our approach
outperforms established classification methods on several well-known UCI
datasets. While computationally intensive due to overlap condition
calculations, the proposed method demonstrates significant advantages in
decentralized data processing.

</details>


### [113] [Hybrid Least Squares/Gradient Descent Methods for DeepONets](https://arxiv.org/abs/2508.15394)
*Jun Choi,Chang-Ock Lee,Minam Moon*

Main category: cs.LG

TL;DR: 提出了一种高效的混合最小二乘法/梯度下降法来加速DeepONet训练，通过分解大线性系统为两个更小的子问题来解决计算难题。


<details>
  <summary>Details</summary>
Motivation: DeepONet最后一层参数可线性化，但直接构建最小二乘系统计算量过大，需一种高效方法优化训练。

Method: 将大线性系统分解为分支网络和主干网络两个子问题，分别求解，并推广到带有正则项的$L^2$损失。

Result: 提出的方法有效解决了大线性系统的计算难题，适用于监督和非监督学习。

Conclusion: 该方法显著提升了DeepONet的训练效率，适用于更广泛的损失函数和场景。

Abstract: We propose an efficient hybrid least squares/gradient descent method to
accelerate DeepONet training. Since the output of DeepONet can be viewed as
linear with respect to the last layer parameters of the branch network, these
parameters can be optimized using a least squares (LS) solve, and the remaining
hidden layer parameters are updated by means of gradient descent form. However,
building the LS system for all possible combinations of branch and trunk inputs
yields a prohibitively large linear problem that is infeasible to solve
directly. To address this issue, our method decomposes the large LS system into
two smaller, more manageable subproblems $\unicode{x2014}$ one for the branch
network and one for the trunk network $\unicode{x2014}$ and solves them
separately. This method is generalized to a broader type of $L^2$ loss with a
regularization term for the last layer parameters, including the case of
unsupervised learning with physics-informed loss.

</details>


### [114] [Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning](https://arxiv.org/abs/2508.15413)
*Pixi Kang,Julian Moosmann,Mengxi Liu,Bo Zhou,Michele Magno,Paul Lukowicz,Sizhen Bian*

Main category: cs.LG

TL;DR: 该论文提出一种混合框架，结合通用模型和少样本学习，直接在低功耗微控制器上实现个性化人活动识别，提升了部署后的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决人活动识别（HAR）在新用户上的泛化问题，尤其是用户引起的概念漂移（UICD），需高效个性化方法。

Method: 提出混合框架：先跨用户泛化，再通过少样本学习快速个性化，仅更新分类器层，降低计算和内存开销。

Result: 在三个HAR场景（RecGym、QVAR-Gesture、Ultrasound-Gesture）中，部署后准确性分别提升3.73%、17.38%和3.70%。

Conclusion: 证明在嵌入式平台上实现快速、轻量且有效的个性化是可行的，推动可扩展的用户感知HAR系统发展。

Abstract: Human Activity Recognition (HAR) using wearable devices has advanced
significantly in recent years, yet its generalization remains limited when
models are deployed to new users. This degradation in performance is primarily
due to user-induced concept drift (UICD), highlighting the importance of
efficient personalization. In this paper, we present a hybrid framework that
first generalizes across users and then rapidly adapts to individual users
using few-shot learning directly on-device. By updating only the classifier
layer with user-specific data, our method achieves robust personalization with
minimal computational and memory overhead. We implement this framework on the
energy-efficient RISC-V-based GAP9 microcontroller and validate it across three
diverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture.
Post-deployment adaptation yields consistent accuracy improvements of 3.73\%,
17.38\%, and 3.70\% respectively. These results confirm that fast, lightweight,
and effective personalization is feasible on embedded platforms, paving the way
for scalable and user-aware HAR systems in the wild
\footnote{https://github.com/kangpx/onlineTiny2023}.

</details>


### [115] [Measures of Overlapping Multivariate Gaussian Clusters in Unsupervised Online Learning](https://arxiv.org/abs/2508.15444)
*Miha Ožbot,Igor Škrjanc*

Main category: cs.LG

TL;DR: 提出一种新的多变量高斯聚类重叠检测方法，适用于数据流在线学习，计算效率高且能有效避免正交聚类合并。


<details>
  <summary>Details</summary>
Motivation: 现有分布差异度量方法在处理数据流中的重叠聚类时效率不足且适应性差。

Method: 设计一种专门检测重叠而非差异的快速计算度量方法。

Result: 新方法计算速度更快，能准确检测重叠聚类并避免正交聚类误合并。

Conclusion: 新方法高效解决了数据流中重叠聚类检测问题。

Abstract: In this paper, we propose a new measure for detecting overlap in multivariate
Gaussian clusters. The aim of online learning from data streams is to create
clustering, classification, or regression models that can adapt over time based
on the conceptual drift of streaming data. In the case of clustering, this can
result in a large number of clusters that may overlap and should be merged.
Commonly used distribution dissimilarity measures are not adequate for
determining overlapping clusters in the context of online learning from
streaming data due to their inability to account for all shapes of clusters and
their high computational demands. Our proposed dissimilarity measure is
specifically designed to detect overlap rather than dissimilarity and can be
computed faster compared to existing measures. Our method is several times
faster than compared methods and is capable of detecting overlapping clusters
while avoiding the merging of orthogonal clusters.

</details>


### [116] [Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection](https://arxiv.org/abs/2508.15449)
*Chengcan Wu,Zeming Wei,Huanran Chen,Yinpeng Dong,Meng Sun*

Main category: cs.LG

TL;DR: 论文提出Metamorphosis Representation Projection (MRP)方法，通过不可逆投影技术实现模型安全遗忘，解决现有方法难以彻底消除有害信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLMs）可能存储不安全知识，而传统的机器遗忘方法仅能抑制而非彻底消除这些信息，使其易受重新学习攻击。

Method: 提出MRP方法，在网络层的隐藏状态空间实施投影变换，通过不可逆投影特性彻底消除有害信息。

Result: 实验表明，MRP支持有效连续遗忘，并抵御重新学习攻击，同时在保持模型性能方面表现优异。

Conclusion: MRP为机器遗忘提供了一种高效、安全的解决方案，填补了现有方法的局限性。

Abstract: While Large Language Models (LLMs) have demonstrated impressive performance
in various domains and tasks, concerns about their safety are becoming
increasingly severe. In particular, since models may store unsafe knowledge
internally, machine unlearning has emerged as a representative paradigm to
ensure model safety. Existing approaches employ various training techniques,
such as gradient ascent and negative preference optimization, in attempts to
eliminate the influence of undesired data on target models. However, these
methods merely suppress the activation of undesired data through parametric
training without completely eradicating its informational traces within the
model. This fundamental limitation makes it difficult to achieve effective
continuous unlearning, rendering these methods vulnerable to relearning
attacks. To overcome these challenges, we propose a Metamorphosis
Representation Projection (MRP) approach that pioneers the application of
irreversible projection properties to machine unlearning. By implementing
projective transformations in the hidden state space of specific network
layers, our method effectively eliminates harmful information while preserving
useful knowledge. Experimental results demonstrate that our approach enables
effective continuous unlearning and successfully defends against relearning
attacks, achieving state-of-the-art performance in unlearning effectiveness
while preserving natural performance. Our code is available in
https://github.com/ChengcanWu/MRP.

</details>


### [117] [A Solvable Molecular Switch Model for Stable Temporal Information Processing](https://arxiv.org/abs/2508.15451)
*H. I. Nurdin,C. A. Nijhuis*

Main category: cs.LG

TL;DR: 本文研究了一种基于输入驱动的单状态微分方程模型，展示了其在神经形态计算中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探究动态分子开关模型的数学性质及其在模拟生物行为和稳定学习中的适用性。

Method: 采用线性状态和非线性输入的模型，通过解析求解验证其收敛性和渐消记忆特性。

Result: 模型兼具生物启发行为和数学稳定性，适用于深度前馈和循环架构。

Conclusion: 结果为动态分子开关作为计算单元提供了理论支持，并启发更广泛的精确可解模型。

Abstract: This paper studies an input-driven one-state differential equation model
initially developed for an experimentally demonstrated dynamic molecular switch
that switches like synapses in the brain do. The linear-in-the-state and
nonlinear-in-the-input model is exactly solvable, and it is shown that it also
possesses mathematical properties of convergence and fading memory that enable
stable processing of time-varying inputs by nonlinear dynamical systems. Thus,
the model exhibits the co-existence of biologically-inspired behavior and
desirable mathematical properties for stable learning on sequential data. The
results give theoretical support for the use of the dynamic molecular switches
as computational units in deep cascaded/layered feedforward and recurrent
architectures as well as other more general structures for neuromorphic
computing. They could also inspire more general exactly solvable models that
can be fitted to emulate arbitrary physical devices which can mimic
brain-inspired behaviour and perform stable computation on input signals.

</details>


### [118] [Mini-Batch Robustness Verification of Deep Neural Networks](https://arxiv.org/abs/2508.15454)
*Saar Tzour-Shaday,Dana Drachsler Cohen*

Main category: cs.LG

TL;DR: 提出了一种名为BaVerLy的新方法，通过动态构建和验证mini-batches来提高神经网络的局部鲁棒性验证效率，分析时间平均提升2.3倍。


<details>
  <summary>Details</summary>
Motivation: 现有局部鲁棒性验证器存在分析时间过长或精度不足的问题，影响了大规模输入的验证效果。

Method: 提出了分组局部鲁棒性验证（Group Local Robustness Verification），利用ε球的网络计算相似性动态构建mini-batches并联合验证。BaVerLy自适应调整mini-batch大小，提升验证效率。

Result: 在MNIST和CIFAR-10数据集上的实验表明，BaVerLy将验证效率平均提升2.3倍，最高达4.1倍，将总分析时间从24小时缩短至6小时。

Conclusion: BaVerLy显著提升了局部鲁棒性验证的效率，适用于大规模输入的高效分析。

Abstract: Neural network image classifiers are ubiquitous in many safety-critical
applications. However, they are susceptible to adversarial attacks. To
understand their robustness to attacks, many local robustness verifiers have
been proposed to analyze $\epsilon$-balls of inputs. Yet, existing verifiers
introduce a long analysis time or lose too much precision, making them less
effective for a large set of inputs. In this work, we propose a new approach to
local robustness: group local robustness verification. The key idea is to
leverage the similarity of the network computations of certain $\epsilon$-balls
to reduce the overall analysis time. We propose BaVerLy, a sound and complete
verifier that boosts the local robustness verification of a set of
$\epsilon$-balls by dynamically constructing and verifying mini-batches.
BaVerLy adaptively identifies successful mini-batch sizes, accordingly
constructs mini-batches of $\epsilon$-balls that have similar network
computations, and verifies them jointly. If a mini-batch is verified, all
$\epsilon$-balls are proven robust. Otherwise, one $\epsilon$-ball is suspected
as not being robust, guiding the refinement. In the latter case, BaVerLy
leverages the analysis results to expedite the analysis of that $\epsilon$-ball
as well as the other $\epsilon$-balls in the batch. We evaluate BaVerLy on
fully connected and convolutional networks for MNIST and CIFAR-10. Results show
that BaVerLy scales the common one by one verification by 2.3x on average and
up to 4.1x, in which case it reduces the total analysis time from 24 hours to 6
hours.

</details>


### [119] [Learning Protein-Ligand Binding in Hyperbolic Space](https://arxiv.org/abs/2508.15480)
*Jianhui Wang,Wenyu Zhu,Bowen Gao,Xin Hong,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan*

Main category: cs.LG

TL;DR: HypSeek是一种基于双曲几何的表示学习框架，用于蛋白质-配体结合预测，显著提高了虚拟筛选和亲和力排名的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的欧几里得嵌入方法无法充分捕捉分子相互作用的层次结构和细微亲和力变化。

Method: 采用双曲空间（Lorentz模型）嵌入配体、蛋白质口袋和序列，利用其指数几何和负曲率特性，实现表达力更强的嵌入。

Result: 在DUD-E上虚拟筛选的早期富集提高了20.7%，在JACS上亲和力排名相关性提高了25.4%。

Conclusion: 双曲几何为蛋白质-配体建模提供了有效的归纳偏差，能同时提升虚拟筛选和亲和力排名的效果。

Abstract: Protein-ligand binding prediction is central to virtual screening and
affinity ranking, two fundamental tasks in drug discovery. While recent
retrieval-based methods embed ligands and protein pockets into Euclidean space
for similarity-based search, the geometry of Euclidean embeddings often fails
to capture the hierarchical structure and fine-grained affinity variations
intrinsic to molecular interactions. In this work, we propose HypSeek, a
hyperbolic representation learning framework that embeds ligands, protein
pockets, and sequences into Lorentz-model hyperbolic space. By leveraging the
exponential geometry and negative curvature of hyperbolic space, HypSeek
enables expressive, affinity-sensitive embeddings that can effectively model
both global activity and subtle functional differences-particularly in
challenging cases such as activity cliffs, where structurally similar ligands
exhibit large affinity gaps. Our mode unifies virtual screening and affinity
ranking in a single framework, introducing a protein-guided three-tower
architecture to enhance representational structure. HypSeek improves early
enrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and
affinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%),
demonstrating the benefits of hyperbolic geometry across both tasks and
highlighting its potential as a powerful inductive bias for protein-ligand
modeling.

</details>


### [120] [Let's Grow an Unbiased Community: Guiding the Fairness of Graphs via New Links](https://arxiv.org/abs/2508.15499)
*Jiahua Lu,Huaxiao Liu,Shuotong Bai,Junjie Xu,Renqiang Luo,Enyan Dai*

Main category: cs.LG

TL;DR: 论文提出FairGuide框架，通过引入新链接优化图结构公平性，提升下游任务的公平性。


<details>
  <summary>Details</summary>
Motivation: 图神经网络(GNNs)在许多应用中表现优异，但由于图结构的偏见，公平性问题显著。希望通过优化图结构提升公平性。

Method: 提出FairGuide框架，引入可微分社区检测任务作为伪下游任务，并利用元梯度识别新链接以增强结构公平性。

Result: 大量实验证明FairGuide在多种基于图的公平性任务中有效且具有通用性。

Conclusion: FairGuide通过优化图结构公平性，显著提升了GNNs在多场景中的公平性表现。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success across diverse
applications. However, due to the biases in the graph structures, graph neural
networks face significant challenges in fairness. Although the original user
graph structure is generally biased, it is promising to guide these existing
structures toward unbiased ones by introducing new links. The fairness guidance
via new links could foster unbiased communities, thereby enhancing fairness in
downstream applications. To address this issue, we propose a novel framework
named FairGuide. Specifically, to ensure fairness in downstream tasks trained
on fairness-guided graphs, we introduce a differentiable community detection
task as a pseudo downstream task. Our theoretical analysis further demonstrates
that optimizing fairness within this pseudo task effectively enhances
structural fairness, promoting fairness generalization across diverse
downstream applications. Moreover, FairGuide employs an effective strategy
which leverages meta-gradients derived from the fairness-guidance objective to
identify new links that significantly enhance structural fairness. Extensive
experimental results demonstrate the effectiveness and generalizability of our
proposed method across a variety of graph-based fairness tasks.

</details>


### [121] [Jointly Computation- and Communication-Efficient Distributed Learning](https://arxiv.org/abs/2508.15509)
*Xiaoxing Ren,Nicola Bastianello,Karl H. Johansson,Thomas Parisini*

Main category: cs.LG

TL;DR: 提出一种基于ADMM的分布式学习算法，兼具计算和通信高效性，通过使用随机梯度和压缩传输实现优化。


<details>
  <summary>Details</summary>
Motivation: 解决无向网络中的分布式学习问题，设计一种同时优化计算和通信效率的算法。

Method: 采用ADMM框架，结合随机梯度的多轮本地训练和压缩传输技术。

Result: 在强凸设置下证明了算法的线性收敛性，并通过分类任务的实验验证其优于现有技术。

Conclusion: 该算法在计算和通信效率上均表现优异，适用于分布式学习场景。

Abstract: We address distributed learning problems over undirected networks.
Specifically, we focus on designing a novel ADMM-based algorithm that is
jointly computation- and communication-efficient. Our design guarantees
computational efficiency by allowing agents to use stochastic gradients during
local training. Moreover, communication efficiency is achieved as follows: i)
the agents perform multiple training epochs between communication rounds, and
ii) compressed transmissions are used. We prove exact linear convergence of the
algorithm in the strongly convex setting. We corroborate our theoretical
results by numerical comparisons with state of the art techniques on a
classification task.

</details>


### [122] [Stabilization of Perturbed Loss Function: Differential Privacy without Gradient Noise](https://arxiv.org/abs/2508.15523)
*Salman Habib,Remi Chou,Taejoon Kim*

Main category: cs.LG

TL;DR: SPOF通过稳定泰勒展开多项式近似模型损失函数，注入噪声到多项式系数而不是梯度，提升计算效率和稳定性，在WBAN场景下比DP-SGD表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有差分隐私训练机制（如DP-SGD）需在梯度中注入噪声，计算效率低且不稳定，SPOF旨在改进这一点。

Method: SPOF使用稳定的泰勒展开多项式近似损失函数，并在其系数中加入噪声以实现隐私保护，避免直接扰动梯度。

Result: SPOF在WBAN场景中比DP-SGD重建精度平均高3.5%，训练时间减少57.2%，且对环境噪声鲁棒。

Conclusion: SPOF在计算效率、稳定性和隐私-效用权衡上优于DP-SGD，适合多用户本地差分隐私场景。

Abstract: We propose SPOF (Stabilization of Perturbed Loss Function), a differentially
private training mechanism intended for multi-user local differential privacy
(LDP). SPOF perturbs a stabilized Taylor expanded polynomial approximation of a
model's training loss function, where each user's data is privatized by
calibrated noise added to the coefficients of the polynomial. Unlike
gradient-based mechanisms such as differentially private stochastic gradient
descent (DP-SGD), SPOF does not require injecting noise into the gradients of
the loss function, which improves both computational efficiency and stability.
This formulation naturally supports simultaneous privacy guarantees across all
users. Moreover, SPOF exhibits robustness to environmental noise during
training, maintaining stable performance even when user inputs are corrupted.
We compare SPOF with a multi-user extension of DP-SGD, evaluating both methods
in a wireless body area network (WBAN) scenario involving heterogeneous user
data and stochastic channel noise from body sensors. Our results show that SPOF
achieves, on average, up to 3.5% higher reconstruction accuracy and reduces
mean training time by up to 57.2% compared to DP-SGD, demonstrating superior
privacy-utility trade-offs in multi-user environments.

</details>


### [123] [AI-Powered Machine Learning Approaches for Fault Diagnosis in Industrial Pumps](https://arxiv.org/abs/2508.15550)
*Khaled M. A. Alghtus,Ayad Gannan,Khalid M. Alhajri,Ali L. A. Al Jubouri,Hassan A. I. Al-Janahi*

Main category: cs.LG

TL;DR: 本研究提出了一种基于实际传感器数据的工业泵系统早期故障检测方法，结合固定阈值与自适应阈值，并通过合成故障信号增强数据，利用多种机器学习模型实现高精度检测。


<details>
  <summary>Details</summary>
Motivation: 针对工业泵系统在苛刻的海洋环境中运行的故障检测需求，特别是在故障样本稀少的情况下，研究旨在开发一种可扩展且稳健的早期故障检测方法。

Method: 通过监测振动、温度、流量、压力和电流五个关键参数，结合双阈值标记方法（固定工程阈值与历史数据95%分位数），并注入合成故障信号。随机森林、XGBoost和SVM三种模型被用于分类。

Result: 随机森林和XGBoost模型在各类别中均表现出高准确率，包括罕见的故障情况，而SVM模型对异常敏感度较低。可视化分析验证了方法的稳健性。

Conclusion: 该框架可扩展性强，适用于实时工业部署，并能推广到其他类似传感器架构的设备，为复杂系统的预测性维护提供了有效解决方案。

Abstract: This study presents a practical approach for early fault detection in
industrial pump systems using real-world sensor data from a large-scale
vertical centrifugal pump operating in a demanding marine environment. Five key
operational parameters were monitored: vibration, temperature, flow rate,
pressure, and electrical current. A dual-threshold labeling method was applied,
combining fixed engineering limits with adaptive thresholds calculated as the
95th percentile of historical sensor values. To address the rarity of
documented failures, synthetic fault signals were injected into the data using
domain-specific rules, simulating critical alerts within plausible operating
ranges. Three machine learning classifiers - Random Forest, Extreme Gradient
Boosting (XGBoost), and Support Vector Machine (SVM) - were trained to
distinguish between normal operation, early warnings, and critical alerts.
Results showed that Random Forest and XGBoost models achieved high accuracy
across all classes, including minority cases representing rare or emerging
faults, while the SVM model exhibited lower sensitivity to anomalies. Visual
analyses, including grouped confusion matrices and time-series plots, indicated
that the proposed hybrid method provides robust detection capabilities. The
framework is scalable, interpretable, and suitable for real-time industrial
deployment, supporting proactive maintenance decisions before failures occur.
Furthermore, it can be adapted to other machinery with similar sensor
architectures, highlighting its potential as a scalable solution for predictive
maintenance in complex systems.

</details>


### [124] [Conformalized Exceptional Model Mining: Telling Where Your Model Performs (Not) Well](https://arxiv.org/abs/2508.15569)
*Xin Du,Sikun Yang,Wouter Duivesteijn,Mykola Pechenizkiy*

Main category: cs.LG

TL;DR: 论文提出了一种结合Conformal Prediction和Exceptional Model Mining的新框架，用于识别数据中模型性能异常的子组，提升模型的可解释性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域（如医疗和金融）中，理解机器学习模型的性能表现至关重要，需要一种能够识别性能异常子组的方法。

Method: 提出Conformalized Exceptional Model Mining框架，结合Conformal Prediction和EMM，开发新模型mSMoPE及质量度量RAUL。

Result: 实验表明该框架能有效识别多类分类和回归任务中性能异常的可解释子组。

Conclusion: 该研究为增强模型可解释性和可靠性奠定了基础，推动了可解释AI和不确定性量化的前沿发展。

Abstract: Understanding the nuanced performance of machine learning models is essential
for responsible deployment, especially in high-stakes domains like healthcare
and finance. This paper introduces a novel framework, Conformalized Exceptional
Model Mining, which combines the rigor of Conformal Prediction with the
explanatory power of Exceptional Model Mining (EMM). The proposed framework
identifies cohesive subgroups within data where model performance deviates
exceptionally, highlighting regions of both high confidence and high
uncertainty. We develop a new model class, mSMoPE (multiplex Soft Model
Performance Evaluation), which quantifies uncertainty through conformal
prediction's rigorous coverage guarantees. By defining a new quality measure,
Relative Average Uncertainty Loss (RAUL), our framework isolates subgroups with
exceptional performance patterns in multi-class classification and regression
tasks. Experimental results across diverse datasets demonstrate the framework's
effectiveness in uncovering interpretable subgroups that provide critical
insights into model behavior. This work lays the groundwork for enhancing model
interpretability and reliability, advancing the state-of-the-art in explainable
AI and uncertainty quantification.

</details>


### [125] [Inductive Domain Transfer In Misspecified Simulation-Based Inference](https://arxiv.org/abs/2508.15593)
*Ortal Senouf,Antoine Wehenkel,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard*

Main category: cs.LG

TL;DR: 提出了一种完全归纳和摊销的SBI框架，通过集成校准和分布对齐到单一端到端可训练模型，解决了RoPE在测试时需批量样本的限制，提升了可扩展性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 解决SBI方法中模型错误规范和RoPE方法的局限性，如需要批量测试样本，限制了可扩展性和通用性。

Method: 利用小批量最优传输（OT）和闭合形式耦合对齐真实和模拟观测，结合配对的校准数据和非配对样本，训练条件归一化流以近似OT诱导的后验。

Result: 在合成和真实世界基准测试（包括复杂的医学生物标志物估计）中，性能优于或媲美RoPE和其他标准SBI与非SBI估计器。

Conclusion: 该方法在具有挑战性的错误规范环境中，提供了更好的可扩展性和适用性。

Abstract: Simulation-based inference (SBI) is a statistical inference approach for
estimating latent parameters of a physical system when the likelihood is
intractable but simulations are available. In practice, SBI is often hindered
by model misspecification--the mismatch between simulated and real-world
observations caused by inherent modeling simplifications. RoPE, a recent SBI
approach, addresses this challenge through a two-stage domain transfer process
that combines semi-supervised calibration with optimal transport (OT)-based
distribution alignment. However, RoPE operates in a fully transductive setting,
requiring access to a batch of test samples at inference time, which limits
scalability and generalization. We propose here a fully inductive and amortized
SBI framework that integrates calibration and distributional alignment into a
single, end-to-end trainable model. Our method leverages mini-batch OT with a
closed-form coupling to align real and simulated observations that correspond
to the same latent parameters, using both paired calibration data and unpaired
samples. A conditional normalizing flow is then trained to approximate the
OT-induced posterior, enabling efficient inference without simulation access at
test time. Across a range of synthetic and real-world benchmarks--including
complex medical biomarker estimation--our approach matches or surpasses the
performance of RoPE, as well as other standard SBI and non-SBI estimators,
while offering improved scalability and applicability in challenging,
misspecified environments.

</details>


### [126] [Continual Neural Topic Model](https://arxiv.org/abs/2508.15612)
*Charu Karakkaparambil James,Waleed Mustafa,Marius Kloft,Sophie Fellenz*

Main category: cs.LG

TL;DR: 提出了一种新的持续神经主题模型（CoNTM），旨在解决持续学习中新任务学习时遗忘旧知识的问题，相比动态主题模型和在线主题模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有动态主题模型（DTMs）需要整个训练语料库，而在线主题模型缺乏长期记忆。CoNTM旨在填补这一空白，实现持续学习新主题而不遗忘旧主题。

Method: 通过持续更新的全局先验分布，CoNTM在后续时间步中持续学习主题模型。

Result: 实验表明，CoNTM在主题质量和预测困惑度上优于动态主题模型，并能在线捕捉主题变化。

Conclusion: CoNTM能学习更多样化的主题并更好地捕捉时间变化，优于现有方法。

Abstract: In continual learning, our aim is to learn a new task without forgetting what
was learned previously. In topic models, this translates to learning new topic
models without forgetting previously learned topics. Previous work either
considered Dynamic Topic Models (DTMs), which learn the evolution of topics
based on the entire training corpus at once, or Online Topic Models, which are
updated continuously based on new data but do not have long-term memory. To
fill this gap, we propose the Continual Neural Topic Model (CoNTM), which
continuously learns topic models at subsequent time steps without forgetting
what was previously learned. This is achieved using a global prior distribution
that is continuously updated. In our experiments, CoNTM consistently
outperformed the dynamic topic model in terms of topic quality and predictive
perplexity while being able to capture topic changes online. The analysis
reveals that CoNTM can learn more diverse topics and better capture temporal
changes than existing methods.

</details>


### [127] [GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)](https://arxiv.org/abs/2508.15633)
*Wei Herng Choong,Jixing Liu,Ching-Yu Kao,Philip Sperl*

Main category: cs.LG

TL;DR: 该论文提出了一种名为GRASPED的无监督学习模型，用于图异常检测，通过结合频谱编码器和解码器来捕捉多尺度信息。


<details>
  <summary>Details</summary>
Motivation: 现有监督方法受限于标注数据的稀缺性，而无监督方法多依赖空间信息或仅使用低通滤波器，无法进行多频带分析，因此需要更有效的模型。

Method: GRASPED采用基于图小波卷积的编码器和Wiener图反卷积解码器，具备带通滤波特性，支持多尺度信息捕捉和节点属性重建。

Result: 实验结果表明，GRASPED在多个真实图异常检测数据集上优于当前最优模型。

Conclusion: 该模型通过频谱信息的多尺度分析，有效提升了无监督图异常检测的性能。

Abstract: Graph machine learning has been widely explored in various domains, such as
community detection, transaction analysis, and recommendation systems. In these
applications, anomaly detection plays an important role. Recently, studies have
shown that anomalies on graphs induce spectral shifts. Some supervised methods
have improved the utilization of such spectral domain information. However,
they remain limited by the scarcity of labeled data due to the nature of
anomalies. On the other hand, existing unsupervised learning approaches
predominantly rely on spatial information or only employ low-pass filters,
thereby losing the capacity for multi-band analysis. In this paper, we propose
Graph Autoencoder with Spectral Encoder and Spectral Decoder (GRASPED) for node
anomaly detection. Our unsupervised learning model features an encoder based on
Graph Wavelet Convolution, along with structural and attribute decoders. The
Graph Wavelet Convolution-based encoder, combined with a Wiener Graph
Deconvolution-based decoder, exhibits bandpass filter characteristics that
capture global and local graph information at multiple scales. This design
allows for a learning-based reconstruction of node attributes, effectively
capturing anomaly information. Extensive experiments on several real-world
graph anomaly detection datasets demonstrate that GRASPED outperforms current
state-of-the-art models.

</details>


### [128] [Classification errors distort findings in automated speech processing: examples and solutions from child-development research](https://arxiv.org/abs/2508.15637)
*Lucas Gautheron,Evan Kidd,Anton Malko,Marvin Lavechin,Alejandrina Cristia*

Main category: cs.LG

TL;DR: 论文研究了自动分类错误对儿童语言习得研究的影响，提出贝叶斯方法校准估计偏差，发现分类错误会显著扭曲统计结果。


<details>
  <summary>Details</summary>
Motivation: 研究自动分类器的错误对测量和统计推断的影响，补充现有文献中对分类误差下游影响的不足。

Method: 采用贝叶斯方法分析两种自动分类器（LENA和ACLEW的Voice Type Classifier）的分类错误对关键科学问题的估计偏差。

Result: 分类错误显著低估了兄弟姐妹对成人语言输入的负面影响（20-80%），贝叶斯校准方法能部分恢复无偏估计。

Conclusion: 分类错误可能广泛影响事件检测研究，贝叶斯方法是一种有效但不完美的解决方案。

Abstract: With the advent of wearable recorders, scientists are increasingly turning to
automated methods of analysis of audio and video data in order to measure
children's experience, behavior, and outcomes, with a sizable literature
employing long-form audio-recordings to study language acquisition. While
numerous articles report on the accuracy and reliability of the most popular
automated classifiers, less has been written on the downstream effects of
classification errors on measurements and statistical inferences (e.g., the
estimate of correlations and effect sizes in regressions). This paper proposes
a Bayesian approach to study the effects of algorithmic errors on key
scientific questions, including the effect of siblings on children's language
experience and the association between children's production and their input.
In both the most commonly used \gls{lena}, and an open-source alternative (the
Voice Type Classifier from the ACLEW system), we find that classification
errors can significantly distort estimates. For instance, automated annotations
underestimated the negative effect of siblings on adult input by 20--80\%,
potentially placing it below statistical significance thresholds. We further
show that a Bayesian calibration approach for recovering unbiased estimates of
effect sizes can be effective and insightful, but does not provide a fool-proof
solution. Both the issue reported and our solution may apply to any classifier
involving event detection and classification with non-zero error rates.

</details>


### [129] [Correct-By-Construction: Certified Individual Fairness through Neural Network Training](https://arxiv.org/abs/2508.15642)
*Ruihan Zhang,Jun Sun*

Main category: cs.LG

TL;DR: 论文提出了一种新颖的框架，通过可证明公平的初始化和训练算法，确保机器学习模型在整个训练过程中保持个体公平性。


<details>
  <summary>Details</summary>
Motivation: 随着伦理问题的日益突出，机器学习的公平性变得尤为重要。现有方法虽然有效，但缺乏形式化的公平性保证。

Method: 提出一种包含两个部分的方法：可证明公平的初始化和保持公平的训练算法，使用随机响应机制保护敏感属性。

Result: 实验证明，该方法不仅保证了模型的公平性，还保持了较高的准确性，且比基于验证的方法更高效。

Conclusion: 该框架为机器学习模型的公平性提供了形式化保证，同时提升了训练效率。

Abstract: Fairness in machine learning is more important than ever as ethical concerns
continue to grow. Individual fairness demands that individuals differing only
in sensitive attributes receive the same outcomes. However, commonly used
machine learning algorithms often fail to achieve such fairness. To improve
individual fairness, various training methods have been developed, such as
incorporating fairness constraints as optimisation objectives. While these
methods have demonstrated empirical effectiveness, they lack formal guarantees
of fairness. Existing approaches that aim to provide fairness guarantees
primarily rely on verification techniques, which can sometimes fail to produce
definitive results. Moreover, verification alone does not actively enhance
individual fairness during training. To address this limitation, we propose a
novel framework that formally guarantees individual fairness throughout
training. Our approach consists of two parts, i.e., (1) provably fair
initialisation that ensures the model starts in a fair state, and (2) a
fairness-preserving training algorithm that maintains fairness as the model
learns. A key element of our method is the use of randomised response
mechanisms, which protect sensitive attributes while maintaining fairness
guarantees. We formally prove that this mechanism sustains individual fairness
throughout the training process. Experimental evaluations confirm that our
approach is effective, i.e., producing models that are empirically fair and
accurate. Furthermore, our approach is much more efficient than the alternative
approach based on certified training (which requires neural network
verification during training).

</details>


### [130] [Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot Approach for Pharmacokinetics](https://arxiv.org/abs/2508.15659)
*César Ali Ojeda Marin,Wilhelm Huisinga,Purity Kavwele,Niklas Hartung*

Main category: cs.LG

TL;DR: AICMET模型通过结合变压器和贝叶斯推断，实现了在稀疏采样下的精准剂量预测，显著提升了预测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决精确药物治疗中稀疏采样下的剂量反应预测问题，提升模型对新化合物的零样本适应能力。

Method: 开发了AICMET模型，结合变压器和先验知识，通过预训练和贝叶斯推断生成后验预测。

Result: 在公开数据集上，AICMET表现出最佳预测精度，并能量化患者间差异。

Conclusion: AICMET为个性化剂量方案提供了新途径，具有潜力成为标准建模工具的替代方案。

Abstract: Accurate dose-response forecasting under sparse sampling is central to
precision pharmacotherapy. We present the Amortized In-Context Mixed-Effect
Transformer (AICMET) model, a transformer-based latent-variable framework that
unifies mechanistic compartmental priors with amortized in-context Bayesian
inference. AICMET is pre-trained on hundreds of thousands of synthetic
pharmacokinetic trajectories with Ornstein-Uhlenbeck priors over the parameters
of compartment models, endowing the model with strong inductive biases and
enabling zero-shot adaptation to new compounds. At inference time, the decoder
conditions on the collective context of previously profiled trial participants,
generating calibrated posterior predictions for newly enrolled patients after a
few early drug concentration measurements. This capability collapses
traditional model-development cycles from weeks to hours while preserving some
degree of expert modelling. Experiments across public datasets show that AICMET
attains state-of-the-art predictive accuracy and faithfully quantifies
inter-patient variability -- outperforming both nonlinear mixed-effects
baselines and recent neural ODE variants. Our results highlight the feasibility
of transformer-based, population-aware neural architectures as offering a new
alternative for bespoke pharmacokinetic modeling pipelines, charting a path
toward truly population-aware personalized dosing regimens.

</details>


### [131] [Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data](https://arxiv.org/abs/2508.15676)
*Elif Konyar,Mostafa Reisi Gahrooei,Kamran Paynabar*

Main category: cs.LG

TL;DR: 该论文提出了一种结合多任务学习和低秩张量分解的新方法，用于建模异构子群体，提高个性化模型的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 异构子群体的建模因个体特征和行为差异而具有挑战性。

Method: 采用多任务学习和低秩张量分解技术，通过共享结构和分解任务模型参数来捕捉子群体的共性和个性。

Result: 实验表明，该方法在多变性子群体场景中优于基准方法，提高了预测准确性和模型可解释性。

Conclusion: 该方法为异构子群体建模提供了一种高效且可解释的解决方案。

Abstract: Effective modeling of heterogeneous subpopulations presents a significant
challenge due to variations in individual characteristics and behaviors. This
paper proposes a novel approach to address this issue through multi-task
learning (MTL) and low-rank tensor decomposition techniques. Our MTL approach
aims to enhance personalized modeling by leveraging shared structures among
similar tasks while accounting for distinct subpopulation-specific variations.
We introduce a framework where low-rank decomposition decomposes the collection
of task model parameters into a low-rank structure that captures commonalities
and variations across tasks and subpopulations. This approach allows for
efficient learning of personalized models by sharing knowledge between similar
tasks while preserving the unique characteristics of each subpopulation.
Experimental results in simulation and case study datasets demonstrate the
superior performance of the proposed method compared to several benchmarks,
particularly in scenarios with high variability among subpopulations. The
proposed framework not only improves prediction accuracy but also enhances
interpretability by revealing underlying patterns that contribute to the
personalization of models.

</details>


### [132] [An Efficient Open World Environment for Multi-Agent Social Learning](https://arxiv.org/abs/2508.15679)
*Eric Ye,Ren Tao,Natasha Jaques*

Main category: cs.LG

TL;DR: 论文提出一个开放多智能体环境，用于研究社交智能AI的发展，探讨了专家存在和隐式合作对智能体性能的影响。


<details>
  <summary>Details</summary>
Motivation: 研究AI在开放多智能体环境中如何利用社交智能学习自适应行为，解决现实世界中的复杂问题。

Method: 设计一个多智能体环境，智能体可追求独立和复杂目标，研究社交学习和隐式合作的效果。

Result: 发现智能体可以通过社交学习提升性能，并在环境中实现合作性工具使用等行为。

Conclusion: 开放多智能体环境有助于研究社交智能AI的发展，合作和竞争对智能体学习有积极影响。

Abstract: Many challenges remain before AI agents can be deployed in real-world
environments. However, one virtue of such environments is that they are
inherently multi-agent and contain human experts. Using advanced social
intelligence in such an environment can help an AI agent learn adaptive skills
and behaviors that a known expert exhibits. While social intelligence could
accelerate training, it is currently difficult to study due to the lack of
open-ended multi-agent environments. In this work, we present an environment in
which multiple self-interested agents can pursue complex and independent goals,
reflective of real world challenges. This environment will enable research into
the development of socially intelligent AI agents in open-ended multi-agent
settings, where agents may be implicitly incentivized to cooperate to defeat
common enemies, build and share tools, and achieve long horizon goals. In this
work, we investigate the impact on agent performance due to social learning in
the presence of experts and implicit cooperation such as emergent collaborative
tool use, and whether agents can benefit from either cooperation or competition
in this environment.

</details>


### [133] [Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks](https://arxiv.org/abs/2508.15695)
*Qifeng Hu,Shamsulhaq Basir,Inanc Senocak*

Main category: cs.LG

TL;DR: 该论文提出了改进PECANN框架的多种方法，包括多参数ALM、点约束期望化、傅里叶特征映射、时间窗口策略及自适应惩罚更新策略，提升了其在PDE求解中的能力。


<details>
  <summary>Details</summary>
Motivation: 提升PECANN框架在求解偏微分方程时的能力，特别是针对多尺度、振荡特征及长时间演化的复杂问题。

Method: 1. 多参数ALM；2. 约束期望化；3. 傅里叶特征映射；4. 时间窗口策略；5. 条件自适应惩罚更新策略（CAPU）。

Result: PECANN-CAPU在多个问题上表现出高精度，包括跨音速膨胀、涡旋被动平流、高波数方程及逆问题求解。

Conclusion: 改进的PECANN框架显著提升了计算效率、鲁棒性及在科学计算中的适用性。

Abstract: We present several advances to the physics and equality constrained
artificial neural networks (PECANN) framework that substantially improve its
capability to learn solutions of canonical partial differential equations
(PDEs). First, we generalize the augmented Lagrangian method (ALM) to support
multiple independent penalty parameters, enabling simultaneous enforcement of
heterogeneous constraints. Second, we reformulate pointwise constraint
enforcement and Lagrange multipliers as expectations over constraint terms,
reducing memory overhead and permitting efficient mini-batch training. Third,
to address PDEs with oscillatory, multi-scale features, we incorporate Fourier
feature mappings and show that a single mapping suffices where multiple
mappings or more costly architectures were required in related methods. Fourth,
we introduce a time-windowing strategy for long-time evolution in which the
terminal state of each window is enforced as an initial-condition constraint
for the next, ensuring continuity without discrete time models. Crucially, we
propose a conditionally adaptive penalty update (CAPU) strategy for ALM, which
preserves the principle that larger constraint violations incur stronger
penalties. CAPU accelerates the growth of Lagrange multipliers for selectively
challenging constraints, enhancing constraint enforcement during training. We
demonstrate the effectiveness of PECANN-CAPU on problems including the
transonic rarefaction problem, reversible advection of a passive by a vortex,
high-wavenumber Helmholtz and Poisson equations, and inverse identification of
spatially varying heat sources. Comparisons with established methods and recent
Kolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive
accuracy across all cases. Collectively, these advances improve PECANN's
robustness, efficiency, and applicability to demanding problems in scientific
computing.

</details>


### [134] [Investigation of D-Wave quantum annealing for training Restricted Boltzmann Machines and mitigating catastrophic forgetting](https://arxiv.org/abs/2508.15697)
*Abdelmoula El-Yazizi,Yaroslav Koshka*

Main category: cs.LG

TL;DR: 研究探讨了D-Wave量子退火器（QA）和经典马尔可夫链蒙特卡洛（MCMC）在受限玻尔兹曼机（RBM）采样中的细微差异，提出了一种混合采样方法，但因差异不足未显著改善RBM训练，但展示了QA在缓解灾难性遗忘（CF）中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索D-Wave QA与经典MCMC在RBM采样中的差异，以解释之前研究中QA未显著改善训练效果的原因，并尝试提出新方法以利用这些差异。

Method: 提出了一种结合QA和MCMC的混合采样方法，并测试其在RBM训练和CF缓解中的应用效果。

Result: 混合采样未改善RBM训练，但首次证明了QA生成样本在缓解CF中的可行性，效果与经典方法相当。

Conclusion: QA在RBM训练中的优势有限，但在CF等机器学习任务中具有潜在应用价值，未来改进可能提升其效率。

Abstract: Modest statistical differences between the sampling performances of the
D-Wave quantum annealer (QA) and the classical Markov Chain Monte Carlo (MCMC),
when applied to Restricted Boltzmann Machines (RBMs), are explored to explain,
and possibly address, the absence of significant and consistent improvements in
RBM trainability when the D-Wave sampling was used in previous investigations.
A novel hybrid sampling approach, combining the classical and the QA
contributions, is investigated as a promising way to benefit from the modest
differences between the two sampling methods. No improvements in the RBM
training are achieved in this work, thereby suggesting that the differences
between the QA-based and MCMC sampling, mainly found in the medium-to-low
probability regions of the distribution, which are less important for the
quality of the sample, are insufficient to benefit the training. Difficulties
in achieving sufficiently high quality of embedding RBMs into the lattice of
the newer generation of D-Wave hardware could be further complicating the task.
On the other hand, the ability to generate samples of sufficient variety from
lower-probability parts of the distribution has a potential to benefit other
machine learning applications, such as the mitigation of catastrophic
forgetting (CF) during incremental learning. The feasibility of using
QA-generated patterns of desirable classes for CF mitigation by the generative
replay is demonstrated in this work for the first time. While the efficiency of
the CF mitigation using the D-Wave QA was comparable to that of the classical
mitigation, both the speed of generating a large number of distinct desirable
patterns and the potential for further improvement make this approach promising
for a variety of challenging machine learning applications.

</details>


### [135] [Communication Efficient LLM Pre-training with SparseLoCo](https://arxiv.org/abs/2508.15706)
*Amir Sarfi,Benjamin Thérien,Joel Lidin,Eugene Belilovsky*

Main category: cs.LG

TL;DR: SparseLoCo 是一种高效的分布式训练算法，通过稀疏化和量化技术显著减少通信开销，适用于带宽受限的 LLM 训练场景，且性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决大规模语言模型训练中通信开销高的问题，特别是在带宽受限的环境下（如数据中心间或互联网），传统方法仍存在通信瓶颈。

Method: 提出 SparseLoCo 算法，通过结合 Top-k 稀疏化和 2-bit 量化技术，实现高达 1-3% 稀疏率和 2-bit 量化的极端压缩，同时利用误差反馈和稀疏聚合优化性能。

Result: 实验表明，SparseLoCo 在多种通信受限的 LLM 训练场景中，显著降低了通信成本，且性能优于全精度 DiLoCo。

Conclusion: SparseLoCo 是一种有效的通信高效训练方法，能够在不牺牲性能的前提下显著减少通信开销，特别适合大规模语言模型的分布式训练。

Abstract: Communication-efficient distributed training algorithms have received
considerable interest recently due to their benefits for training Large
Language Models (LLMs) in bandwidth-constrained settings, such as across data
centers and over the internet. Despite reducing communication frequency, these
methods still typically require communicating a full copy of the model's
gradients-resulting in a communication bottleneck even for cross-datacenter
links. Furthermore, they can slightly degrade performance compared to a naive
AdamW DDP baseline. While quantization and error feedback are often applied to
reduce the pseudo-gradient's size, in the context of LLM pre-training, existing
approaches have been unable to additionally leverage sparsification and have
obtained limited quantization. In this work, we introduce SparseLoCo, a
communication-efficient training algorithm for LLMs that effectively leverages
Top-k sparsification and quantization to reach extreme compression ratios of up
to 1-3% sparsity and 2-bit quantization while outperforming full-precision
DiLoCo. Our key observations are that outer momentum can be locally
approximated by an error feedback combined with aggressive sparsity and that
sparse aggregation can actually improve model performance. We empirically
demonstrate in a range of communication-constrained LLM training settings that
SparseLoCo provides significant benefits in both performance and communication
cost.

</details>


### [136] [Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI](https://arxiv.org/abs/2508.15719)
*Mohammed Elmusrati*

Main category: cs.LG

TL;DR: 该论文提供了一个统一的数学框架，连接经典估计理论、统计推断和现代机器学习，展示了多种AI方法共享的概率基础。


<details>
  <summary>Details</summary>
Motivation: 提取不确定、噪声数据中的意义是时间序列分析、模式识别和语言建模的核心问题，研究旨在统一不同方法的理论基础。

Method: 通过分析最大似然估计、贝叶斯推断和注意力机制等技术如何处理不确定性，论文展示了这些方法的共同概率原理。

Result: 论文表明，从最大似然到深度学习，这些方法都是通过不同方式从噪声和/或有偏观察中推断隐藏原因。

Conclusion: 该研究为机器学习的理论和实践提供了综合指南，适用于学生和研究者在快速发展的领域中导航。

Abstract: Extracting meaning from uncertain, noisy data is a fundamental problem across
time series analysis, pattern recognition, and language modeling. This survey
presents a unified mathematical framework that connects classical estimation
theory, statistical inference, and modern machine learning, including deep
learning and large language models. By analyzing how techniques such as maximum
likelihood estimation, Bayesian inference, and attention mechanisms address
uncertainty, the paper illustrates that many AI methods are rooted in shared
probabilistic principles. Through illustrative scenarios including system
identification, image classification, and language generation, we show how
increasingly complex models build upon these foundations to tackle practical
challenges like overfitting, data sparsity, and interpretability. In other
words, the work demonstrates that maximum likelihood, MAP estimation, Bayesian
classification, and deep learning all represent different facets of a shared
goal: inferring hidden causes from noisy and/or biased observations. It serves
as both a theoretical synthesis and a practical guide for students and
researchers navigating the evolving landscape of machine learning.

</details>


### [137] [Probability Density from Latent Diffusion Models for Out-of-Distribution Detection](https://arxiv.org/abs/2508.15737)
*Joonas Järve,Karl Kaspar Haavel,Meelis Kull*

Main category: cs.LG

TL;DR: 该论文探讨了生成模型中基于数据似然的OOD检测方法在实际中的表现，并通过在预训练ResNet-18的表示空间上训练变分扩散模型，验证了其效果与OpenOOD套件中先进方法的对比。


<details>
  <summary>Details</summary>
Motivation: 尽管AI快速发展，安全性仍是部署机器学习系统的主要瓶颈，其中OOD检测是关键。研究旨在验证数据似然作为OOD检测器的实际有效性。

Method: 在预训练ResNet-18的表示空间上训练变分扩散模型，利用数据似然作为OOD检测器，并与OpenOOD套件中的先进方法进行比较。

Result: 研究发现数据似然在实际中存在局限性，但通过改变表示空间（而非传统的像素空间），可以部分解决这一问题。

Conclusion: 数据似然在特定条件下（如均匀分布的OOD数据）可能是最优OOD检测器，但在实践中仍需优化表示空间以提高检测效果。

Abstract: Despite rapid advances in AI, safety remains the main bottleneck to deploying
machine-learning systems. A critical safety component is out-of-distribution
detection: given an input, decide whether it comes from the same distribution
as the training data. In generative models, the most natural OOD score is the
data likelihood. Actually, under the assumption of uniformly distributed OOD
data, the likelihood is even the optimal OOD detector, as we show in this work.
However, earlier work reported that likelihood often fails in practice, raising
doubts about its usefulness. We explore whether, in practice, the
representation space also suffers from the inability to learn good density
estimation for OOD detection, or if it is merely a problem of the pixel space
typically used in generative models. To test this, we trained a Variational
Diffusion Model not on images, but on the representation space of a pre-trained
ResNet-18 to assess the performance of our likelihood-based detector in
comparison to state-of-the-art methods from the OpenOOD suite.

</details>


### [138] [Intern-S1: A Scientific Multimodal Foundation Model](https://arxiv.org/abs/2508.15763)
*Lei Bai,Zhongrui Cai,Maosong Cao,Weihan Cao,Chiyu Chen,Haojiong Chen,Kai Chen,Pengcheng Chen,Ying Chen,Yongkang Chen,Yu Cheng,Yu Cheng,Pei Chu,Tao Chu,Erfei Cui,Ganqu Cui,Long Cui,Ziyun Cui,Nianchen Deng,Ning Ding,Nanqin Dong,Peijie Dong,Shihan Dou,Sinan Du,Haodong Duan,Caihua Fan,Ben Gao,Changjiang Gao,Jianfei Gao,Songyang Gao,Yang Gao,Zhangwei Gao,Jiaye Ge,Qiming Ge,Lixin Gu,Yuzhe Gu,Aijia Guo,Qipeng Guo,Xu Guo,Conghui He,Junjun He,Yili Hong,Siyuan Hou,Caiyu Hu,Hanglei Hu,Jucheng Hu,Ming Hu,Zhouqi Hua,Haian Huang,Junhao Huang,Xu Huang,Zixian Huang,Zhe Jiang,Lingkai Kong,Linyang Li,Peiji Li,Pengze Li,Shuaibin Li,Tianbin Li,Wei Li,Yuqiang Li,Dahua Lin,Junyao Lin,Tianyi Lin,Zhishan Lin,Hongwei Liu,Jiangning Liu,Jiyao Liu,Junnan Liu,Kai Liu,Kaiwen Liu,Kuikun Liu,Shichun Liu,Shudong Liu,Wei Liu,Xinyao Liu,Yuhong Liu,Zhan Liu,Yinquan Lu,Haijun Lv,Hongxia Lv,Huijie Lv,Qidang Lv,Ying Lv,Chengqi Lyu,Chenglong Ma,Jianpeng Ma,Ren Ma,Runmin Ma,Runyuan Ma,Xinzhu Ma,Yichuan Ma,Zihan Ma,Sixuan Mi,Junzhi Ning,Wenchang Ning,Xinle Pang,Jiahui Peng,Runyu Peng,Yu Qiao,Jiantao Qiu,Xiaoye Qu,Yuan Qu,Yuchen Ren,Fukai Shang,Wenqi Shao,Junhao Shen,Shuaike Shen,Chunfeng Song,Demin Song,Diping Song,Chenlin Su,Weijie Su,Weigao Sun,Yu Sun,Qian Tan,Cheng Tang,Huanze Tang,Kexian Tang,Shixiang Tang,Jian Tong,Aoran Wang,Bin Wang,Dong Wang,Lintao Wang,Rui Wang,Weiyun Wang,Wenhai Wang,Yi Wang,Ziyi Wang,Ling-I Wu,Wen Wu,Yue Wu,Zijian Wu,Linchen Xiao,Shuhao Xing,Chao Xu,Huihui Xu,Jun Xu,Ruiliang Xu,Wanghan Xu,GanLin Yang,Yuming Yang,Haochen Ye,Jin Ye,Shenglong Ye,Jia Yu,Jiashuo Yu,Jing Yu,Fei Yuan,Bo Zhang,Chao Zhang,Chen Zhang,Hongjie Zhang,Jin Zhang,Qiaosheng Zhang,Qiuyinzhe Zhang,Songyang Zhang,Taolin Zhang,Wenlong Zhang,Wenwei Zhang,Yechen Zhang,Ziyang Zhang,Haiteng Zhao,Qian Zhao,Xiangyu Zhao,Xiangyu Zhao,Bowen Zhou,Dongzhan Zhou,Peiheng Zhou,Yuhao Zhou,Yunhua Zhou,Dongsheng Zhu,Lin Zhu,Yicheng Zou*

Main category: cs.LG

TL;DR: 开源基础模型在科学专业领域表现不足，Intern-S1通过多模态专家混合模型和混合奖励强化学习，在科学任务上超越开源模型并接近闭源模型。


<details>
  <summary>Details</summary>
Motivation: 解决开源模型在科学领域的性能差距，推动通用人工智能发展。

Method: 采用多模态专家混合模型（MoE）和混合奖励强化学习（MoR），训练28B激活参数模型。

Result: 在科学任务上表现优异，超越开源模型并接近闭源模型。

Conclusion: Intern-S1填补了科学领域开源与闭源模型的差距，为AGI迈进一步。

Abstract: In recent years, a plethora of open-source foundation models have emerged,
achieving remarkable progress in some widely attended fields, with performance
being quite close to that of closed-source models. However, in high-value but
more challenging scientific professional fields, either the fields still rely
on expert models, or the progress of general foundation models lags
significantly compared to those in popular areas, far from sufficient for
transforming scientific research and leaving substantial gap between
open-source models and closed-source models in these scientific domains. To
mitigate this gap and explore a step further toward Artificial General
Intelligence (AGI), we introduce Intern-S1, a specialized generalist equipped
with general understanding and reasoning capabilities with expertise to analyze
multiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE)
model with 28 billion activated parameters and 241 billion total parameters,
continually pre-trained on 5T tokens, including over 2.5T tokens from
scientific domains. In the post-training stage, Intern-S1 undergoes offline and
then online reinforcement learning (RL) in InternBootCamp, where we propose
Mixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks
simultaneously. Through integrated innovations in algorithms, data, and
training systems, Intern-S1 achieved top-tier performance in online RL
training.On comprehensive evaluation benchmarks, Intern-S1 demonstrates
competitive performance on general reasoning tasks among open-source models and
significantly outperforms open-source models in scientific domains, surpassing
closed-source state-of-the-art models in professional tasks, such as molecular
synthesis planning, reaction condition prediction, predicting thermodynamic
stabilities for crystals. Our models are available at
https://huggingface.co/internlm/Intern-S1.

</details>


### [139] [Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space](https://arxiv.org/abs/2508.15764)
*Kiarash Kazari,Ezzeldin Shereen,György Dán*

Main category: cs.LG

TL;DR: 提出了一种用于检测连续动作空间下多智能体强化学习中对抗攻击的分散式检测器，利用深度神经网络和统计方法实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在连续动作空间中容易受到对抗攻击，需要一种分散的检测方法以保障系统安全。

Method: 使用深度神经网络建模智能体的正常行为为高斯分布，基于预测密度函数定义正态性评分，并通过CUSUM方法实时检测异常。

Result: 在多种PettingZoo环境中测试，对最严重攻击的检测AUC-ROC分数超过0.95，表现优于离散方法。

Conclusion: 该方法有效检测对抗攻击，适用于连续动作空间的多智能体系统，具有实际应用价值。

Abstract: We address the problem of detecting adversarial attacks against cooperative
multi-agent reinforcement learning with continuous action space. We propose a
decentralized detector that relies solely on the local observations of the
agents and makes use of a statistical characterization of the normal behavior
of observable agents. The proposed detector utilizes deep neural networks to
approximate the normal behavior of agents as parametric multivariate Gaussian
distributions. Based on the predicted density functions, we define a normality
score and provide a characterization of its mean and variance. This
characterization allows us to employ a two-sided CUSUM procedure for detecting
deviations of the normality score from its mean, serving as a detector of
anomalous behavior in real-time. We evaluate our scheme on various multi-agent
PettingZoo benchmarks against different state-of-the-art attack methods, and
our results demonstrate the effectiveness of our method in detecting impactful
adversarial attacks. Particularly, it outperforms the discrete counterpart by
achieving AUC-ROC scores of over 0.95 against the most impactful attacks in all
evaluated environments.

</details>


### [140] [Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO](https://arxiv.org/abs/2508.15766)
*Jaeha Lee,Gio Huh,Ning Su,Tony Yue YU*

Main category: cs.LG

TL;DR: 本文探讨了Transformer在多元多项式分解这一复杂代数任务中的非线性格局发现能力，提出了一种合成数据生成管道、一种名为BGRPO的强化学习方法和多项实验验证。


<details>
  <summary>Details</summary>
Motivation: 多元多项式分解在科学与工程中有广泛应用，但其NP难特性要求高精度与深度洞察，因此需要探索更高效的方法。

Method: 开发了合成数据生成管道，训练了监督学习模型，并提出了BGRPO强化学习方法进行优化。

Result: BGRPO优化后，模型精度提升，推理计算量减少75%，并在多项式简化任务中表现优于Mathematica。

Conclusion: Transformer结合BGRPO在复杂代数任务中展现出潜力，为相关领域提供了新的解决方案。

Abstract: Recent efforts have extended the capabilities of transformers in logical
reasoning and symbolic computations. In this work, we investigate their
capacity for non-linear latent pattern discovery in the context of functional
decomposition, focusing on the challenging algebraic task of multivariate
polynomial decomposition. This problem, with widespread applications in science
and engineering, is proved to be NP-hard, and demands both precision and
insight. Our contributions are threefold: First, we develop a synthetic data
generation pipeline providing fine-grained control over problem complexity.
Second, we train transformer models via supervised learning and evaluate them
across four key dimensions involving scaling behavior and generalizability.
Third, we propose Beam Grouped Relative Policy Optimization (BGRPO), a
rank-aware reinforcement learning method suitable for hard algebraic problems.
Finetuning with BGRPO improves accuracy while reducing beam width by up to
half, resulting in approximately 75% lower inference compute. Additionally, our
model demonstrates competitive performance in polynomial simplification,
outperforming Mathematica in various cases.

</details>
