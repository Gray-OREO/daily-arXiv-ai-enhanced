<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 220]
- [eess.IV](#eess.IV) [Total: 15]
- [cs.MM](#cs.MM) [Total: 8]
- [cs.LG](#cs.LG) [Total: 144]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

TL;DR: 论文提出了一种名为BIND的表示模型和Med-GRIM系统，用于提高医学视觉问答（VQA）的精确性和效率，同时引入了一个新的数据集DermaGraph以支持多模态医学应用研究。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂领域（如医学VQA）中缺乏详细精确的回答能力，因此需要改进嵌入空间并开发高效、模块化的解决方案。

Method: BIND通过密集的查询标记编码优化联合嵌入空间，Med-GRIM结合图检索和提示工程，使用小语言模型（SLMs）实现高效模块化工作流程。

Result: Med-GRIM在低计算成本下实现了大语言模型的性能，并开发了DermaGraph数据集支持多模态医学研究。

Conclusion: BIND和Med-GRIM为医学VQA提供了高效、精确的解决方案，同时通过DermaGraph数据集推动了多模态医学研究的可扩展性。

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [2] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

TL;DR: DiTalker是一种基于DiT的统一框架，用于控制说话风格的肖像动画，通过分离音频和风格特征，提升唇部同步和动态风格表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注唇部同步或静态情感转换，忽视了动态风格（如头部动作），且计算开销较大。DiTalker旨在解决这些问题。

Method: DiTalker设计了风格-情感编码模块和音频-风格融合模块，通过并行注意力层解耦音频与风格，并采用优化约束提升结果质量。

Result: 实验表明，DiTalker在唇部同步和说话风格控制方面表现优越。

Conclusion: DiTalker为肖像动画提供了一种高效且可控的解决方案，具备动态风格表现和高质量结果。

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [3] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

TL;DR: 论文开发了一种名为BigTokDetect的多模态检测框架，用于识别社交媒体上可能引发肌肉变形行为的误导性内容（如健身相关视频），并通过专家标注的数据集和技术优化，显著提高了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上存在大量伪装成合法健身内容的误导性信息，这些信息可能对青少年男性产生负面影响，传统基于文本的检测方法难以捕捉其复杂多模态特征。

Method: 研究人员开发了BigTokDetect框架，并创建了一个专家标注的多模态数据集BigTok（2,200多个TikTok视频），通过对最新视觉语言模型的综合评估和领域微调，实现了多模态融合检测。

Result: BigTokDetect在主要类别和子类别分类上分别达到82.9%和69%的准确率，多模态融合比纯文本方法性能提升5-10%，其中视频特征最具判别力。

Conclusion: 该研究为复杂多模态有害内容检测提供了新基准和工具，并为心理健康领域的内容审核提供了方法论框架。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [4] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

TL;DR: FPGM是一种新的增强框架，通过利用息肉边缘的频域一致性特征，显著提高了跨域鲁棒性，实现了在标注数据有限情况下的高性能息肉分割。


<details>
  <summary>Details</summary>
Motivation: 当前息肉分割模型在数据有限和域转移情况下表现不佳，现有半监督学习方法忽视了息肉的结构特性，导致泛化能力差。

Method: FPGM通过两阶段过程学习域不变的频率先验，并在未标注图像上进行光谱扰动，以对齐频谱并保留结构完整性。

Result: 在六个公共数据集上验证，FPGM在零样本泛化和数据稀缺场景中表现优异，Dice分数绝对提升超过10%。

Conclusion: FPGM为临床部署提供了强大的有限监督下息肉分割解决方案，显著提升了跨域鲁棒性。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [5] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

TL;DR: 论文探讨了视觉反思在多模态模型中的可解释性，发现通过反思可以提升识别准确率，并揭示了模型如何将视觉特征映射为文本概念。


<details>
  <summary>Details</summary>
Motivation: 研究多模态模型中视觉反思的可解释性，探索如何通过语言模型提升视觉任务的性能。

Method: 采用视觉反思策略，分析视觉-语言连接器的作用，并测试训练无关的连接器对性能的影响。

Result: 实验表明，视觉反思能提升ImageNet等基准的识别准确率，模型主要依赖文本概念而非原始视觉特征。

Conclusion: 视觉反思是实现可解释和鲁棒视觉识别的新策略。

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [6] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

TL;DR: 提出了一种结合3D CNN和Transformer的混合框架，用于视频行为识别，优于单独使用3D CNN或Transformer。


<details>
  <summary>Details</summary>
Motivation: 传统3D CNN难以建模长距离依赖，而Transformer计算成本高，需结合两者优势。

Method: 3D CNN提取低级时空特征，Transformer捕获长距离时间依赖，通过融合机制整合两者。

Result: 在基准数据集上表现优于传统方法，识别精度更高且复杂度可控。

Conclusion: 混合框架为视频行为识别提供了高效且可扩展的解决方案。

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [7] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

TL;DR: RMT-PPAD是一种基于Transformer的实时多任务模型，用于对象检测、可行驶区域分割和车道线分割，通过轻量级模块和自适应解码器提升性能，并在BDD100K数据集上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要高精度和实时性的全景驾驶感知，因此研究团队提出了一种能够同时处理多个任务的模型。

Method: 采用Transformer架构，引入轻量级门控模块和自适应分割解码器，解决了任务间负迁移和标签不一致问题。

Result: 在BDD100K数据集上，对象检测mAP50为84.9%、召回率95.4%，可行驶区域分割mIoU为92.6%，车道线分割IoU为56.8%，推理速度32.6FPS。

Conclusion: RMT-PPAD在多任务感知中表现出色，且在实际场景中性能稳定，代码和预训练模型已开源。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [8] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

TL;DR: 本文提出了HOPE基准测试，通过生成误导性干扰项来更严格评估大视觉语言模型的幻觉问题，相比POPE基准测试效果更显著。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型取得了显著进展，但其仍存在对象幻觉问题。现有的POPE基准测试因简单的采样策略而效能下降，需要更严格的评估方法。

Method: 提出HOPE基准测试，利用内容感知幻觉搜索（基于CLIP）和描述性幻觉搜索，选择最具误导性的干扰项来评估模型幻觉问题。

Result: 实验表明，HOPE使多种先进LVLMs的精度下降9%至23%，显著优于POPE。

Conclusion: HOPE基准测试能更有效地暴露LVLMs的幻觉漏洞，为未来研究提供了更严格的评估工具。

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [9] [PP-Motion: Physical-Perceptual Fidelity Evaluation for Human Motion Generation](https://arxiv.org/abs/2508.08179)
*Sihan Zhao,Zixuan Wang,Tianyu Luan,Jia Jia,Wentao Zhu,Jiebo Luo,Junsong Yuan,Nan Xi*

Main category: cs.CV

TL;DR: 本文提出了一种用于评估人类动作生成真实性的新方法PP-Motion，结合物理标注和人类感知损失，同时考虑物理可行性和人类感知的真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的人类动作生成真实性评估方法存在主观性和物理可行性的差距，需要更客观和细致的评估标准。

Method: 通过物理标注方法计算动作的最小修改量以符合物理规律，并结合Pearson相关损失和人类感知损失训练PP-Motion指标。

Result: 实验结果表明，PP-Motion不仅在物理上更符合规律，而且在人类感知的真实性评估上优于以往方法。

Conclusion: PP-Motion为人类动作生成的评估提供了一种更全面、客观的解决方案。

Abstract: Human motion generation has found widespread applications in AR/VR, film,
sports, and medical rehabilitation, offering a cost-effective alternative to
traditional motion capture systems. However, evaluating the fidelity of such
generated motions is a crucial, multifaceted task. Although previous approaches
have attempted at motion fidelity evaluation using human perception or physical
constraints, there remains an inherent gap between human-perceived fidelity and
physical feasibility. Moreover, the subjective and coarse binary labeling of
human perception further undermines the development of a robust data-driven
metric. We address these issues by introducing a physical labeling method. This
method evaluates motion fidelity by calculating the minimum modifications
needed for a motion to align with physical laws. With this approach, we are
able to produce fine-grained, continuous physical alignment annotations that
serve as objective ground truth. With these annotations, we propose PP-Motion,
a novel data-driven metric to evaluate both physical and perceptual fidelity of
human motion. To effectively capture underlying physical priors, we employ
Pearson's correlation loss for the training of our metric. Additionally, by
incorporating a human-based perceptual fidelity loss, our metric can capture
fidelity that simultaneously considers both human perception and physical
alignment. Experimental results demonstrate that our metric, PP-Motion, not
only aligns with physical laws but also aligns better with human perception of
motion fidelity than previous work.

</details>


### [10] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

TL;DR: 论文研究了在稀疏信号条件下（如天文摄影）物体检测模型的性能，并使用智能手机拍摄的夜空数据集进行测试。


<details>
  <summary>Details</summary>
Motivation: 已有数据集（如ImageNet、COCO和PASCAL VOC）专注于日常物体，缺乏非商业领域的稀疏信号特征，因此需要研究模型在这些条件下的表现。

Method: 使用了MobilTelesco数据集（基于智能手机的天文摄影数据）对多个检测模型进行基准测试。

Result: 研究突出了在特征稀缺条件下物体检测模型面临的挑战。

Conclusion: 现有的物体检测模型在处理稀疏信号时存在局限性，需要进一步优化以适应此类场景。

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [11] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

TL;DR: 提出了一个高质量的多实例人类擦除数据集和Multi-Layer Diffusion（MILD）方法，通过分层生成和人类形态引导，显著提升了复杂场景中的人类擦除效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂多实例场景（如人物遮挡、背景干扰）中的局限性，主要由于数据稀缺和空间解耦不足。

Method: 引入MILD策略，将生成分解为语义分离的路径，并加入人类形态引导和空间调制注意力机制。

Result: 实验表明，MILD在具有挑战性的人类擦除基准测试中优于现有方法。

Conclusion: MILD通过分层生成和人类形态引导，有效解决了复杂场景中的人类擦除问题。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [12] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 该方法仅利用多视角RGB图像进行3D语义场景图估计，克服了深度图噪声和背景干扰，通过语义掩码和邻居关系增强特征，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在没有3D标注数据的情况下，仅依靠多视角RGB图像完成3D语义场景图估计任务，解决深度图噪声和背景特征干扰问题。

Method: 利用语义掩码指导特征聚合以减少背景噪声，设计新方法整合邻居节点信息，并基于训练统计先验优化节点和边预测。

Result: 实验表明，该方法在仅使用多视角图像作为输入时，性能优于现有方法。

Conclusion: 通过语义和空间信息增强节点和边特征，结合统计先验，提升了多视角图像场景图估计的准确性和鲁棒性。

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [13] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

TL;DR: NNObfuscator提出了一种动态调整AI模型性能的新方法，避免了传统多模型方案的资源浪费和维护难题。


<details>
  <summary>Details</summary>
Motivation: 当前DNNs训练和定制化成本高，传统多模型方案效率低下。

Method: 通过NNObfuscator机制，单模型可实时动态调整性能，支持分级访问。

Result: 实验验证了NNObfuscator在图像分类、语义分割等任务中的有效性。

Conclusion: NNObfuscator提高了模型适应性和资源利用率，支持可持续AI部署。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [14] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

TL;DR: 该论文通过构建一个年龄多样化的深度伪造数据集，减少了数据集中的年龄偏见，提升了检测模型的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测面临技术挑战和数据集中的年龄偏见问题，缺乏公平性。

Method: 通过整合现有数据集（Celeb-DF、FaceForensics++、UTKFace）并生成合成数据，构建了一个年龄多样化的数据集，并使用XceptionNet、EfficientNet和LipForensics模型评估其效果。

Result: 新数据集显著提升了模型在不同年龄组间的公平性、整体准确性和跨数据集的泛化能力。

Conclusion: 研究提供了一个可复现的公平性深度伪造数据集和模型流程，为未来公平检测研究奠定了基础。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [15] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提出了一种名为StaticEmbriedBench的静态场景评估基准，解决了现有基准成本高、分散且难以扩展的问题，支持42个场景和8个核心维度的评估，并首次建立了统一的静态排行榜。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准依赖交互式模拟环境或实际设置，成本高、分散且难以扩展，亟需更高效的评估方法。

Method: 引入StaticEmbriedBench，基于静态场景表示的统一评估框架，支持通过简单接口进行可扩展和全面的评估。

Result: 评估了19个VLM和11个VLA模型，建立了首个统一的静态排行榜，并发布了200个样本以加速研发。

Conclusion: StaticEmbriedBench提供了一种高效、可扩展的评估方法，推动了具身智能的发展。

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [16] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

TL;DR: StyleTailor是一个协同代理框架，将个性化服装设计、购物推荐、虚拟试穿和系统评估整合为统一工作流，通过多级负面反馈提升推荐质量。


<details>
  <summary>Details</summary>
Motivation: 个性化时尚造型解决方案尚未充分探索，但具有提升购物体验的巨大潜力。

Method: 提出StyleTailor框架，包含Designer和Consultant两个核心代理，通过分层视觉语言模型反馈和负面提示闭环机制迭代优化结果。

Result: 实验表明StyleTailor在个性化设计和推荐方面表现优异，超越无负面反馈的基线方法。

Conclusion: StyleTailor为智能时尚系统设立了新基准，展示了协同代理和负面反馈的有效性。

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [17] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

TL;DR: 论文提出了一个半自动化的标签错误修正框架REC$\checkmark$D，通过众包微任务验证和改进对象检测数据集中的标签错误。


<details>
  <summary>Details</summary>
Motivation: 对象检测数据集中的标签错误（如缺失标签、分类错误或定位不准确）会影响训练和评估结果，但目前缺乏系统性的大规模修正方法。

Method: REC$\checkmark$D结合现有错误检测器和众包微任务，让多个标注者独立验证候选框，并通过聚合反馈提高标签质量。

Result: 在KITTI数据集的“行人”类中，该方法发现至少24%的原始标注存在错误，并生成高质量修正标注作为新基准。

Conclusion: 当前错误检测方法结合REC$\checkmark$D可高效修正标签，但仍需更多研究以提升准确性，新发布的基准将推动相关研究。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [18] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

TL;DR: 提出了多模态特权知识蒸馏（MMPKD），利用训练时才有的多模态数据提升单模态视觉模型的性能；验证了其在特定领域的注意力图零样本能力提升，但效果不具备跨领域普适性。


<details>
  <summary>Details</summary>
Motivation: 临床实际应用中，多模态数据（如图像、文本、结构化数据）可能无法在推理时全部获取，如何利用训练时的多模态数据提升单模态模型性能是关键。

Method: 提出MMPKD训练策略，使用文本或表格元数据作为教师模型，在训练时指导单模态视觉Transformer学生模型。

Result: 在胸部X光片和乳腺X光片数据上，MMPKD提升了学生模型对感兴趣区域（ROI）的零样本定位能力，但此效果未跨领域泛化。

Conclusion: MMPKD在特定领域内有效，但需进一步研究跨领域普适性问题。

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [19] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

TL;DR: 本文提出了一种名为VEGA的新型视觉情感引导锚定机制，通过引入类级视觉语义和改进多模态对齐，显著提升了对话中多模态情感识别的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在情感识别中缺乏心理学有意义先验的问题，利用CLIP的图像编码器构建情感特定视觉锚点，提升多模态对齐效果。

Method: 采用VEGA机制，通过面部样本构建情感特定视觉锚点，结合随机锚点采样策略和自蒸馏的双分支架构。

Result: 在IEMOCAP和MELD数据集上实现了最优性能。

Conclusion: VEGA机制在多模态情感识别中表现优异，为心理学理论与深度学习结合提供了新思路。

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [20] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的框架，将大脑连接组与临床报告在多模态潜在空间中对齐，以增强表征学习，特别适用于脑疾病研究。


<details>
  <summary>Details</summary>
Motivation: 结合大脑影像数据和临床报告，可以更有效地利用多模态信息进行及时诊断，但目前如何将客观影像数据与主观文本报告有效关联仍是一个挑战。

Method: 通过将大脑子网络视为影像数据的标记而非原始图像块，与临床报告中的单词标记对齐，从而在主体和连接组级别的共享潜在空间中进行表征学习。

Result: 应用于轻度认知障碍（MCI）的ADNI数据集时，该方法不仅实现了最先进的预测性能，还发现了具有临床意义的连接组-文本对。

Conclusion: 该方法为阿尔茨海默病的早期机制提供了新见解，并支持开发临床有用的多模态生物标志物。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [21] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的Surformer v1架构，用于结合触觉和视觉输入进行表面材料分类，展示了其在准确性和计算效率上的优越性。


<details>
  <summary>Details</summary>
Motivation: 表面材料识别在机器人感知和物理交互中至关重要，尤其是结合触觉和视觉输入时。现有深度学习方法在视觉任务中表现出色，但触觉信息的整合仍有待探索。

Method: 设计了Surformer v1，结合结构化触觉特征和ResNet-50提取的视觉嵌入；先评估触觉分类模型，再扩展为多模态融合实验，对比特征基与图像基方法。

Result: Surformer v1达到99.4%准确率，推理时间仅0.77毫秒；多模态CNN准确率略高但耗时显著增加。

Conclusion: Surformer v1在准确性、效率和计算成本间实现了优异平衡，适合实时表面材料识别。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [22] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出了一种新的视频数据集ImpliHateVid，用于隐式仇恨言论检测，并设计了一个两阶段对比学习框架进行视频中的仇恨言论检测。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在文本和图像领域的仇恨言论检测，视频领域的研究较少，尤其是隐式仇恨言论的检测更是缺乏。

Method: 1. 构建了ImpliHateVid数据集，包含2009个视频。2. 提出了两阶段对比学习框架，第一阶段训练模态特定编码器，第二阶段训练跨模态编码器，并结合情感、情绪和字幕特征提升检测性能。

Result: 在ImpliHateVid和HateMM数据集上验证了方法的有效性，证明了多模态对比学习在视频仇恨内容检测中的优势。

Conclusion: 该研究填补了视频领域隐式仇恨言论检测的空白，提出的数据集和方法为未来研究提供了重要基础。

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [23] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: 文章提出了ContextGuard-LVLM，一个新框架，用于解决细粒度跨模态上下文一致性问题，通过结合高级视觉-语言大模型和多阶段推理机制，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体的普及需要验证内容真实性的方法，特别是视觉和文本信息的一致性。传统方法无法解决细粒度的跨模态上下文一致性问题。

Method: 利用高级视觉-语言大模型（LVLMs）和多阶段推理机制，通过强化或对抗学习增强模型能力，检测细粒度的上下文不一致。

Result: ContextGuard-LVLM在实验中对细粒度一致性任务表现优异，优于零样本基线（如InstructBLIP和LLaVA 1.5），并在复杂逻辑推理和上下文理解上有显著提升。

Conclusion: 模型在检测复杂上下文分离方面表现出高效性和鲁棒性，并与人类专家判断高度一致。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [24] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

TL;DR: VL-MedGuide利用视觉-语言大模型，通过多模态理解和推理能力提供可解释的皮肤病辅助诊断，性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病诊断中复杂视觉特征和现有模型不可解释性的问题。

Method: 采用多模态概念感知模块和可解释疾病推理模块，结合提示工程和链式思维推理。

Result: 在Derm7pt数据集上，诊断和概念检测性能均达到最优，且生成解释获高评价。

Conclusion: VL-MedGuide为皮肤病实践提供了可操作且可解释的AI辅助工具。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [25] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的跨域图像翻译方法，通过联合学习框架将扩散和翻译过程对齐，提升了全局最优性和生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有GAN方法在跨域图像翻译中表现不足，而扩散模型虽然能更好地建模数据分布，但如何将翻译过程与扩散过程对齐仍然是一个挑战。本文旨在解决这一问题。

Method: 提出了一种新颖的联合学习框架，通过从扩散模型中提取图像组件表示干净信号，并结合时间依赖的翻译网络，实现了端到端的联合优化。

Result: 在多种跨域翻译任务（如RGB↔RGB、RGB↔语义分割等）中，该方法展现了优于现有技术的生成性能。

Conclusion: 通过联合学习框架，本文方法在跨域图像翻译中取得了更高的全局最优性，提升了保真度和结构一致性。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [26] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

TL;DR: 本文提出了一种基于动态系数分解的神经渲染框架，以改进视点依赖外观的建模。通过分解复杂外观为静态神经基和动态系数，实验表明其能产生更清晰的镜面高光。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂镜面反射时可能会出现模糊或优化不稳定的问题，因此需要一种更有效的方式建模视点依赖外观。

Method: 采用动态系数分解，将外观分解为静态神经基和动态系数，并通过动态辐射积分器合成最终辐射。

Result: 在多个挑战性基准测试中，该方法能够生成比现有技术更清晰和真实的镜面高光。

Conclusion: 该分解范式为神经场景表示中复杂外观的建模提供了灵活有效的方向。

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [27] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

TL;DR: CausalNet 是一个新颖的框架，通过输入完整的微表情序列来应对关键帧索引错误，同时保持识别准确性。通过 CMPLM 和 CAB 模块，它减少了冗余信息并学习肌肉运动的因果关系。


<details>
  <summary>Details</summary>
Motivation: 解决现有关键帧方法依赖准确关键帧索引的问题，提高微表情识别在关键帧索引错误下的鲁棒性。

Method: 提出 CausalNet 框架，包含 CMPLM 模块和 CAB 模块，前者帮助定位肌肉运动区域，后者学习肌肉运动的因果关系。

Result: CausalNet 在不同关键帧索引噪声水平下表现鲁棒，并在多个标准基准上超过现有方法。

Conclusion: CausalNet 为微表情识别提供了鲁棒且高效的解决方案，适用于实际应用。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [28] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

TL;DR: 论文提出了两种新型的水印方法，用于自回归图像模型中检测和归属生成内容，通过视觉标记聚类提高水印的鲁棒性和可检测性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索自回归图像模型中内嵌水印的可行性，因为先前的水印技术主要关注潜在扩散模型，而自回归模型的水印效果尚未被研究。

Method: 方法包括两种基于视觉标记聚类的水印方案：1) 无训练的聚类查找表方法；2) 通过微调VAE编码器直接预测聚类。这些方法通过将相似标记分配到同一集合中，提升水印的鲁棒性。

Result: 实验表明，聚类级别的水印显著提高了对图像扰动和再生攻击的鲁棒性，同时保持图像质量。聚类分类进一步提高了水印的可检测性，优于基线方法。

Conclusion: 结论表明，提出的聚类水印方法在自回归模型中有效，且验证速度快，适合实际应用。

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [29] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

TL;DR: 论文提出使用线描作为预训练模态，以提高视觉表示的数据效率和泛化能力，实验表明线描预训练模型在分类、检测和分割任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现代视觉系统依赖于丰富的视觉输入，而人类能够轻松理解稀疏的线描。研究认为结构而非外观是高效视觉理解的基础，因此探索线描是否可以作为更紧凑的预训练方式。

Method: 通过线描预训练模型，并评估其在分类、检测和分割任务中的表现。同时提出无监督学习方法“学习绘图”。

Result: 线描预训练模型表现出更强的形状偏置、注意力集中度和数据效率，且具有更低的内在维度。知识蒸馏效果也优于传统方法。

Conclusion: 结构优先的视觉学习能提升效率和泛化能力，提供了一种简单但强大的视觉系统构建策略。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [30] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: MMFformer是一种多模态抑郁症检测网络，通过社交媒体信息提取时空特征，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症早期检测困难，社交媒体的多样性数据提供了研究机会。

Method: 使用Transformer网络提取视频空间特征和音频时间动态，采用晚期和中期融合策略整合多模态信息。

Result: 在D-Vlog和LMVD数据集上F1-Score分别提升13.92%和7.74%。

Conclusion: MMFformer在多模态抑郁症检测中表现优异，代码已开源。

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [31] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

TL;DR: 提出了一种高效快速的三维数据生成全息图的框架，通过优化算法和2D中值滤波提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用点云和MRI数据快速生成高质量的全息图。

Method: 将输入数据重建为体积对象，通过交替投影、SGD和拟牛顿方法优化生成相位全息图和复杂全息图。

Result: 优化算法与深度学习HoloNet相比，结合2D中值滤波减少了伪影和噪声，提升了性能指标（MSE、RMSE、PSNR）。

Conclusion: 提出的框架和优化方法在计算机生成全息图中表现优异，尤其通过滤波进一步提升了重建质量。

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [32] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: Restage4D提出了一种利用真实视频运动先验来生成物理一致的4D内容的管道，通过视频重放训练策略和几何一致性损失，提升了4D场景合成的质量和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像或图像到视频生成模型难以捕捉真实物理运动和动态，而真实视频可为4D场景合成提供物理基础和运动线索。

Method: Restage4D采用视频重放训练策略，结合遮挡感知的刚性损失和遮挡回溯机制，通过共享运动表征桥接真实基视频与合成驱动视频。

Result: 在DAVIS和PointOdyssey数据集上验证，Restage4D在几何一致性、运动质量和3D跟踪性能上优于原有方法。

Conclusion: Restage4D不仅能在新运动中保持可变形结构，还能自动纠正生成模型的错误，展示了视频先验在4D重构任务中的潜力。

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [33] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

TL;DR: 提出FoundBioNet模型，利用SWIN-UNETR架构和两个关键模块（TAFE和CMD），通过多参数MRI非侵入性预测IDH突变状态，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖侵入性组织采样，无法捕捉肿瘤空间异质性，且深度学习模型受限于标注数据稀缺。

Method: 采用SWIN-UNETR架构，结合TAFE提取多尺度肿瘤特征，CMD突出T2-FLAIR不匹配信号，训练于1705名患者的多中心数据。

Result: 在多个测试集上AUC达90.58%至80.31%，显著优于基线方法，TAFE和CMD模块对提升准确性至关重要。

Conclusion: FoundBioNet结合大规模预训练和任务微调，提高诊断准确性和可解释性，有望个性化患者护理。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [34] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: 提出了一种新的视频基准数据集VOccl3D，用于解决真实世界中复杂遮挡环境下的人体姿态和形状估计问题，并展示了在该数据集上微调的HPS方法的显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的人体姿态和形状估计方法在复杂姿态或被遮挡场景中表现不佳，且现有数据集缺乏真实的遮挡情景，因此需要构建更具现实性的遮挡数据集。

Method: 利用先进的计算机图形渲染技术构建VOccl3D数据集，包含多样化的真实遮挡场景。并微调了CLIFF和BEDLAM-CLIFF等方法，提升了性能。

Result: 在多个公共数据集及VOccl3D测试集上，微调后的方法显著优于现有技术。同时，还提升了遮挡环境下的人体检测性能。

Conclusion: VOccl3D为遮挡环境下的HPS研究提供了有价值的基准，并推动了相关技术的进步。

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [35] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG是一种新型多模态大语言模型框架，专注于交通场景的细粒度理解，支持像素级分割与时间事件定位。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在交通场景中缺乏细粒度视觉细节与局部组件理解能力，限制了复杂事故场景的应用。

Method: 提出SafePLUG框架，支持区域感知问答、像素级分割及时间事件锚定，并构建了新数据集。

Result: 实验证明SafePLUG在区域问答、像素分割、时间定位等任务中表现优异。

Conclusion: SafePLUG为复杂交通场景的细粒度理解奠定基础，有望提升智能交通系统的安全性与情境感知能力。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [36] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: DiffUS是一个基于物理的可微分超声渲染器，通过机器学习将MRI 3D扫描转换为声阻抗体积，并模拟超声波束传播，生成真实的B型图像，用于术中引导和术前规划。


<details>
  <summary>Details</summary>
Motivation: 为解决术中超声图像的噪声、伪影以及与术前MRI/CT配准困难的问题，提出DiffUS以提供更准确的术中引导。

Method: 1. 通过机器学习将MRI 3D扫描转换为声阻抗体积；2. 使用射线追踪模拟超声波传播；3. 通过稀疏线性系统模拟多次反射；4. 结合B型图像重建。

Result: 在ReMIND数据集上验证了DiffUS能够从脑MRI数据生成解剖学准确的超声图像。

Conclusion: DiffUS是一种有效的工具，可通过梯度优化支持切片-体积配准和体积重建等下游应用。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [37] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

TL;DR: 本文提出了一种针对医学图像的精确边缘检测方法，通过改进卷积网络架构，显著提升了器官边界的定位精度，并在多种医学任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像中对器官边界的精确定位至关重要，但现有深度卷积网络的边缘检测方法在定位精度上存在不足，无法满足毫米级精度的医学需求。

Method: 采用一种自上而下的反向细化架构，通过逐步上采样并融合高层语义特征与低层细节信息，生成高分辨率的器官边界，同时扩展到各向异性体积数据。

Result: 在CT和MRI数据集上的实验表明，该方法显著提升了边界定位精度（边界F-measure、Hausdorff距离），并在器官分割、图像配准等下游任务中带来一致改进。

Conclusion: 该方法生成的清晰器官边缘对医学成像任务具有重要临床价值，可用于提升分割精度和病灶定位准确性。

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [38] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 论文提出了一种基于ResNet的双分辨率架构，用于黑色素瘤病变的精确分割，通过结合高分辨率边界信息和多尺度上下文线索，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤病变的精确分割对于皮肤癌自动筛查和临床决策支持至关重要，但现有方法难以处理细微的纹理变化和影像伪影。

Method: 采用双分辨率架构，包含一个全分辨率流和一个池化流，通过边界感知残差连接和通道注意力模块增强分割效果，并结合轻量级伪影抑制块和多任务训练目标。

Result: 在公共数据集上，该方法显著提升了边界贴合度和临床相关分割指标，优于标准编码器-解码器基线模型。

Conclusion: 该方法为黑色素瘤自动评估系统提供了一种高效且实用的解决方案。

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [39] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: 提出了一种弱监督训练框架，用于皮下血管分割，利用稀疏标注生成密集监督，结合图像特征和连续先验，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决皮下血管分割中标注稀缺、噪声多及低对比度的问题。

Method: 使用随机游走标签传播模型扩增稀疏标注为密集监督，结合CNN分割预测器和拓扑正则化器。

Result: 在临床数据集上表现优于传统方法，生成更完整的血管图和校准的不确定性。

Conclusion: 显著减少标注负担，保持血管拓扑结构，适用于临床决策。

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [40] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

TL;DR: SAGE-reID是一种高效的无源多源域自适应方法，通过源特定低秩适配器和轻量级门控网络动态融合知识，提升行人重识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有MSDA方法需要访问源域数据或学习特定域的主干模型，导致训练参数和计算成本显著增加。SAGE-reID旨在解决这一问题。

Method: 先训练源特定低秩适配器（LoRA），再通过轻量级门控网络动态分配权重融合LoRA专家，实现跨域知识迁移。

Result: 在Market-1501、DukeMTMC-reID和MSMT17基准测试中，SAGE-reID优于现有方法且计算高效。

Conclusion: SAGE-reID显著减少了内存消耗和过拟合风险，同时提升了行人重识别的准确性和效率。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


### [41] [Hybrid Machine Learning Framework for Predicting Geometric Deviations from 3D Surface Metrology](https://arxiv.org/abs/2508.06845)
*Hamidreza Samadi,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.CV

TL;DR: 该研究提出一种结合3D扫描和混合机器学习框架的方法，用于预测制造部件的几何偏差，精度提升显著。


<details>
  <summary>Details</summary>
Motivation: 现代制造中复杂几何形状的尺寸精度难以保持，需改进预测方法。

Method: 使用高分辨率3D扫描器采集多角度数据，通过精确对齐、降噪和合并处理，再结合卷积神经网络和梯度提升决策树进行建模。

Result: 预测精度达0.012 mm（95%置信水平），较传统方法提升73%，并揭示制造参数与几何偏差的隐藏相关性。

Conclusion: 该方法适用于自动化质量控制、预测性维护和设计优化，数据集为未来研究奠定基础。

Abstract: This study addresses the challenge of accurately forecasting geometric
deviations in manufactured components using advanced 3D surface analysis.
Despite progress in modern manufacturing, maintaining dimensional precision
remains difficult, particularly for complex geometries. We present a
methodology that employs a high-resolution 3D scanner to acquire multi-angle
surface data from 237 components produced across different batches. The data
were processed through precise alignment, noise reduction, and merging
techniques to generate accurate 3D representations. A hybrid machine learning
framework was developed, combining convolutional neural networks for feature
extraction with gradient-boosted decision trees for predictive modeling. The
proposed system achieved a prediction accuracy of 0.012 mm at a 95% confidence
level, representing a 73% improvement over conventional statistical process
control methods. In addition to improved accuracy, the model revealed hidden
correlations between manufacturing parameters and geometric deviations. This
approach offers significant potential for automated quality control, predictive
maintenance, and design optimization in precision manufacturing, and the
resulting dataset provides a strong foundation for future predictive modeling
research.

</details>


### [42] [AGIC: Attention-Guided Image Captioning to Improve Caption Relevance](https://arxiv.org/abs/2508.06853)
*L. D. M. S. Sai Teja,Ashok Urlana,Pruthwik Mishra*

Main category: cs.CV

TL;DR: AGIC是一种基于注意力引导的图像描述生成方法，通过特征空间中的显著区域增强和混合解码策略，提升了描述准确性与多样性，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决图像描述生成中准确性和描述性不足的问题，提出更高效且可解释的解决方案。

Method: 采用注意力机制增强显著视觉区域特征，结合确定性与概率性采样的混合解码策略。

Result: 在Flickr8k和Flickr30k数据集上表现优异，推理速度更快，且在多指标评估中表现突出。

Conclusion: AGIC为图像描述任务提供了可扩展且可解释的高效解决方案。

Abstract: Despite significant progress in image captioning, generating accurate and
descriptive captions remains a long-standing challenge. In this study, we
propose Attention-Guided Image Captioning (AGIC), which amplifies salient
visual regions directly in the feature space to guide caption generation. We
further introduce a hybrid decoding strategy that combines deterministic and
probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we
conduct extensive experiments on the Flickr8k and Flickr30k datasets. The
results show that AGIC matches or surpasses several state-of-the-art models
while achieving faster inference. Moreover, AGIC demonstrates strong
performance across multiple evaluation metrics, offering a scalable and
interpretable solution for image captioning.

</details>


### [43] [A Joint Sparse Self-Representation Learning Method for Multiview Clustering](https://arxiv.org/abs/2508.06857)
*Mengxue Jia,Zhihua Allen-Zhao,You Zhao,Sanyang Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种新的联合稀疏自表示学习模型，用于多视图聚类，通过引入基数约束提取视图特定局部信息，并开发了一种具有全局收敛性的交替二次惩罚方法。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类（MC）的目标是利用不同视图间一致和互补的信息对样本进行分组。子空间聚类作为MC的基础技术，需要更好地提取局部和全局信息，同时解决现有方法收敛性和泛化能力不足的问题。

Method: 提出了一种联合稀疏自表示学习模型，通过基数约束提取视图特定的局部信息，并使用低秩约束在合并阶段揭示全局一致结构。为了解决非凸非光滑模型的收敛问题，开发了一种交替二次惩罚（AQP）方法。

Result: 在六个标准数据集上的实验结果表明，所提出的模型和AQP方法优于八种现有最先进算法。

Conclusion: 该模型通过基数约束和低秩约束有效提取了多视图的局部和全局结构信息，AQP方法解决了收敛性问题，表现优越。

Abstract: Multiview clustering (MC) aims to group samples using consistent and
complementary information across various views. The subspace clustering, as a
fundamental technique of MC, has attracted significant attention. In this
paper, we propose a novel joint sparse self-representation learning model for
MC, where a featured difference is the extraction of view-specific local
information by introducing cardinality (i.e., $\ell_0$-norm) constraints
instead of Graph-Laplacian regularization. Specifically, under each view,
cardinality constraints directly restrict the samples used in the
self-representation stage to extract reliable local and global structure
information, while the low-rank constraint aids in revealing a global coherent
structure in the consensus affinity matrix during merging. The attendant
challenge is that Augmented Lagrange Method (ALM)-based alternating
minimization algorithms cannot guarantee convergence when applied directly to
our nonconvex, nonsmooth model, thus resulting in poor generalization ability.
To address it, we develop an alternating quadratic penalty (AQP) method with
global convergence, where two subproblems are iteratively solved by closed-form
solutions. Empirical results on six standard datasets demonstrate the
superiority of our model and AQP method, compared to eight state-of-the-art
algorithms.

</details>


### [44] [VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding](https://arxiv.org/abs/2508.06869)
*Jianxiang He,Shaoguang Wang,Weiyu Guo,Meisheng Hong,Jungang Li,Yijie Xu,Ziyang Chen,Hui Xiong*

Main category: cs.CV

TL;DR: 论文提出了一种名为VSI的多模态关键帧搜索方法，通过整合字幕、时间戳和场景边界信息，显著提升了长视频理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 长视频理解因数据规模巨大而具有挑战性，现有的关键帧检索方法因多模态对齐弱和无法捕捉复杂的时间语义信息而效果不佳。

Method: 提出VSI方法，通过双流搜索机制（视频搜索流和字幕匹配流）整合视觉和文本信息，提升关键帧搜索精度。

Result: VSI在LongVideoBench的关键帧定位准确性达到40.00%，下游长视频问答任务中达到68.48%，显著优于基线方法。

Conclusion: VSI在中长视频问答任务中达到了SOTA性能，证明了其多模态搜索策略的鲁棒性和泛化能力。

Abstract: Long video understanding presents a significant challenge to multimodal large
language models (MLLMs) primarily due to the immense data scale. A critical and
widely adopted strategy for making this task computationally tractable is
keyframe retrieval, which seeks to identify a sparse set of video frames that
are most salient to a given textual query. However, the efficacy of this
approach is hindered by weak multimodal alignment between textual queries and
visual content and fails to capture the complex temporal semantic information
required for precise reasoning. To address this, we propose Visual-Subtitle
Integeration(VSI), a multimodal keyframe search method that integrates
subtitles, timestamps, and scene boundaries into a unified multimodal search
process. The proposed method captures the visual information of video frames as
well as the complementary textual information through a dual-stream search
mechanism by Video Search Stream as well as Subtitle Match Stream,
respectively, and improves the keyframe search accuracy through the interaction
of the two search streams. Experimental results show that VSI achieve 40.00%
key frame localization accuracy on the text-relevant subset of LongVideoBench
and 68.48% accuracy on downstream long Video-QA tasks, surpassing competitive
baselines by 20.35% and 15.79%, respectively. Furthermore, on the
LongVideoBench, VSI achieved state-of-the-art(SOTA) in medium-to-long video-QA
tasks, demonstrating the robustness and generalizability of the proposed
multimodal search strategy.

</details>


### [45] [NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective](https://arxiv.org/abs/2508.06878)
*Maoxun Yuan,Duanni Meng,Ziteng Xi,Tianyi Zhao,Shiji Zhao,Yimian Dai,Xingxing Wei*

Main category: cs.CV

TL;DR: 提出了一种新的噪声抑制特征金字塔网络（NS-FPN），通过低频引导特征净化（LFP）模块和螺旋感知特征采样（SFS）模块，有效抑制噪声并提升红外小目标检测与分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法虽能感知目标，但仅通过增强特征表示来抵消噪声影响，导致误报率上升。本文从频域分析出发，提出从噪声抑制角度提升性能。

Method: NS-FPN结合了LFP模块（通过净化高频成分抑制噪声）和SFS模块（螺旋采样融合目标相关特征），设计轻量且易于集成到现有框架。

Result: 在公开数据集上，NS-FPN显著减少误报，性能优于现有方法。

Conclusion: 从噪声抑制角度出发的NS-FPN有效提升了红外小目标检测与分割任务的性能，且易于部署。

Abstract: Infrared small target detection and segmentation (IRSTDS) is a critical yet
challenging task in defense and civilian applications, owing to the dim,
shapeless appearance of targets and severe background clutter. Recent CNN-based
methods have achieved promising target perception results, but they only focus
on enhancing feature representation to offset the impact of noise, which
results in the increased false alarms problem. In this paper, through analyzing
the problem from the frequency domain, we pioneer in improving performance from
noise suppression perspective and propose a novel noise-suppression feature
pyramid network (NS-FPN), which integrates a low-frequency guided feature
purification (LFP) module and a spiral-aware feature sampling (SFS) module into
the original FPN structure. The LFP module suppresses the noise features by
purifying high-frequency components to achieve feature enhancement devoid of
noise interference, while the SFS module further adopts spiral sampling to fuse
target-relevant features in feature fusion process. Our NS-FPN is designed to
be lightweight yet effective and can be easily plugged into existing IRSTDS
frameworks. Extensive experiments on the public IRSTDS datasets demonstrate
that our method significantly reduces false alarms and achieves superior
performance on IRSTDS tasks.

</details>


### [46] [BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models](https://arxiv.org/abs/2508.06895)
*Jianting Tang,Yubo Wang,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: 论文提出了一种名为BASIC的方法，通过直接对视觉嵌入进行监督，优化多模态大语言模型（MLLMs）的视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型在视觉理解上存在视觉嵌入与文本模态之间的鸿沟，现有的对齐方法仅关注文本输出的自回归监督，忽视了视觉嵌入的直接监督。

Method: BASIC方法利用大语言模型浅层中的精细视觉嵌入作为监督，直接从两个角度指导投影器生成初始视觉嵌入：优化嵌入方向和提高语义匹配。

Result: BASIC显著提升了MLLMs在多个基准测试中的表现，证明了直接视觉监督的有效性。

Conclusion: 通过引入直接视觉监督，BASIC解决了视觉嵌入的细粒度对齐问题，为MLLMs的视觉理解提供了新的解决方案。

Abstract: Mainstream Multimodal Large Language Models (MLLMs) achieve visual
understanding by using a vision projector to bridge well-pretrained vision
encoders and large language models (LLMs). The inherent gap between visual and
textual modalities makes the embeddings from the vision projector critical for
visual comprehension. However, current alignment approaches treat visual
embeddings as contextual cues and merely apply auto-regressive supervision to
textual outputs, neglecting the necessity of introducing equivalent direct
visual supervision, which hinders the potential finer alignment of visual
embeddings. In this paper, based on our analysis of the refinement process of
visual embeddings in the LLM's shallow layers, we propose BASIC, a method that
utilizes refined visual embeddings within the LLM as supervision to directly
guide the projector in generating initial visual embeddings. Specifically, the
guidance is conducted from two perspectives: (i) optimizing embedding
directions by reducing angles between initial and supervisory embeddings in
semantic space; (ii) improving semantic matching by minimizing disparities
between the logit distributions of both visual embeddings. Without additional
supervisory models or artificial annotations, BASIC significantly improves the
performance of MLLMs across a wide range of benchmarks, demonstrating the
effectiveness of our introduced direct visual supervision.

</details>


### [47] [Advancements in Chinese font generation since deep learning era: A survey](https://arxiv.org/abs/2508.06900)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

TL;DR: 该论文综述了基于深度学习的汉字字体生成方法，分为多参考样本和少参考样本两类，详细讨论了代表性方法的优缺点，并展望了未来方向。


<details>
  <summary>Details</summary>
Motivation: 汉字字体生成是一个备受关注的领域，但生成字符图像质量的提升仍是难题，本文旨在系统梳理深度学习在该领域的应用。

Method: 论文首先介绍研究背景和文献选择方法，随后分类回顾多参考样本和少参考样本生成方法，分析其优缺点。

Result: 总结了现有方法的代表性技术和局限，为研究人员提供了清晰的领域现状和未来发展方向。

Conclusion: 论文指出了该领域的挑战和未来方向，希望为研究者提供有价值的启发。

Abstract: Chinese font generation aims to create a new Chinese font library based on
some reference samples. It is a topic of great concern to many font designers
and typographers. Over the past years, with the rapid development of deep
learning algorithms, various new techniques have achieved flourishing and
thriving progress. Nevertheless, how to improve the overall quality of
generated Chinese character images remains a tough issue. In this paper, we
conduct a holistic survey of the recent Chinese font generation approaches
based on deep learning. To be specific, we first illustrate the research
background of the task. Then, we outline our literature selection and analysis
methodology, and review a series of related fundamentals, including classical
deep learning architectures, font representation formats, public datasets, and
frequently-used evaluation metrics. After that, relying on the number of
reference samples required to generate a new font, we categorize the existing
methods into two major groups: many-shot font generation and few-shot font
generation methods. Within each category, representative approaches are
summarized, and their strengths and limitations are also discussed in detail.
Finally, we conclude our paper with the challenges and future directions, with
the expectation to provide some valuable illuminations for the researchers in
this field.

</details>


### [48] [eMotions: A Large-Scale Dataset and Audio-Visual Fusion Network for Emotion Analysis in Short-form Videos](https://arxiv.org/abs/2508.06902)
*Xuecheng Wu,Dingkang Yang,Danlei Huang,Xinyi Yin,Yifan Wang,Jia Zhang,Jiayu Nie,Liangyu Fu,Yang Liu,Junxiao Xue,Hadi Amirpour,Wei Zhou*

Main category: cs.CV

TL;DR: 论文提出了eMotions数据集和AV-CANet方法，用于解决短视频情绪分析的挑战，并通过实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 短视频的复杂性和多样性给情绪分析带来挑战，缺乏大规模标注数据集。

Method: 提出了多阶段标注流程和AV-CANet网络，结合视频Transformer和局部-全局融合模块。

Result: 在多个数据集上验证了AV-CANet的有效性，并进行了消融实验。

Conclusion: 研究为短视频情绪分析提供了新方法和数据集，具有广泛的应用前景。

Abstract: Short-form videos (SVs) have become a vital part of our online routine for
acquiring and sharing information. Their multimodal complexity poses new
challenges for video analysis, highlighting the need for video emotion analysis
(VEA) within the community. Given the limited availability of SVs emotion data,
we introduce eMotions, a large-scale dataset consisting of 27,996 videos with
full-scale annotations. To ensure quality and reduce subjective bias, we
emphasize better personnel allocation and propose a multi-stage annotation
procedure. Additionally, we provide the category-balanced and test-oriented
variants through targeted sampling to meet diverse needs. While there have been
significant studies on videos with clear emotional cues (e.g., facial
expressions), analyzing emotions in SVs remains a challenging task. The
challenge arises from the broader content diversity, which introduces more
distinct semantic gaps and complicates the representations learning of
emotion-related features. Furthermore, the prevalence of audio-visual
co-expressions in SVs leads to the local biases and collective information gaps
caused by the inconsistencies in emotional expressions. To tackle this, we
propose AV-CANet, an end-to-end audio-visual fusion network that leverages
video transformer to capture semantically relevant representations. We further
introduce the Local-Global Fusion Module designed to progressively capture the
correlations of audio-visual features. Besides, EP-CE Loss is constructed to
globally steer optimizations with tripolar penalties. Extensive experiments
across three eMotions-related datasets and four public VEA datasets demonstrate
the effectiveness of our proposed AV-CANet, while providing broad insights for
future research. Moreover, we conduct ablation studies to examine the critical
components of our method. Dataset and code will be made available at Github.

</details>


### [49] [A Simple yet Powerful Instance-Aware Prompting Framework for Training-free Camouflaged Object Segmentation](https://arxiv.org/abs/2508.06904)
*Chao Yin,Jide Li,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出IAPF框架，通过多模态大语言模型生成实例级掩模，显著提升训练无关的伪装目标分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练无关COS方法因生成语义级视觉提示而无法有效处理多离散伪装实例。

Method: IAPF三步框架：文本提示生成、实例掩模生成（结合Grounding DINO和点提示采样）及自一致掩模投票。

Result: 在标准COS基准测试中，IAPF显著优于现有训练无关方法。

Conclusion: IAPF通过实例级提示，有效解决多离散伪装实例场景，为训练无关COS提供新思路。

Abstract: Camouflaged Object Segmentation (COS) remains highly challenging due to the
intrinsic visual similarity between target objects and their surroundings.
While training-based COS methods achieve good performance, their performance
degrades rapidly with increased annotation sparsity. To circumvent this
limitation, recent studies have explored training-free COS methods, leveraging
the Segment Anything Model (SAM) by automatically generating visual prompts
from a single task-generic prompt (\textit{e.g.}, "\textit{camouflaged
animal}") uniformly applied across all test images. However, these methods
typically produce only semantic-level visual prompts, causing SAM to output
coarse semantic masks and thus failing to handle scenarios with multiple
discrete camouflaged instances effectively. To address this critical
limitation, we propose a simple yet powerful \textbf{I}nstance-\textbf{A}ware
\textbf{P}rompting \textbf{F}ramework (IAPF), the first training-free COS
pipeline that explicitly converts a task-generic prompt into fine-grained
instance masks. Specifically, the IAPF comprises three steps: (1) Text Prompt
Generator, utilizing task-generic queries to prompt a Multimodal Large Language
Model (MLLM) for generating image-specific foreground and background tags; (2)
\textbf{Instance Mask Generator}, leveraging Grounding DINO to produce precise
instance-level bounding box prompts, alongside the proposed Single-Foreground
Multi-Background Prompting strategy to sample region-constrained point prompts
within each box, enabling SAM to yield a candidate instance mask; (3)
Self-consistency Instance Mask Voting, which selects the final COS prediction
by identifying the candidate mask most consistent across multiple candidate
instance masks. Extensive evaluations on standard COS benchmarks demonstrate
that the proposed IAPF significantly surpasses existing state-of-the-art
training-free COS methods.

</details>


### [50] [MultiRef: Controllable Image Generation with Multiple Visual References](https://arxiv.org/abs/2508.06905)
*Ruoxi Chen,Dongping Chen,Siyuan Wu,Sinan Wang,Shiyun Lang,Petr Sushko,Gaoyang Jiang,Yao Wan,Ranjay Krishna*

Main category: cs.CV

TL;DR: 该论文提出了一种多视觉参考的图像生成评估框架MultiRef-bench，揭示了当前先进模型在多参考条件下的局限性。


<details>
  <summary>Details</summary>
Motivation: 视觉设计通常需要从多个参考资料中获取灵感，而现有图像生成框架多依赖单一输入，限制了创作的灵活性。

Method: 构建了包含1,990个样本的评估框架MultiRef-bench，并通过RefBlend生成了38k高质量图像数据集MultiRef。

Result: 实验显示，最佳模型OmniGen在合成和真实样本中的表现仅为66.6%和79.0%，远未达到理想状态。

Conclusion: 研究为开发更灵活、能够整合多源视觉灵感的创作工具提供了方向和数据集支持。

Abstract: Visual designers naturally draw inspiration from multiple visual references,
combining diverse elements and aesthetic principles to create artwork. However,
current image generative frameworks predominantly rely on single-source inputs
-- either text prompts or individual reference images. In this paper, we focus
on the task of controllable image generation using multiple visual references.
We introduce MultiRef-bench, a rigorous evaluation framework comprising 990
synthetic and 1,000 real-world samples that require incorporating visual
content from multiple reference images. The synthetic samples are synthetically
generated through our data engine RefBlend, with 10 reference types and 33
reference combinations. Based on RefBlend, we further construct a dataset
MultiRef containing 38k high-quality images to facilitate further research. Our
experiments across three interleaved image-text models (i.e., OmniGen, ACE, and
Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that
even state-of-the-art systems struggle with multi-reference conditioning, with
the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in
real-world cases on average compared to the golden answer. These findings
provide valuable directions for developing more flexible and human-like
creative tools that can effectively integrate multiple sources of visual
inspiration. The dataset is publicly available at: https://multiref.github.io/.

</details>


### [51] [MMReID-Bench: Unleashing the Power of MLLMs for Effective and Versatile Person Re-identification](https://arxiv.org/abs/2508.06908)
*Jinhao Li,Zijian Chen,Lirong Deng,Changbo Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文针对传统人物再识别模型在多模态数据中泛化能力不足的问题，提出首个多任务多模态基准MMReID-Bench，并展示了多模态大语言模型（MLLMs）在人物再识别任务中的潜力与局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统人物再识别模型在多模态数据中泛化能力不足的问题，充分发挥多模态大语言模型（MLLMs）的推理、指令遵循和跨模态理解能力。

Method: 提出MMReID-Bench基准，包含20,710个多模态查询和图像，涵盖10种不同的人物再识别任务。

Result: 实验证明MLLMs在人物再识别任务中表现出色，但在处理某些模态（如热成像和红外数据）时仍存在局限性。

Conclusion: MMReID-Bench有望推动社区开发更强大、泛化能力更强的多模态基础模型用于人物再识别。

Abstract: Person re-identification (ReID) aims to retrieve the images of an interested
person in the gallery images, with wide applications in medical rehabilitation,
abnormal behavior detection, and public security. However, traditional person
ReID models suffer from uni-modal capability, leading to poor generalization
ability in multi-modal data, such as RGB, thermal, infrared, sketch images,
textual descriptions, etc. Recently, the emergence of multi-modal large
language models (MLLMs) shows a promising avenue for addressing this problem.
Despite this potential, existing methods merely regard MLLMs as feature
extractors or caption generators, which do not fully unleash their reasoning,
instruction-following, and cross-modal understanding capabilities. To bridge
this gap, we introduce MMReID-Bench, the first multi-task multi-modal benchmark
specifically designed for person ReID. The MMReID-Bench includes 20,710
multi-modal queries and gallery images covering 10 different person ReID tasks.
Comprehensive experiments demonstrate the remarkable capabilities of MLLMs in
delivering effective and versatile person ReID. Nevertheless, they also have
limitations in handling a few modalities, particularly thermal and infrared
data. We hope MMReID-Bench can facilitate the community to develop more robust
and generalizable multimodal foundation models for person ReID.

</details>


### [52] [Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing](https://arxiv.org/abs/2508.06916)
*Shichao Ma,Yunhe Guo,Jiahao Su,Qihe Huang,Zhengyang Zhou,Yang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种名为Talk2Image的多智能体系统，用于多轮对话场景中的交互式图像生成与编辑，解决了现有方法在迭代创作任务中的意图漂移和不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成任务主要集中在单轮场景，难以应对迭代式、多轮创作任务；现有对话系统由于单智能体连续模式易导致意图漂移和不连贯编辑。

Method: Talk2Image系统整合了三个关键组件：从对话历史中解析意图、通过专用智能体分解任务并协作执行、基于多视角评估机制的反馈驱动优化。

Result: 实验表明，Talk2Image在可控性、连贯性和用户满意度方面优于现有基线，适用于迭代式图像生成和编辑任务。

Conclusion: Talk2Image通过多智能体协作和反馈机制，实现了用户意图逐步对齐和一致图像编辑，为交互式图像生成任务提供了有效解决方案。

Abstract: Text-to-image generation tasks have driven remarkable advances in diverse
media applications, yet most focus on single-turn scenarios and struggle with
iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to
bridge this gap, but their single-agent, sequential paradigm often causes
intention drift and incoherent edits. To address these limitations, we present
Talk2Image, a novel multi-agent system for interactive image generation and
editing in multi-turn dialogue scenarios. Our approach integrates three key
components: intention parsing from dialogue history, task decomposition and
collaborative execution across specialized agents, and feedback-driven
refinement based on a multi-view evaluation mechanism. Talk2Image enables
step-by-step alignment with user intention and consistent image editing.
Experiments demonstrate that Talk2Image outperforms existing baselines in
controllability, coherence, and user satisfaction across iterative image
generation and editing tasks.

</details>


### [53] [AR-GRPO: Training Autoregressive Image Generation Models via Reinforcement Learning](https://arxiv.org/abs/2508.06924)
*Shihao Yuan,Yahui Liu,Yang Yue,Jingyuan Zhang,Wangmeng Zuo,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种名为AR-GRPO的方法，通过在线强化学习训练优化自回归图像生成模型，显著提高了生成图像的质量和人类偏好。


<details>
  <summary>Details</summary>
Motivation: 受到强化学习在大语言模型优化中的成功启发，作者希望将其应用于自回归图像生成模型，以提升生成图像的多样性和质量。

Method: 将GRPO算法应用于自回归模型，设计了多维度奖励函数（如感知质量、真实感和语义忠实度）来优化生成结果。

Result: 实验表明，该方法在类条件和文本条件图像生成任务中，显著提升了图像质量和人类偏好。

Conclusion: AR-GRPO证明了基于强化学习的优化在自回归图像生成中的可行性，为高质量可控图像合成开辟了新途径。

Abstract: Inspired by the success of reinforcement learning (RL) in refining large
language models (LLMs), we propose AR-GRPO, an approach to integrate online RL
training into autoregressive (AR) image generation models. We adapt the Group
Relative Policy Optimization (GRPO) algorithm to refine the vanilla
autoregressive models' outputs by carefully designed reward functions that
evaluate generated images across multiple quality dimensions, including
perceptual quality, realism, and semantic fidelity. We conduct comprehensive
experiments on both class-conditional (i.e., class-to-image) and
text-conditional (i.e., text-to-image) image generation tasks, demonstrating
that our RL-enhanced framework significantly improves both the image quality
and human preference of generated images compared to the standard AR baselines.
Our results show consistent improvements across various evaluation metrics,
establishing the viability of RL-based optimization for AR image generation and
opening new avenues for controllable and high-quality image synthesis. The
source codes and models are available at:
https://github.com/Kwai-Klear/AR-GRPO.

</details>


### [54] [CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing](https://arxiv.org/abs/2508.06937)
*Weiyan Xie,Han Gao,Didan Deng,Kaican Li,April Hua Liu,Yongxiang Huang,Nevin L. Zhang*

Main category: cs.CV

TL;DR: CannyEdit是一种无需训练的图像编辑框架，通过选择性Canny控制和双提示引导，显著提升了文本遵循和上下文保真度的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图像编辑时难以平衡文本遵循、上下文保真度和编辑无缝性，CannyEdit旨在解决这一问题。

Method: 采用选择性Canny控制保留未编辑区域的细节，并通过双提示引导结合局部和全局提示实现连贯编辑。

Result: 在真实图像编辑任务中，CannyEdit在文本遵循和上下文保真度上优于现有方法，用户研究显示其编辑结果更难被识别为AI生成。

Conclusion: CannyEdit通过创新设计实现了高质量、无缝的图像编辑，为训练自由的区域图像编辑提供了新思路。

Abstract: Recent advances in text-to-image (T2I) models have enabled training-free
regional image editing by leveraging the generative priors of foundation
models. However, existing methods struggle to balance text adherence in edited
regions, context fidelity in unedited areas, and seamless integration of edits.
We introduce CannyEdit, a novel training-free framework that addresses these
challenges through two key innovations: (1) Selective Canny Control, which
masks the structural guidance of Canny ControlNet in user-specified editable
regions while strictly preserving details of the source images in unedited
areas via inversion-phase ControlNet information retention. This enables
precise, text-driven edits without compromising contextual integrity. (2)
Dual-Prompt Guidance, which combines local prompts for object-specific edits
with a global target prompt to maintain coherent scene interactions. On
real-world image editing tasks (addition, replacement, removal), CannyEdit
outperforms prior methods like KV-Edit, achieving a 2.93 to 10.49 percent
improvement in the balance of text adherence and context fidelity. In terms of
editing seamlessness, user studies reveal only 49.2 percent of general users
and 42.0 percent of AIGC experts identified CannyEdit's results as AI-edited
when paired with real images without edits, versus 76.08 to 89.09 percent for
competitor methods.

</details>


### [55] [SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work](https://arxiv.org/abs/2508.06951)
*Harry Walsh,Ed Fish,Ozge Mercanoglu Sincan,Mohamed Ilyes Lakhal,Richard Bowden,Neil Fox,Bencie Woll,Kepeng Wu,Zecheng Li,Weichao Zhao,Haodong Wang,Wengang Zhou,Houqiang Li,Shengeng Tang,Jiayi He,Xu Wang,Ruobei Zhang,Yaxiong Wang,Lechao Cheng,Meryem Tasyurek,Tugce Kiziltepe,Hacer Yalim Keles*

Main category: cs.CV

TL;DR: 介绍了首个手语生成挑战赛，旨在通过标准化的评估指标比较不同系统。比赛中获胜团队采用了基于检索的框架和预训练语言模型。


<details>
  <summary>Details</summary>
Motivation: 由于手语生成领域缺乏标准化的评估指标，难以比较不同系统的表现，因此提出了这一挑战赛。

Method: 比赛采用了RWTH-PHOENIX-Weather-2014T数据集，任务是将文本转换为骨架姿势序列（T2P），并通过多种指标进行评估。

Result: 33名参赛者提交了231个解决方案，获胜团队的BLEU-1分数为31.40，DTW-MJE为0.0574。

Conclusion: 发布了一个标准化的评估网络，为手语生成领域提供了统一的基准，便于未来研究比较。

Abstract: Sign Language Production (SLP) is the task of generating sign language video
from spoken language inputs. The field has seen a range of innovations over the
last few years, with the introduction of deep learning-based approaches
providing significant improvements in the realism and naturalness of generated
outputs. However, the lack of standardized evaluation metrics for SLP
approaches hampers meaningful comparisons across different systems. To address
this, we introduce the first Sign Language Production Challenge, held as part
of the third SLRTP Workshop at CVPR 2025. The competition's aims are to
evaluate architectures that translate from spoken language sentences to a
sequence of skeleton poses, known as Text-to-Pose (T2P) translation, over a
range of metrics. For our evaluation data, we use the
RWTH-PHOENIX-Weather-2014T dataset, a German Sign Language - Deutsche
Gebardensprache (DGS) weather broadcast dataset. In addition, we curate a
custom hidden test set from a similar domain of discourse. This paper presents
the challenge design and the winning methodologies. The challenge attracted 33
participants who submitted 231 solutions, with the top-performing team
achieving BLEU-1 scores of 31.40 and DTW-MJE of 0.0574. The winning approach
utilized a retrieval-based framework and a pre-trained language model. As part
of the workshop, we release a standardized evaluation network, including
high-quality skeleton extraction-based keypoints establishing a consistent
baseline for the SLP field, which will enable future researchers to compare
their work against a broader range of methods.

</details>


### [56] [Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification](https://arxiv.org/abs/2508.06959)
*Qin Xu,Lili Zhu,Xiaoxia Cheng,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了一种名为SCOPE的新方法，用于细粒度视觉分类（FGVC），通过自适应增强空间域的低级细节和高级语义表现能力，克服了频域固定尺度的限制。


<details>
  <summary>Details</summary>
Motivation: 解决FGVC中捕捉细微视觉特征的挑战，频域方法因固定基础函数缺乏适应性，无法动态调整特征提取。

Method: SCOPE包含两个模块：SDE动态增强浅层特征的细微细节（如边缘和纹理），SSR通过学习高级特征生成语义一致的细化特征。

Result: 在四个流行的细粒度图像分类基准测试中达到了新的最优性能。

Conclusion: SCOPE通过自适应多尺度融合提升了FGVC的灵活性，取得了显著性能提升。

Abstract: The crux of resolving fine-grained visual classification (FGVC) lies in
capturing discriminative and class-specific cues that correspond to subtle
visual characteristics. Recently, frequency decomposition/transform based
approaches have attracted considerable interests since its appearing
discriminative cue mining ability. However, the frequency-domain methods are
based on fixed basis functions, lacking adaptability to image content and
unable to dynamically adjust feature extraction according to the discriminative
requirements of different images. To address this, we propose a novel method
for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively
enhances the representational capability of low-level details and high-level
semantics in the spatial domain, breaking through the limitations of fixed
scales in the frequency domain and improving the flexibility of multi-scale
fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor
(SDE), which dynamically enhances subtle details such as edges and textures
from shallow features, and the Salient Semantic Refiner (SSR), which learns
semantically coherent and structure-aware refinement features from the
high-level features guided by the enhanced shallow features. The SDE and SSR
are cascaded stage-by-stage to progressively combine local details with global
semantics. Extensive experiments demonstrate that our method achieves new
state-of-the-art on four popular fine-grained image classification benchmarks.

</details>


### [57] [Adversarial Video Promotion Against Text-to-Video Retrieval](https://arxiv.org/abs/2508.06964)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Qian Li,Shuai Liu,Chao Shen*

Main category: cs.CV

TL;DR: 该研究首次提出一种针对文本到视频检索（T2VR）的视频推广攻击（ViPro），通过模态细化（MoRe）提升黑盒可迁移性，实验表明其优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有T2VR攻击主要关注降低视频排名，而通过提升视频排名（推广攻击）的攻击未被充分探索，其可能带来更大的影响（如点击量或信息传播）。

Method: 提出ViPro攻击和MoRe方法，通过捕捉视觉与文本模态的细粒度交互增强攻击的可迁移性。

Result: ViPro在白盒、灰盒和黑盒设置下分别平均超越基线30%、10%和4%。

Conclusion: 该研究揭示了T2VR的潜在漏洞，分析了攻击的上下界，并为防御提供了见解。

Abstract: Thanks to the development of cross-modal models, text-to-video retrieval
(T2VR) is advancing rapidly, but its robustness remains largely unexamined.
Existing attacks against T2VR are designed to push videos away from queries,
i.e., suppressing the ranks of videos, while the attacks that pull videos
towards selected queries, i.e., promoting the ranks of videos, remain largely
unexplored. These attacks can be more impactful as attackers may gain more
views/clicks for financial benefits and widespread (mis)information. To this
end, we pioneer the first attack against T2VR to promote videos adversarially,
dubbed the Video Promotion attack (ViPro). We further propose Modal Refinement
(MoRe) to capture the finer-grained, intricate interaction between visual and
textual modalities to enhance black-box transferability. Comprehensive
experiments cover 2 existing baselines, 3 leading T2VR models, 3 prevailing
datasets with over 10k videos, evaluated under 3 scenarios. All experiments are
conducted in a multi-target setting to reflect realistic scenarios where
attackers seek to promote the video regarding multiple queries simultaneously.
We also evaluated our attacks for defences and imperceptibility. Overall, ViPro
surpasses other baselines by over $30/10/4\%$ for white/grey/black-box settings
on average. Our work highlights an overlooked vulnerability, provides a
qualitative analysis on the upper/lower bound of our attacks, and offers
insights into potential counterplays. Code will be publicly available at
https://github.com/michaeltian108/ViPro.

</details>


### [58] [Evaluating Fisheye-Compatible 3D Gaussian Splatting Methods on Real Images Beyond 180 Degree Field of View](https://arxiv.org/abs/2508.06968)
*Ulas Gunes,Matias Turkulainen,Juho Kannala,Esa Rahtu*

Main category: cs.CV

TL;DR: 评估了Fisheye-GS和3DGUT两种鱼眼3D高斯泼溅方法在超180度视场的性能，提出基于深度的初始化策略。


<details>
  <summary>Details</summary>
Motivation: 解决鱼眼相机在高畸变下的3D重建问题，尤其是SfM初始化在强畸变下失败的情况。

Method: 通过不同视场（200度、160度、120度）测试方法性能，提出基于UniK3D的深度初始化策略。

Result: Fisheye-GS在160度视场表现最佳，3DGUT在所有视场稳定且保持高质量；UniK3D策略效果与SfM相当。

Conclusion: 鱼眼3DGS方法适用于宽角度3D重建，即使在畸变严重的稀疏图像输入下也具备实用性。

Abstract: We present the first evaluation of fisheye-based 3D Gaussian Splatting
methods, Fisheye-GS and 3DGUT, on real images with fields of view exceeding 180
degree. Our study covers both indoor and outdoor scenes captured with 200
degree fisheye cameras and analyzes how each method handles extreme distortion
in real world settings. We evaluate performance under varying fields of view
(200 degree, 160 degree, and 120 degree) to study the tradeoff between
peripheral distortion and spatial coverage. Fisheye-GS benefits from field of
view (FoV) reduction, particularly at 160 degree, while 3DGUT remains stable
across all settings and maintains high perceptual quality at the full 200
degree view. To address the limitations of SfM-based initialization, which
often fails under strong distortion, we also propose a depth-based strategy
using UniK3D predictions from only 2-3 fisheye images per scene. Although
UniK3D is not trained on real fisheye data, it produces dense point clouds that
enable reconstruction quality on par with SfM, even in difficult scenes with
fog, glare, or sky. Our results highlight the practical viability of
fisheye-based 3DGS methods for wide-angle 3D reconstruction from sparse and
distortion-heavy image inputs.

</details>


### [59] [WeatherDiffusion: Weather-Guided Diffusion Model for Forward and Inverse Rendering](https://arxiv.org/abs/2508.06982)
*Yixin Zhu,Zuoliang Zhu,Miloš Hašan,Jian Yang,Jin Xie,Beibei Wang*

Main category: cs.CV

TL;DR: 提出WeatherDiffusion，基于扩散模型的框架，用于自动驾驶场景中多天气和光照条件下的正向和逆向渲染，支持可控的天气和光照编辑。


<details>
  <summary>Details</summary>
Motivation: 复杂天气和光照对自动驾驶场景的理解和重建带来挑战，现有扩散模型难以控制且缺乏鲁棒性，因此需要新方法。

Method: 使用预测的本征图（guided by text）进行天气和光照编辑，提出本征图感知注意力（MAA）提升逆向渲染质量，并创建了两个数据集（WeatherSynthetic和WeatherReal）。

Result: WeatherDiffusion在多个基准测试中优于现有方法，并提升了自动驾驶下游任务的鲁棒性（如目标检测和图像分割）。

Conclusion: WeatherDiffusion在天气和光照多样性场景中表现优异，对自动驾驶的实用价值显著。

Abstract: Forward and inverse rendering have emerged as key techniques for enabling
understanding and reconstruction in the context of autonomous driving (AD).
However, complex weather and illumination pose great challenges to this task.
The emergence of large diffusion models has shown promise in achieving
reasonable results through learning from 2D priors, but these models are
difficult to control and lack robustness. In this paper, we introduce
WeatherDiffusion, a diffusion-based framework for forward and inverse rendering
on AD scenes with various weather and lighting conditions. Our method enables
authentic estimation of material properties, scene geometry, and lighting, and
further supports controllable weather and illumination editing through the use
of predicted intrinsic maps guided by text descriptions. We observe that
different intrinsic maps should correspond to different regions of the original
image. Based on this observation, we propose Intrinsic map-aware attention
(MAA) to enable high-quality inverse rendering. Additionally, we introduce a
synthetic dataset (\ie WeatherSynthetic) and a real-world dataset (\ie
WeatherReal) for forward and inverse rendering on AD scenes with diverse
weather and lighting. Extensive experiments show that our WeatherDiffusion
outperforms state-of-the-art methods on several benchmarks. Moreover, our
method demonstrates significant value in downstream tasks for AD, enhancing the
robustness of object detection and image segmentation in challenging weather
scenarios.

</details>


### [60] [TADoc: Robust Time-Aware Document Image Dewarping](https://arxiv.org/abs/2508.06988)
*Fangmin Zhao,Weichao Zeng,Zhenhang Li,Dongbao Yang,Yu Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种新的文档图像去扭曲方法TADoc，通过动态过程建模和轻量级框架，提升了复杂变形场景下的处理效果，并提出了新的评价指标DLS。


<details>
  <summary>Details</summary>
Motivation: 随着数字经济和在线工作的兴起，便携设备拍摄的文档图像去扭曲需求增加，但现有方法在处理复杂结构和高度变形时效果不佳。

Method: 论文重新定义了任务为动态过程，设计了一个轻量级框架TADoc，并通过新指标DLS评估效果。

Result: 实验表明，TADoc在多种文档类型和变形程度下表现出色，具有强鲁棒性。

Conclusion: TADoc方法在文档去扭曲任务中表现优异，且DLS指标为下游任务提供了更全面的评价。

Abstract: Flattening curved, wrinkled, and rotated document images captured by portable
photographing devices, termed document image dewarping, has become an
increasingly important task with the rise of digital economy and online
working. Although many methods have been proposed recently, they often struggle
to achieve satisfactory results when confronted with intricate document
structures and higher degrees of deformation in real-world scenarios. Our main
insight is that, unlike other document restoration tasks (e.g., deblurring),
dewarping in real physical scenes is a progressive motion rather than a
one-step transformation. Based on this, we have undertaken two key initiatives.
Firstly, we reformulate this task, modeling it for the first time as a dynamic
process that encompasses a series of intermediate states. Secondly, we design a
lightweight framework called TADoc (Time-Aware Document Dewarping Network) to
address the geometric distortion of document images. In addition, due to the
inadequacy of OCR metrics for document images containing sparse text, the
comprehensiveness of evaluation is insufficient. To address this shortcoming,
we propose a new metric -- DLS (Document Layout Similarity) -- to evaluate the
effectiveness of document dewarping in downstream tasks. Extensive experiments
and in-depth evaluations have been conducted and the results indicate that our
model possesses strong robustness, achieving superiority on several benchmarks
with different document types and degrees of distortion.

</details>


### [61] [OctreeNCA: Single-Pass 184 MP Segmentation on Consumer Hardware](https://arxiv.org/abs/2508.06993)
*Nick Lemke,John Kalkhof,Niklas Babendererde,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: OctreeNCA 通过八叉树数据结构改进神经网络细胞自动机（NCA），实现高效全局知识传递，显著降低 VRAM 消耗，适用于高分辨率图像和视频分割。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像和视频分割中因 VRAM 限制导致的全局一致性缺失和推理速度下降问题。

Method: 引入八叉树数据结构扩展 NCA 的邻域定义，并实现优化的 CUDA 推理函数以减少 VRAM 占用。

Result: OctreeNCA 在评估中比 UNet 节省 90% VRAM，能高效处理 184 兆像素病理切片或 1 分钟手术视频。

Conclusion: OctreeNCA 通过八叉树和 CUDA 优化提供高效、节能的大规模医学图像分割方案。

Abstract: Medical applications demand segmentation of large inputs, like prostate MRIs,
pathology slices, or videos of surgery. These inputs should ideally be inferred
at once to provide the model with proper spatial or temporal context. When
segmenting large inputs, the VRAM consumption of the GPU becomes the
bottleneck. Architectures like UNets or Vision Transformers scale very poorly
in VRAM consumption, resulting in patch- or frame-wise approaches that
compromise global consistency and inference speed. The lightweight Neural
Cellular Automaton (NCA) is a bio-inspired model that is by construction
size-invariant. However, due to its local-only communication rules, it lacks
global knowledge. We propose OctreeNCA by generalizing the neighborhood
definition using an octree data structure. Our generalized neighborhood
definition enables the efficient traversal of global knowledge. Since deep
learning frameworks are mainly developed for large multi-layer networks, their
implementation does not fully leverage the advantages of NCAs. We implement an
NCA inference function in CUDA that further reduces VRAM demands and increases
inference speed. Our OctreeNCA segments high-resolution images and videos
quickly while occupying 90% less VRAM than a UNet during evaluation. This
allows us to segment 184 Megapixel pathology slices or 1-minute surgical videos
at once.

</details>


### [62] [S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision](https://arxiv.org/abs/2508.06995)
*Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: 提出了一种快速的伪掩码生成算法UniAP，并基于此开发了可扩展的自监督通用分割模型S2-UniSeg，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有自监督图像分割模型预训练过程中的多阶段伪掩码生成问题，优化效率与性能。

Method: 使用Fast Universal Agglomerative Pooling (UniAP) 快速生成伪掩码，并通过Query-wise Self-Distillation (QuerySD) 预训练S2-UniSeg模型。

Result: 在多个基准测试中表现优异，例如AP+6.9 (COCO)、AR+11.1 (UVO)等，进一步扩展到SA-1B数据后性能持续提升。

Conclusion: S2-UniSeg通过连续预训练和快速伪掩码生成，显著提升了自监督分割的性能和可扩展性。

Abstract: Recent self-supervised image segmentation models have achieved promising
performance on semantic segmentation and class-agnostic instance segmentation.
However, their pretraining schedule is multi-stage, requiring a time-consuming
pseudo-masks generation process between each training epoch. This
time-consuming offline process not only makes it difficult to scale with
training dataset size, but also leads to sub-optimal solutions due to its
discontinuous optimization routine. To solve these, we first present a novel
pseudo-mask algorithm, Fast Universal Agglomerative Pooling (UniAP). Each layer
of UniAP can identify groups of similar nodes in parallel, allowing to generate
both semantic-level and instance-level and multi-granular pseudo-masks within
ens of milliseconds for one image. Based on the fast UniAP, we propose the
Scalable Self-Supervised Universal Segmentation (S2-UniSeg), which employs a
student and a momentum teacher for continuous pretraining. A novel
segmentation-oriented pretext task, Query-wise Self-Distillation (QuerySD), is
proposed to pretrain S2-UniSeg to learn the local-to-global correspondences.
Under the same setting, S2-UniSeg outperforms the SOTA UnSAM model, achieving
notable improvements of AP+6.9 on COCO, AR+11.1 on UVO, PixelAcc+4.5 on
COCOStuff-27, RQ+8.0 on Cityscapes. After scaling up to a larger 2M-image
subset of SA-1B, S2-UniSeg further achieves performance gains on all four
benchmarks. Our code and pretrained models are available at
https://github.com/bio-mlhui/S2-UniSeg

</details>


### [63] [HiMat: DiT-based Ultra-High Resolution SVBRDF Generation](https://arxiv.org/abs/2508.07011)
*Zixiong Wang,Jian Yang,Yiwei Hu,Milos Hasan,Beibei Wang*

Main category: cs.CV

TL;DR: HiMat是一个高效的基于扩散的框架，能够生成原生4K分辨率的SVBRDF，通过轻量化的CrossStitch模块保持不同贴图间的一致性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率文本到图像生成模型的兴起为SVBRDF生成提供了机会，但如何在保持高效率的同时生成多个对齐的SVBRDF贴图仍是一个挑战。

Method: 引入HiMat框架和轻量化的CrossStitch模块，通过局部化操作捕捉贴图间依赖关系，并在不显著改变DiT主干的情况下实现一致性。

Result: 实验表明，HiMat能生成具有强结构一致性和高频细节的4K SVBRDF，并在其他任务（如本征分解）中表现出泛化能力。

Conclusion: HiMat提供了一种高效且轻量的方法，用于生成高质量的SVBRDF贴图，展示了其广泛的适用性。

Abstract: Creating highly detailed SVBRDFs is essential for 3D content creation. The
rise of high-resolution text-to-image generative models, based on diffusion
transformers (DiT), suggests an opportunity to finetune them for this task.
However, retargeting the models to produce multiple aligned SVBRDF maps instead
of just RGB images, while achieving high efficiency and ensuring consistency
across different maps, remains a challenge. In this paper, we introduce HiMat:
a memory- and computation-efficient diffusion-based framework capable of
generating native 4K-resolution SVBRDFs. A key challenge we address is
maintaining consistency across different maps in a lightweight manner, without
relying on training new VAEs or significantly altering the DiT backbone (which
would damage its prior capabilities). To tackle this, we introduce the
CrossStitch module, a lightweight convolutional module that captures inter-map
dependencies through localized operations. Its weights are initialized such
that the DiT backbone operation is unchanged before finetuning starts. HiMat
enables generation with strong structural coherence and high-frequency details.
Results with a large set of text prompts demonstrate the effectiveness of our
approach for 4K SVBRDF generation. Further experiments suggest generalization
to tasks such as intrinsic decomposition.

</details>


### [64] [TerraMAE: Learning Spatial-Spectral Representations from Hyperspectral Earth Observation Data via Adaptive Masked Autoencoders](https://arxiv.org/abs/2508.07020)
*Tanjim Bin Faruk,Abdul Matin,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: TerraMAE是一种新型高光谱图像编码框架，通过自适应通道分组和增强的损失函数，有效捕捉空间-光谱信息，并在多项下游地理空间任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 高光谱卫星图像具有丰富的空间-光谱信息，但现有自监督方法难以充分利用200+波段的高光谱数据。

Method: 提出TerraMAE框架，包括自适应通道分组策略和增强的重建损失函数，以优化空间-光谱嵌入。

Result: TerraMAE在高保真图像重建和多项下游任务（如作物识别、土地覆盖分类和土壤纹理预测）中表现优越。

Conclusion: TerraMAE能有效学习高光谱图像的代表性嵌入，提升地理空间分析的性能。

Abstract: Hyperspectral satellite imagery offers sub-30 m views of Earth in hundreds of
contiguous spectral bands, enabling fine-grained mapping of soils, crops, and
land cover. While self-supervised Masked Autoencoders excel on RGB and low-band
multispectral data, they struggle to exploit the intricate spatial-spectral
correlations in 200+ band hyperspectral images. We introduce TerraMAE, a novel
HSI encoding framework specifically designed to learn highly representative
spatial-spectral embeddings for diverse geospatial analyses. TerraMAE features
an adaptive channel grouping strategy, based on statistical reflectance
properties to capture spectral similarities, and an enhanced reconstruction
loss function that incorporates spatial and spectral quality metrics. We
demonstrate TerraMAE's effectiveness through superior spatial-spectral
information preservation in high-fidelity image reconstruction. Furthermore, we
validate its practical utility and the quality of its learned representations
through strong performance on three key downstream geospatial tasks: crop
identification, land cover classification, and soil texture prediction.

</details>


### [65] [DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents](https://arxiv.org/abs/2508.07021)
*Kun Qian,Wenjie Li,Tianyu Sun,Wenhong Wang,Wenhan Luo*

Main category: cs.CV

TL;DR: DocRefine 是一个基于多智能体系统的创新框架，专为科学 PDF 文档的智能理解、内容优化和自动摘要设计。它在语义一致性和视觉保真度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 科学文献的爆炸式增长需要高效准确的工具来处理复杂布局和多模态内容，传统方法及 LLMs 和 LVLMs 的直接应用无法满足精准编辑需求。

Method: DocRefine 通过六种协作智能体（布局分析、内容理解、指令分解、内容优化、摘要生成、一致性验证）实现多模态文档的精准处理。

Result: 在 DocEditBench 数据集上，DocRefine 的语义一致性得分达 86.7%，布局保真度指数 93.9%，指令遵循率 85.0%，显著优于现有基线。

Conclusion: DocRefine 在多模态文档编辑中表现出色，推动了自动化科学文档处理的进步。

Abstract: The exponential growth of scientific literature in PDF format necessitates
advanced tools for efficient and accurate document understanding,
summarization, and content optimization. Traditional methods fall short in
handling complex layouts and multimodal content, while direct application of
Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks
precision and control for intricate editing tasks. This paper introduces
DocRefine, an innovative framework designed for intelligent understanding,
content refinement, and automated summarization of scientific PDF documents,
driven by natural language instructions. DocRefine leverages the power of
advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent
system comprising six specialized and collaborative agents: Layout & Structure
Analysis, Multimodal Content Understanding, Instruction Decomposition, Content
Refinement, Summarization & Generation, and Fidelity & Consistency
Verification. This closed-loop feedback architecture ensures high semantic
accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench
dataset, DocRefine consistently outperforms state-of-the-art baselines across
various tasks, achieving overall scores of 86.7% for Semantic Consistency Score
(SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction
Adherence Rate (IAR). These results demonstrate DocRefine's superior capability
in handling complex multimodal document editing, preserving semantic integrity,
and maintaining visual consistency, marking a significant advancement in
automated scientific document processing.

</details>


### [66] [MV-CoRe: Multimodal Visual-Conceptual Reasoning for Complex Visual Question Answering](https://arxiv.org/abs/2508.07023)
*Jingwei Peng,Jiehao Chen,Mateo Alejandro Rojas,Meilin Zhang*

Main category: cs.CV

TL;DR: MV-CoRe是一种新颖的多模态视觉-概念推理模型，通过深度整合视觉和语言信息提升复杂视觉问答任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有大型视觉语言模型在复杂视觉问答任务中依赖高层全局特征的局限性。

Method: 整合预训练视觉和语言模型的全局嵌入与细粒度语义感知特征，并通过多模态融合变换器进行深度整合。

Result: 在GQA、A-OKVQA和OKVQA等基准测试中表现优于基线模型，GQA上达到77.5%的准确率。

Conclusion: MV-CoRe通过细粒度和全局特征的深度整合，展示了在复杂视觉问答任务中的强大能力。

Abstract: Complex Visual Question Answering (Complex VQA) tasks, which demand
sophisticated multi-modal reasoning and external knowledge integration, present
significant challenges for existing large vision-language models (LVLMs) often
limited by their reliance on high-level global features. To address this, we
propose MV-CoRe (Multimodal Visual-Conceptual Reasoning), a novel model
designed to enhance Complex VQA performance through the deep fusion of diverse
visual and linguistic information. MV-CoRe meticulously integrates global
embeddings from pre-trained Vision Large Models (VLMs) and Language Large
Models (LLMs) with fine-grained semantic-aware visual features, including
object detection characteristics and scene graph representations. An innovative
Multimodal Fusion Transformer then processes and deeply integrates these
diverse feature sets, enabling rich cross-modal attention and facilitating
complex reasoning. We evaluate MV-CoRe on challenging Complex VQA benchmarks,
including GQA, A-OKVQA, and OKVQA, after training on VQAv2. Our experimental
results demonstrate that MV-CoRe consistently outperforms established LVLM
baselines, achieving an overall accuracy of 77.5% on GQA. Ablation studies
confirm the critical contribution of both object and scene graph features, and
human evaluations further validate MV-CoRe's superior factual correctness and
reasoning depth, underscoring its robust capabilities for deep visual and
conceptual understanding.

</details>


### [67] [Large Language Model Evaluated Stand-alone Attention-Assisted Graph Neural Network with Spatial and Structural Information Interaction for Precise Endoscopic Image Segmentation](https://arxiv.org/abs/2508.07028)
*Juntong Fan,Shuyi Fan,Debesh Jha,Changsheng Fang,Tieyong Zeng,Hengyong Yu,Dayang Wang*

Main category: cs.CV

TL;DR: FOCUS-Med 是一种新的内窥镜图像分割方法，通过融合空间和结构图以及注意力机制，提升息肉分割的准确性，适用于早期结直肠癌检测。


<details>
  <summary>Details</summary>
Motivation: 内窥镜图像息肉分割对早期结直肠癌检测至关重要，但由于低对比度、镜面高光和模糊边界等挑战，该任务仍具难度。

Method: 提出 FOCUS-Med 方法，结合双图卷积网络（Dual-GCN）捕捉空间和拓扑结构依赖，利用自注意力机制增强全局上下文，并通过多尺度融合策略优化编码器-解码器层间的语义差距。

Result: 在多个公开基准测试中，FOCUS-Med 在五项关键指标上达到最先进性能。

Conclusion: FOCUS-Med 展示了在 AI 辅助结肠镜检查中的有效性和临床应用潜力。

Abstract: Accurate endoscopic image segmentation on the polyps is critical for early
colorectal cancer detection. However, this task remains challenging due to low
contrast with surrounding mucosa, specular highlights, and indistinct
boundaries. To address these challenges, we propose FOCUS-Med, which stands for
Fusion of spatial and structural graph with attentional context-aware polyp
segmentation in endoscopic medical imaging. FOCUS-Med integrates a Dual Graph
Convolutional Network (Dual-GCN) module to capture contextual spatial and
topological structural dependencies. This graph-based representation enables
the model to better distinguish polyps from background tissues by leveraging
topological cues and spatial connectivity, which are often obscured in raw
image intensities. It enhances the model's ability to preserve boundaries and
delineate complex shapes typical of polyps. In addition, a location-fused
stand-alone self-attention is employed to strengthen global context
integration. To bridge the semantic gap between encoder-decoder layers, we
incorporate a trainable weighted fast normalized fusion strategy for efficient
multi-scale aggregation. Notably, we are the first to introduce the use of a
Large Language Model (LLM) to provide detailed qualitative evaluations of
segmentation quality. Extensive experiments on public benchmarks demonstrate
that FOCUS-Med achieves state-of-the-art performance across five key metrics,
underscoring its effectiveness and clinical potential for AI-assisted
colonoscopy.

</details>


### [68] [TeSO: Representing and Compressing 3D Point Cloud Scenes with Textured Surfel Octree](https://arxiv.org/abs/2508.07083)
*Yueyu Hu,Ran Gong,Tingyu Fan,Yao Wang*

Main category: cs.CV

TL;DR: 提出了一种名为TeSO的新型3D表示方法，通过结合八叉树结构和纹理贴图，解决了现有3D表示在渲染质量和压缩效率上的局限。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D表示（如点云、网格和3D高斯）在渲染质量、表面定义和压缩性方面的不足。

Method: 基于点云构建纹理化的八叉树小面（TeSO），利用八叉树层级结构和纹理贴图保留高频细节。

Result: 在较低比特率下实现了比点云和3D高斯基线更高的渲染质量。

Conclusion: TeSO是一种高效且高质量的3D表示方法，适用于3D流媒体技术。

Abstract: 3D visual content streaming is a key technology for emerging 3D telepresence
and AR/VR applications. One fundamental element underlying the technology is a
versatile 3D representation that is capable of producing high-quality renders
and can be efficiently compressed at the same time. Existing 3D representations
like point clouds, meshes and 3D Gaussians each have limitations in terms of
rendering quality, surface definition, and compressibility. In this paper, we
present the Textured Surfel Octree (TeSO), a novel 3D representation that is
built from point clouds but addresses the aforementioned limitations. It
represents a 3D scene as cube-bounded surfels organized on an octree, where
each surfel is further associated with a texture patch. By approximating a
smooth surface with a large surfel at a coarser level of the octree, it reduces
the number of primitives required to represent the 3D scene, and yet retains
the high-frequency texture details through the texture map attached to each
surfel. We further propose a compression scheme to encode the geometry and
texture efficiently, leveraging the octree structure. The proposed textured
surfel octree combined with the compression scheme achieves higher rendering
quality at lower bit-rates compared to multiple point cloud and 3D
Gaussian-based baselines.

</details>


### [69] [ForeSight: Multi-View Streaming Joint Object Detection and Trajectory Forecasting](https://arxiv.org/abs/2508.07089)
*Sandro Papais,Letian Wang,Brian Cheong,Steven L. Waslander*

Main category: cs.CV

TL;DR: ForeSight是一个用于自动驾驶车辆视觉3D感知的新型联合检测与预测框架，通过多任务流式与双向学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将检测与预测作为独立任务处理，无法充分利用时间线索，ForeSight旨在解决这一限制。

Method: 采用多任务流式与双向学习，共享查询内存和无缝信息传递，结合预测感知检测变换器和流式预测变换器。

Result: 在nuScenes数据集上，EPA达54.9%，优于之前方法9.3%，同时在多视图检测与预测模型中表现最佳。

Conclusion: ForeSight通过免跟踪模型高效扩展多帧序列，显著提升性能，为自动驾驶感知提供新方向。

Abstract: We introduce ForeSight, a novel joint detection and forecasting framework for
vision-based 3D perception in autonomous vehicles. Traditional approaches treat
detection and forecasting as separate sequential tasks, limiting their ability
to leverage temporal cues. ForeSight addresses this limitation with a
multi-task streaming and bidirectional learning approach, allowing detection
and forecasting to share query memory and propagate information seamlessly. The
forecast-aware detection transformer enhances spatial reasoning by integrating
trajectory predictions from a multiple hypothesis forecast memory queue, while
the streaming forecast transformer improves temporal consistency using past
forecasts and refined detections. Unlike tracking-based methods, ForeSight
eliminates the need for explicit object association, reducing error propagation
with a tracking-free model that efficiently scales across multi-frame
sequences. Experiments on the nuScenes dataset show that ForeSight achieves
state-of-the-art performance, achieving an EPA of 54.9%, surpassing previous
methods by 9.3%, while also attaining the best mAP and minADE among multi-view
detection and forecasting models.

</details>


### [70] [Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration](https://arxiv.org/abs/2508.07092)
*Yue Hu,Juntong Peng,Yunqiao Yang,Siheng Chen*

Main category: cs.CV

TL;DR: 提出了一种名为HyComm的通信高效LiDAR协作3D检测系统，通过自适应整合紧凑的感知输出和丰富的原始观测数据，优化检测性能与通信带宽的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决协作3D检测中检测性能与通信带宽的瓶颈问题。

Method: 采用混合协作方法，自适应选择关键信息，并结合感知输出和原始观测两种通信消息。

Result: HyComm在DAIR-V2X和OPV2V数据集上表现优异，通信量降低超过2006倍，性能优于之前的方法。

Conclusion: HyComm通过自适应消息选择和标准化数据格式，实现了高效的协作3D检测，适用于不同的通信场景和代理配置。

Abstract: Collaborative 3D detection can substantially boost detection performance by
allowing agents to exchange complementary information. It inherently results in
a fundamental trade-off between detection performance and communication
bandwidth. To tackle this bottleneck issue, we propose a novel hybrid
collaboration that adaptively integrates two types of communication messages:
perceptual outputs, which are compact, and raw observations, which offer richer
information. This approach focuses on two key aspects: i) integrating
complementary information from two message types and ii) prioritizing the most
critical data within each type. By adaptively selecting the most critical set
of messages, it ensures optimal perceptual information and adaptability,
effectively meeting the demands of diverse communication scenarios.Building on
this hybrid collaboration, we present \texttt{HyComm}, a
communication-efficient LiDAR-based collaborative 3D detection system.
\texttt{HyComm} boasts two main benefits: i) it facilitates adaptable
compression rates for messages, addressing various communication requirements,
and ii) it uses standardized data formats for messages. This ensures they are
independent of specific detection models, fostering adaptability across
different agent configurations. To evaluate HyComm, we conduct experiments on
both real-world and simulation datasets: DAIR-V2X and OPV2V. HyComm
consistently outperforms previous methods and achieves a superior
performance-bandwidth trade-off regardless of whether agents use the same or
varied detection models. It achieves a lower communication volume of more than
2,006$\times$ and still outperforms Where2comm on DAIR-V2X in terms of AP50.
The related code will be released.

</details>


### [71] [AugLift: Boosting Generalization in Lifting-based 3D Human Pose Estimation](https://arxiv.org/abs/2508.07112)
*Nikolai Warner,Wenjin Zhang,Irfan Essa,Apaar Sadhwani*

Main category: cs.CV

TL;DR: AugLift通过增强2D关键点数据显著提升3D人体姿态估计的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提升的方法在新数据集和实际场景中泛化能力较差。

Method: 提出AugLift，通过在标准输入中加入关键点置信度和深度估计，利用预训练模型计算这些信号。

Result: 跨数据集性能平均提升10.1%，内部数据集性能提升4.0%。

Conclusion: AugLift是一种简单有效的模块化方法，可显著提升3D姿态估计的泛化能力。

Abstract: Lifting-based methods for 3D Human Pose Estimation (HPE), which predict 3D
poses from detected 2D keypoints, often generalize poorly to new datasets and
real-world settings. To address this, we propose \emph{AugLift}, a simple yet
effective reformulation of the standard lifting pipeline that significantly
improves generalization performance without requiring additional data
collection or sensors. AugLift sparsely enriches the standard input -- the 2D
keypoint coordinates $(x, y)$ -- by augmenting it with a keypoint detection
confidence score $c$ and a corresponding depth estimate $d$. These additional
signals are computed from the image using off-the-shelf, pre-trained models
(e.g., for monocular depth estimation), thereby inheriting their strong
generalization capabilities. Importantly, AugLift serves as a modular add-on
and can be readily integrated into existing lifting architectures.
  Our extensive experiments across four datasets demonstrate that AugLift
boosts cross-dataset performance on unseen datasets by an average of $10.1\%$,
while also improving in-distribution performance by $4.0\%$. These gains are
consistent across various lifting architectures, highlighting the robustness of
our method. Our analysis suggests that these sparse, keypoint-aligned cues
provide robust frame-level context, offering a practical way to significantly
improve the generalization of any lifting-based pose estimation model. Code
will be made publicly available.

</details>


### [72] [Perceptual Evaluation of GANs and Diffusion Models for Generating X-rays](https://arxiv.org/abs/2508.07128)
*Gregory Schuit,Denis Parra,Cecilia Besa*

Main category: cs.CV

TL;DR: 论文探讨了生成对抗网络（GANs）和扩散模型（DMs）在合成医学胸部X光图像上的表现，评估了它们在临床效用和视觉逼真度上的差异。研究发现，DMs整体上更逼真，而GANs在特定条件下表现更好。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像数据稀缺问题，尤其是罕见异常情况，以提高AI诊断和分割工具的泛化性能。

Method: 使用MIMIC-CXR数据集的真实图像和GANs、DMs生成的合成图像，通过三位放射科医生的读者研究评估图像的真实性和临床一致性。

Result: DMs生成的图像更逼真，但GANs在特定条件（如无ECS）下更准确。研究还揭示了放射科医生识别合成图像的视觉线索。

Conclusion: GANs和DMs各有优势，需进一步优化以可靠地扩充AI诊断系统的训练数据。

Abstract: Generative image models have achieved remarkable progress in both natural and
medical imaging. In the medical context, these techniques offer a potential
solution to data scarcity-especially for low-prevalence anomalies that impair
the performance of AI-driven diagnostic and segmentation tools. However,
questions remain regarding the fidelity and clinical utility of synthetic
images, since poor generation quality can undermine model generalizability and
trust. In this study, we evaluate the effectiveness of state-of-the-art
generative models-Generative Adversarial Networks (GANs) and Diffusion Models
(DMs)-for synthesizing chest X-rays conditioned on four abnormalities:
Atelectasis (AT), Lung Opacity (LO), Pleural Effusion (PE), and Enlarged
Cardiac Silhouette (ECS). Using a benchmark composed of real images from the
MIMIC-CXR dataset and synthetic images from both GANs and DMs, we conducted a
reader study with three radiologists of varied experience. Participants were
asked to distinguish real from synthetic images and assess the consistency
between visual features and the target abnormality. Our results show that while
DMs generate more visually realistic images overall, GANs can report better
accuracy for specific conditions, such as absence of ECS. We further identify
visual cues radiologists use to detect synthetic images, offering insights into
the perceptual gaps in current models. These findings underscore the
complementary strengths of GANs and DMs and point to the need for further
refinement to ensure generative models can reliably augment training datasets
for AI diagnostic systems.

</details>


### [73] [CMAMRNet: A Contextual Mask-Aware Network Enhancing Mural Restoration Through Comprehensive Mask Guidance](https://arxiv.org/abs/2508.07140)
*Yingtie Lei,Fanghai Yi,Yihang Dong,Weihuang Liu,Xiaofeng Zhang,Zimeng Li,Chi-Man Pun,Xuhang Chen*

Main category: cs.CV

TL;DR: 论文提出了一种新颖的壁画修复网络CMAMRNet，通过多尺度特征提取和掩码感知机制，解决了现有方法在修复过程中对损坏区域关注不足的问题，显著提升了修复质量。


<details>
  <summary>Details</summary>
Motivation: 壁画的复杂退化模式和艺术真实性的保护需求，使得传统学习方法难以有效修复，需要一种更先进的技术来应对这些挑战。

Method: 提出了CMAMRNet网络，包括掩码感知上下采样器（MAUDS）和共特征聚合器（CFA），前者确保掩码敏感性，后者提取多尺度特征以捕捉细节和全局结构。

Result: 在基准数据集上的实验表明，CMAMRNet优于现有方法，能够更好地保留壁画的结构完整性和艺术细节。

Conclusion: CMAMRNet通过创新的掩码感知和多尺度特征提取机制，为壁画修复提供了更高效的解决方案，具有实际应用价值。

Abstract: Murals, as invaluable cultural artifacts, face continuous deterioration from
environmental factors and human activities. Digital restoration of murals faces
unique challenges due to their complex degradation patterns and the critical
need to preserve artistic authenticity. Existing learning-based methods
struggle with maintaining consistent mask guidance throughout their networks,
leading to insufficient focus on damaged regions and compromised restoration
quality. We propose CMAMRNet, a Contextual Mask-Aware Mural Restoration Network
that addresses these limitations through comprehensive mask guidance and
multi-scale feature extraction. Our framework introduces two key components:
(1) the Mask-Aware Up/Down-Sampler (MAUDS), which ensures consistent mask
sensitivity across resolution scales through dedicated channel-wise feature
selection and mask-guided feature fusion; and (2) the Co-Feature Aggregator
(CFA), operating at both the highest and lowest resolutions to extract
complementary features for capturing fine textures and global structures in
degraded regions. Experimental results on benchmark datasets demonstrate that
CMAMRNet outperforms state-of-the-art methods, effectively preserving both
structural integrity and artistic details in restored murals. The code is
available
at~\href{https://github.com/CXH-Research/CMAMRNet}{https://github.com/CXH-Research/CMAMRNet}.

</details>


### [74] [Dynamic Pattern Alignment Learning for Pretraining Lightweight Human-Centric Vision Models](https://arxiv.org/abs/2508.07144)
*Xuanhan Wang,Huimin Deng,Ke Liu,Jun Wang,Lianli Gao,Jingkuan Song*

Main category: cs.CV

TL;DR: 论文提出了动态模式对齐学习（DPAL），一种基于蒸馏的轻量化人本视觉模型预训练框架，通过动态模式解码器和多级对齐目标，显著提升了轻量模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决大规模人本视觉模型（HVMs）因依赖大架构和受限预训练数据而实用性不足的问题。

Method: 设计动态模式解码器（D-PaDe）和多级对齐目标，从大模型中提取典型视觉模式并指导轻量模型学习。

Result: 在15个数据集上验证了DPAL的有效性，轻量模型（5M参数）性能接近大模型（84M/307M），并优于其他蒸馏方法。

Conclusion: DPAL为轻量化人本视觉模型提供了一种高效且通用的预训练方案。

Abstract: Human-centric vision models (HVMs) have achieved remarkable generalization
due to large-scale pretraining on massive person images. However, their
dependence on large neural architectures and the restricted accessibility of
pretraining data significantly limits their practicality in real-world
applications. To address this limitation, we propose Dynamic Pattern Alignment
Learning (DPAL), a novel distillation-based pretraining framework that
efficiently trains lightweight HVMs to acquire strong generalization from large
HVMs. In particular, human-centric visual perception are highly dependent on
three typical visual patterns, including global identity pattern, local shape
pattern and multi-person interaction pattern. To achieve generalizable
lightweight HVMs, we firstly design a dynamic pattern decoder (D-PaDe), acting
as a dynamic Mixture of Expert (MoE) model. It incorporates three specialized
experts dedicated to adaptively extract typical visual patterns, conditioned on
both input image and pattern queries. And then, we present three levels of
alignment objectives, which aims to minimize generalization gap between
lightweight HVMs and large HVMs at global image level, local pixel level, and
instance relation level. With these two deliberate designs, the DPAL
effectively guides lightweight model to learn all typical human visual patterns
from large HVMs, which can generalize to various human-centric vision tasks.
Extensive experiments conducted on 15 challenging datasets demonstrate the
effectiveness of the DPAL. Remarkably, when employing PATH-B as the teacher,
DPAL-ViT/Ti (5M parameters) achieves surprising generalizability similar to
existing large HVMs such as PATH-B (84M) and Sapiens-L (307M), and outperforms
previous distillation-based pretraining methods including Proteus-ViT/Ti (5M)
and TinyMiM-ViT/Ti (5M) by a large margin.

</details>


### [75] [Intention-Aware Diffusion Model for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2508.07146)
*Yu Liu,Zhijie Liu,Xiao Ren,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 提出了一种结合短期和长期意图的扩散模型，用于行人轨迹预测，提升了预测准确性和多模态意图建模能力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型缺乏对行人意图的显式语义建模，导致行为误判和预测精度下降。

Method: 使用残差极坐标表示短期意图，并通过可学习的令牌式终点预测器建模长期意图，同时引入自适应引导和残差噪声预测器优化扩散过程。

Result: 在ETH、UCY和SDD基准测试中表现优异，优于现有方法。

Conclusion: 结合意图建模的扩散框架有效提升了行人轨迹预测的准确性和鲁棒性。

Abstract: Predicting pedestrian motion trajectories is critical for the path planning
and motion control of autonomous vehicles. Recent diffusion-based models have
shown promising results in capturing the inherent stochasticity of pedestrian
behavior for trajectory prediction. However, the absence of explicit semantic
modelling of pedestrian intent in many diffusion-based methods may result in
misinterpreted behaviors and reduced prediction accuracy. To address the above
challenges, we propose a diffusion-based pedestrian trajectory prediction
framework that incorporates both short-term and long-term motion intentions.
Short-term intent is modelled using a residual polar representation, which
decouples direction and magnitude to capture fine-grained local motion
patterns. Long-term intent is estimated through a learnable, token-based
endpoint predictor that generates multiple candidate goals with associated
probabilities, enabling multimodal and context-aware intention modelling.
Furthermore, we enhance the diffusion process by incorporating adaptive
guidance and a residual noise predictor that dynamically refines denoising
accuracy. The proposed framework is evaluated on the widely used ETH, UCY, and
SDD benchmarks, demonstrating competitive results against state-of-the-art
methods.

</details>


### [76] [SketchAnimator: Animate Sketch via Motion Customization of Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.07149)
*Ruolin Yang,Da Li,Honggang Zhang,Yi-Zhe Song*

Main category: cs.CV

TL;DR: 论文提出了一种名为SketchAnimator的新型草图动画模型，可将静态草图转化为动态视频，通过三个阶段实现：外观学习、运动学习和视频先验蒸馏。


<details>
  <summary>Details</summary>
Motivation: 草图动画通常需要专业技能和大量时间，对于业余用户来说是一项挑战。本文旨在简化这一过程，使非专业人士也能轻松为草图添加动态效果。

Method: 模型分为三个阶段：外观学习（利用LoRA集成草图外观信息）、运动学习（从参考视频中提取动态信息）和视频先验蒸馏（利用SDS更新Bezier曲线参数）。

Result: 该模型生成的动画视频既保留了草图的外观特征，又准确复现了参考视频的动态效果，相比其他方法更具优势。

Conclusion: SketchAnimator为草图动画提供了一种高效且易于使用的解决方案，特别适合非专业人士快速实现创意动态效果。

Abstract: Sketching is a uniquely human tool for expressing ideas and creativity. The
animation of sketches infuses life into these static drawings, opening a new
dimension for designers. Animating sketches is a time-consuming process that
demands professional skills and extensive experience, often proving daunting
for amateurs. In this paper, we propose a novel sketch animation model
SketchAnimator, which enables adding creative motion to a given sketch, like "a
jumping car''. Namely, given an input sketch and a reference video, we divide
the sketch animation into three stages: Appearance Learning, Motion Learning
and Video Prior Distillation. In stages 1 and 2, we utilize LoRA to integrate
sketch appearance information and motion dynamics from the reference video into
the pre-trained T2V model. In the third stage, we utilize Score Distillation
Sampling (SDS) to update the parameters of the Bezier curves in each sketch
frame according to the acquired motion information. Consequently, our model
produces a sketch video that not only retains the original appearance of the
sketch but also mirrors the dynamic movements of the reference video. We
compare our method with alternative approaches and demonstrate that it
generates the desired sketch video under the challenge of one-shot motion
customization.

</details>


### [77] [CoopDiff: Anticipating 3D Human-object Interactions via Contact-consistent Decoupled Diffusion](https://arxiv.org/abs/2508.07162)
*Xiaotong Lin,Tianming Liang,Jian-Fang Hu,Kun-Yu Lin,Yulei Kang,Chunwei Tian,Jianhuang Lai,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: CoopDiff提出了一种新的3D人-物交互预测框架，通过分离人和物体的运动建模，并利用接触点作为共享锚点，提升了预测的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常用一个模型预测人和物体的运动，忽略了二者运动模式的差异。为了解决这一问题，本文提出了分离建模的思想。

Method: 采用接触一致解耦扩散框架CoopDiff，使用两个分支分别建模人和物体的运动，并通过接触点和一致性约束桥接二者。

Result: 在BEHAVE和Human-object Interaction数据集上的实验表明，CoopDiff优于现有方法。

Conclusion: 分离建模和接触点一致性约束有效提升了3D人-物交互预测的准确性。

Abstract: 3D human-object interaction (HOI) anticipation aims to predict the future
motion of humans and their manipulated objects, conditioned on the historical
context. Generally, the articulated humans and rigid objects exhibit different
motion patterns, due to their distinct intrinsic physical properties. However,
this distinction is ignored by most of the existing works, which intend to
capture the dynamics of both humans and objects within a single prediction
model. In this work, we propose a novel contact-consistent decoupled diffusion
framework CoopDiff, which employs two distinct branches to decouple human and
object motion modeling, with the human-object contact points as shared anchors
to bridge the motion generation across branches. The human dynamics branch is
aimed to predict highly structured human motion, while the object dynamics
branch focuses on the object motion with rigid translations and rotations.
These two branches are bridged by a series of shared contact points with
consistency constraint for coherent human-object motion prediction. To further
enhance human-object consistency and prediction reliability, we propose a
human-driven interaction module to guide object motion modeling. Extensive
experiments on the BEHAVE and Human-object Interaction datasets demonstrate
that our CoopDiff outperforms state-of-the-art methods.

</details>


### [78] [Lightweight Multi-Scale Feature Extraction with Fully Connected LMF Layer for Salient Object Detection](https://arxiv.org/abs/2508.07170)
*Yunpeng Shi,Lei Chen,Xiaolu Shen,Yanju Guo*

Main category: cs.CV

TL;DR: 提出了一种轻量级多尺度特征提取层LMF层，构建了LMFNet网络，在显著物体检测任务中实现了高效和性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决轻量级网络中多尺度特征提取的挑战，同时保持高效和性能。

Method: 使用深度可分离扩张卷积构建LMF层，集成多个LMF层形成LMFNet。

Result: 在五个基准数据集上取得最佳或可比结果，参数量仅为0.81M。

Conclusion: LMFNet在轻量级网络中解决了多尺度学习问题，并展示了在图像处理任务中的广泛应用潜力。

Abstract: In the domain of computer vision, multi-scale feature extraction is vital for
tasks such as salient object detection. However, achieving this capability in
lightweight networks remains challenging due to the trade-off between
efficiency and performance. This paper proposes a novel lightweight multi-scale
feature extraction layer, termed the LMF layer, which employs depthwise
separable dilated convolutions in a fully connected structure. By integrating
multiple LMF layers, we develop LMFNet, a lightweight network tailored for
salient object detection. Our approach significantly reduces the number of
parameters while maintaining competitive performance. Here, we show that LMFNet
achieves state-of-the-art or comparable results on five benchmark datasets with
only 0.81M parameters, outperforming several traditional and lightweight models
in terms of both efficiency and accuracy. Our work not only addresses the
challenge of multi-scale learning in lightweight networks but also demonstrates
the potential for broader applications in image processing tasks. The related
code files are available at https://github.com/Shi-Yun-peng/LMFNet

</details>


### [79] [EventRR: Event Referential Reasoning for Referring Video Object Segmentation](https://arxiv.org/abs/2508.07171)
*Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu*

Main category: cs.CV

TL;DR: EventRR框架通过解耦视频对象分割任务，利用事件图结构提高了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了表达式的语义结构，且视频表达式的复杂性挑战了传统方法。

Method: 提出EventRR框架，分为对象摘要和引用推理两部分，利用事件图结构进行推理。

Result: 在四个基准数据集上，EventRR性能优于现有方法。

Conclusion: EventRR通过结构化推理显著提升了视频对象分割的准确性。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment out the object in
a video referred by an expression. Current RVOS methods view referring
expressions as unstructured sequences, neglecting their crucial semantic
structure essential for referent reasoning. Besides, in contrast to
image-referring expressions whose semantics focus only on object attributes and
object-object relations, video-referring expressions also encompass event
attributes and event-event temporal relations. This complexity challenges
traditional structured reasoning image approaches. In this paper, we propose
the Event Referential Reasoning (EventRR) framework. EventRR decouples RVOS
into object summarization part and referent reasoning part. The summarization
phase begins by summarizing each frame into a set of bottleneck tokens, which
are then efficiently aggregated in the video-level summarization step to
exchange the global cross-modal temporal context. For reasoning part, EventRR
extracts semantic eventful structure of a video-referring expression into
highly expressive Referential Event Graph (REG), which is a single-rooted
directed acyclic graph. Guided by topological traversal of REG, we propose
Temporal Concept-Role Reasoning (TCRR) to accumulate the referring score of
each temporal query from REG leaf nodes to root node. Each reasoning step can
be interpreted as a question-answer pair derived from the concept-role
relations in REG. Extensive experiments across four widely recognized benchmark
datasets, show that EventRR quantitatively and qualitatively outperforms
state-of-the-art RVOS methods. Code is available at
https://github.com/bio-mlhui/EventRR

</details>


### [80] [Similarity Matters: A Novel Depth-guided Network for Image Restoration and A New Dataset](https://arxiv.org/abs/2508.07211)
*Junyi He,Liuling Chen,Hongyang Zhou,Zhang xiaoxing,Xiaobin Zhu,Shengxiang Yu,Jingyan Qin,Xu-Cheng Yin*

Main category: cs.CV

TL;DR: 提出了一种基于深度引导的图像修复网络（DGN），利用深度信息提升修复质量，并通过新数据集验证其效果。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法常忽略深度信息，导致相似性匹配问题、注意力分散或背景过度增强。

Method: 设计双分支网络（深度估计分支和修复分支），结合窗口自注意力和稀疏非局部注意力，并通过联合训练优化。

Result: 在标准基准测试中达到最优性能，对新植物图像也有良好泛化能力。

Conclusion: 深度引导显著提升图像修复质量，新数据集支持了方法的有效性和鲁棒性。

Abstract: Image restoration has seen substantial progress in recent years. However,
existing methods often neglect depth information, which hurts similarity
matching, results in attention distractions in shallow depth-of-field (DoF)
scenarios, and excessive enhancement of background content in deep DoF
settings. To overcome these limitations, we propose a novel Depth-Guided
Network (DGN) for image restoration, together with a novel large-scale
high-resolution dataset. Specifically, the network consists of two interactive
branches: a depth estimation branch that provides structural guidance, and an
image restoration branch that performs the core restoration task. In addition,
the image restoration branch exploits intra-object similarity through
progressive window-based self-attention and captures inter-object similarity
via sparse non-local attention. Through joint training, depth features
contribute to improved restoration quality, while the enhanced visual features
from the restoration branch in turn help refine depth estimation. Notably, we
also introduce a new dataset for training and evaluation, consisting of 9,205
high-resolution images from 403 plant species, with diverse depth and texture
variations. Extensive experiments show that our method achieves
state-of-the-art performance on several standard benchmarks and generalizes
well to unseen plant images, demonstrating its effectiveness and robustness.

</details>


### [81] [Unsupervised Real-World Super-Resolution via Rectified Flow Degradation Modelling](https://arxiv.org/abs/2508.07214)
*Hongyang Zhou,Xiaobin Zhu,Liuling Chen,Junyi He,Jingyan Qin,Xu-Cheng Yin,Zhang xiaoxing*

Main category: cs.CV

TL;DR: 提出了一种基于修正流的无监督真实世界超分辨率方法，通过创新的降解模块和傅里叶先验增强降解建模，显著提升了超分辨率性能。


<details>
  <summary>Details</summary>
Motivation: 解决无监督真实世界超分辨率中因复杂未知降解分布导致的泛化问题。

Method: 结合修正流降解模块（RFDM）和傅里叶先验引导降解模块（FGDM），合成具有真实降解的低分辨率图像用于训练。

Result: 在真实世界数据集上的实验表明，该方法显著提升了现有超分辨率方法的性能。

Conclusion: 提出的方法有效建模真实世界降解，为无监督超分辨率提供了新方向。

Abstract: Unsupervised real-world super-resolution (SR) faces critical challenges due
to the complex, unknown degradation distributions in practical scenarios.
Existing methods struggle to generalize from synthetic low-resolution (LR) and
high-resolution (HR) image pairs to real-world data due to a significant domain
gap. In this paper, we propose an unsupervised real-world SR method based on
rectified flow to effectively capture and model real-world degradation,
synthesizing LR-HR training pairs with realistic degradation. Specifically,
given unpaired LR and HR images, we propose a novel Rectified Flow Degradation
Module (RFDM) that introduces degradation-transformed LR (DT-LR) images as
intermediaries. By modeling the degradation trajectory in a continuous and
invertible manner, RFDM better captures real-world degradation and enhances the
realism of generated LR images. Additionally, we propose a Fourier Prior Guided
Degradation Module (FGDM) that leverages structural information embedded in
Fourier phase components to ensure more precise modeling of real-world
degradation. Finally, the LR images are processed by both FGDM and RFDM,
producing final synthetic LR images with real-world degradation. The synthetic
LR images are paired with the given HR images to train the off-the-shelf SR
networks. Extensive experiments on real-world datasets demonstrate that our
method significantly enhances the performance of existing SR approaches in
real-world scenarios.

</details>


### [82] [Bridging Semantic Logic Gaps: A Cognition-Inspired Multimodal Boundary-Preserving Network for Image Manipulation Localization](https://arxiv.org/abs/2508.07216)
*Songlin Li,Zhiqing Guo,Yuanman Li,Zeyu Li,Yunfeng Diao,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 提出了一种基于认知启发的多模态边界保留网络（CMB-Net），通过结合视觉和文本信息，提高图像篡改定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有图像篡改定位（IML）模型依赖视觉线索，忽略内容特征的语义逻辑关系。真实图像的语义通常符合人类认知规律，而篡改会破坏这种关系，留下语义线索。

Method: 利用大语言模型（LLMs）分析篡改区域并生成文本信息；提出图像-文本中心模糊模块（ITCAM）量化模糊性以加权文本特征；图像-文本交互模块（ITIM）对齐视觉和文本特征；提出还原边缘解码器（RED）保留边界信息。

Result: 实验表明CMB-Net性能优于多数现有IML模型。

Conclusion: CMB-Net通过多模态信息融合和边界保留技术，显著提升了图像篡改定位的准确性和鲁棒性。

Abstract: The existing image manipulation localization (IML) models mainly relies on
visual cues, but ignores the semantic logical relationships between content
features. In fact, the content semantics conveyed by real images often conform
to human cognitive laws. However, image manipulation technology usually
destroys the internal relationship between content features, thus leaving
semantic clues for IML. In this paper, we propose a cognition-inspired
multimodal boundary-preserving network (CMB-Net). Specifically, CMB-Net
utilizes large language models (LLMs) to analyze manipulated regions within
images and generate prompt-based textual information to compensate for the lack
of semantic relationships in the visual information. Considering that the
erroneous texts induced by hallucination from LLMs will damage the accuracy of
IML, we propose an image-text central ambiguity module (ITCAM). It assigns
weights to the text features by quantifying the ambiguity between text and
image features, thereby ensuring the beneficial impact of textual information.
We also propose an image-text interaction module (ITIM) that aligns visual and
text features using a correlation matrix for fine-grained interaction. Finally,
inspired by invertible neural networks, we propose a restoration edge decoder
(RED) that mutually generates input and output features to preserve boundary
information in manipulated regions without loss. Extensive experiments show
that CMB-Net outperforms most existing IML models.

</details>


### [83] [Generic Calibration: Pose Ambiguity/Linear Solution and Parametric-hybrid Pipeline](https://arxiv.org/abs/2508.07217)
*Yuqi Han,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种混合标定方法，结合通用和参数化模型，解决了传统标定中因模型选择不当或复杂过程导致的问题，并通过线性求解器和非线性优化消除了姿态模糊性，显著提高了标定精度。


<details>
  <summary>Details</summary>
Motivation: 离线相机标定技术通常依赖于参数化或通用相机模型。参数化模型的选择需要用户经验，不当选择会影响标定精度；通用方法则过程复杂且无法提供传统内参。本文旨在解决这些局限性。

Method: 提出线性求解器和非线性优化解决通用标定中的姿态模糊性问题，并开发了混合标定方法，结合通用和参数化模型的优势。

Result: 仿真和真实实验表明，混合标定方法在各种镜头类型和噪声环境下均表现优异。

Conclusion: 混合标定方法既提高了通用标定的外参精度，又避免了参数化标定的过拟合和数值不稳定问题，为复杂场景下的相机标定提供了可靠解决方案。

Abstract: Offline camera calibration techniques typically employ parametric or generic
camera models. Selecting parametric models relies heavily on user experience,
and an inappropriate camera model can significantly affect calibration
accuracy. Meanwhile, generic calibration methods involve complex procedures and
cannot provide traditional intrinsic parameters. This paper reveals a pose
ambiguity in the pose solutions of generic calibration methods that
irreversibly impacts subsequent pose estimation. A linear solver and a
nonlinear optimization are proposed to address this ambiguity issue. Then a
global optimization hybrid calibration method is introduced to integrate
generic and parametric models together, which improves extrinsic parameter
accuracy of generic calibration and mitigates overfitting and numerical
instability in parametric calibration. Simulation and real-world experimental
results demonstrate that the generic-parametric hybrid calibration method
consistently excels across various lens types and noise contamination,
hopefully serving as a reliable and accurate solution for camera calibration in
complex scenarios.

</details>


### [84] [Landmark Guided Visual Feature Extractor for Visual Speech Recognition with Limited Resource](https://arxiv.org/abs/2508.07233)
*Lei Yang,Junshan Jin,Mingyuan Zhang,Yi He,Bofan Chen,Shilin Wang*

Main category: cs.CV

TL;DR: 提出了一种基于面部关键点的视觉特征提取方法，通过融合时空特征，提高有限数据下的视觉语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在视觉语音识别中易受视觉干扰（如光照、皮肤纹理）影响，且需大量数据和计算资源。

Method: 利用面部关键点辅助训练视觉特征提取器，设计时空多图卷积网络和唇部动态多级融合框架。

Result: 实验表明，该方法在有限数据下表现优异，并提升了对未见过的说话者的识别准确率。

Conclusion: 结合面部关键点的时空特征提取方法能有效提升视觉语音识别的鲁棒性和准确性。

Abstract: Visual speech recognition is a technique to identify spoken content in silent
speech videos, which has raised significant attention in recent years.
Advancements in data-driven deep learning methods have significantly improved
both the speed and accuracy of recognition. However, these deep learning
methods can be effected by visual disturbances, such as lightning conditions,
skin texture and other user-specific features. Data-driven approaches could
reduce the performance degradation caused by these visual disturbances using
models pretrained on large-scale datasets. But these methods often require
large amounts of training data and computational resources, making them costly.
To reduce the influence of user-specific features and enhance performance with
limited data, this paper proposed a landmark guided visual feature extractor.
Facial landmarks are used as auxiliary information to aid in training the
visual feature extractor. A spatio-temporal multi-graph convolutional network
is designed to fully exploit the spatial locations and spatio-temporal features
of facial landmarks. Additionally, a multi-level lip dynamic fusion framework
is introduced to combine the spatio-temporal features of the landmarks with the
visual features extracted from the raw video frames. Experimental results show
that this approach performs well with limited data and also improves the
model's accuracy on unseen speakers.

</details>


### [85] [ASM-UNet: Adaptive Scan Mamba Integrating Group Commonalities and Individual Variations for Fine-Grained Segmentation](https://arxiv.org/abs/2508.07237)
*Bo Wang,Mengyuan Xu,Yue Yan,Yuqun Yang,Kechen Shu,Wei Ping,Xu Tang,Wei Jiang,Zheng You*

Main category: cs.CV

TL;DR: ASM-UNet提出了一种基于Mamba的新型架构，通过动态扫描顺序改进细粒度分割，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有粗粒度分割方法在临床细粒度分割（FGS）中表现不佳，尤其是个体差异问题。

Method: 结合群体共性和个体差异生成自适应扫描分数，动态指导扫描顺序。

Result: 在ACDC、Synapse和BTMS数据集上表现优异，适用于粗粒度和细粒度任务。

Conclusion: ASM-UNet是一种有效的FGS解决方案，代码和数据集已开源。

Abstract: Precise lesion resection depends on accurately identifying fine-grained
anatomical structures. While many coarse-grained segmentation (CGS) methods
have been successful in large-scale segmentation (e.g., organs), they fall
short in clinical scenarios requiring fine-grained segmentation (FGS), which
remains challenging due to frequent individual variations in small-scale
anatomical structures. Although recent Mamba-based models have advanced medical
image segmentation, they often rely on fixed manually-defined scanning orders,
which limit their adaptability to individual variations in FGS. To address
this, we propose ASM-UNet, a novel Mamba-based architecture for FGS. It
introduces adaptive scan scores to dynamically guide the scanning order,
generated by combining group-level commonalities and individual-level
variations. Experiments on two public datasets (ACDC and Synapse) and a newly
proposed challenging biliary tract FGS dataset, namely BTMS, demonstrate that
ASM-UNet achieves superior performance in both CGS and FGS tasks. Our code and
dataset are available at https://github.com/YqunYang/ASM-UNet.

</details>


### [86] [Consistent and Controllable Image Animation with Motion Linear Diffusion Transformers](https://arxiv.org/abs/2508.07246)
*Xin Ma,Yaohui Wang,Genyun Jia,Xinyuan Chen,Tien-Tsin Wong,Cunjian Chen*

Main category: cs.CV

TL;DR: MiraMo框架通过高效线性注意力、运动残差学习和DCT噪声优化策略，提升了图像动画的效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在图像动画中效率低、外观不一致和运动突变的问题。

Method: 采用线性注意力替换传统自注意力、运动残差学习范式及DCT噪声优化。

Result: 在实验中优于现有方法，生成更一致、平滑且可控的动画。

Conclusion: MiraMo在图像动画领域表现出高效性和多功能性，适用于运动转移和视频编辑。

Abstract: Image animation has seen significant progress, driven by the powerful
generative capabilities of diffusion models. However, maintaining appearance
consistency with static input images and mitigating abrupt motion transitions
in generated animations remain persistent challenges. While text-to-video (T2V)
generation has demonstrated impressive performance with diffusion transformer
models, the image animation field still largely relies on U-Net-based diffusion
models, which lag behind the latest T2V approaches. Moreover, the quadratic
complexity of vanilla self-attention mechanisms in Transformers imposes heavy
computational demands, making image animation particularly resource-intensive.
To address these issues, we propose MiraMo, a framework designed to enhance
efficiency, appearance consistency, and motion smoothness in image animation.
Specifically, MiraMo introduces three key elements: (1) A foundational
text-to-video architecture replacing vanilla self-attention with efficient
linear attention to reduce computational overhead while preserving generation
quality; (2) A novel motion residual learning paradigm that focuses on modeling
motion dynamics rather than directly predicting frames, improving temporal
consistency; and (3) A DCT-based noise refinement strategy during inference to
suppress sudden motion artifacts, complemented by a dynamics control module to
balance motion smoothness and expressiveness. Extensive experiments against
state-of-the-art methods validate the superiority of MiraMo in generating
consistent, smooth, and controllable animations with accelerated inference
speed. Additionally, we demonstrate the versatility of MiraMo through
applications in motion transfer and video editing tasks.

</details>


### [87] [SUIT: Spatial-Spectral Union-Intersection Interaction Network for Hyperspectral Object Tracking](https://arxiv.org/abs/2508.07250)
*Fengchao Xiong,Zhenxing Wu,Sen Jia,Yuntao Qian*

Main category: cs.CV

TL;DR: 该论文提出了一种利用光谱交互提升高光谱视频跟踪性能的方法，通过架构和训练层面的创新，实现了state-of-the-art效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注空间交互，忽略了光谱交互，导致在复杂背景和小目标跟踪中表现不佳。

Method: 在架构层面，使用Transformer建立带间空间长程关系，并基于集合论的包含-排除原则建模光谱交互；在训练层面，引入光谱损失以对齐目标与预测区域的材质分布。

Result: 实验表明，该方法在高光谱视频跟踪任务中达到了最先进的性能。

Conclusion: 通过结合光谱交互与空间交互，显著提升了跟踪精度，特别是在复杂场景下。

Abstract: Hyperspectral videos (HSVs), with their inherent spatial-spectral-temporal
structure, offer distinct advantages in challenging tracking scenarios such as
cluttered backgrounds and small objects. However, existing methods primarily
focus on spatial interactions between the template and search regions, often
overlooking spectral interactions, leading to suboptimal performance. To
address this issue, this paper investigates spectral interactions from both the
architectural and training perspectives. At the architectural level, we first
establish band-wise long-range spatial relationships between the template and
search regions using Transformers. We then model spectral interactions using
the inclusion-exclusion principle from set theory, treating them as the union
of spatial interactions across all bands. This enables the effective
integration of both shared and band-specific spatial cues. At the training
level, we introduce a spectral loss to enforce material distribution alignment
between the template and predicted regions, enhancing robustness to shape
deformation and appearance variations. Extensive experiments demonstrate that
our tracker achieves state-of-the-art tracking performance. The source code,
trained models and results will be publicly available via
https://github.com/bearshng/suit to support reproducibility.

</details>


### [88] [Understanding Dynamic Scenes in Ego Centric 4D Point Clouds](https://arxiv.org/abs/2508.07251)
*Junsheng Huang,Shengyu Hao,Bocheng Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: 论文提出了EgoDynamic4D，一个用于复杂动态场景问答的基准数据集，包含丰富的标注和多维评估任务，并提出了一种新的时空推理框架。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集中缺乏统一4D标注和任务驱动评估的不足，以支持精细的时空推理。

Method: 构建包含RGB-D视频、相机位姿、实例掩码和4D边界框的EgoDynamic4D数据集，设计12种动态QA任务，并提出一个端到端的时空推理框架。

Result: 实验表明提出的方法在EgoDynamic4D上优于基线，验证了多模态时间建模的有效性。

Conclusion: 该研究为动态场景理解提供了新基准和方法，推动了相关领域的发展。

Abstract: Understanding dynamic 4D scenes from an egocentric perspective-modeling
changes in 3D spatial structure over time-is crucial for human-machine
interaction, autonomous navigation, and embodied intelligence. While existing
egocentric datasets contain dynamic scenes, they lack unified 4D annotations
and task-driven evaluation protocols for fine-grained spatio-temporal
reasoning, especially on motion of objects and human, together with their
interactions. To address this gap, we introduce EgoDynamic4D, a novel QA
benchmark on highly dynamic scenes, comprising RGB-D video, camera poses,
globally unique instance masks, and 4D bounding boxes. We construct 927K QA
pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable,
step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering
agent motion, human-object interaction, trajectory prediction, relation
understanding, and temporal-causal reasoning, with fine-grained,
multidimensional metrics. To tackle these tasks, we propose an end-to-end
spatio-temporal reasoning framework that unifies dynamic and static scene
information, using instance-aware feature encoding, time and camera encoding,
and spatially adaptive down-sampling to compress large 4D scenes into token
sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method
consistently outperforms baselines, validating the effectiveness of multimodal
temporal modeling for egocentric dynamic scene understanding.

</details>


### [89] [Small-Large Collaboration: Training-efficient Concept Personalization for Large VLM using a Meta Personalized Small VLM](https://arxiv.org/abs/2508.07260)
*Sihan Yang,Huitong Ji,Shaolin Lu,Jiayi Chen,Binxiao Xu,Ming Lu,Yuanxing Zhang,Wenhui Dong,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出Small-Large Collaboration (SLC)框架，通过小型VLM生成个性化信息，大型VLM整合信息以实现高效个性化应用。


<details>
  <summary>Details</summary>
Motivation: 大型VLMs训练成本高且难以直接个性化，小型VLMs易个性化但缺乏推理能力，SLC旨在解决这一问题。

Method: 采用小型VLM生成个性化信息，大型VLM整合信息，并开发测试时反思策略防止幻觉。

Result: 实验证明SLC在多种基准和大型VLM中有效，且训练高效。

Conclusion: SLC是首个支持开源和闭源大型VLMs的训练高效框架，具有广泛的实际应用前景。

Abstract: Personalizing Vision-Language Models (VLMs) to transform them into daily
assistants has emerged as a trending research direction. However, leading
companies like OpenAI continue to increase model size and develop complex
designs such as the chain of thought (CoT). While large VLMs are proficient in
complex multi-modal understanding, their high training costs and limited access
via paid APIs restrict direct personalization. Conversely, small VLMs are
easily personalized and freely available, but they lack sufficient reasoning
capabilities. Inspired by this, we propose a novel collaborative framework
named Small-Large Collaboration (SLC) for large VLM personalization, where the
small VLM is responsible for generating personalized information, while the
large model integrates this personalized information to deliver accurate
responses. To effectively incorporate personalized information, we develop a
test-time reflection strategy, preventing the potential hallucination of the
small VLM. Since SLC only needs to train a meta personalized small VLM for the
large VLMs, the overall process is training-efficient. To the best of our
knowledge, this is the first training-efficient framework that supports both
open-source and closed-source large VLMs, enabling broader real-world
personalized applications. We conduct thorough experiments across various
benchmarks and large VLMs to demonstrate the effectiveness of the proposed SLC
framework. The code will be released at https://github.com/Hhankyangg/SLC.

</details>


### [90] [OpenHAIV: A Framework Towards Practical Open-World Learning](https://arxiv.org/abs/2508.07270)
*Xiang Xiang,Qinhao Zhou,Zhuo Xu,Jing Ma,Jiaxin Dai,Yifan Liang,Hanlin Li*

Main category: cs.CV

TL;DR: OpenHAIV框架整合了OOD检测、新类发现和增量持续微调，解决了开放世界场景下模型自主知识更新的问题。


<details>
  <summary>Details</summary>
Motivation: 开放世界识别中，现有方法如OOD检测和增量学习存在局限性，无法同时支持知识更新和适应无监督条件。

Method: 提出OpenHAIV框架，将OOD检测、新类发现和增量持续微调结合为统一流程。

Result: 框架使模型能在开放世界环境中自主获取和更新知识。

Conclusion: OpenHAIV为开放世界场景提供了一种有效的解决方案，整合了多种技术以提升模型的适应性。

Abstract: Substantial progress has been made in various techniques for open-world
recognition. Out-of-distribution (OOD) detection methods can effectively
distinguish between known and unknown classes in the data, while incremental
learning enables continuous model knowledge updates. However, in open-world
scenarios, these approaches still face limitations. Relying solely on OOD
detection does not facilitate knowledge updates in the model, and incremental
fine-tuning typically requires supervised conditions, which significantly
deviate from open-world settings. To address these challenges, this paper
proposes OpenHAIV, a novel framework that integrates OOD detection, new class
discovery, and incremental continual fine-tuning into a unified pipeline. This
framework allows models to autonomously acquire and update knowledge in
open-world environments. The proposed framework is available at
https://haiv-lab.github.io/openhaiv .

</details>


### [91] [Representation Understanding via Activation Maximization](https://arxiv.org/abs/2508.07281)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.CV

TL;DR: 该论文提出了一个统一的特征可视化框架，适用于CNN和ViT，并扩展到中间层，以揭示DNN的潜在漏洞和决策边界。


<details>
  <summary>Details</summary>
Motivation: 理解DNN的内部特征表示是实现模型可解释性的关键步骤。

Method: 采用激活最大化（AM）方法，生成能强烈激活人工神经元的输入，并扩展到中间层。

Result: 实验证明该方法在CNN和ViT中均有效，具有普适性和解释价值。

Conclusion: 该框架为DNN的特征表示和潜在漏洞提供了更深层次的见解。

Abstract: Understanding internal feature representations of deep neural networks (DNNs)
is a fundamental step toward model interpretability. Inspired by neuroscience
methods that probe biological neurons using visual stimuli, recent deep
learning studies have employed Activation Maximization (AM) to synthesize
inputs that elicit strong responses from artificial neurons. In this work, we
propose a unified feature visualization framework applicable to both
Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). Unlike
prior efforts that predominantly focus on the last output-layer neurons in
CNNs, we extend feature visualization to intermediate layers as well, offering
deeper insights into the hierarchical structure of learned feature
representations. Furthermore, we investigate how activation maximization can be
leveraged to generate adversarial examples, revealing potential vulnerabilities
and decision boundaries of DNNs. Our experiments demonstrate the effectiveness
of our approach in both traditional CNNs and modern ViT, highlighting its
generalizability and interpretive value.

</details>


### [92] [SynMatch: Rethinking Consistency in Medical Image Segmentation with Sparse Annotations](https://arxiv.org/abs/2508.07298)
*Zhiqiang Shen,Peng Cao,Xiaoli Liu,Jinzhu Yang,Osmar R. Zaiane*

Main category: cs.CV

TL;DR: SynMatch通过合成图像与伪标签匹配，避免了改进伪标签的需求，显著提升了医学图像分割的性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习中医学图像分割因标签稀缺和伪标签与图像不一致带来的性能瓶颈。

Method: 提出SynMatch框架，利用分割模型提取的纹理和形状特征合成图像，生成高度一致的合成图像-伪标签对。

Result: 在多种医学图像分割任务中表现优异，尤其是在标注极少的BSL设置下，性能显著优于现有方法。

Conclusion: SynMatch通过合成图像与伪标签的一致匹配，有效提升了标签稀缺场景下的分割性能。

Abstract: Label scarcity remains a major challenge in deep learning-based medical image
segmentation. Recent studies use strong-weak pseudo supervision to leverage
unlabeled data. However, performance is often hindered by inconsistencies
between pseudo labels and their corresponding unlabeled images. In this work,
we propose \textbf{SynMatch}, a novel framework that sidesteps the need for
improving pseudo labels by synthesizing images to match them instead.
Specifically, SynMatch synthesizes images using texture and shape features
extracted from the same segmentation model that generates the corresponding
pseudo labels for unlabeled images. This design enables the generation of
highly consistent synthesized-image-pseudo-label pairs without requiring any
training parameters for image synthesis. We extensively evaluate SynMatch
across diverse medical image segmentation tasks under semi-supervised learning
(SSL), weakly-supervised learning (WSL), and barely-supervised learning (BSL)
settings with increasingly limited annotations. The results demonstrate that
SynMatch achieves superior performance, especially in the most challenging BSL
setting. For example, it outperforms the recent strong-weak pseudo
supervision-based method by 29.71\% and 10.05\% on the polyp segmentation task
with 5\% and 10\% scribble annotations, respectively. The code will be released
at https://github.com/Senyh/SynMatch.

</details>


### [93] [BEVANet: Bilateral Efficient Visual Attention Network for Real-Time Semantic Segmentation](https://arxiv.org/abs/2508.07300)
*Ping-Mao Huang,I-Tien Chao,Ping-Chia Huang,Jia-Wei Liao,Yung-Yu Chuang*

Main category: cs.CV

TL;DR: 提出了BEVANet网络，通过大核注意力机制和双边架构实现实时语义分割，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决实时语义分割中高效架构设计和大感受野捕获的挑战。

Method: 引入大核注意力（LKA）、双边架构、CKS机制、DLKPPM模块和BGAF模块。

Result: 在Cityscapes数据集上达到81.0% mIoU，33 FPS实时性能。

Conclusion: BEVANet在性能和效率上达到领先水平。

Abstract: Real-time semantic segmentation presents the dual challenge of designing
efficient architectures that capture large receptive fields for semantic
understanding while also refining detailed contours. Vision transformers model
long-range dependencies effectively but incur high computational cost. To
address these challenges, we introduce the Large Kernel Attention (LKA)
mechanism. Our proposed Bilateral Efficient Visual Attention Network (BEVANet)
expands the receptive field to capture contextual information and extracts
visual and structural features using Sparse Decomposed Large Separable Kernel
Attentions (SDLSKA). The Comprehensive Kernel Selection (CKS) mechanism
dynamically adapts the receptive field to further enhance performance.
Furthermore, the Deep Large Kernel Pyramid Pooling Module (DLKPPM) enriches
contextual features by synergistically combining dilated convolutions and large
kernel attention. The bilateral architecture facilitates frequent branch
communication, and the Boundary Guided Adaptive Fusion (BGAF) module enhances
boundary delineation by integrating spatial and semantic features under
boundary guidance. BEVANet achieves real-time segmentation at 33 FPS, yielding
79.3% mIoU without pretraining and 81.0% mIoU on Cityscapes after ImageNet
pretraining, demonstrating state-of-the-art performance. The code and model is
available at https://github.com/maomao0819/BEVANet.

</details>


### [94] [DragonFruitQualityNet: A Lightweight Convolutional Neural Network for Real-Time Dragon Fruit Quality Inspection on Mobile Devices](https://arxiv.org/abs/2508.07306)
*Md Zahurul Haquea,Yeahyea Sarker,Muhammed Farhan Sadique Mahi,Syed Jubayer Jaman,Md Robiul Islam*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级CNN模型DragonFruitQualityNet，用于火龙果的实时质量评估，准确率达93.98%，并嵌入移动应用以支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 火龙果需求增长，需高效的质量检测提升生产效率和减少损失。

Method: 使用13,789张火龙果图像数据集训练CNN模型，分类为新鲜、未成熟、成熟和缺陷四类。

Result: 模型准确率达93.98%，优于现有方法，并嵌入移动应用实现实时检测。

Conclusion: 该研究为火龙果质量控制提供了高效、可扩展的AI解决方案，支持数字农业和小农户。

Abstract: Dragon fruit, renowned for its nutritional benefits and economic value, has
experienced rising global demand due to its affordability and local
availability. As dragon fruit cultivation expands, efficient pre- and
post-harvest quality inspection has become essential for improving agricultural
productivity and minimizing post-harvest losses. This study presents
DragonFruitQualityNet, a lightweight Convolutional Neural Network (CNN)
optimized for real-time quality assessment of dragon fruits on mobile devices.
We curated a diverse dataset of 13,789 images, integrating self-collected
samples with public datasets (dataset from Mendeley Data), and classified them
into four categories: fresh, immature, mature, and defective fruits to ensure
robust model training. The proposed model achieves an impressive 93.98%
accuracy, outperforming existing methods in fruit quality classification. To
facilitate practical adoption, we embedded the model into an intuitive mobile
application, enabling farmers and agricultural stakeholders to conduct
on-device, real-time quality inspections. This research provides an accurate,
efficient, and scalable AI-driven solution for dragon fruit quality control,
supporting digital agriculture and empowering smallholder farmers with
accessible technology. By bridging the gap between research and real-world
application, our work advances post-harvest management and promotes sustainable
farming practices.

</details>


### [95] [MCITlib: Multimodal Continual Instruction Tuning Library and Benchmark](https://arxiv.org/abs/2508.07307)
*Haiyang Guo,Fei Zhu,Hongbo Zhao,Fanhu Zeng,Wenzhuo Liu,Shijie Ma,Da-Han Wang,Xu-Yao Zhang*

Main category: cs.CV

TL;DR: 本文介绍了MCITlib，一个用于多模态大语言模型持续指令调优的代码库，旨在促进多模态持续学习的研究。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法在单模态任务上取得成功，但多模态大语言模型的兴起引发了对涉及多模态的持续学习任务的研究需求。

Method: 作者开发了MCITlib，实现了8种多模态持续指令调优算法，并在2个基准测试上进行了系统评估。

Result: MCITlib为多模态持续学习提供了工具，未来将不断更新以反映领域进展。

Conclusion: MCITlib是一个持续演进的代码库，为多模态持续学习研究提供了支持。

Abstract: Continual learning aims to equip AI systems with the ability to continuously
acquire and adapt to new knowledge without forgetting previously learned
information, similar to human learning. While traditional continual learning
methods focusing on unimodal tasks have achieved notable success, the emergence
of Multimodal Large Language Models has brought increasing attention to
Multimodal Continual Learning tasks involving multiple modalities, such as
vision and language. In this setting, models are expected to not only mitigate
catastrophic forgetting but also handle the challenges posed by cross-modal
interactions and coordination. To facilitate research in this direction, we
introduce MCITlib, a comprehensive and constantly evolving code library for
continual instruction tuning of Multimodal Large Language Models. In MCITlib,
we have currently implemented 8 representative algorithms for Multimodal
Continual Instruction Tuning and systematically evaluated them on 2 carefully
selected benchmarks. MCITlib will be continuously updated to reflect advances
in the Multimodal Continual Learning field. The codebase is released at
https://github.com/Ghy0501/MCITlib.

</details>


### [96] [MobileViCLIP: An Efficient Video-Text Model for Mobile Devices](https://arxiv.org/abs/2508.07312)
*Min Yang,Zihan Jia,Zhilin Dai,Sheng Guo,Limin Wang*

Main category: cs.CV

TL;DR: 该论文提出了MobileViCLIP，一种在移动设备上运行的高效视频-文本模型，通过时间结构重参数化和大规模视频-文本数据集训练，实现了快速的推理速度和强大的零样本分类与检索能力。


<details>
  <summary>Details</summary>
Motivation: 当前视频预训练模型多基于高延迟的ViT架构，缺乏针对移动设备的轻量级高效模型。本文旨在填补这一空白，设计一种能够在移动设备上高效运行的视频-文本模型。

Method: 通过将时间结构重参数化引入高效的图像-文本模型，并利用大规模高质量视频-文本数据集进行训练，构建了MobileViCLIP。

Result: MobileViCLIP-Small在移动设备上的推理速度比InternVideo2-L14快55.4倍，比InternVideo2-S14快6.7倍；在零样本检索任务中，性能与InternVideo2-L14相当，并在MSR-VTT上超过InternVideo2-S14 6.9%。

Conclusion: MobileViCLIP是一种高效的视频-文本模型，适合在移动设备上部署，具有快速的推理速度和强大的零样本性能。

Abstract: Efficient lightweight neural networks are with increasing attention due to
their faster reasoning speed and easier deployment on mobile devices. However,
existing video pre-trained models still focus on the common ViT architecture
with high latency, and few works attempt to build efficient architecture on
mobile devices. This paper bridges this gap by introducing temporal structural
reparameterization into an efficient image-text model and training it on a
large-scale high-quality video-text dataset, resulting in an efficient
video-text model that can run on mobile devices with strong zero-shot
classification and retrieval capabilities, termed as MobileViCLIP. In
particular, in terms of inference speed on mobile devices, our
MobileViCLIP-Small is 55.4x times faster than InternVideo2-L14 and 6.7x faster
than InternVideo2-S14. In terms of zero-shot retrieval performance, our
MobileViCLIP-Small obtains similar performance as InternVideo2-L14 and obtains
6.9\% better than InternVideo2-S14 on MSR-VTT. The code is available at
https://github.com/MCG-NJU/MobileViCLIP.

</details>


### [97] [DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding](https://arxiv.org/abs/2508.07313)
*Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li*

Main category: cs.CV

TL;DR: 介绍DocR1模型及其RL框架EviGRPO，用于多页文档理解，通过证据引导和课程学习策略取得卓越效果。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）在多页文档理解中的挑战，包括细粒度视觉理解和多跳推理。

Method: 提出EviGRPO训练框架，结合证据感知奖励机制和两阶段标注流程，构建数据集EviBench和ArxivFullQA。

Result: DocR1在多页任务上达到SOTA性能，同时在单页任务上保持稳定表现。

Conclusion: EviGRPO和DocR1为多页文档理解提供了高效解决方案，证明了RL框架在此领域的潜力。

Abstract: Understanding multi-page documents poses a significant challenge for
multimodal large language models (MLLMs), as it requires fine-grained visual
comprehension and multi-hop reasoning across pages. While prior work has
explored reinforcement learning (RL) for enhancing advanced reasoning in MLLMs,
its application to multi-page document understanding remains underexplored. In
this paper, we introduce DocR1, an MLLM trained with a novel RL framework,
Evidence Page-Guided GRPO (EviGRPO). EviGRPO incorporates an evidence-aware
reward mechanism that promotes a coarse-to-fine reasoning strategy, guiding the
model to first retrieve relevant pages before generating answers. This training
paradigm enables us to build high-quality models with limited supervision. To
support this, we design a two-stage annotation pipeline and a curriculum
learning strategy, based on which we construct two datasets: EviBench, a
high-quality training set with 4.8k examples, and ArxivFullQA, an evaluation
benchmark with 8.6k QA pairs based on scientific papers. Extensive experiments
across a wide range of benchmarks demonstrate that DocR1 achieves
state-of-the-art performance on multi-page tasks, while consistently
maintaining strong results on single-page benchmarks.

</details>


### [98] [RORPCap: Retrieval-based Objects and Relations Prompt for Image Captioning](https://arxiv.org/abs/2508.07318)
*Jinjing Gu,Tianbao Qin,Yuanyuan Pu,Zhengpeng Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于检索的对象和关系提示方法（RORPCap），用于图像描述生成，解决了传统方法中冗余检测信息、GCN构建困难和训练成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述方法依赖对象检测器或结合GCN，存在冗余信息、构建复杂和高成本的问题，RORPCap通过图像-文本检索获取丰富语义信息以解决这些问题。

Method: RORPCap提取图像中的对象和关系词，结合预定义提示模板编码为提示嵌入，设计Mamba映射网络将CLIP图像嵌入快速映射为视觉-文本嵌入，最终结合GPT-2生成描述。

Result: 在MS-COCO数据集上，RORPCap仅需2.6小时训练，CIDEr得分120.5%和SPICE得分22.0%，达到与传统方法相当的性能指标。

Conclusion: RORPCap在训练时间和性能上优于传统方法，展现了作为图像描述生成替代方案的潜力。

Abstract: Image captioning aims to generate natural language descriptions for input
images in an open-form manner. To accurately generate descriptions related to
the image, a critical step in image captioning is to identify objects and
understand their relations within the image. Modern approaches typically
capitalize on object detectors or combine detectors with Graph Convolutional
Network (GCN). However, these models suffer from redundant detection
information, difficulty in GCN construction, and high training costs. To
address these issues, a Retrieval-based Objects and Relations Prompt for Image
Captioning (RORPCap) is proposed, inspired by the fact that image-text
retrieval can provide rich semantic information for input images. RORPCap
employs an Objects and relations Extraction Model to extract object and
relation words from the image. These words are then incorporate into predefined
prompt templates and encoded as prompt embeddings. Next, a Mamba-based mapping
network is designed to quickly map image embeddings extracted by CLIP to
visual-text embeddings. Finally, the resulting prompt embeddings and
visual-text embeddings are concatenated to form textual-enriched feature
embeddings, which are fed into a GPT-2 model for caption generation. Extensive
experiments conducted on the widely used MS-COCO dataset show that the RORPCap
requires only 2.6 hours under cross-entropy loss training, achieving 120.5%
CIDEr score and 22.0% SPICE score on the "Karpathy" test split. RORPCap
achieves comparable performance metrics to detector-based and GCN-based models
with the shortest training time and demonstrates its potential as an
alternative for image captioning.

</details>


### [99] [Planner-Refiner: Dynamic Space-Time Refinement for Vision-Language Alignment in Videos](https://arxiv.org/abs/2508.07330)
*Tuyen Tran,Thao Minh Le,Quang-Hung Le,Truyen Tran*

Main category: cs.CV

TL;DR: Planner-Refiner框架通过迭代优化视觉元素的时空表示来解决视频与语言对齐问题，特别适合复杂语言提示。


<details>
  <summary>Details</summary>
Motivation: 解决视频与语言对齐中语言复杂性、动态交互实体和语义鸿沟的挑战。

Method: 采用Planner和Refiner模块，前者将复杂语言提示分解为短句链，后者逐步优化视觉标记的表示。

Result: 在指代视频对象分割和时间定位任务中表现优异，尤其在处理复杂查询时超越现有方法。

Conclusion: Planner-Refiner有效缩小了视频与语言的语义差距，为复杂语言任务提供了新思路。

Abstract: Vision-language alignment in video must address the complexity of language,
evolving interacting entities, their action chains, and semantic gaps between
language and vision. This work introduces Planner-Refiner, a framework to
overcome these challenges. Planner-Refiner bridges the semantic gap by
iteratively refining visual elements' space-time representation, guided by
language until semantic gaps are minimal. A Planner module schedules language
guidance by decomposing complex linguistic prompts into short sentence chains.
The Refiner processes each short sentence, a noun-phrase and verb-phrase pair,
to direct visual tokens' self-attention across space then time, achieving
efficient single-step refinement. A recurrent system chains these steps,
maintaining refined visual token representations. The final representation
feeds into task-specific heads for alignment generation. We demonstrate
Planner-Refiner's effectiveness on two video-language alignment tasks:
Referring Video Object Segmentation and Temporal Grounding with varying
language complexity. We further introduce a new MeViS-X benchmark to assess
models' capability with long queries. Superior performance versus
state-of-the-art methods on these benchmarks shows the approach's potential,
especially for complex prompts.

</details>


### [100] [CoAR: Concept Injection into Autoregressive Models for Personalized Text-to-Image Generation](https://arxiv.org/abs/2508.07341)
*Fangtai Wu,Mushui Liu,Weijie He,Wanggui He,Hao Jiang,Zhao Wang,Yunlong Yu*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoAR的新框架，用于在保持预训练参数完全冻结的情况下，将主题概念注入统一的自回归模型，以实现高效的定制化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的定制化生成方法通常依赖全微调或适配器，导致成本高且易过拟合或灾难性遗忘，因此需要一种更高效的解决方案。

Method: CoAR通过层间多模态上下文学习策略，仅用极少参数学习主题表示，并通过正则化技术防止过拟合和语言漂移。

Result: 实验表明，CoAR在主题和风格个性化任务上表现出色，同时显著提升了计算和内存效率，仅需调整极少参数即可达到竞争性性能。

Conclusion: CoAR提供了一种高效且性能优越的定制化图像生成方法，解决了现有技术的高成本和过拟合问题。

Abstract: The unified autoregressive (AR) model excels at multimodal understanding and
generation, but its potential for customized image generation remains
underexplored. Existing customized generation methods rely on full fine-tuning
or adapters, making them costly and prone to overfitting or catastrophic
forgetting. In this paper, we propose \textbf{CoAR}, a novel framework for
injecting subject concepts into the unified AR models while keeping all
pre-trained parameters completely frozen. CoAR learns effective, specific
subject representations with only a minimal number of parameters using a
Layerwise Multimodal Context Learning strategy. To address overfitting and
language drift, we further introduce regularization that preserves the
pre-trained distribution and anchors context tokens to improve subject fidelity
and re-contextualization. Additionally, CoAR supports training-free subject
customization in a user-provided style. Experiments demonstrate that CoAR
achieves superior performance on both subject-driven personalization and style
personalization, while delivering significant gains in computational and memory
efficiency. Notably, CoAR tunes less than \textbf{0.05\%} of the parameters
while achieving competitive performance compared to recent Proxy-Tuning. Code:
https://github.com/KZF-kzf/CoAR

</details>


### [101] [SODiff: Semantic-Oriented Diffusion Model for JPEG Compression Artifacts Removal](https://arxiv.org/abs/2508.07346)
*Tingyu Yang,Jue Gong,Jinpei Guo,Wenbo Li,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: SODiff通过语义导向的一步扩散模型有效去除JPEG伪影，结合语义对齐的图像提示提取器和质量因子感知时间预测器，显著提升恢复效果。


<details>
  <summary>Details</summary>
Motivation: JPEG高压缩比会引入严重视觉伪影，现有深度学习方法难以恢复复杂纹理细节，导致输出过于平滑。

Method: 提出SODiff，结合语义对齐的图像提示提取器（SAIPE）和质量因子感知时间预测器，优化扩散模型生成过程。

Result: SODiff在视觉质量和定量指标上优于现有方法。

Conclusion: SODiff为JPEG伪影去除提供了一种高效且语义导向的新方法。

Abstract: JPEG, as a widely used image compression standard, often introduces severe
visual artifacts when achieving high compression ratios. Although existing deep
learning-based restoration methods have made considerable progress, they often
struggle to recover complex texture details, resulting in over-smoothed
outputs. To overcome these limitations, we propose SODiff, a novel and
efficient semantic-oriented one-step diffusion model for JPEG artifacts
removal. Our core idea is that effective restoration hinges on providing
semantic-oriented guidance to the pre-trained diffusion model, thereby fully
leveraging its powerful generative prior. To this end, SODiff incorporates a
semantic-aligned image prompt extractor (SAIPE). SAIPE extracts rich features
from low-quality (LQ) images and projects them into an embedding space
semantically aligned with that of the text encoder. Simultaneously, it
preserves crucial information for faithful reconstruction. Furthermore, we
propose a quality factor-aware time predictor that implicitly learns the
compression quality factor (QF) of the LQ image and adaptively selects the
optimal denoising start timestep for the diffusion process. Extensive
experimental results show that our SODiff outperforms recent leading methods in
both visual quality and quantitative metrics. Code is available at:
https://github.com/frakenation/SODiff

</details>


### [102] [GS4Buildings: Prior-Guided Gaussian Splatting for 3D Building Reconstruction](https://arxiv.org/abs/2508.07355)
*Qilin Zhang,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: 本文提出GS4Buildings，一种基于语义3D建筑模型的先验引导高斯溅射方法，用于高效且鲁棒的建筑物表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有2D高斯溅射方法在大规模和复杂城市场景中表现不佳，导致建筑物重建不完整。

Method: GS4Buildings直接从低级LoD2语义3D建筑模型初始化高斯，并通过从平面建筑几何生成的深度和法线图指导优化过程。

Result: 实验表明，该方法显著提高了重建完整性和几何精度，并在建筑区域减少了71.8%的高斯基元。

Conclusion: 语义建筑模型集成在高斯溅射重建中具有潜力，适用于智慧城市和数字孪生等实际应用。

Abstract: Recent advances in Gaussian Splatting (GS) have demonstrated its
effectiveness in photo-realistic rendering and 3D reconstruction. Among these,
2D Gaussian Splatting (2DGS) is particularly suitable for surface
reconstruction due to its flattened Gaussian representation and integrated
normal regularization. However, its performance often degrades in large-scale
and complex urban scenes with frequent occlusions, leading to incomplete
building reconstructions. We propose GS4Buildings, a novel prior-guided
Gaussian Splatting method leveraging the ubiquity of semantic 3D building
models for robust and scalable building surface reconstruction. Instead of
relying on traditional Structure-from-Motion (SfM) pipelines, GS4Buildings
initializes Gaussians directly from low-level Level of Detail (LoD)2 semantic
3D building models. Moreover, we generate prior depth and normal maps from the
planar building geometry and incorporate them into the optimization process,
providing strong geometric guidance for surface consistency and structural
accuracy. We also introduce an optional building-focused mode that limits
reconstruction to building regions, achieving a 71.8% reduction in Gaussian
primitives and enabling a more efficient and compact representation.
Experiments on urban datasets demonstrate that GS4Buildings improves
reconstruction completeness by 20.5% and geometric accuracy by 32.8%. These
results highlight the potential of semantic building model integration to
advance GS-based reconstruction toward real-world urban applications such as
smart cities and digital twins. Our project is available:
https://github.com/zqlin0521/GS4Buildings.

</details>


### [103] [Training and Inference within 1 Second -- Tackle Cross-Sensor Degradation of Real-World Pansharpening with Efficient Residual Feature Tailoring](https://arxiv.org/abs/2508.07369)
*Tianyu Xin,Jin-Liang Xiao,Zeyu Xia,Shan Yin,Liang-Jian Deng*

Main category: cs.CV

TL;DR: 提出了一种基于特征裁剪的模块化方法，显著提升了跨传感器泛化能力，同时极大降低了训练和推理时间。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型在跨传感器数据上泛化能力差的问题，避免费时的重训练或额外数据需求。

Method: 通过模块化分解提出特征裁剪模块，结合物理感知无监督损失，实现高效训练和并行推理。

Result: 在多个真实数据集上实现了质量和效率的先进水平，训练和推理速度提升了100倍以上。

Conclusion: 该方法显著提升了跨传感器性能且成本极低，为实际应用提供了可行的解决方案。

Abstract: Deep learning methods for pansharpening have advanced rapidly, yet models
pretrained on data from a specific sensor often generalize poorly to data from
other sensors. Existing methods to tackle such cross-sensor degradation include
retraining model or zero-shot methods, but they are highly time-consuming or
even need extra training data. To address these challenges, our method first
performs modular decomposition on deep learning-based pansharpening models,
revealing a general yet critical interface where high-dimensional fused
features begin mapping to the channel space of the final image. % may need
revisement A Feature Tailor is then integrated at this interface to address
cross-sensor degradation at the feature level, and is trained efficiently with
physics-aware unsupervised losses. Moreover, our method operates in a
patch-wise manner, training on partial patches and performing parallel
inference on all patches to boost efficiency. Our method offers two key
advantages: (1) $\textit{Improved Generalization Ability}$: it significantly
enhance performance in cross-sensor cases. (2) $\textit{Low Generalization
Cost}$: it achieves sub-second training and inference, requiring only partial
test inputs and no external data, whereas prior methods often take minutes or
even hours. Experiments on the real-world data from multiple datasets
demonstrate that our method achieves state-of-the-art quality and efficiency in
tackling cross-sensor degradation. For example, training and inference of
$512\times512\times8$ image within $\textit{0.2 seconds}$ and
$4000\times4000\times8$ image within $\textit{3 seconds}$ at the fastest
setting on a commonly used RTX 3090 GPU, which is over 100 times faster than
zero-shot methods.

</details>


### [104] [DIP-GS: Deep Image Prior For Gaussian Splatting Sparse View Recovery](https://arxiv.org/abs/2508.07372)
*Rajaei Khatib,Raja Giryes*

Main category: cs.CV

TL;DR: DIP-GS是一种基于深度图像先验的3D高斯重建方法，显著提升了在稀疏视角下的重建性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯重建（3DGS）在多视角下表现优越，但在稀疏视角重建中表现不佳，因此提出DIP-GS以解决这一问题。

Method: 利用深度图像先验（DIP）结合3DGS，通过由粗到细的方式学习场景表示，无需预训练模型。

Result: DIP-GS在稀疏视角重建任务中达到SOTA水平，展示了其强大能力。

Conclusion: DIP-GS通过DIP先验显著提升了3DGS在稀疏视角下的性能，且无需依赖外部预训练模型。

Abstract: 3D Gaussian Splatting (3DGS) is a leading 3D scene reconstruction method,
obtaining high-quality reconstruction with real-time rendering runtime
performance. The main idea behind 3DGS is to represent the scene as a
collection of 3D gaussians, while learning their parameters to fit the given
views of the scene. While achieving superior performance in the presence of
many views, 3DGS struggles with sparse view reconstruction, where the input
views are sparse and do not fully cover the scene and have low overlaps. In
this paper, we propose DIP-GS, a Deep Image Prior (DIP) 3DGS representation. By
using the DIP prior, which utilizes internal structure and patterns, with
coarse-to-fine manner, DIP-based 3DGS can operate in scenarios where vanilla
3DGS fails, such as sparse view recovery. Note that our approach does not use
any pre-trained models such as generative models and depth estimation, but
rather relies only on the input frames. Among such methods, DIP-GS obtains
state-of-the-art (SOTA) competitive results on various sparse-view
reconstruction tasks, demonstrating its capabilities.

</details>


### [105] [LET-US: Long Event-Text Understanding of Scenes](https://arxiv.org/abs/2508.07401)
*Rui Chen,Xingyu Chen,Shaoan Wang,Shihan Kong,Junzhi Yu*

Main category: cs.CV

TL;DR: LET-US是一种用于长事件流-文本理解的框架，通过自适应压缩减少输入事件量，同时保留关键视觉细节，实现了跨模态推断理解的新突破。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs虽在RGB视频内容理解上成功，但对事件流的解释能力不足或限于短序列。LET-US旨在填补这一空白。

Method: 采用两阶段优化范式，结合文本引导的跨模态查询和分层聚类，减少时序信息量。构建大规模事件-文本对齐数据集训练模型。

Result: 实验显示，LET-US在长事件流的描述准确性和语义理解上优于现有MLLMs。

Conclusion: LET-US为长事件流与文本的跨模态理解开辟了新方向，具有广泛应用潜力。

Abstract: Event cameras output event streams as sparse, asynchronous data with
microsecond-level temporal resolution, enabling visual perception with low
latency and a high dynamic range. While existing Multimodal Large Language
Models (MLLMs) have achieved significant success in understanding and analyzing
RGB video content, they either fail to interpret event streams effectively or
remain constrained to very short sequences. In this paper, we introduce LET-US,
a framework for long event-stream--text comprehension that employs an adaptive
compression mechanism to reduce the volume of input events while preserving
critical visual details. LET-US thus establishes a new frontier in cross-modal
inferential understanding over extended event sequences. To bridge the
substantial modality gap between event streams and textual representations, we
adopt a two-stage optimization paradigm that progressively equips our model
with the capacity to interpret event-based scenes. To handle the voluminous
temporal information inherent in long event streams, we leverage text-guided
cross-modal queries for feature reduction, augmented by hierarchical clustering
and similarity computation to distill the most representative event features.
Moreover, we curate and construct a large-scale event-text aligned dataset to
train our model, achieving tighter alignment of event features within the LLM
embedding space. We also develop a comprehensive benchmark covering a diverse
set of tasks -- reasoning, captioning, classification, temporal localization
and moment retrieval. Experimental results demonstrate that LET-US outperforms
prior state-of-the-art MLLMs in both descriptive accuracy and semantic
comprehension on long-duration event streams. All datasets, codes, and models
will be publicly available.

</details>


### [106] [ForensicsSAM: Toward Robust and Unified Image Forgery Detection and Localization Resisting to Adversarial Attack](https://arxiv.org/abs/2508.07402)
*Rongxuan Peng,Shunquan Tan,Chenqi Kong,Anwei Luo,Alex C. Kot,Jiwu Huang*

Main category: cs.CV

TL;DR: ForensicsSAM是一种结合对抗鲁棒性的统一IFDL框架，通过引入伪造专家和对抗专家，提升模型对图像伪造检测和定位的性能，并有效抵抗对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 现有基于PEFT的方法忽视了对抗攻击的脆弱性，本文旨在填补这一空白。

Method: 1) 注入伪造专家以增强模型捕捉伪造痕迹的能力；2) 设计轻量级对抗检测器；3) 注入对抗专家以修正特征偏移。

Result: ForensicsSAM在多个基准测试中表现出卓越的对抗鲁棒性和性能。

Conclusion: ForensicsSAM为图像伪造检测和定位提供了高效且鲁棒的解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) has emerged as a popular strategy for
adapting large vision foundation models, such as the Segment Anything Model
(SAM) and LLaVA, to downstream tasks like image forgery detection and
localization (IFDL). However, existing PEFT-based approaches overlook their
vulnerability to adversarial attacks. In this paper, we show that highly
transferable adversarial images can be crafted solely via the upstream model,
without accessing the downstream model or training data, significantly
degrading the IFDL performance. To address this, we propose ForensicsSAM, a
unified IFDL framework with built-in adversarial robustness. Our design is
guided by three key ideas: (1) To compensate for the lack of forgery-relevant
knowledge in the frozen image encoder, we inject forgery experts into each
transformer block to enhance its ability to capture forgery artifacts. These
forgery experts are always activated and shared across any input images. (2) To
detect adversarial images, we design an light-weight adversary detector that
learns to capture structured, task-specific artifact in RGB domain, enabling
reliable discrimination across various attack methods. (3) To resist
adversarial attacks, we inject adversary experts into the global attention
layers and MLP modules to progressively correct feature shifts induced by
adversarial noise. These adversary experts are adaptively activated by the
adversary detector, thereby avoiding unnecessary interference with clean
images. Extensive experiments across multiple benchmarks demonstrate that
ForensicsSAM achieves superior resistance to various adversarial attack
methods, while also delivering state-of-the-art performance in image-level
forgery detection and pixel-level forgery localization. The resource is
available at https://github.com/siriusPRX/ForensicsSAM.

</details>


### [107] [CharacterShot: Controllable and Consistent 4D Character Animation](https://arxiv.org/abs/2508.07409)
*Junyao Gao,Jiaxing Li,Wenran Liu,Yanhong Zeng,Fei Shen,Kai Chen,Yanan Sun,Cairong Zhao*

Main category: cs.CV

TL;DR: CharacterShot是一个可控且一致的4D角色动画框架，支持从单个参考角色图像和2D姿势序列创建动态3D角色。


<details>
  <summary>Details</summary>
Motivation: 为解决设计师从2D图像和姿势序列生成动态3D角色的需求，同时保证动画的时空一致性和稳定性。

Method: 1. 预训练基于DiT的2D动画模型；2. 通过双注意力模块和相机先验将2D提升到3D；3. 使用邻域约束的4D高斯溅射优化生成4D角色。

Result: 在新构建的CharacterBench基准测试中，方法优于当前最先进技术。

Conclusion: CharacterShot为4D角色动画提供了高效解决方案，并公开了代码、模型和数据集。

Abstract: In this paper, we propose \textbf{CharacterShot}, a controllable and
consistent 4D character animation framework that enables any individual
designer to create dynamic 3D characters (i.e., 4D character animation) from a
single reference character image and a 2D pose sequence. We begin by
pretraining a powerful 2D character animation model based on a cutting-edge
DiT-based image-to-video model, which allows for any 2D pose sequnce as
controllable signal. We then lift the animation model from 2D to 3D through
introducing dual-attention module together with camera prior to generate
multi-view videos with spatial-temporal and spatial-view consistency. Finally,
we employ a novel neighbor-constrained 4D gaussian splatting optimization on
these multi-view videos, resulting in continuous and stable 4D character
representations. Moreover, to improve character-centric performance, we
construct a large-scale dataset Character4D, containing 13,115 unique
characters with diverse appearances and motions, rendered from multiple
viewpoints. Extensive experiments on our newly constructed benchmark,
CharacterBench, demonstrate that our approach outperforms current
state-of-the-art methods. Code, models, and datasets will be publicly available
at https://github.com/Jeoyal/CharacterShot.

</details>


### [108] [CLUE: Leveraging Low-Rank Adaptation to Capture Latent Uncovered Evidence for Image Forgery Localization](https://arxiv.org/abs/2508.07413)
*Youqi Wang,Shunquan Tan,Rongxuan Peng,Bin Li,Jiwu Huang*

Main category: cs.CV

TL;DR: CLUE框架通过改造Stable Diffusion 3和Segment Anything Model，高效定位数字媒体伪造痕迹，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着图像编辑工具和生成AI的普及，数字媒体的真实性受到威胁，需要更高效的伪造定位技术。

Method: 结合SD3的噪声注入机制和LoRA调校去噪过程，利用SAM模型的高层语义和空间细节，开发CLUE框架。

Result: CLUE在泛化性能和抗攻击能力上显著优于现有方法，尤其在处理常见后处理攻击和社交网络图像时表现优异。

Conclusion: CLUE为数字媒体真实性验证提供了高效、鲁棒的解决方案，代码已开源。

Abstract: The increasing accessibility of image editing tools and generative AI has led
to a proliferation of visually convincing forgeries, compromising the
authenticity of digital media. In this paper, in addition to leveraging
distortions from conventional forgeries, we repurpose the mechanism of a
state-of-the-art (SOTA) text-to-image synthesis model by exploiting its
internal generative process, turning it into a high-fidelity forgery
localization tool. To this end, we propose CLUE (Capture Latent Uncovered
Evidence), a framework that employs Low- Rank Adaptation (LoRA) to
parameter-efficiently reconfigure Stable Diffusion 3 (SD3) as a forensic
feature extractor. Our approach begins with the strategic use of SD3's
Rectified Flow (RF) mechanism to inject noise at varying intensities into the
latent representation, thereby steering the LoRAtuned denoising process to
amplify subtle statistical inconsistencies indicative of a forgery. To
complement the latent analysis with high-level semantic context and precise
spatial details, our method incorporates contextual features from the image
encoder of the Segment Anything Model (SAM), which is parameter-efficiently
adapted to better trace the boundaries of forged regions. Extensive evaluations
demonstrate CLUE's SOTA generalization performance, significantly outperforming
prior methods. Furthermore, CLUE shows superior robustness against common
post-processing attacks and Online Social Networks (OSNs). Code is publicly
available at https://github.com/SZAISEC/CLUE.

</details>


### [109] [Freeze and Reveal: Exposing Modality Bias in Vision-Language Models](https://arxiv.org/abs/2508.07432)
*Vivek Hruday Kavuri,Vysishtya Karanam,Venkata Jahnavi Venkamsetty,Kriti Madumadukala,Lakshmipathi Balaji Darur,Ponnurangam Kumaraguru*

Main category: cs.CV

TL;DR: 论文分析了视觉语言模型中的性别偏见来源，提出通过数据增强和任务向量方法减少偏见，并引入新指标DAUDoS。实验表明，视觉编码器（如CLIP）和文本编码器（如PaliGemma2）的偏见程度不同，为未来多模态系统的偏见缓解提供了针对性方法。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在训练数据中可能继承性别偏见，论文旨在分解视觉和文本模态对偏见的贡献，并提出高效的去偏方法。

Method: 使用反事实数据增强（CDA）和任务向量方法进行偏见缓解，并引入新指标DAUDoS和数据增强方法以减少计算成本。

Result: CDA减少性别偏见6%，DAUDoS减少3%且仅需1/3数据。模型对性别识别的准确性提高3%。CLIP的视觉编码器和PaliGemma2的文本编码器是主要偏见来源。

Conclusion: 通过识别偏见的来源（视觉或文本编码器），论文为未来多模态系统提供了更有针对性的偏见缓解策略。

Abstract: Vision Language Models achieve impressive multi-modal performance but often
inherit gender biases from their training data. This bias might be coming from
both the vision and text modalities. In this work, we dissect the contributions
of vision and text backbones to these biases by applying targeted debiasing
using Counterfactual Data Augmentation and Task Vector methods. Inspired by
data-efficient approaches in hate-speech classification, we introduce a novel
metric, Degree of Stereotypicality and a corresponding debiasing method, Data
Augmentation Using Degree of Stereotypicality - DAUDoS, to reduce bias with
minimal computational cost. We curate a gender annotated dataset and evaluate
all methods on VisoGender benchmark to quantify improvements and identify
dominant source of bias. Our results show that CDA reduces the gender gap by 6%
and DAUDoS by 3% but using only one-third of the data. Both methods also
improve the model's ability to correctly identify gender in images by 3%, with
DAUDoS achieving this improvement using only almost one-third of training data.
From our experiment's, we observed that CLIP's vision encoder is more biased
whereas PaliGemma2's text encoder is more biased. By identifying whether bias
stems more from vision or text encoders, our work enables more targeted and
effective bias mitigation strategies in future multi-modal systems.

</details>


### [110] [Levarging Learning Bias for Noisy Anomaly Detection](https://arxiv.org/abs/2508.07441)
*Yuxin Zhang,Yunkang Cao,Yuqi Cheng,Yihan Sun,Weiming Shen*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段框架，旨在解决训练数据中可能包含未标记异常的全无监督图像异常检测问题，通过利用模型的学习偏置来过滤净化数据集，并在多种噪声条件下展示了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 由于现实世界中的数据可能存在异常污染，传统方法在异常训练数据假设下的性能下降。作者希望通过利用模型的学习偏置来克服这一问题。

Method: 提出两阶段框架：第一阶段利用学习偏置（正常样本的统计优势和特征空间发散性）训练子模型并过滤异常；第二阶段在净化后的数据集上训练最终检测器。

Result: 在Real-IAD基准测试中，该方法在不同噪声条件下表现出优越的异常检测和定位性能，并通过消融实验验证了其抗污染能力。

Conclusion: 该模型无关的设计适用于多种无监督骨干网络，为解决实际场景中不完美的训练数据提供了实用方案。

Abstract: This paper addresses the challenge of fully unsupervised image anomaly
detection (FUIAD), where training data may contain unlabeled anomalies.
Conventional methods assume anomaly-free training data, but real-world
contamination leads models to absorb anomalies as normal, degrading detection
performance. To mitigate this, we propose a two-stage framework that
systematically exploits inherent learning bias in models. The learning bias
stems from: (1) the statistical dominance of normal samples, driving models to
prioritize learning stable normal patterns over sparse anomalies, and (2)
feature-space divergence, where normal data exhibit high intra-class
consistency while anomalies display high diversity, leading to unstable model
responses. Leveraging the learning bias, stage 1 partitions the training set
into subsets, trains sub-models, and aggregates cross-model anomaly scores to
filter a purified dataset. Stage 2 trains the final detector on this dataset.
Experiments on the Real-IAD benchmark demonstrate superior anomaly detection
and localization performance under different noise conditions. Ablation studies
further validate the framework's contamination resilience, emphasizing the
critical role of learning bias exploitation. The model-agnostic design ensures
compatibility with diverse unsupervised backbones, offering a practical
solution for real-world scenarios with imperfect training data. Code is
available at https://github.com/hustzhangyuxin/LLBNAD.

</details>


### [111] [Health Care Waste Classification Using Deep Learning Aligned with Nepal's Bin Color Guidelines](https://arxiv.org/abs/2508.07450)
*Suman Kunwar,Prabesh Rai*

Main category: cs.CV

TL;DR: 研究比较了多种医疗废物分类模型的性能，发现YOLOv5-s在准确率上表现最佳（95.06%），但稍逊于YOLOv8-n的推理速度。EfficientNet-B0准确率为93.22%，但推理时间最长。模型已根据尼泊尔标准部署到网络供公众使用。


<details>
  <summary>Details</summary>
Motivation: 尼泊尔医疗设施的增加导致医疗废物管理问题日益严重，不当的处理可能引发污染和疾病传播，因此需要高效准确的废物分类方法。

Method: 采用分层K折技术（5折）对比ResNeXt-50、EfficientNet-B0、MobileNetV3-S、YOLOv8-n和YOLOv5-s模型，并通过重复ANOVA验证统计显著性。

Result: YOLOv5-s准确率最高（95.06%），EfficientNet-B0次之（93.22%），但推理时间最长。最佳模型已部署到网络。

Conclusion: YOLOv5-s是医疗废物分类的高效模型，未来需进一步优化数据并考虑本地化需求。

Abstract: The increasing number of Health Care facilities in Nepal has also added up
the challenges on managing health care waste (HCW). Improper segregation and
disposal of HCW leads to the contamination, spreading of infectious diseases
and puts a risk of waste handlers. This study benchmarks the state of the art
waste classification models: ResNeXt-50, EfficientNet-B0, MobileNetV3-S,
YOLOv8-n and YOLOv5-s using Stratified K-fold techniques where we use 5 folds
on combined HCW data, and found that the YOLOv5-s achieved higher of 95.06%
accuracy but fell short few milliseconds in inference speed with YOLOv8-n
model. The EfficientNet-B0 showed promising results of 93.22% accuracy but took
the highest inference time. A repetitive ANOVA was performed to see statistical
significance and the best performing model (YOLOv5-s) was deployed to the web
with mapped bin color using Nepal's HCW management standards for public usage.
Further work on the data was suggested along with localized context.

</details>


### [112] [AURA: A Fine-Grained Benchmark and Decomposed Metric for Audio-Visual Reasoning](https://arxiv.org/abs/2508.07470)
*Siminfar Samakoush Galougah,Rishie Raj,Sanjoy Chowdhury,Sayan Nag,Ramani Duraiswami*

Main category: cs.CV

TL;DR: AURA引入了一个多模态认知评估基准，专门针对AV-LLMs和OLMs的跨模态推理能力，弥补了现有基准忽视推理过程的不足，并提出了AuraScore以量化推理的真实性和逻辑性。


<details>
  <summary>Details</summary>
Motivation: 现有音频-视觉基准仅关注答案准确性，而忽略了推理过程，无法区分模型是否通过错误推理获得正确答案。

Method: AURA包含六个认知领域的挑战性问题，强制模型基于音频和视频构建逻辑路径，并提出AuraScore评估推理的真实性和逻辑性。

Result: 实验表明，SOTA模型在AURA上的准确性虽高（约92%），但推理真实性和逻辑性得分低于45%，揭示其推理缺陷。

Conclusion: AURA填补了多模态评估的空白，为未来更强大的多模态模型提供了评测标准。

Abstract: Current audio-visual (AV) benchmarks focus on final answer accuracy,
overlooking the underlying reasoning process. This makes it difficult to
distinguish genuine comprehension from correct answers derived through flawed
reasoning or hallucinations. To address this, we introduce AURA (Audio-visual
Understanding and Reasoning Assessment), a benchmark for evaluating the
cross-modal reasoning capabilities of Audio-Visual Large Language Models
(AV-LLMs) and Omni-modal Language Models (OLMs). AURA includes questions across
six challenging cognitive domains, such as causality, timbre and pitch, tempo
and AV synchronization, unanswerability, implicit distractions, and skill
profiling, explicitly designed to be unanswerable from a single modality. This
forces models to construct a valid logical path grounded in both audio and
video, setting AURA apart from AV datasets that allow uni-modal shortcuts. To
assess reasoning traces, we propose a novel metric, AuraScore, which addresses
the lack of robust tools for evaluating reasoning fidelity. It decomposes
reasoning into two aspects: (i) Factual Consistency - whether reasoning is
grounded in perceptual evidence, and (ii) Core Inference - the logical validity
of each reasoning step. Evaluations of SOTA models on AURA reveal a critical
reasoning gap: although models achieve high accuracy (up to 92% on some tasks),
their Factual Consistency and Core Inference scores fall below 45%. This
discrepancy highlights that models often arrive at correct answers through
flawed logic, underscoring the need for our benchmark and paving the way for
more robust multimodal evaluation.

</details>


### [113] [Novel View Synthesis with Gaussian Splatting: Impact on Photogrammetry Model Accuracy and Resolution](https://arxiv.org/abs/2508.07483)
*Pranav Chougule*

Main category: cs.CV

TL;DR: 比较Photogrammetry和Gaussian Splatting技术在3D模型重建和视图合成中的表现，通过多种指标评估并改进Gaussian Splatting方法。


<details>
  <summary>Details</summary>
Motivation: 研究两种技术的优劣，提升3D重建质量，为XR、摄影测量和自动驾驶仿真提供支持。

Method: 构建数据集，使用两种方法生成3D模型，通过SSIM、PSNR等指标评估性能，改进Gaussian Splatting以渲染新视角。

Result: Gaussian Splatting在生成高质量新视角方面表现优秀，并能提升Photogrammetry的重建效果。

Conclusion: 研究展示了两种技术的潜力与局限，为相关应用提供了实用参考。

Abstract: In this paper, I present a comprehensive study comparing Photogrammetry and
Gaussian Splatting techniques for 3D model reconstruction and view synthesis. I
created a dataset of images from a real-world scene and constructed 3D models
using both methods. To evaluate the performance, I compared the models using
structural similarity index (SSIM), peak signal-to-noise ratio (PSNR), learned
perceptual image patch similarity (LPIPS), and lp/mm resolution based on the
USAF resolution chart. A significant contribution of this work is the
development of a modified Gaussian Splatting repository, which I forked and
enhanced to enable rendering images from novel camera poses generated in the
Blender environment. This innovation allows for the synthesis of high-quality
novel views, showcasing the flexibility and potential of Gaussian Splatting. My
investigation extends to an augmented dataset that includes both original
ground images and novel views synthesized via Gaussian Splatting. This
augmented dataset was employed to generate a new photogrammetry model, which
was then compared against the original photogrammetry model created using only
the original images. The results demonstrate the efficacy of using Gaussian
Splatting to generate novel high-quality views and its potential to improve
photogrammetry-based 3D reconstructions. The comparative analysis highlights
the strengths and limitations of both approaches, providing valuable
information for applications in extended reality (XR), photogrammetry, and
autonomous vehicle simulations. Code is available at
https://github.com/pranavc2255/gaussian-splatting-novel-view-render.git.

</details>


### [114] [VisR-Bench: An Empirical Study on Visual Retrieval-Augmented Generation for Multilingual Long Document Understanding](https://arxiv.org/abs/2508.07493)
*Jian Chen,Ming Li,Jihyung Kil,Chenguang Wang,Tong Yu,Ryan Rossi,Tianyi Zhou,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: VisR-Bench是一个多语言基准测试，用于长文档中的多模态检索，包含超过35K QA对和16种语言，评估了多种检索模型的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要集中在英文文档检索或单页图像的多语言问答，缺乏对多语言长文档的视觉检索评估。

Method: 引入VisR-Bench基准测试，包含1.2K文档和35K QA对，涵盖16种语言和多种问题类型。

Result: MLLMs表现优于基于文本和多模态编码器的模型，但在结构化表格和低资源语言上仍有挑战。

Conclusion: VisR-Bench填补了多语言长文档视觉检索的空白，并揭示了模型的局限性。

Abstract: Most organizational data in this world are stored as documents, and visual
retrieval plays a crucial role in unlocking the collective intelligence from
all these documents. However, existing benchmarks focus on English-only
document retrieval or only consider multilingual question-answering on a
single-page image. To bridge this gap, we introduce VisR-Bench, a multilingual
benchmark designed for question-driven multimodal retrieval in long documents.
Our benchmark comprises over 35K high-quality QA pairs across 1.2K documents,
enabling fine-grained evaluation of multimodal retrieval. VisR-Bench spans
sixteen languages with three question types (figures, text, and tables),
offering diverse linguistic and question coverage. Unlike prior datasets, we
include queries without explicit answers, preventing models from relying on
superficial keyword matching. We evaluate various retrieval models, including
text-based methods, multimodal encoders, and MLLMs, providing insights into
their strengths and limitations. Our results show that while MLLMs
significantly outperform text-based and multimodal encoder models, they still
struggle with structured tables and low-resource languages, highlighting key
challenges in multilingual visual retrieval.

</details>


### [115] [FormCoach: Lift Smarter, Not Harder](https://arxiv.org/abs/2508.07501)
*Xiaoye Zuo,Nikos Athanasiou,Ginger Delmas,Yiming Huang,Xingyu Fu,Lingjie Liu*

Main category: cs.CV

TL;DR: FormCoach是一款利用视觉语言模型（VLMs）的AI健身教练，通过摄像头实时检测并纠正训练动作，填补了家庭健身爱好者缺乏专业反馈的空白。


<details>
  <summary>Details</summary>
Motivation: 家庭健身爱好者缺乏专业指导，FormCoach旨在通过AI技术提供即时、精准的动作纠正。

Method: 利用VLMs分析用户视频与专家标注的参考动作（1,700对视频），并通过网页界面展示实时反馈。同时发布数据集和评估工具，推动研究。

Result: 基准测试显示，AI与人类教练水平仍有差距，但为结合情境感知的动作分析提供了新方向。

Conclusion: FormCoach通过人机协作的方式，为具身AI开辟了新领域，展示了AI在健身指导中的潜力与挑战。

Abstract: Good form is the difference between strength and strain, yet for the
fast-growing community of at-home fitness enthusiasts, expert feedback is often
out of reach. FormCoach transforms a simple camera into an always-on,
interactive AI training partner, capable of spotting subtle form errors and
delivering tailored corrections in real time, leveraging vision-language models
(VLMs). We showcase this capability through a web interface and benchmark
state-of-the-art VLMs on a dataset of 1,700 expert-annotated user-reference
video pairs spanning 22 strength and mobility exercises. To accelerate research
in AI-driven coaching, we release both the dataset and an automated,
rubric-based evaluation pipeline, enabling standardized comparison across
models. Our benchmarks reveal substantial gaps compared to human-level
coaching, underscoring both the challenges and opportunities in integrating
nuanced, context-aware movement analysis into interactive AI systems. By
framing form correction as a collaborative and creative process between humans
and machines, FormCoach opens a new frontier in embodied AI.

</details>


### [116] [From Field to Drone: Domain Drift Tolerant Automated Multi-Species and Damage Plant Semantic Segmentation for Herbicide Trials](https://arxiv.org/abs/2508.07514)
*Artzai Picon,Itziar Eguskiza,Daniel Mugica,Javier Romero,Carlos Javier Jimenez,Eric White,Gabriel Do-Lago-Junqueira,Christian Klukas,Ramon Navarra-Mestre*

Main category: cs.CV

TL;DR: 提出了一种结合自监督视觉模型和植物分类学的改进分割模型，显著提升了物种识别和损害分类的准确性，并在跨设备评估中展现出强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的除草剂田间试验依赖人工视觉评估，耗时、费力且主观。自动化物种和损害识别能提高效率和一致性，但面临视觉差异细微的挑战。

Method: 开发了一种结合自监督视觉模型和植物分类学的分层推理模型，使用2018-2020年德西数据训练，并在2023年和2024年跨设备（数码相机和无人机）数据上测试其鲁棒性。

Result: 模型显著提升了物种识别（F1从0.52到0.85）和损害分类（F1从0.28到0.44）性能，在领域转移（无人机图像）下仍保持较强表现。

Conclusion: 模型展现出强鲁棒性和实际应用潜力，已被BASF部署用于大规模自动化作物和杂草监测。

Abstract: Field trials are vital in herbicide research and development to assess
effects on crops and weeds under varied conditions. Traditionally, evaluations
rely on manual visual assessments, which are time-consuming, labor-intensive,
and subjective. Automating species and damage identification is challenging due
to subtle visual differences, but it can greatly enhance efficiency and
consistency.
  We present an improved segmentation model combining a general-purpose
self-supervised visual model with hierarchical inference based on botanical
taxonomy. Trained on a multi-year dataset (2018-2020) from Germany and Spain
using digital and mobile cameras, the model was tested on digital camera data
(year 2023) and drone imagery from the United States, Germany, and Spain (year
2024) to evaluate robustness under domain shift. This cross-device evaluation
marks a key step in assessing generalization across platforms of the model.
  Our model significantly improved species identification (F1-score: 0.52 to
0.85, R-squared: 0.75 to 0.98) and damage classification (F1-score: 0.28 to
0.44, R-squared: 0.71 to 0.87) over prior methods. Under domain shift (drone
images), it maintained strong performance with moderate degradation (species:
F1-score 0.60, R-squared 0.80; damage: F1-score 0.41, R-squared 0.62), where
earlier models failed.
  These results confirm the model's robustness and real-world applicability. It
is now deployed in BASF's phenotyping pipeline, enabling large-scale, automated
crop and weed monitoring across diverse geographies.

</details>


### [117] [Exploring Multimodal Diffusion Transformers for Enhanced Prompt-based Image Editing](https://arxiv.org/abs/2508.07519)
*Joonghyuk Shin,Alchan Hwang,Yujin Kim,Daneul Kim,Jaesik Park*

Main category: cs.CV

TL;DR: 多模态扩散变换器（MM-DiT）取代了U-Net架构，通过双向注意力机制改进了传统方法，但给编辑技术带来挑战。本文通过分析其注意力矩阵，提出了一种基于提示的图像编辑方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于U-Net的扩散模型依赖于单向注意力机制，而MM-DiT引入了双向信息流，需要新的编辑方法以适应其架构。

Method: 通过分解MM-DiT的注意力矩阵为四个块，分析其特性，并提出一种基于提示的图像编辑方法。

Result: 所提方法支持从全局到局部的编辑，适用于多种MM-DiT变体，包括少步模型。

Conclusion: 研究填补了U-Net方法与新兴架构之间的空白，提供了对MM-DiT行为的深入理解。

Abstract: Transformer-based diffusion models have recently superseded traditional U-Net
architectures, with multimodal diffusion transformers (MM-DiT) emerging as the
dominant approach in state-of-the-art models like Stable Diffusion 3 and
Flux.1. Previous approaches have relied on unidirectional cross-attention
mechanisms, with information flowing from text embeddings to image latents. In
contrast, MMDiT introduces a unified attention mechanism that concatenates
input projections from both modalities and performs a single full attention
operation, allowing bidirectional information flow between text and image
branches. This architectural shift presents significant challenges for existing
editing techniques. In this paper, we systematically analyze MM-DiT's attention
mechanism by decomposing attention matrices into four distinct blocks,
revealing their inherent characteristics. Through these analyses, we propose a
robust, prompt-based image editing method for MM-DiT that supports global to
local edits across various MM-DiT variants, including few-step models. We
believe our findings bridge the gap between existing U-Net-based methods and
emerging architectures, offering deeper insights into MMDiT's behavioral
patterns.

</details>


### [118] [Enhancing Reliability of Medical Image Diagnosis through Top-rank Learning with Rejection Module](https://arxiv.org/abs/2508.07528)
*Xiaotong Ji,Ryoma Bise,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种结合拒绝模块的top-rank学习方法，用于处理医学图像中的噪声标签和模糊实例，提升诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 医学图像诊断中，噪声标签和类别模糊的实例会严重影响top-rank学习的效果，导致关键实例被错误排列。为了解决这一问题，提出了新的方法。

Method: 通过在top-rank学习中集成一个拒绝模块，该模块与top-rank损失共同优化，能够识别并减少异常实例对训练的影响。拒绝模块作为一个附加分支，通过评估实例与常态的偏差来筛选异常。

Result: 在医学数据集上的实验验证表明，该方法能有效检测并减少异常实例，从而提高医学图像诊断的可靠性和准确性。

Conclusion: 提出的方法通过引入拒绝模块，显著提升了top-rank学习在医学图像诊断中的性能，为解决噪声标签和模糊实例问题提供了有效途径。

Abstract: In medical image processing, accurate diagnosis is of paramount importance.
Leveraging machine learning techniques, particularly top-rank learning, shows
significant promise by focusing on the most crucial instances. However,
challenges arise from noisy labels and class-ambiguous instances, which can
severely hinder the top-rank objective, as they may be erroneously placed among
the top-ranked instances. To address these, we propose a novel approach that
enhances toprank learning by integrating a rejection module. Cooptimized with
the top-rank loss, this module identifies and mitigates the impact of outliers
that hinder training effectiveness. The rejection module functions as an
additional branch, assessing instances based on a rejection function that
measures their deviation from the norm. Through experimental validation on a
medical dataset, our methodology demonstrates its efficacy in detecting and
mitigating outliers, improving the reliability and accuracy of medical image
diagnoses.

</details>


### [119] [Enhanced Generative Structure Prior for Chinese Text Image Super-resolution](https://arxiv.org/abs/2508.07537)
*Xiaoming Li,Wangmeng Zuo,Chen Change Loy*

Main category: cs.CV

TL;DR: 本文提出了一种高质量的中文文本图像超分辨率框架，通过引入结构先验和StyleGAN模型，专注于恢复低分辨率中文字符的精确笔画。


<details>
  <summary>Details</summary>
Motivation: 由于中文字符结构复杂且字体多样，现有方法主要针对英文文本，本文旨在解决中文文本图像超分辨率的挑战。

Method: 提出了一种基于StyleGAN的结构先验框架，利用代码本机制限制生成空间，结合样式控制生成高分辨率结构先验。

Result: 实验表明，该方法能够恢复低分辨率中文字符的清晰笔画，尤其在真实场景中表现优异。

Conclusion: 该框架通过结构先验和生成模型的有效结合，显著提升了中文文本图像的超分辨率效果。

Abstract: Faithful text image super-resolution (SR) is challenging because each
character has a unique structure and usually exhibits diverse font styles and
layouts. While existing methods primarily focus on English text, less attention
has been paid to more complex scripts like Chinese. In this paper, we introduce
a high-quality text image SR framework designed to restore the precise strokes
of low-resolution (LR) Chinese characters. Unlike methods that rely on
character recognition priors to regularize the SR task, we propose a novel
structure prior that offers structure-level guidance to enhance visual quality.
Our framework incorporates this structure prior within a StyleGAN model,
leveraging its generative capabilities for restoration. To maintain the
integrity of character structures while accommodating various font styles and
layouts, we implement a codebook-based mechanism that restricts the generative
space of StyleGAN. Each code in the codebook represents the structure of a
specific character, while the vector $w$ in StyleGAN controls the character's
style, including typeface, orientation, and location. Through the collaborative
interaction between the codebook and style, we generate a high-resolution
structure prior that aligns with LR characters both spatially and structurally.
Experiments demonstrate that this structure prior provides robust,
character-specific guidance, enabling the accurate restoration of clear strokes
in degraded characters, even for real-world LR Chinese text with irregular
layouts. Our code and pre-trained models will be available at
https://github.com/csxmli2016/MARCONetPlusPlus

</details>


### [120] [A DICOM Image De-identification Algorithm in the MIDI-B Challenge](https://arxiv.org/abs/2508.07538)
*Hongzhu Jiang,Sihan Xie,Zhiyu Wan*

Main category: cs.CV

TL;DR: 该论文探讨了DICOM图像去标识化的重要性，介绍了MIDI-B挑战赛及其方法，并展示了算法的高效表现。


<details>
  <summary>Details</summary>
Motivation: 保护患者隐私并满足法规要求，同时确保医学数据的实用性。

Method: 应用像素掩码、日期偏移、哈希、文本识别、替换和移除等方法。

Result: 算法正确执行99.92%的操作，在10支完成挑战的团队中排名第二。

Conclusion: 当前方法存在局限，未来需进一步改进。

Abstract: Image de-identification is essential for the public sharing of medical
images, particularly in the widely used Digital Imaging and Communications in
Medicine (DICOM) format as required by various regulations and standards,
including Health Insurance Portability and Accountability Act (HIPAA) privacy
rules, the DICOM PS3.15 standard, and best practices recommended by the Cancer
Imaging Archive (TCIA). The Medical Image De-Identification Benchmark (MIDI-B)
Challenge at the 27th International Conference on Medical Image Computing and
Computer Assisted Intervention (MICCAI 2024) was organized to evaluate
rule-based DICOM image de-identification algorithms with a large dataset of
clinical DICOM images. In this report, we explore the critical challenges of
de-identifying DICOM images, emphasize the importance of removing personally
identifiable information (PII) to protect patient privacy while ensuring the
continued utility of medical data for research, diagnostics, and treatment, and
provide a comprehensive overview of the standards and regulations that govern
this process. Additionally, we detail the de-identification methods we applied
- such as pixel masking, date shifting, date hashing, text recognition, text
replacement, and text removal - to process datasets during the test phase in
strict compliance with these standards. According to the final leaderboard of
the MIDI-B challenge, the latest version of our solution algorithm correctly
executed 99.92% of the required actions and ranked 2nd out of 10 teams that
completed the challenge (from a total of 22 registered teams). Finally, we
conducted a thorough analysis of the resulting statistics and discussed the
limitations of current approaches and potential avenues for future improvement.

</details>


### [121] [Domain Generalization of Pathological Image Segmentation by Patch-Level and WSI-Level Contrastive Learning](https://arxiv.org/abs/2508.07539)
*Yuki Shigeyasu,Shota Harada,Akihiko Yoshizawa,Kazuhiro Terada,Naoki Nakazima,Mariyo Kurata,Hiroyuki Abe,Tetsuo Ushiku,Ryoma Bise*

Main category: cs.CV

TL;DR: 论文提出了一种针对病理图像领域内域偏移的新方法，通过聚类和对比学习来减少特征差距。


<details>
  <summary>Details</summary>
Motivation: 针对传统多医院数据方法的局限性，研究专注于病理图像内部域偏移（如患者特性和组织厚度）。

Method: 通过聚类非肿瘤区域的WSI级特征，并应用两阶段对比学习（WSI级和贴片级）以减少域偏移。

Result: 方法有效减少了不同聚类间的特征差距。

Conclusion: 该方法为病理图像领域内域偏移问题提供了一种实用且有效的解决方案。

Abstract: In this paper, we address domain shifts in pathological images by focusing on
shifts within whole slide images~(WSIs), such as patient characteristics and
tissue thickness, rather than shifts between hospitals. Traditional approaches
rely on multi-hospital data, but data collection challenges often make this
impractical. Therefore, the proposed domain generalization method captures and
leverages intra-hospital domain shifts by clustering WSI-level features from
non-tumor regions and treating these clusters as domains. To mitigate domain
shift, we apply contrastive learning to reduce feature gaps between WSI pairs
from different clusters. The proposed method introduces a two-stage contrastive
learning approach WSI-level and patch-level contrastive learning to minimize
these gaps effectively.

</details>


### [122] [CoT-Pose: Chain-of-Thought Reasoning for 3D Pose Generation from Abstract Prompts](https://arxiv.org/abs/2508.07540)
*Junuk Cha,Jihyeon Kim*

Main category: cs.CV

TL;DR: 论文提出了一种结合链式推理（CoT）的新型框架CoT-Pose，用于从抽象文本生成准确的3D人体姿势，解决了现有模型依赖低级别详细提示的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体姿势生成模型依赖低级别详细描述，而人类常用抽象语言表达意图。这种不匹配限制了模型的实际应用。

Method: 提出结合CoT推理的框架，将抽象提示转换为3D姿势，并设计数据合成管道生成训练用的三元组（抽象提示、详细提示、姿势）。

Result: 实验表明，CoT-Pose能够从抽象文本生成语义一致的合理姿势。

Conclusion: 该研究强调了高级理解在姿势生成中的重要性，为推理增强型姿势生成方法开辟了新方向。

Abstract: Recent advances in multi-modal large language models (MLLMs) and
chain-of-thought (CoT) reasoning have led to significant progress in image and
text generation tasks. However, the field of 3D human pose generation still
faces critical limitations. Most existing text-to-pose models rely heavily on
detailed (low-level) prompts that explicitly describe joint configurations. In
contrast, humans tend to communicate actions and intentions using abstract
(high-level) language. This mismatch results in a practical challenge for
deploying pose generation systems in real-world scenarios. To bridge this gap,
we introduce a novel framework that incorporates CoT reasoning into the pose
generation process, enabling the interpretation of abstract prompts into
accurate 3D human poses. We further propose a data synthesis pipeline that
automatically generates triplets of abstract prompts, detailed prompts, and
corresponding 3D poses for training process. Experimental results demonstrate
that our reasoning-enhanced model, CoT-Pose, can effectively generate plausible
and semantically aligned poses from abstract textual inputs. This work
highlights the importance of high-level understanding in pose generation and
opens new directions for reasoning-enhanced approach for human pose generation.

</details>


### [123] [Commentary Generation for Soccer Highlights](https://arxiv.org/abs/2508.07543)
*Chidaksh Ravuru*

Main category: cs.CV

TL;DR: 本文扩展了MatchVoice模型，用于足球集锦的解说生成，评估了训练配置和硬件限制的影响，并探索了零样本性能的窗口大小效果。


<details>
  <summary>Details</summary>
Motivation: 现有的足球解说生成系统在视频内容与解说之间的细粒度对齐方面存在不足，MatchVoice通过粗粒度和细粒度对齐技术改进了这一领域，但仍需进一步提升性能。

Method: 利用GOAL数据集，扩展MatchVoice模型进行足球集锦的解说生成，通过实验复现MatchTime结果并评估不同训练配置和硬件限制的影响，探索窗口大小对零样本性能的作用。

Result: MatchVoice展现出良好的泛化能力，但需结合更广泛的视频-语言领域技术以进一步提升性能。

Conclusion: 研究表明，虽然MatchVoice在解说生成方面表现良好，但仍需进一步整合其他技术以优化性能，为未来研究提供了方向。

Abstract: Automated soccer commentary generation has evolved from template-based
systems to advanced neural architectures, aiming to produce real-time
descriptions of sports events. While frameworks like SoccerNet-Caption laid
foundational work, their inability to achieve fine-grained alignment between
video content and commentary remains a significant challenge. Recent efforts
such as MatchTime, with its MatchVoice model, address this issue through coarse
and fine-grained alignment techniques, achieving improved temporal
synchronization. In this paper, we extend MatchVoice to commentary generation
for soccer highlights using the GOAL dataset, which emphasizes short clips over
entire games. We conduct extensive experiments to reproduce the original
MatchTime results and evaluate our setup, highlighting the impact of different
training configurations and hardware limitations. Furthermore, we explore the
effect of varying window sizes on zero-shot performance. While MatchVoice
exhibits promising generalization capabilities, our findings suggest the need
for integrating techniques from broader video-language domains to further
enhance performance. Our code is available at
https://github.com/chidaksh/SoccerCommentary.

</details>


### [124] [Adaptive Pseudo Label Selection for Individual Unlabeled Data by Positive and Unlabeled Learning](https://arxiv.org/abs/2508.07548)
*Takehiro Yamane,Itaru Tsuge,Susumu Saito,Ryoma Bise*

Main category: cs.CV

TL;DR: 提出一种新的医学图像分割伪标签方法，通过正样本和无标签学习（PU学习）为未标记图像选择有效的伪标签。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中伪标签选择的挑战，利用PU学习区分前景和背景区域。

Method: 使用正样本和无标签数据（PU学习）进行二分类，获取适用于每张未标记图像的度量标准。

Result: 实验证明该方法能有效选择伪标签。

Conclusion: 该方法能够简便地为各种背景区域选择伪标签，效果显著。

Abstract: This paper proposes a novel pseudo-labeling method for medical image
segmentation that can perform learning on ``individual images'' to select
effective pseudo-labels. We introduce Positive and Unlabeled Learning (PU
learning), which uses only positive and unlabeled data for binary
classification problems, to obtain the appropriate metric for discriminating
foreground and background regions on each unlabeled image. Our PU learning
makes us easy to select pseudo-labels for various background regions. The
experimental results show the effectiveness of our method.

</details>


### [125] [Decoupled Functional Evaluation of Autonomous Driving Models via Feature Map Quality Scoring](https://arxiv.org/abs/2508.07552)
*Ludan Zhang,Sihan Wang,Yuqi Dai,Shuofei Qiao,Lei He*

Main category: cs.CV

TL;DR: 论文提出了一种基于特征图收敛分数（FMCS）的独立评估方法，通过双粒度动态加权评分系统（DG-DWSS）和CLIP-FMQE-Net网络，实现了对自动驾驶功能模块生成的特征图质量的实时评估。实验表明，该方法能提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 端到端模型在自动驾驶感知和规划中逐渐成为主流，但中间功能模块缺乏显式监督信号，导致其机制不透明且可解释性差。传统方法难以独立评估和训练这些模块。

Method: 基于特征图-真值表示相似性的评估框架，提出FMCS方法，构建DG-DWSS评分系统，并使用CLIP-FMQE-Net网络实时评估特征图质量。

Result: 在NuScenes数据集上的实验显示，该方法将3D目标检测性能提升了3.89%（NDS指标），验证了其有效性。

Conclusion: 提出的FMCS方法和评分系统能有效提升特征图质量和整体模型性能，为功能模块的独立评估和训练提供了新思路。

Abstract: End-to-end models are emerging as the mainstream in autonomous driving
perception and planning. However, the lack of explicit supervision signals for
intermediate functional modules leads to opaque operational mechanisms and
limited interpretability, making it challenging for traditional methods to
independently evaluate and train these modules. Pioneering in the issue, this
study builds upon the feature map-truth representation similarity-based
evaluation framework and proposes an independent evaluation method based on
Feature Map Convergence Score (FMCS). A Dual-Granularity Dynamic Weighted
Scoring System (DG-DWSS) is constructed, formulating a unified quantitative
metric - Feature Map Quality Score - to enable comprehensive evaluation of the
quality of feature maps generated by functional modules. A CLIP-based Feature
Map Quality Evaluation Network (CLIP-FMQE-Net) is further developed, combining
feature-truth encoders and quality score prediction heads to enable real-time
quality analysis of feature maps generated by functional modules. Experimental
results on the NuScenes dataset demonstrate that integrating our evaluation
module into the training improves 3D object detection performance, achieving a
3.89 percent gain in NDS. These results verify the effectiveness of our method
in enhancing feature representation quality and overall model performance.

</details>


### [126] [Splat4D: Diffusion-Enhanced 4D Gaussian Splatting for Temporally and Spatially Consistent Content Creation](https://arxiv.org/abs/2508.07557)
*Minghao Yin,Yukang Cao,Songyou Peng,Kai Han*

Main category: cs.CV

TL;DR: Splat4D是一个新颖框架，用于从单目视频生成高质量4D内容，通过多视角渲染、不一致性识别、视频扩散模型和非对称U-Net优化，实现了时空一致性和细节保留。


<details>
  <summary>Details</summary>
Motivation: 解决单目视频生成4D内容时面临的时空一致性、细节保留和用户指导有效性等挑战。

Method: 利用多视角渲染、不一致性识别、视频扩散模型和非对称U-Net进行优化。

Result: 在公开基准测试中表现优异，支持文本/图像条件生成、4D人体生成和文本指导编辑等多种应用。

Conclusion: Splat4D展示了高效且多功能的4D内容生成能力，满足用户需求。

Abstract: Generating high-quality 4D content from monocular videos for applications
such as digital humans and AR/VR poses challenges in ensuring temporal and
spatial consistency, preserving intricate details, and incorporating user
guidance effectively. To overcome these challenges, we introduce Splat4D, a
novel framework enabling high-fidelity 4D content generation from a monocular
video. Splat4D achieves superior performance while maintaining faithful
spatial-temporal coherence by leveraging multi-view rendering, inconsistency
identification, a video diffusion model, and an asymmetric U-Net for
refinement. Through extensive evaluations on public benchmarks, Splat4D
consistently demonstrates state-of-the-art performance across various metrics,
underscoring the efficacy of our approach. Additionally, the versatility of
Splat4D is validated in various applications such as text/image conditioned 4D
generation, 4D human generation, and text-guided content editing, producing
coherent outcomes following user instructions.

</details>


### [127] [Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2508.07570)
*Khanh-Binh Nguyen,Phuoc-Nguyen Bui,Hyunseung Choo,Duc Thanh Nguyen*

Main category: cs.CV

TL;DR: ACE框架通过动态优化缓存和自适应的类边界，解决了测试时适应中缓存不可靠和决策边界不灵活的问题，显著提升了视觉语言模型在分布偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLM）在分布偏移下的下游任务中表现不佳，尤其是在缺乏标注数据时。现有缓存基础的方法存在不可靠置信度和固定决策边界的问题。

Method: 提出Adaptive Cache Enhancement（ACE）框架，通过动态选择高置信度或低熵图像嵌入，结合类特定阈值和指数移动平均优化缓存，实现自适应决策边界。

Result: 在15个基准数据集上验证，ACE在分布偏移场景中表现出色，优于现有测试时适应方法。

Conclusion: ACE显著提升了视觉语言模型的鲁棒性和泛化能力，解决了现有方法的局限性。

Abstract: Vision-language models (VLMs) exhibit remarkable zero-shot generalization but
suffer performance degradation under distribution shifts in downstream tasks,
particularly in the absence of labeled data. Test-Time Adaptation (TTA)
addresses this challenge by enabling online optimization of VLMs during
inference, eliminating the need for annotated data. Cache-based TTA methods
exploit historical knowledge by maintaining a dynamic memory cache of
low-entropy or high-confidence samples, promoting efficient adaptation to
out-of-distribution data. Nevertheless, these methods face two critical
challenges: (1) unreliable confidence metrics under significant distribution
shifts, resulting in error accumulation within the cache and degraded
adaptation performance; and (2) rigid decision boundaries that fail to
accommodate substantial distributional variations, leading to suboptimal
predictions. To overcome these limitations, we introduce the Adaptive Cache
Enhancement (ACE) framework, which constructs a robust cache by selectively
storing high-confidence or low-entropy image embeddings per class, guided by
dynamic, class-specific thresholds initialized from zero-shot statistics and
iteratively refined using an exponential moving average and
exploration-augmented updates. This approach enables adaptive, class-wise
decision boundaries, ensuring robust and accurate predictions across diverse
visual distributions. Extensive experiments on 15 diverse benchmark datasets
demonstrate that ACE achieves state-of-the-art performance, delivering superior
robustness and generalization compared to existing TTA methods in challenging
out-of-distribution scenarios.

</details>


### [128] [Exploiting Layer Normalization Fine-tuning in Visual Transformer Foundation Models for Classification](https://arxiv.org/abs/2508.07577)
*Zhaorui Tan,Tan Pan,Kaizhu Huang,Weimiao Yu,Kai Yao,Chen Jiang,Qiufeng Wang,Anh Nguyen,Xin Guo,Yuan Cheng,Xi Yang*

Main category: cs.CV

TL;DR: 论文研究了Vision Transformers中LayerNorm在数据稀缺和域转移下的微调动态，提出了一种基于Fine-tuning Shift Ratio的简单有效调整机制，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 探索LayerNorm在数据稀缺和域转移下的微调动态，提供对目标域转移的理解和实用调整策略。

Method: 提出基于Fine-tuning Shift Ratio的标量调整机制和循环框架，用于优化LayerNorm的微调。

Result: 实验表明，该方法在自然和病理图像中的ID和OOD场景下均有效，OOD任务更倾向于低FSR和高λ。

Conclusion: 研究揭示了LayerNorm在迁移学习中的动态特征，并提供了实际微调策略。

Abstract: LayerNorm is pivotal in Vision Transformers (ViTs), yet its fine-tuning
dynamics under data scarcity and domain shifts remain underexplored. This paper
shows that shifts in LayerNorm parameters after fine-tuning (LayerNorm shifts)
are indicative of the transitions between source and target domains; its
efficacy is contingent upon the degree to which the target training samples
accurately represent the target domain, as quantified by our proposed
Fine-tuning Shift Ratio ($FSR$). Building on this, we propose a simple yet
effective rescaling mechanism using a scalar $\lambda$ that is negatively
correlated to $FSR$ to align learned LayerNorm shifts with those ideal shifts
achieved under fully representative data, combined with a cyclic framework that
further enhances the LayerNorm fine-tuning. Extensive experiments across
natural and pathological images, in both in-distribution (ID) and
out-of-distribution (OOD) settings, and various target training sample regimes
validate our framework. Notably, OOD tasks tend to yield lower $FSR$ and higher
$\lambda$ in comparison to ID cases, especially with scarce data, indicating
under-represented target training samples. Moreover, ViTFs fine-tuned on
pathological data behave more like ID settings, favoring conservative LayerNorm
updates. Our findings illuminate the underexplored dynamics of LayerNorm in
transfer learning and provide practical strategies for LayerNorm fine-tuning.

</details>


### [129] [GAPNet: A Lightweight Framework for Image and Video Salient Object Detection via Granularity-Aware Paradigm](https://arxiv.org/abs/2508.07585)
*Yu-Huan Wu,Wei Liu,Zi-Xuan Zhu,Zizhou Wang,Yong Liu,Liangli Zhen*

Main category: cs.CV

TL;DR: GAPNet是一个轻量级网络，通过粒度感知范式用于图像和视频显着目标检测（SOD），优化特征利用和语义解释，并在每个处理阶段应用适当的监督。


<details>
  <summary>Details</summary>
Motivation: 当前的显着目标检测（SOD）模型大多依赖计算成本高的主干网络，限制了其在边缘设备等实际场景中的应用。因此，需要一个轻量化的解决方案。

Method: 采用粒度感知范式，为多尺度解码器输出分配不同粒度的显着性图（粗粒度对象位置用于高层输出，细粒度对象边界用于低层输出）。设计了粒度金字塔卷积（GPC）和跨尺度注意力（CSA）模块，优化特征融合，并在编码器上使用自注意力模块学习全局信息。

Result: 实验结果表明，GAPNet在轻量级图像和视频显着目标检测模型中达到了新的最先进性能。

Conclusion: GAPNet通过粒度感知连接和高效特征融合模块，显著降低了计算成本，同时在性能上超越了传统U-Net方法，适用于边缘设备等资源受限场景。

Abstract: Recent salient object detection (SOD) models predominantly rely on
heavyweight backbones, incurring substantial computational cost and hindering
their practical application in various real-world settings, particularly on
edge devices. This paper presents GAPNet, a lightweight network built on the
granularity-aware paradigm for both image and video SOD. We assign saliency
maps of different granularities to supervise the multi-scale decoder
side-outputs: coarse object locations for high-level outputs and fine-grained
object boundaries for low-level outputs. Specifically, our decoder is built
with granularity-aware connections which fuse high-level features of low
granularity and low-level features of high granularity, respectively. To
support these connections, we design granular pyramid convolution (GPC) and
cross-scale attention (CSA) modules for efficient fusion of low-scale and
high-scale features, respectively. On top of the encoder, a self-attention
module is built to learn global information, enabling accurate object
localization with negligible computational cost. Unlike traditional U-Net-based
approaches, our proposed method optimizes feature utilization and semantic
interpretation while applying appropriate supervision at each processing stage.
Extensive experiments show that the proposed method achieves a new
state-of-the-art performance among lightweight image and video SOD models. Code
is available at https://github.com/yuhuan-wu/GAPNet.

</details>


### [130] [Voice Pathology Detection Using Phonation](https://arxiv.org/abs/2508.07587)
*Sri Raksha Siva,Nived Suthahar,Prakash Boominathan,Uma Ranjan*

Main category: cs.CV

TL;DR: 该研究提出了一种基于机器学习的方法，通过非侵入性方式检测声音病理，利用声学特征和RNN进行分类，旨在改善早期诊断和患者治疗效果。


<details>
  <summary>Details</summary>
Motivation: 传统的声音病理诊断方法（如喉镜检查）具有侵入性和主观性，且不易获取。因此，需要一种非侵入、自动化的诊断工具。

Method: 使用声学特征（如MFCC、chroma特征和Mel频谱图）分析声音数据，结合RNN（包括LSTM和注意力机制）进行分类，并通过数据增强和预处理提高模型泛化能力。

Result: 提出的框架为声音病理的早期检测提供了一种非侵入、自动化的诊断工具。

Conclusion: 该方法支持AI驱动的医疗保健，有望改善患者治疗效果。

Abstract: Voice disorders significantly affect communication and quality of life,
requiring an early and accurate diagnosis. Traditional methods like
laryngoscopy are invasive, subjective, and often inaccessible. This research
proposes a noninvasive, machine learning-based framework for detecting voice
pathologies using phonation data.
  Phonation data from the Saarbr\"ucken Voice Database are analyzed using
acoustic features such as Mel Frequency Cepstral Coefficients (MFCCs), chroma
features, and Mel spectrograms. Recurrent Neural Networks (RNNs), including
LSTM and attention mechanisms, classify samples into normal and pathological
categories. Data augmentation techniques, including pitch shifting and Gaussian
noise addition, enhance model generalizability, while preprocessing ensures
signal quality. Scale-based features, such as H\"older and Hurst exponents,
further capture signal irregularities and long-term dependencies.
  The proposed framework offers a noninvasive, automated diagnostic tool for
early detection of voice pathologies, supporting AI-driven healthcare, and
improving patient outcomes.

</details>


### [131] [From Prediction to Explanation: Multimodal, Explainable, and Interactive Deepfake Detection Framework for Non-Expert Users](https://arxiv.org/abs/2508.07596)
*Shahroz Tariq,Simon S. Woo,Priyanka Singh,Irena Irmalasari,Saakshi Gupta,Dev Gupta*

Main category: cs.CV

TL;DR: 提出了DF-P2E框架，通过视觉、语义和叙事层解释，实现可解释的深度伪造检测。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度伪造检测系统缺乏透明度和可解释性，影响非专家用户使用的问题。

Method: 开发了多模态框架DF-P2E，包含分类器、视觉描述模块和叙事优化模块。

Result: 在DF40数据集上验证，系统在检测性能和解释质量上表现优异。

Conclusion: DF-P2E为可解释的深度伪造检测提供了可扩展的解决方案，推动了可信AI的发展。

Abstract: The proliferation of deepfake technologies poses urgent challenges and
serious risks to digital integrity, particularly within critical sectors such
as forensics, journalism, and the legal system. While existing detection
systems have made significant progress in classification accuracy, they
typically function as black-box models, offering limited transparency and
minimal support for human reasoning. This lack of interpretability hinders
their usability in real-world decision-making contexts, especially for
non-expert users. In this paper, we present DF-P2E (Deepfake: Prediction to
Explanation), a novel multimodal framework that integrates visual, semantic,
and narrative layers of explanation to make deepfake detection interpretable
and accessible. The framework consists of three modular components: (1) a
deepfake classifier with Grad-CAM-based saliency visualisation, (2) a visual
captioning module that generates natural language summaries of manipulated
regions, and (3) a narrative refinement module that uses a fine-tuned Large
Language Model (LLM) to produce context-aware, user-sensitive explanations. We
instantiate and evaluate the framework on the DF40 benchmark, the most diverse
deepfake dataset to date. Experiments demonstrate that our system achieves
competitive detection performance while providing high-quality explanations
aligned with Grad-CAM activations. By unifying prediction and explanation in a
coherent, human-aligned pipeline, this work offers a scalable approach to
interpretable deepfake detection, advancing the broader vision of trustworthy
and transparent AI systems in adversarial media environments.

</details>


### [132] [ShoulderShot: Generating Over-the-Shoulder Dialogue Videos](https://arxiv.org/abs/2508.07597)
*Yuang Zhang,Junqi Cheng,Haoyu Zhao,Jiaxi Gu,Fangyuan Zou,Zenghui Lu,Peng Shu*

Main category: cs.CV

TL;DR: 论文提出了ShoulderShot框架，结合双镜头生成与循环视频技术，解决了多角色对话视频中一致性、空间连续性和计算成本的问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在影视、短剧和广告中，肩部对话视频对情感连接至关重要，但目前研究中此类场景的生成仍未被充分探索。主要挑战包括角色一致性、空间连续性和计算资源限制下的长对话生成。

Method: 采用双镜头生成与循环视频技术相结合的ShoulderShot框架，以实现长对话视频的一致性生成。

Result: ShoulderShot在镜头反向布局、空间连续性及对话长度灵活性方面优于现有方法，为实际对话视频生成提供了新可能。

Conclusion: ShoulderShot框架在对话视频生成中展现出优越性能，为解决现有挑战提供了有效方案。

Abstract: Over-the-shoulder dialogue videos are essential in films, short dramas, and
advertisements, providing visual variety and enhancing viewers' emotional
connection. Despite their importance, such dialogue scenes remain largely
underexplored in video generation research. The main challenges include
maintaining character consistency across different shots, creating a sense of
spatial continuity, and generating long, multi-turn dialogues within limited
computational budgets. Here, we present ShoulderShot, a framework that combines
dual-shot generation with looping video, enabling extended dialogues while
preserving character consistency. Our results demonstrate capabilities that
surpass existing methods in terms of shot-reverse-shot layout, spatial
continuity, and flexibility in dialogue length, thereby opening up new
possibilities for practical dialogue video generation. Videos and comparisons
are available at https://shouldershot.github.io.

</details>


### [133] [LaVieID: Local Autoregressive Diffusion Transformers for Identity-Preserving Video Creation](https://arxiv.org/abs/2508.07603)
*Wenhui Song,Hanhui Li,Jiehui Huang,Panwen Hu,Yuhao Cheng,Long Chen,Yiqiang Yan,Xiaodan Liang*

Main category: cs.CV

TL;DR: LaVieID是一种新型的局部自回归视频扩散框架，旨在解决身份保留的文本到视频生成任务，通过空间和时间角度的改进，提高了身份信息的保留和视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散变换器（DiTs）在全局生成过程中容易丢失身份信息，为此提出了LaVieID框架，从空间和时间两方面解决这一问题。

Method: 通过局部路由器显式表示细粒度面部结构，减少特征干扰；引入时间自回归模块，利用长时依赖预测偏差修正潜在标记，增强帧间身份一致性。

Result: LaVieID能够生成高质量个性化视频，达到了最先进的性能水平。

Conclusion: LaVieID在身份保留和视频生成质量方面表现优异，为文本到视频生成任务提供了有效解决方案。

Abstract: In this paper, we present LaVieID, a novel \underline{l}ocal
\underline{a}utoregressive \underline{vi}d\underline{e}o diffusion framework
designed to tackle the challenging \underline{id}entity-preserving
text-to-video task. The key idea of LaVieID is to mitigate the loss of identity
information inherent in the stochastic global generation process of diffusion
transformers (DiTs) from both spatial and temporal perspectives. Specifically,
unlike the global and unstructured modeling of facial latent states in existing
DiTs, LaVieID introduces a local router to explicitly represent latent states
by weighted combinations of fine-grained local facial structures. This
alleviates undesirable feature interference and encourages DiTs to capture
distinctive facial characteristics. Furthermore, a temporal autoregressive
module is integrated into LaVieID to refine denoised latent tokens before video
decoding. This module divides latent tokens temporally into chunks, exploiting
their long-range temporal dependencies to predict biases for rectifying tokens,
thereby significantly enhancing inter-frame identity consistency. Consequently,
LaVieID can generate high-fidelity personalized videos and achieve
state-of-the-art performance. Our code and models are available at
https://github.com/ssugarwh/LaVieID.

</details>


### [134] [X2Edit: Revisiting Arbitrary-Instruction Image Editing through Self-Constructed Data and Task-Aware Representation Learning](https://arxiv.org/abs/2508.07607)
*Jian Ma,Xujie Zhu,Zihao Pan,Qirong Peng,Xu Guo,Chen Chen,Haonan Lu*

Main category: cs.CV

TL;DR: 该论文提出了X2Edit数据集和一个基于FLUX.1的任务感知MoE-LoRA训练方法，显著提升了图像编辑性能。


<details>
  <summary>Details</summary>
Motivation: 当前开源数据集对于任意指令图像编辑效果不佳，且缺乏与主流生成模型的兼容模块。

Method: 构建X2Edit数据集（包含14种编辑任务），使用专家模型筛选数据；设计任务感知MoE-LoRA训练方法，结合对比学习提升性能。

Result: 模型编辑性能优异，数据集优于现有开源数据。

Conclusion: X2Edit数据集和训练方法为图像编辑任务提供了高效解决方案。

Abstract: Existing open-source datasets for arbitrary-instruction image editing remain
suboptimal, while a plug-and-play editing module compatible with
community-prevalent generative models is notably absent. In this paper, we
first introduce the X2Edit Dataset, a comprehensive dataset covering 14 diverse
editing tasks, including subject-driven generation. We utilize the
industry-leading unified image generation models and expert models to construct
the data. Meanwhile, we design reasonable editing instructions with the VLM and
implement various scoring mechanisms to filter the data. As a result, we
construct 3.7 million high-quality data with balanced categories. Second, to
better integrate seamlessly with community image generation models, we design
task-aware MoE-LoRA training based on FLUX.1, with only 8\% of the parameters
of the full model. To further improve the final performance, we utilize the
internal representations of the diffusion model and define positive/negative
samples based on image editing types to introduce contrastive learning.
Extensive experiments demonstrate that the model's editing performance is
competitive among many excellent models. Additionally, the constructed dataset
exhibits substantial advantages over existing open-source datasets. The
open-source code, checkpoints, and datasets for X2Edit can be found at the
following link: https://github.com/OPPO-Mente-Lab/X2Edit.

</details>


### [135] [An Iterative Reconstruction Method for Dental Cone-Beam Computed Tomography with a Truncated Field of View](https://arxiv.org/abs/2508.07618)
*Hyoung Suk Park,Kiwan Jeon*

Main category: cs.CV

TL;DR: 提出了一种两阶段方法，通过使用隐式神经表示（INR）生成先验图像并校正投影数据，有效减少了牙科CBCT中的截断伪影。


<details>
  <summary>Details</summary>
Motivation: 在牙科CBCT中，小探测器的使用导致截断视野（FOV），影响重建图像质量，迫切需要解决这一问题。

Method: 采用两阶段方法：第一阶段用INR生成覆盖全头的先验图像并校正截断FOV的投影数据；第二阶段用校正后的数据进行迭代重建。

Result: 数值实验证明该方法能有效抑制截断伪影，提升CBCT图像质量。

Conclusion: 两阶段方法通过INR和迭代重建的结合，显著改善了牙科CBCT的图像质量。

Abstract: In dental cone-beam computed tomography (CBCT), compact and cost-effective
system designs often use small detectors, resulting in a truncated field of
view (FOV) that does not fully encompass the patient's head. In iterative
reconstruction approaches, the discrepancy between the actual projection and
the forward projection within the truncated FOV accumulates over iterations,
leading to significant degradation in the reconstructed image quality. In this
study, we propose a two-stage approach to mitigate truncation artifacts in
dental CBCT. In the first stage, we employ Implicit Neural Representation
(INR), leveraging its superior representation power, to generate a prior image
over an extended region so that its forward projection fully covers the
patient's head. To reduce computational and memory burdens, INR reconstruction
is performed with a coarse voxel size. The forward projection of this prior
image is then used to estimate the discrepancy due to truncated FOV in the
measured projection data. In the second stage, the discrepancy-corrected
projection data is utilized in a conventional iterative reconstruction process
within the truncated region. Our numerical results demonstrate that the
proposed two-grid approach effectively suppresses truncation artifacts, leading
to improved CBCT image quality.

</details>


### [136] [SOFA: Deep Learning Framework for Simulating and Optimizing Atrial Fibrillation Ablation](https://arxiv.org/abs/2508.07621)
*Yunsung Chung,Chanho Lim,Ghassan Bidaoui,Christian Massad,Nassir Marrouche,Jihun Hamm*

Main category: cs.CV

TL;DR: SOFA是一种新型深度学习框架，通过模拟消融手术效果、预测房颤复发风险并优化手术参数，个性化房颤消融治疗。


<details>
  <summary>Details</summary>
Motivation: 房颤（AF）消融手术效果差异大，需要评估和改进消融效果，但目前缺乏有效方法。

Method: 提出SOFA框架，模拟消融后疤痕形成，预测复发风险，并优化手术参数以减少风险。

Result: SOFA能准确合成消融后图像，优化方案使模型预测的复发风险降低22.18%。

Conclusion: SOFA首次整合了手术效果模拟、复发预测和参数优化，为房颤消融个性化治疗提供了新工具。

Abstract: Atrial fibrillation (AF) is a prevalent cardiac arrhythmia often treated with
catheter ablation procedures, but procedural outcomes are highly variable.
Evaluating and improving ablation efficacy is challenging due to the complex
interaction between patient-specific tissue and procedural factors. This paper
asks two questions: Can AF recurrence be predicted by simulating the effects of
procedural parameters? How should we ablate to reduce AF recurrence? We propose
SOFA (Simulating and Optimizing Atrial Fibrillation Ablation), a novel
deep-learning framework that addresses these questions. SOFA first simulates
the outcome of an ablation strategy by generating a post-ablation image
depicting scar formation, conditioned on a patient's pre-ablation LGE-MRI and
the specific procedural parameters used (e.g., ablation locations, duration,
temperature, power, and force). During this simulation, it predicts AF
recurrence risk. Critically, SOFA then introduces an optimization scheme that
refines these procedural parameters to minimize the predicted risk. Our method
leverages a multi-modal, multi-view generator that processes 2.5D
representations of the atrium. Quantitative evaluations show that SOFA
accurately synthesizes post-ablation images and that our optimization scheme
leads to a 22.18\% reduction in the model-predicted recurrence risk. To the
best of our knowledge, SOFA is the first framework to integrate the simulation
of procedural effects, recurrence prediction, and parameter optimization,
offering a novel tool for personalizing AF ablation.

</details>


### [137] [Enhancing Egocentric Object Detection in Static Environments using Graph-based Spatial Anomaly Detection and Correction](https://arxiv.org/abs/2508.07624)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于图的后期处理方法，利用空间关系纠正物体检测异常，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在静态环境中，物体的空间布局通常是固定的，但现有检测模型未能充分利用这一先验，导致不一致或错误的检测结果。

Method: 使用图神经网络（GNN）对物体的空间关系建模，通过邻域上下文纠正异常检测结果。

Result: 实验表明，该方法显著提升了检测性能，mAP@50最高提升4%。

Conclusion: 通过利用环境空间结构，可以提高物体检测系统的可靠性。

Abstract: In many real-world applications involving static environments, the spatial
layout of objects remains consistent across instances. However,
state-of-the-art object detection models often fail to leverage this spatial
prior, resulting in inconsistent predictions, missed detections, or
misclassifications, particularly in cluttered or occluded scenes. In this work,
we propose a graph-based post-processing pipeline that explicitly models the
spatial relationships between objects to correct detection anomalies in
egocentric frames. Using a graph neural network (GNN) trained on manually
annotated data, our model identifies invalid object class labels and predicts
corrected class labels based on their neighbourhood context. We evaluate our
approach both as a standalone anomaly detection and correction framework and as
a post-processing module for standard object detectors such as YOLOv7 and
RT-DETR. Experiments demonstrate that incorporating this spatial reasoning
significantly improves detection performance, with mAP@50 gains of up to 4%.
This method highlights the potential of leveraging the environment's spatial
structure to improve reliability in object detection systems.

</details>


### [138] [A Trustworthy Method for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.07625)
*Junxiao Xue,Xiaozhen Liu,Jie Wang,Xuecheng Wu,Bin Wu*

Main category: cs.CV

TL;DR: 提出了一种基于不确定性的可信情感识别方法（TER），通过多模态置信度融合提高了预测的可靠性，并引入了新的评估标准。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽有效但复杂且未充分考虑数据的噪声和分布偏移问题，需要提高预测的可靠性。

Method: 结合不确定性估计计算预测置信度，基于多模态置信度融合输出可信预测，提出可信精度和可信召回率作为评估标准。

Result: TER在Music-video上准确率达82.40%，在IEMOCAP和Music-video上的可信F1分数分别为0.7511和0.9035。

Conclusion: TER在性能和可信度上均优于现有方法，适用于噪声和异常数据场景。

Abstract: Existing emotion recognition methods mainly focus on enhancing performance by
employing complex deep models, typically resulting in significantly higher
model complexity. Although effective, it is also crucial to ensure the
reliability of the final decision, especially for noisy, corrupted and
out-of-distribution data. To this end, we propose a novel emotion recognition
method called trusted emotion recognition (TER), which utilizes uncertainty
estimation to calculate the confidence value of predictions. TER combines the
results from multiple modalities based on their confidence values to output the
trusted predictions. We also provide a new evaluation criterion to assess the
reliability of predictions. Specifically, we incorporate trusted precision and
trusted recall to determine the trusted threshold and formulate the trusted
Acc. and trusted F1 score to evaluate the model's trusted performance. The
proposed framework combines the confidence module that accordingly endows the
model with reliability and robustness against possible noise or corruption. The
extensive experimental results validate the effectiveness of our proposed
model. The TER achieves state-of-the-art performance on the Music-video,
achieving 82.40% Acc. In terms of trusted performance, TER outperforms other
methods on the IEMOCAP and Music-video, achieving trusted F1 scores of 0.7511
and 0.9035, respectively.

</details>


### [139] [AR-VRM: Imitating Human Motions for Visual Robot Manipulation with Analogical Reasoning](https://arxiv.org/abs/2508.07626)
*Dejie Yang,Zijing Zhao,Yang Liu*

Main category: cs.CV

TL;DR: 论文提出了一种通过类比学习人类动作的视觉机器人操作方法（AR-VRM），以解决机器人数据不足的问题，并在小样本场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人数据不足的问题，通过利用人类动作视频数据显式学习动作知识，提升机器人操作的泛化能力。

Method: 使用关键点视觉语言模型（VLM）从人类动作视频中学习动作知识，并通过对类比推理（AR）将人类手部关键点映射到机器人组件，实现动作模仿。

Result: 在CALVIN基准测试和实际实验中取得领先性能，特别是在小样本场景中大幅超越现有方法。

Conclusion: 显式模仿人类动作可以有效解决机器人数据稀缺问题，提升操作性能。

Abstract: Visual Robot Manipulation (VRM) aims to enable a robot to follow natural
language instructions based on robot states and visual observations, and
therefore requires costly multi-modal data. To compensate for the deficiency of
robot data, existing approaches have employed vision-language pretraining with
large-scale data. However, they either utilize web data that differs from
robotic tasks, or train the model in an implicit way (e.g., predicting future
frames at the pixel level), thus showing limited generalization ability under
insufficient robot data. In this paper, we propose to learn from large-scale
human action video datasets in an explicit way (i.e., imitating human actions
from hand keypoints), introducing Visual Robot Manipulation with Analogical
Reasoning (AR-VRM). To acquire action knowledge explicitly from human action
videos, we propose a keypoint Vision-Language Model (VLM) pretraining scheme,
enabling the VLM to learn human action knowledge and directly predict human
hand keypoints. During fine-tuning on robot data, to facilitate the robotic arm
in imitating the action patterns of human motions, we first retrieve human
action videos that perform similar manipulation tasks and have similar
historical observations , and then learn the Analogical Reasoning (AR) map
between human hand keypoints and robot components. Taking advantage of focusing
on action keypoints instead of irrelevant visual cues, our method achieves
leading performance on the CALVIN benchmark {and real-world experiments}. In
few-shot scenarios, our AR-VRM outperforms previous methods by large margins ,
underscoring the effectiveness of explicitly imitating human actions under data
scarcity.

</details>


### [140] [LaRender: Training-Free Occlusion Control in Image Generation via Latent Rendering](https://arxiv.org/abs/2508.07647)
*Xiaohang Zhan,Dingming Liu*

Main category: cs.CV

TL;DR: 提出了一种无需训练的图像生成算法，精确控制图像中物体间的遮挡关系，基于物理渲染原理在潜在空间中实现遮挡控制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成方法依赖提示控制遮挡关系，精度不足；布局到图像方法虽能控制物体位置，但未明确处理遮挡关系。

Method: 利用体积渲染原理在潜在空间“渲染”场景，通过遮挡关系和物体透射率指导生成，无需重新训练或微调扩散模型。

Result: 在遮挡精度上显著优于现有方法，并可调整物体透明度、质量密度、粒子浓度等效果。

Conclusion: 该方法基于物理原理实现精确遮挡控制，扩展性强，适用于多种视觉效果生成。

Abstract: We propose a novel training-free image generation algorithm that precisely
controls the occlusion relationships between objects in an image. Existing
image generation methods typically rely on prompts to influence occlusion,
which often lack precision. While layout-to-image methods provide control over
object locations, they fail to address occlusion relationships explicitly.
Given a pre-trained image diffusion model, our method leverages volume
rendering principles to "render" the scene in latent space, guided by occlusion
relationships and the estimated transmittance of objects. This approach does
not require retraining or fine-tuning the image diffusion model, yet it enables
accurate occlusion control due to its physics-grounded foundation. In extensive
experiments, our method significantly outperforms existing approaches in terms
of occlusion accuracy. Furthermore, we demonstrate that by adjusting the
opacities of objects or concepts during rendering, our method can achieve a
variety of effects, such as altering the transparency of objects, the density
of mass (e.g., forests), the concentration of particles (e.g., rain, fog), the
intensity of light, and the strength of lens effects, etc.

</details>


### [141] [Collaborative Learning of Scattering and Deep Features for SAR Target Recognition with Noisy Labels](https://arxiv.org/abs/2508.07656)
*Yimin Fu,Zhunga Liu,Dongxiu Guo,Longfei Wang*

Main category: cs.CV

TL;DR: 提出了一种名为CLSDF的方法，通过结合散射和深度学习特征来解决SAR ATR中噪声标签问题，显著提升了目标识别的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于SAR数据标记需要专业知识，噪声标签问题不可避免，导致ATR性能下降。现有方法主要针对图像数据，无法直接适用于SAR数据。

Method: 设计了一个多模型特征融合框架，结合散射特征和深度学习特征。通过GMM模型区分干净和噪声标签，并采用半监督学习和联合分布对齐策略优化模型。

Result: 在MSTAR数据集上的实验表明，该方法在不同噪声条件下均能达到最佳性能。

Conclusion: CLSDF方法有效提升了SAR ATR在噪声标签情况下的识别性能，展现了其在复杂条件下的实用性。

Abstract: The acquisition of high-quality labeled synthetic aperture radar (SAR) data
is challenging due to the demanding requirement for expert knowledge.
Consequently, the presence of unreliable noisy labels is unavoidable, which
results in performance degradation of SAR automatic target recognition (ATR).
Existing research on learning with noisy labels mainly focuses on image data.
However, the non-intuitive visual characteristics of SAR data are insufficient
to achieve noise-robust learning. To address this problem, we propose
collaborative learning of scattering and deep features (CLSDF) for SAR ATR with
noisy labels. Specifically, a multi-model feature fusion framework is designed
to integrate scattering and deep features. The attributed scattering centers
(ASCs) are treated as dynamic graph structure data, and the extracted physical
characteristics effectively enrich the representation of deep image features.
Then, the samples with clean and noisy labels are divided by modeling the loss
distribution with multiple class-wise Gaussian Mixture Models (GMMs).
Afterward, the semi-supervised learning of two divergent branches is conducted
based on the data divided by each other. Moreover, a joint distribution
alignment strategy is introduced to enhance the reliability of co-guessed
labels. Extensive experiments have been done on the Moving and Stationary
Target Acquisition and Recognition (MSTAR) dataset, and the results show that
the proposed method can achieve state-of-the-art performance under different
operating conditions with various label noises.

</details>


### [142] [Undress to Redress: A Training-Free Framework for Virtual Try-On](https://arxiv.org/abs/2508.07680)
*Zhiying Li,Junhao Wu,Yeying Jin,Daiheng Gao,Yun Ji,Kaichuan Kong,Lei Yu,Hao Xu,Kai Chen,Bruce Gu,Nana Wang,Zhaoxin Fan*

Main category: cs.CV

TL;DR: UR-VTON是一种无需训练的新框架，通过“脱衣-穿衣”机制改进长袖到短袖的虚拟试穿效果，结合动态指导和结构细化器提升细节逼真度。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法在长袖到短袖转换中表现不佳，因皮肤区域不足导致结果不真实。

Method: 提出UR-VTON框架，采用“脱衣-穿衣”两步法，结合动态指导和结构细化器优化细节。

Result: 实验表明UR-VTON在细节保留和图像质量上优于现有方法。

Conclusion: UR-VTON为虚拟试穿提供了一种更高效的解决方案，尤其在长袖到短袖转换中表现优异。

Abstract: Virtual try-on (VTON) is a crucial task for enhancing user experience in
online shopping by generating realistic garment previews on personal photos.
Although existing methods have achieved impressive results, they struggle with
long-sleeve-to-short-sleeve conversions-a common and practical scenario-often
producing unrealistic outputs when exposed skin is underrepresented in the
original image. We argue that this challenge arises from the ''majority''
completion rule in current VTON models, which leads to inaccurate skin
restoration in such cases. To address this, we propose UR-VTON (Undress-Redress
Virtual Try-ON), a novel, training-free framework that can be seamlessly
integrated with any existing VTON method. UR-VTON introduces an
''undress-to-redress'' mechanism: it first reveals the user's torso by
virtually ''undressing,'' then applies the target short-sleeve garment,
effectively decomposing the conversion into two more manageable steps.
Additionally, we incorporate Dynamic Classifier-Free Guidance scheduling to
balance diversity and image quality during DDPM sampling, and employ Structural
Refiner to enhance detail fidelity using high-frequency cues. Finally, we
present LS-TON, a new benchmark for long-sleeve-to-short-sleeve try-on.
Extensive experiments demonstrate that UR-VTON outperforms state-of-the-art
methods in both detail preservation and image quality. Code will be released
upon acceptance.

</details>


### [143] [TAR-TVG: Enhancing VLMs with Timestamp Anchor-Constrained Reasoning for Temporal Video Grounding](https://arxiv.org/abs/2508.07683)
*Chaohong Guo,Xun Mo,Yongwei Nie,Xuemiao Xu,Chao Xu,Fei Yu,Chengjiang Long*

Main category: cs.CV

TL;DR: TAR-TVG框架通过时间锚点约束推理过程，提升视频片段定位的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法未能显式约束推理过程，影响最终时间预测质量。

Method: 引入时间锚点作为中间监督，采用自蒸馏训练策略（GRPO、SFT、GRPO优化）。

Result: 模型达到最先进性能，产生可验证的推理链及逐步精确的时间估计。

Conclusion: TAR-TVG显著提升视频定位任务的性能与可解释性。

Abstract: Temporal Video Grounding (TVG) aims to precisely localize video segments
corresponding to natural language queries, which is a critical capability for
long-form video understanding. Although existing reinforcement learning
approaches encourage models to generate reasoning chains before predictions,
they fail to explicitly constrain the reasoning process to ensure the quality
of the final temporal predictions. To address this limitation, we propose
Timestamp Anchor-constrained Reasoning for Temporal Video Grounding (TAR-TVG),
a novel framework that introduces timestamp anchors within the reasoning
process to enforce explicit supervision to the thought content. These anchors
serve as intermediate verification points. More importantly, we require each
reasoning step to produce increasingly accurate temporal estimations, thereby
ensuring that the reasoning process contributes meaningfully to the final
prediction. To address the challenge of low-probability anchor generation in
models (e.g., Qwen2.5-VL-3B), we develop an efficient self-distillation
training strategy: (1) initial GRPO training to collect 30K high-quality
reasoning traces containing multiple timestamp anchors, (2) supervised
fine-tuning (SFT) on distilled data, and (3) final GRPO optimization on the
SFT-enhanced model. This three-stage training strategy enables robust anchor
generation while maintaining reasoning quality. Experiments show that our model
achieves state-of-the-art performance while producing interpretable, verifiable
reasoning chains with progressively refined temporal estimations.

</details>


### [144] [Make Your MoVe: Make Your 3D Contents by Adapting Multi-View Diffusion Models to External Editing](https://arxiv.org/abs/2508.07700)
*Weitao Wang,Haoran Xu,Jun Meng,Haoqian Wang*

Main category: cs.CV

TL;DR: 本文提出了一种无需调整、即插即用的方法，用于在3D生成中保持编辑内容与原始几何的对齐，通过几何保留模块和注入控制器实现高质量编辑效果。


<details>
  <summary>Details</summary>
Motivation: 随着3D生成技术的普及，用户对个性化内容的需求增加，但现有2D编辑工具直接用于3D生成会导致信息丢失，影响最终资产质量。

Method: 提出了一种基于几何保留模块和注入控制器的方案，通过单次推理对齐编辑后的资产与原始几何。

Result: 实验表明，该方法显著提升了编辑后3D资产的多视角一致性和网格质量。

Conclusion: 该方法为3D内容编辑提供了一种高效且高质量的解决方案，适用于多种多视角扩散模型和编辑方法的组合。

Abstract: As 3D generation techniques continue to flourish, the demand for generating
personalized content is rapidly rising. Users increasingly seek to apply
various editing methods to polish generated 3D content, aiming to enhance its
color, style, and lighting without compromising the underlying geometry.
However, most existing editing tools focus on the 2D domain, and directly
feeding their results into 3D generation methods (like multi-view diffusion
models) will introduce information loss, degrading the quality of the final 3D
assets. In this paper, we propose a tuning-free, plug-and-play scheme that
aligns edited assets with their original geometry in a single inference run.
Central to our approach is a geometry preservation module that guides the
edited multi-view generation with original input normal latents. Besides, an
injection switcher is proposed to deliberately control the supervision extent
of the original normals, ensuring the alignment between the edited color and
normal views. Extensive experiments show that our method consistently improves
both the multi-view consistency and mesh quality of edited 3D assets, across
multiple combinations of multi-view diffusion models and editing methods.

</details>


### [145] [Multi-view Normal and Distance Guidance Gaussian Splatting for Surface Reconstruction](https://arxiv.org/abs/2508.07701)
*Bo Jia,Yanan Guo,Ying Chang,Benkui Zhang,Ying Xie,Kangning Du,Lin Cao*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）在多视图场景中提出了一种距离和法线引导的方法，通过约束深度图和对齐3D法线，提升了表面重建精度。


<details>
  <summary>Details</summary>
Motivation: 解决3DGS在多视图下法线对齐和距离匹配的问题，提高几何深度的一致性和重建精度。

Method: 设计了多视图距离重投影正则化模块和法线增强模块，通过计算相邻视图间的距离损失和法线匹配损失，实现多视图对齐。

Result: 实验表明，该方法在定量和定性评估中均优于基线，显著提升了3DGS的表面重建能力。

Conclusion: 提出的方法在多视图场景中有效解决了3DGS的几何偏差问题，为小室内外场景的高精度重建提供了新思路。

Abstract: 3D Gaussian Splatting (3DGS) achieves remarkable results in the field of
surface reconstruction. However, when Gaussian normal vectors are aligned
within the single-view projection plane, while the geometry appears reasonable
in the current view, biases may emerge upon switching to nearby views. To
address the distance and global matching challenges in multi-view scenes, we
design multi-view normal and distance-guided Gaussian splatting. This method
achieves geometric depth unification and high-accuracy reconstruction by
constraining nearby depth maps and aligning 3D normals. Specifically, for the
reconstruction of small indoor and outdoor scenes, we propose a multi-view
distance reprojection regularization module that achieves multi-view Gaussian
alignment by computing the distance loss between two nearby views and the same
Gaussian surface. Additionally, we develop a multi-view normal enhancement
module, which ensures consistency across views by matching the normals of pixel
points in nearby views and calculating the loss. Extensive experimental results
demonstrate that our method outperforms the baseline in both quantitative and
qualitative evaluations, significantly enhancing the surface reconstruction
capability of 3DGS.

</details>


### [146] [DoorDet: Semi-Automated Multi-Class Door Detection Dataset via Object Detection and Large Language Models](https://arxiv.org/abs/2508.07714)
*Licheng Zhang,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

TL;DR: 提出了一种结合深度学习和多模态推理的半自动化流程，用于低成本构建多类别门检测数据集。


<details>
  <summary>Details</summary>
Motivation: 由于公开可用的细粒度多类别门检测数据集稀缺，本文旨在解决这一问题，以支持建筑合规检查和室内场景理解等应用。

Method: 使用深度学习目标检测器初步检测门，再通过大型语言模型（LLM）根据视觉和上下文特征分类，最后引入人工干预确保标签质量。

Result: 显著降低了标注成本，并生成了适合评估神经网络在楼层平面图分析中性能的数据集。

Conclusion: 展示了深度学习与多模态推理结合在复杂现实场景数据集构建中的潜力。

Abstract: Accurate detection and classification of diverse door types in floor plans
drawings is critical for multiple applications, such as building compliance
checking, and indoor scene understanding. Despite their importance, publicly
available datasets specifically designed for fine-grained multi-class door
detection remain scarce. In this work, we present a semi-automated pipeline
that leverages a state-of-the-art object detector and a large language model
(LLM) to construct a multi-class door detection dataset with minimal manual
effort. Doors are first detected as a unified category using a deep object
detection model. Next, an LLM classifies each detected instance based on its
visual and contextual features. Finally, a human-in-the-loop stage ensures
high-quality labels and bounding boxes. Our method significantly reduces
annotation cost while producing a dataset suitable for benchmarking neural
models in floor plan analysis. This work demonstrates the potential of
combining deep learning and multimodal reasoning for efficient dataset
construction in complex real-world domains.

</details>


### [147] [Architectural Co-Design for Zero-Shot Anomaly Detection: Decoupling Representation and Dynamically Fusing Features in CLIP](https://arxiv.org/abs/2508.07819)
*Ke Ma,Jun Long,Hongxiao Fei,Liujie Hua,Yueyi Luo*

Main category: cs.CV

TL;DR: 该论文提出了一种联合优化特征表示和跨模态融合的架构协同设计框架，解决了预训练视觉语言模型在零样本异常检测中的适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型在零样本异常检测中存在适应性缺陷，缺乏局部归纳偏差和灵活的特征融合方式。

Method: 采用卷积低秩适应适配器注入局部归纳偏差，并引入动态融合网关实现双向融合。

Result: 在工业和医疗基准测试中表现出卓越的准确性和鲁棒性。

Conclusion: 协同设计框架有效提升了基础模型在密集感知任务中的适应能力。

Abstract: Pre-trained Vision-Language Models (VLMs) face a significant adaptation gap
when applied to Zero-Shot Anomaly Detection (ZSAD), stemming from their lack of
local inductive biases for dense prediction and their reliance on inflexible
feature fusion paradigms. We address these limitations through an Architectural
Co-Design framework that jointly refines feature representation and cross-modal
fusion. Our method integrates a parameter-efficient Convolutional Low-Rank
Adaptation (Conv-LoRA) adapter to inject local inductive biases for
fine-grained representation, and introduces a Dynamic Fusion Gateway (DFG) that
leverages visual context to adaptively modulate text prompts, enabling a
powerful bidirectional fusion. Extensive experiments on diverse industrial and
medical benchmarks demonstrate superior accuracy and robustness, validating
that this synergistic co-design is critical for robustly adapting foundation
models to dense perception tasks.

</details>


### [148] [A Registration-Based Star-Shape Segmentation Model and Fast Algorithms](https://arxiv.org/abs/2508.07721)
*Daoping Zhang,Xue-Cheng Tai,Lok Ming Lui*

Main category: cs.CV

TL;DR: 提出了一种基于配准框架的星形分割模型，结合水平集表示和约束条件，支持单中心或多中心的完整或部分星形分割，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 图像分割在提取感兴趣对象及其边界时至关重要，但在遮挡、模糊或噪声情况下表现不佳，因此需要利用先验信息（如星形先验）。

Method: 结合水平集表示与配准框架，对变形水平集函数施加约束，支持多中心星形分割，并通过交替方向乘子法求解模型。

Result: 在合成和真实图像上的数值实验表明，该方法能够有效实现准确的星形分割。

Conclusion: 提出的模型在星形分割任务中表现出色，适应性强，且能通过指定标志点约束边界。

Abstract: Image segmentation plays a crucial role in extracting objects of interest and
identifying their boundaries within an image. However, accurate segmentation
becomes challenging when dealing with occlusions, obscurities, or noise in
corrupted images. To tackle this challenge, prior information is often
utilized, with recent attention on star-shape priors. In this paper, we propose
a star-shape segmentation model based on the registration framework. By
combining the level set representation with the registration framework and
imposing constraints on the deformed level set function, our model enables both
full and partial star-shape segmentation, accommodating single or multiple
centers. Additionally, our approach allows for the enforcement of identified
boundaries to pass through specified landmark locations. We tackle the proposed
models using the alternating direction method of multipliers. Through numerical
experiments conducted on synthetic and real images, we demonstrate the efficacy
of our approach in achieving accurate star-shape segmentation.

</details>


### [149] [Being-M0.5: A Real-Time Controllable Vision-Language-Motion Model](https://arxiv.org/abs/2508.07863)
*Bin Cao,Sipeng Zheng,Ye Wang,Lujie Xia,Qianshan Wei,Qin Jin,Jing Liu,Zongqing Lu*

Main category: cs.CV

TL;DR: 生成人类运动的模型存在可控性不足的问题，Being-M0.5通过新数据集和分部分量化技术解决了这些问题，并展示出实时性和高性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-运动模型在可控性方面的局限性，包括对多样化指令的响应、初始姿态能力不足等问题。

Method: 基于HuMo100M数据集，采用分部分残差量化技术进行运动标记化，实现精细控制。

Result: 在多个运动生成任务中达到最先进性能，并证实实时能力。

Conclusion: HuMo100M和Being-M0.5是推动运动生成技术实际应用的重要进展。

Abstract: Human motion generation has emerged as a critical technology with
transformative potential for real-world applications. However, existing
vision-language-motion models (VLMMs) face significant limitations that hinder
their practical deployment. We identify controllability as a main bottleneck,
manifesting in five key aspects: inadequate response to diverse human commands,
limited pose initialization capabilities, poor performance on long-term
sequences, insufficient handling of unseen scenarios, and lack of fine-grained
control over individual body parts. To overcome these limitations, we present
Being-M0.5, the first real-time, controllable VLMM that achieves
state-of-the-art performance across multiple motion generation tasks. Our
approach is built upon HuMo100M, the largest and most comprehensive human
motion dataset to date, comprising over 5 million self-collected motion
sequences, 100 million multi-task instructional instances, and detailed
part-level annotations that address a critical gap in existing datasets. We
introduce a novel part-aware residual quantization technique for motion
tokenization that enables precise, granular control over individual body parts
during generation. Extensive experimental validation demonstrates Being-M0.5's
superior performance across diverse motion benchmarks, while comprehensive
efficiency analysis confirms its real-time capabilities. Our contributions
include design insights and detailed computational analysis to guide future
development of practical motion generators. We believe that HuMo100M and
Being-M0.5 represent significant advances that will accelerate the adoption of
motion generation technologies in real-world applications. The project page is
available at https://beingbeyond.github.io/Being-M0.5.

</details>


### [150] [Enhancing Small-Scale Dataset Expansion with Triplet-Connection-based Sample Re-Weighting](https://arxiv.org/abs/2508.07723)
*Ting Xiang,Changjian Chen,Zhuo Tang,Qifeng Zhang,Fei Lyu,Li Yang,Jiapeng Zhang,Kenli Li*

Main category: cs.CV

TL;DR: 论文提出TriReWeight方法，通过三重连接样本权重调整提升生成数据增强性能，理论证明其泛化性接近最优，实验显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决因生成模型不可控性和自然语言歧义导致的噪声图像问题，提升生成数据增强质量。

Method: 提出TriReWeight方法，基于三重连接的样本权重调整，可集成任何生成数据增强方法。

Result: 在6个自然图像和3个医学数据集上平均分别提升7.9%和3.4%，理论泛化性接近最优。

Conclusion: TriReWeight方法有效提升生成数据增强性能，且理论支持其泛化性最优。

Abstract: The performance of computer vision models in certain real-world applications,
such as medical diagnosis, is often limited by the scarcity of available
images. Expanding datasets using pre-trained generative models is an effective
solution. However, due to the uncontrollable generation process and the
ambiguity of natural language, noisy images may be generated. Re-weighting is
an effective way to address this issue by assigning low weights to such noisy
images. We first theoretically analyze three types of supervision for the
generated images. Based on the theoretical analysis, we develop TriReWeight, a
triplet-connection-based sample re-weighting method to enhance generative data
augmentation. Theoretically, TriReWeight can be integrated with any generative
data augmentation methods and never downgrade their performance. Moreover, its
generalization approaches the optimal in the order $O(\sqrt{d\ln (n)/n})$. Our
experiments validate the correctness of the theoretical analysis and
demonstrate that our method outperforms the existing SOTA methods by $7.9\%$ on
average over six natural image datasets and by $3.4\%$ on average over three
medical datasets. We also experimentally validate that our method can enhance
the performance of different generative data augmentation methods.

</details>


### [151] [Grouped Speculative Decoding for Autoregressive Image Generation](https://arxiv.org/abs/2508.07747)
*Junhyuk So,Juncheol Shin,Hyunho Kook,Eunhyeok Park*

Main category: cs.CV

TL;DR: 提出了Grouped Speculative Decoding (GSD)方法，通过动态分组评估视觉有效token集群，加速自回归图像模型生成，平均提升3.7倍速度且不损失图像质量。


<details>
  <summary>Details</summary>
Motivation: 自回归图像模型生成速度慢，传统Speculative Decoding方法仅接受单一最可能token，未能利用图像token的冗余性和多样性。

Method: 提出GSD，动态评估视觉有效token集群，而非单一目标token，避免过度拒绝有效token。

Result: 实验显示GSD平均加速3.7倍，且保持图像质量，无需额外训练。

Conclusion: GSD为自回归图像模型提供了一种高效、无需训练的加速方案。

Abstract: Recently, autoregressive (AR) image models have demonstrated remarkable
generative capabilities, positioning themselves as a compelling alternative to
diffusion models. However, their sequential nature leads to long inference
times, limiting their practical scalability. In this work, we introduce Grouped
Speculative Decoding (GSD), a novel, training-free acceleration method for AR
image models. While recent studies have explored Speculative Decoding (SD) as a
means to speed up AR image generation, existing approaches either provide only
modest acceleration or require additional training. Our in-depth analysis
reveals a fundamental difference between language and image tokens: image
tokens exhibit inherent redundancy and diversity, meaning multiple tokens can
convey valid semantics. However, traditional SD methods are designed to accept
only a single most-likely token, which fails to leverage this difference,
leading to excessive false-negative rejections. To address this, we propose a
new SD strategy that evaluates clusters of visually valid tokens rather than
relying on a single target token. Additionally, we observe that static
clustering based on embedding distance is ineffective, which motivates our
dynamic GSD approach. Extensive experiments show that GSD accelerates AR image
models by an average of 3.7x while preserving image quality-all without
requiring any additional training. The source code is available at
https://github.com/junhyukso/GSD

</details>


### [152] [Safeguarding Generative AI Applications in Preclinical Imaging through Hybrid Anomaly Detection](https://arxiv.org/abs/2508.07923)
*Jakub Binda,Valentina Paneta,Vasileios Eleftheriadis,Hongkyou Chung,Panagiotis Papadimitroulas,Neo Christopher Chung*

Main category: cs.CV

TL;DR: 提出了一种混合异常检测框架，以增强生成式AI在核医学数据合成中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 生物医学影像的高风险性质需要检测和管理生成式AI模型的异常行为。

Method: 开发并实施了混合异常检测框架，应用于Pose2Xray和DosimetrEYE两个系统。

Result: 异常检测提高了系统可靠性、减少了人工监督，并支持实时质量控制。

Conclusion: 该方法增强了生成式AI在临床前环境中的工业可行性。

Abstract: Generative AI holds great potentials to automate and enhance data synthesis
in nuclear medicine. However, the high-stakes nature of biomedical imaging
necessitates robust mechanisms to detect and manage unexpected or erroneous
model behavior. We introduce development and implementation of a hybrid anomaly
detection framework to safeguard GenAI models in BIOEMTECH's eyes(TM) systems.
Two applications are demonstrated: Pose2Xray, which generates synthetic X-rays
from photographic mouse images, and DosimetrEYE, which estimates 3D radiation
dose maps from 2D SPECT/CT scans. In both cases, our outlier detection (OD)
enhances reliability, reduces manual oversight, and supports real-time quality
control. This approach strengthens the industrial viability of GenAI in
preclinical settings by increasing robustness, scalability, and regulatory
compliance.

</details>


### [153] [Comparison Reveals Commonality: Customized Image Generation through Contrastive Inversion](https://arxiv.org/abs/2508.07755)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

TL;DR: 提出了一种名为对比反转的新方法，无需额外信息即可通过对比图像提取共同概念，并通过对比学习和注意力调整提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手动提供的文本提示或空间掩码来提取共同概念，但可能导致辅助特征分离不完全，影响生成质量。

Method: 通过对比学习训练目标标记与图像辅助文本标记，并应用解耦交叉注意力微调来提高概念保真度。

Result: 实验结果表明，该方法在概念表示和编辑方面表现优异，优于现有技术。

Conclusion: 对比反转方法在无需额外信息的情况下实现了高质量的概念提取与编辑。

Abstract: The recent demand for customized image generation raises a need for
techniques that effectively extract the common concept from small sets of
images. Existing methods typically rely on additional guidance, such as text
prompts or spatial masks, to capture the common target concept. Unfortunately,
relying on manually provided guidance can lead to incomplete separation of
auxiliary features, which degrades generation quality.In this paper, we propose
Contrastive Inversion, a novel approach that identifies the common concept by
comparing the input images without relying on additional information. We train
the target token along with the image-wise auxiliary text tokens via
contrastive learning, which extracts the well-disentangled true semantics of
the target. Then we apply disentangled cross-attention fine-tuning to improve
concept fidelity without overfitting. Experimental results and analysis
demonstrate that our method achieves a balanced, high-level performance in both
concept representation and editing, outperforming existing techniques.

</details>


### [154] [PrIINeR: Towards Prior-Informed Implicit Neural Representations for Accelerated MRI](https://arxiv.org/abs/2508.08058)
*Ziad Al-Haj Hemidi,Eytan Kats,Mattias P. Heinrich*

Main category: cs.CV

TL;DR: PrIINeR是一种结合预训练深度学习模型和隐式神经表示（INR）的MRI重建方法，显著提高了图像质量和减少伪影。


<details>
  <summary>Details</summary>
Motivation: 现有的INR在MRI高加速因子下表现不佳，导致结构丢失和伪影。PrIINeR旨在通过整合预训练模型的先验知识来改进这一问题。

Method: PrIINeR通过结合群体知识和实例优化，并强制双重数据一致性，以更有效地重建k空间数据。

Result: 在NYU fastMRI数据集上，PrIINeR不仅优于现有INR方法，还超越了一些基于学习的先进方法，显著提高了结构保留和保真度。

Conclusion: PrIINeR为高质量、加速MRI重建提供了一个更可靠的解决方案，并公开了代码。

Abstract: Accelerating Magnetic Resonance Imaging (MRI) reduces scan time but often
degrades image quality. While Implicit Neural Representations (INRs) show
promise for MRI reconstruction, they struggle at high acceleration factors due
to weak prior constraints, leading to structural loss and aliasing artefacts.
To address this, we propose PrIINeR, an INR-based MRI reconstruction method
that integrates prior knowledge from pre-trained deep learning models into the
INR framework. By combining population-level knowledge with instance-based
optimization and enforcing dual data consistency, PrIINeR aligns both with the
acquired k-space data and the prior-informed reconstruction. Evaluated on the
NYU fastMRI dataset, our method not only outperforms state-of-the-art INR-based
approaches but also improves upon several learning-based state-of-the-art
methods, significantly improving structural preservation and fidelity while
effectively removing aliasing artefacts.PrIINeR bridges deep learning and
INR-based techniques, offering a more reliable solution for high-quality,
accelerated MRI reconstruction. The code is publicly available on
https://github.com/multimodallearning/PrIINeR.

</details>


### [155] [Correspondence as Video: Test-Time Adaption on SAM2 for Reference Segmentation in the Wild](https://arxiv.org/abs/2508.07759)
*Haoran Wang,Zekun Li,Jian Zhang,Lei Qi,Yinghuan Shi*

Main category: cs.CV

TL;DR: 提出了一种名为CAV-SAM的新方法，通过将参考-目标图像对的对应关系视为伪视频，利用SAM2的交互式视频对象分割能力，实现轻量化的下游任务适配。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉模型（如SAM）在下游任务中存在显著局限性，现有参考分割方法依赖于元学习，但需要大量数据和计算成本。

Method: 将参考-目标图像对的对应关系表示为伪视频，利用SAM2的iVOS能力构建CAV-SAM框架，包括语义转换（DBST）和几何对齐（TTGA）模块。

Result: 在广泛使用的数据集上，CAV-SAM实现超过5%的分割性能提升。

Conclusion: CAV-SAM是一种轻量化的适应方法，显著提升性能且无需大规模元训练。

Abstract: Large vision models like the Segment Anything Model (SAM) exhibit significant
limitations when applied to downstream tasks in the wild. Consequently,
reference segmentation, which leverages reference images and their
corresponding masks to impart novel knowledge to the model, emerges as a
promising new direction for adapting vision models. However, existing reference
segmentation approaches predominantly rely on meta-learning, which still
necessitates an extensive meta-training process and brings massive data and
computational cost. In this study, we propose a novel approach by representing
the inherent correspondence between reference-target image pairs as a pseudo
video. This perspective allows the latest version of SAM, known as SAM2, which
is equipped with interactive video object segmentation (iVOS) capabilities, to
be adapted to downstream tasks in a lightweight manner. We term this approach
Correspondence As Video for SAM (CAV-SAM). CAV-SAM comprises two key modules:
the Diffusion-Based Semantic Transition (DBST) module employs a diffusion model
to construct a semantic transformation sequence, while the Test-Time Geometric
Alignment (TTGA) module aligns the geometric changes within this sequence
through test-time fine-tuning. We evaluated CAVSAM on widely-used datasets,
achieving segmentation performance improvements exceeding 5% over SOTA methods.
Implementation is provided in the supplementary materials.

</details>


### [156] [Investigating the Design Space of Visual Grounding in Multimodal Large Language Model](https://arxiv.org/abs/2508.08066)
*Weitai Kang,Weiming Zhuang,Zhizhong Li,Yan Yan,Lingjuan Lyu*

Main category: cs.CV

TL;DR: 本文全面研究了影响多模态大语言模型（MLLMs）视觉定位（VG）性能的不同设计选择，通过LLaVA-1.5模型验证，提出了优化设计并显著提升了VG任务的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管现有方法在多模态大语言模型的视觉定位任务中表现良好，但其设计选择缺乏系统性验证。本文旨在填补这一空白，为VG任务提供更优化的MLLM设计。

Method: 使用广泛采用的LLaVA-1.5模型，分析不同视觉定位范式和数据设计的影响，并通过消融实验验证最优设计。

Result: 研究显著提升了VG任务的性能，在RefCOCO/+/g数据集上分别提升了5.6%、6.9%和7.0%。

Conclusion: 本文的系统研究为MLLMs的视觉定位任务提供了有效的设计指南，显著提升了模型性能。

Abstract: Fine-grained multimodal capability in Multimodal Large Language Models
(MLLMs) has emerged as a critical research direction, particularly for tackling
the visual grounding (VG) problem. Despite the strong performance achieved by
existing approaches, they often employ disparate design choices when
fine-tuning MLLMs for VG, lacking systematic verification to support these
designs. To bridge this gap, this paper presents a comprehensive study of
various design choices that impact the VG performance of MLLMs. We conduct our
analysis using LLaVA-1.5, which has been widely adopted in prior empirical
studies of MLLMs. While more recent models exist, we follow this convention to
ensure our findings remain broadly applicable and extendable to other
architectures. We cover two key aspects: (1) exploring different visual
grounding paradigms in MLLMs, identifying the most effective design, and
providing our insights; and (2) conducting ablation studies on the design of
grounding data to optimize MLLMs' fine-tuning for the VG task. Finally, our
findings contribute to a stronger MLLM for VG, achieving improvements of +5.6%
/ +6.9% / +7.0% on RefCOCO/+/g over the LLaVA-1.5.

</details>


### [157] [UniSVG: A Unified Dataset for Vector Graphic Understanding and Generation with Multimodal Large Language Models](https://arxiv.org/abs/2508.07766)
*Jinke Li,Jiarui Yu,Chenxing Wei,Hande Dong,Qiang Lin,Liangjing Yang,Zhicai Wang,Yanbin Hao*

Main category: cs.CV

TL;DR: 论文提出首个综合性SVG数据集UniSVG，用于多模态大语言模型训练与评估，显著提升SVG理解与生成任务性能。


<details>
  <summary>Details</summary>
Motivation: 由于SVG在缩放时保持质量且广泛用于计算机视觉和艺术设计，AI对SVG的理解与生成需求迫切，但目前仍具挑战性。

Method: 开发包含525k数据项的SVG数据集UniSVG，支持多模态输入（文本提示与视觉参考）的SVG生成与理解。

Result: 基于UniSVG训练的模型在SVG任务中表现优异，超越GPT-4V等闭源模型。

Conclusion: UniSVG数据集为SVG领域的研究提供了统一平台，显著提升多模态大语言模型的性能。

Abstract: Unlike bitmap images, scalable vector graphics (SVG) maintain quality when
scaled, frequently employed in computer vision and artistic design in the
representation of SVG code. In this era of proliferating AI-powered systems,
enabling AI to understand and generate SVG has become increasingly urgent.
However, AI-driven SVG understanding and generation (U&G) remain significant
challenges. SVG code, equivalent to a set of curves and lines controlled by
floating-point parameters, demands high precision in SVG U&G. Besides, SVG
generation operates under diverse conditional constraints, including textual
prompts and visual references, which requires powerful multi-modal processing
for condition-to-SVG transformation. Recently, the rapid growth of Multi-modal
Large Language Models (MLLMs) have demonstrated capabilities to process
multi-modal inputs and generate complex vector controlling parameters,
suggesting the potential to address SVG U&G tasks within a unified model. To
unlock MLLM's capabilities in the SVG area, we propose an SVG-centric dataset
called UniSVG, comprising 525k data items, tailored for MLLM training and
evaluation. To our best knowledge, it is the first comprehensive dataset
designed for unified SVG generation (from textual prompts and images) and SVG
understanding (color, category, usage, etc.). As expected, learning on the
proposed dataset boosts open-source MLLMs' performance on various SVG U&G
tasks, surpassing SOTA close-source MLLMs like GPT-4V. We release dataset,
benchmark, weights, codes and experiment details on
https://ryanlijinke.github.io/.

</details>


### [158] [MDD-Net: Multimodal Depression Detection through Mutual Transformer](https://arxiv.org/abs/2508.08093)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出了一种基于声学和视觉数据的多模态抑郁检测网络（MDD-Net），利用互Transformer有效提取和融合多模态特征，实验结果表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用社交媒体平台的数据进行心理健康研究，通过多模态数据更高效地检测抑郁状态。

Method: 设计MDD-Net，包含声学特征提取模块、视觉特征提取模块、互Transformer模块和检测层，融合多模态特征进行抑郁检测。

Result: 在D-Vlog数据集上的实验显示，MDD-Net的F1-Score比现有方法提高了17.37%。

Conclusion: MDD-Net在多模态抑郁检测中表现出色，为心理健康研究提供了有效工具。

Abstract: Depression is a major mental health condition that severely impacts the
emotional and physical well-being of individuals. The simple nature of data
collection from social media platforms has attracted significant interest in
properly utilizing this information for mental health research. A Multimodal
Depression Detection Network (MDD-Net), utilizing acoustic and visual data
obtained from social media networks, is proposed in this work where mutual
transformers are exploited to efficiently extract and fuse multimodal features
for efficient depression detection. The MDD-Net consists of four core modules:
an acoustic feature extraction module for retrieving relevant acoustic
attributes, a visual feature extraction module for extracting significant
high-level patterns, a mutual transformer for computing the correlations among
the generated features and fusing these features from multiple modalities, and
a detection layer for detecting depression using the fused feature
representations. The extensive experiments are performed using the multimodal
D-Vlog dataset, and the findings reveal that the developed multimodal
depression detection network surpasses the state-of-the-art by up to 17.37% for
F1-Score, demonstrating the greater performance of the proposed system. The
source code is accessible at
https://github.com/rezwanh001/Multimodal-Depression-Detection.

</details>


### [159] [Dream4D: Lifting Camera-Controlled I2V towards Spatiotemporally Consistent 4D Generation](https://arxiv.org/abs/2508.07769)
*Xiaoyan Liu,Kangrui Li,Jiaxin Liu*

Main category: cs.CV

TL;DR: Dream4D是一个新框架，通过结合可控视频生成和神经4D重建，解决了4D内容合成中的时空一致性问题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理复杂场景动力学时难以保持视图一致性，特别是在大规模动态环境中。

Method: 采用两阶段架构：首先通过少样本学习从单图像预测最优相机轨迹，然后通过姿势条件扩散生成几何一致的多视图序列，最后转换为持久4D表示。

Result: Dream4D在质量指标（如mPSNR、mSSIM）上优于现有方法。

Conclusion: 该框架首次同时利用视频扩散模型的丰富时间先验和重建模型的几何意识，显著提升了4D生成质量。

Abstract: The synthesis of spatiotemporally coherent 4D content presents fundamental
challenges in computer vision, requiring simultaneous modeling of high-fidelity
spatial representations and physically plausible temporal dynamics. Current
approaches often struggle to maintain view consistency while handling complex
scene dynamics, particularly in large-scale environments with multiple
interacting elements. This work introduces Dream4D, a novel framework that
bridges this gap through a synergy of controllable video generation and neural
4D reconstruction. Our approach seamlessly combines a two-stage architecture:
it first predicts optimal camera trajectories from a single image using
few-shot learning, then generates geometrically consistent multi-view sequences
via a specialized pose-conditioned diffusion process, which are finally
converted into a persistent 4D representation. This framework is the first to
leverage both rich temporal priors from video diffusion models and geometric
awareness of the reconstruction models, which significantly facilitates 4D
generation and shows higher quality (e.g., mPSNR, mSSIM) over existing methods.

</details>


### [160] [Integrating Task-Specific and Universal Adapters for Pre-Trained Model-based Class-Incremental Learning](https://arxiv.org/abs/2508.08165)
*Yan Wang,Da-Wei Zhou,Han-Jia Ye*

Main category: cs.CV

TL;DR: 该论文提出了一种结合任务特定和通用适配器（TUNA）的方法，用于类增量学习（CIL），通过熵选择机制和融合策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练模型的CIL方法通常冻结网络并使用轻量级模块（如适配器）适应增量任务，但模块选择错误和任务特定模块忽略共享知识导致性能下降。

Method: 提出TUNA方法，训练任务特定适配器捕获关键特征并引入熵选择机制，同时通过适配器融合策略构建通用适配器，结合两类适配器预测以利用专业和共享知识。

Result: 在多个基准数据集上的实验表明，该方法实现了最先进的性能。

Conclusion: TUNA方法通过结合任务特定和通用适配器，有效解决了CIL中模块选择和知识共享的问题，显著提升了性能。

Abstract: Class-Incremental Learning (CIL) requires a learning system to continually
learn new classes without forgetting. Existing pre-trained model-based CIL
methods often freeze the pre-trained network and adapt to incremental tasks
using additional lightweight modules such as adapters. However, incorrect
module selection during inference hurts performance, and task-specific modules
often overlook shared general knowledge, leading to errors on distinguishing
between similar classes across tasks. To address the aforementioned challenges,
we propose integrating Task-Specific and Universal Adapters (TUNA) in this
paper. Specifically, we train task-specific adapters to capture the most
crucial features relevant to their respective tasks and introduce an
entropy-based selection mechanism to choose the most suitable adapter.
Furthermore, we leverage an adapter fusion strategy to construct a universal
adapter, which encodes the most discriminative features shared across tasks. We
combine task-specific and universal adapter predictions to harness both
specialized and general knowledge during inference. Extensive experiments on
various benchmark datasets demonstrate the state-of-the-art performance of our
approach. Code is available at: https://github.com/LAMDA-CL/ICCV2025-TUNA

</details>


### [161] [Prototype-Guided Curriculum Learning for Zero-Shot Learning](https://arxiv.org/abs/2508.07771)
*Lei Wang,Shiming Chen,Guo-Sen Xie,Ziming Hong,Chaojian Yu,Qinmu Peng,Xinge You*

Main category: cs.CV

TL;DR: 本文提出了一种原型引导的课程学习框架（CLZSL），通过两个模块改进零样本学习中噪声监督问题，提升视觉-语义映射的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本学习中的语义原型是手动定义的，可能因实例级不匹配和类别级不精确引入噪声，影响知识迁移效果。

Method: 提出CLZSL框架，包含原型引导的课程学习（PCL）模块和原型更新（PUP）模块，分别解决实例级不匹配和类别级不精确问题。

Result: 在AWA2、SUN和CUB数据集上的实验验证了方法的有效性。

Conclusion: CLZSL通过动态更新原型和渐进学习策略，显著提升了零样本学习的性能。

Abstract: In Zero-Shot Learning (ZSL), embedding-based methods enable knowledge
transfer from seen to unseen classes by learning a visual-semantic mapping from
seen-class images to class-level semantic prototypes (e.g., attributes).
However, these semantic prototypes are manually defined and may introduce noisy
supervision for two main reasons: (i) instance-level mismatch: variations in
perspective, occlusion, and annotation bias will cause discrepancies between
individual sample and the class-level semantic prototypes; and (ii) class-level
imprecision: the manually defined semantic prototypes may not accurately
reflect the true semantics of the class. Consequently, the visual-semantic
mapping will be misled, reducing the effectiveness of knowledge transfer to
unseen classes. In this work, we propose a prototype-guided curriculum learning
framework (dubbed as CLZSL), which mitigates instance-level mismatches through
a Prototype-Guided Curriculum Learning (PCL) module and addresses class-level
imprecision via a Prototype Update (PUP) module. Specifically, the PCL module
prioritizes samples with high cosine similarity between their visual mappings
and the class-level semantic prototypes, and progressively advances to
less-aligned samples, thereby reducing the interference of instance-level
mismatches to achieve accurate visual-semantic mapping. Besides, the PUP module
dynamically updates the class-level semantic prototypes by leveraging the
visual mappings learned from instances, thereby reducing class-level
imprecision and further improving the visual-semantic mapping. Experiments were
conducted on standard benchmark datasets-AWA2, SUN, and CUB-to verify the
effectiveness of our method.

</details>


### [162] [Forecasting Continuous Non-Conservative Dynamical Systems in SO(3)](https://arxiv.org/abs/2508.07775)
*Lennart Bastian,Mohammad Rashed,Nassir Navab,Tolga Birdal*

Main category: cs.CV

TL;DR: 论文提出了一种利用神经控制微分方程和SO(3) Savitzky-Golay路径，对3D旋转运动进行物理和几何意义建模的方法，解决了传统依赖能量守恒或恒速假设的局限性。


<details>
  <summary>Details</summary>
Motivation: 旋转运动建模是计算机视觉中的基础任务，但SO(3)外推面临未知惯性矩、非保守力噪声观察等问题，需要一种无需依赖能量守恒的鲁棒方法。

Method: 结合神经控制微分方程和SO(3) Savitzky-Golay路径，直接从噪声状态中学习动态，适用于复杂非惯性系统。

Result: 模型在训练中从噪声状态近似物体动态，在仿真和真实场景中表现出鲁棒外推能力，并能整合到现有流程中。

Conclusion: 本文方法无需能量或动量守恒假设，对输入噪声鲁棒，适用于复杂系统，扩展了传统方法的局限性。

Abstract: Modeling the rotation of moving objects is a fundamental task in computer
vision, yet $SO(3)$ extrapolation still presents numerous challenges: (1)
unknown quantities such as the moment of inertia complicate dynamics, (2) the
presence of external forces and torques can lead to non-conservative
kinematics, and (3) estimating evolving state trajectories under sparse, noisy
observations requires robustness. We propose modeling trajectories of noisy
pose estimates on the manifold of 3D rotations in a physically and
geometrically meaningful way by leveraging Neural Controlled Differential
Equations guided with $SO(3)$ Savitzky-Golay paths. Existing extrapolation
methods often rely on energy conservation or constant velocity assumptions,
limiting their applicability in real-world scenarios involving non-conservative
forces. In contrast, our approach is agnostic to energy and momentum
conservation while being robust to input noise, making it applicable to
complex, non-inertial systems. Our approach is easily integrated as a module in
existing pipelines and generalizes well to trajectories with unknown physical
parameters. By learning to approximate object dynamics from noisy states during
training, our model attains robust extrapolation capabilities in simulation and
various real-world settings. Code is available at
https://github.com/bastianlb/forecasting-rotational-dynamics

</details>


### [163] [GaitSnippet: Gait Recognition Beyond Unordered Sets and Ordered Sequences](https://arxiv.org/abs/2508.07782)
*Saihui Hou,Chenye Wang,Wenpeng Lang,Zhengxiang Lan,Yongzhen Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于片段（snippet）的步态识别方法，通过结合多尺度时间上下文信息，解决了现有方法在短范围和长范围时间依赖性上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法（基于无序集或有序序列）在短范围和长范围时间依赖性上存在不足，限制了性能。

Method: 将步态视为个性化动作的组合，用随机选取的片段（snippet）表示动作，提出了片段采样和片段建模的关键技术。

Result: 在四个常用步态数据集上验证了方法的有效性，例如在Gait3D和GREW上分别达到77.5%和81.7%的rank-1准确率。

Conclusion: 该方法通过片段学习多尺度时间上下文信息，提升了步态识别性能，展现了片段的潜力。

Abstract: Recent advancements in gait recognition have significantly enhanced
performance by treating silhouettes as either an unordered set or an ordered
sequence. However, both set-based and sequence-based approaches exhibit notable
limitations. Specifically, set-based methods tend to overlook short-range
temporal context for individual frames, while sequence-based methods struggle
to capture long-range temporal dependencies effectively. To address these
challenges, we draw inspiration from human identification and propose a new
perspective that conceptualizes human gait as a composition of individualized
actions. Each action is represented by a series of frames, randomly selected
from a continuous segment of the sequence, which we term a snippet.
Fundamentally, the collection of snippets for a given sequence enables the
incorporation of multi-scale temporal context, facilitating more comprehensive
gait feature learning. Moreover, we introduce a non-trivial solution for
snippet-based gait recognition, focusing on Snippet Sampling and Snippet
Modeling as key components. Extensive experiments on four widely-used gait
datasets validate the effectiveness of our proposed approach and, more
importantly, highlight the potential of gait snippets. For instance, our method
achieves the rank-1 accuracy of 77.5% on Gait3D and 81.7% on GREW using a 2D
convolution-based backbone.

</details>


### [164] [Boosting Active Defense Persistence: A Two-Stage Defense Framework Combining Interruption and Poisoning Against Deepfake](https://arxiv.org/abs/2508.07795)
*Hongrui Zheng,Yuezun Li,Liejun Wang,Yunfeng Diao,Zhiqing Guo*

Main category: cs.CV

TL;DR: 本文提出了一种新型的两阶段防御框架（TSDF），通过双功能对抗扰动同时扭曲伪造内容和破坏攻击者的模型适应能力，解决了现有主动防御策略持久性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造主动防御策略因无法持久抵抗攻击者模型的重训练而失效，亟需一种能够长期有效的防御机制。

Method: 采用两阶段防御框架（TSDF），利用双功能对抗扰动直接扭曲伪造结果并破坏攻击者的数据准备过程，防止模型适应防御扰动。

Result: 实验表明，TSDF具有强大的双重防御能力，能显著提升主动防御的持久性，优于传统中断方法。

Conclusion: TSDF通过双功能对抗扰动和中毒数据源，实现了长期有效的深度伪造防御，解决了静态防御的持久性问题。

Abstract: Active defense strategies have been developed to counter the threat of
deepfake technology. However, a primary challenge is their lack of persistence,
as their effectiveness is often short-lived. Attackers can bypass these
defenses by simply collecting protected samples and retraining their models.
This means that static defenses inevitably fail when attackers retrain their
models, which severely limits practical use. We argue that an effective defense
not only distorts forged content but also blocks the model's ability to adapt,
which occurs when attackers retrain their models on protected images. To
achieve this, we propose an innovative Two-Stage Defense Framework (TSDF).
Benefiting from the intensity separation mechanism designed in this paper, the
framework uses dual-function adversarial perturbations to perform two roles.
First, it can directly distort the forged results. Second, it acts as a
poisoning vehicle that disrupts the data preparation process essential for an
attacker's retraining pipeline. By poisoning the data source, TSDF aims to
prevent the attacker's model from adapting to the defensive perturbations, thus
ensuring the defense remains effective long-term. Comprehensive experiments
show that the performance of traditional interruption methods degrades sharply
when it is subjected to adversarial retraining. However, our framework shows a
strong dual defense capability, which can improve the persistence of active
defense. Our code will be available at https://github.com/vpsg-research/TSDF.

</details>


### [165] [Power Battery Detection](https://arxiv.org/abs/2508.07797)
*Xiaoqi Zhao,Peiqian Cao,Lihe Zhang,Zonglei Feng,Hanqi Liu,Jiaming Zuo,Youwei Pang,Weisi Lin,Georges El Fakhri,Huchuan Lu,Xiaofeng Liu*

Main category: cs.CV

TL;DR: 论文提出首个大规模动力电池检测（PBD）基准数据集PBD5K，并开发智能标注流程与模型MDCNeXt，用于定位X光图像中极板的密集端点。


<details>
  <summary>Details</summary>
Motivation: 动力电池内部缺陷可能引发安全隐患，现有手动检测和传统视觉算法效率低下且效果不佳，急需新方法和工具。

Method: 将PBD任务定义为点级分割问题，提出MDCNeXt模型，整合多维结构线索并使用状态空间模块优化结果。

Result: 开发了PBD5K数据集和智能标注流程，MDCNeXt模型通过任务提示和密度感知模块显著提升了检测精度。

Conclusion: PBD5K和MDCNeXt为动力电池检测提供了高效解决方案，并为相关研究开辟了新方向。

Abstract: Power batteries are essential components in electric vehicles, where internal
structural defects can pose serious safety risks. We conduct a comprehensive
study on a new task, power battery detection (PBD), which aims to localize the
dense endpoints of cathode and anode plates from industrial X-ray images for
quality inspection. Manual inspection is inefficient and error-prone, while
traditional vision algorithms struggle with densely packed plates, low
contrast, scale variation, and imaging artifacts. To address this issue and
drive more attention into this meaningful task, we present PBD5K, the first
large-scale benchmark for this task, consisting of 5,000 X-ray images from nine
battery types with fine-grained annotations and eight types of real-world
visual interference. To support scalable and consistent labeling, we develop an
intelligent annotation pipeline that combines image filtering, model-assisted
pre-labeling, cross-verification, and layered quality evaluation. We formulate
PBD as a point-level segmentation problem and propose MDCNeXt, a model designed
to extract and integrate multi-dimensional structure clues including point,
line, and count information from the plate itself. To improve discrimination
between plates and suppress visual interference, MDCNeXt incorporates two state
space modules. The first is a prompt-filtered module that learns contrastive
relationships guided by task-specific prompts. The second is a density-aware
reordering module that refines segmentation in regions with high plate density.
In addition, we propose a distance-adaptive mask generation strategy to provide
robust supervision under varying spatial distributions of anode and cathode
positions. The source code and datasets will be publicly available at
\href{https://github.com/Xiaoqi-Zhao-DLUT/X-ray-PBD}{PBD5K}.

</details>


### [166] [MambaTrans: Multimodal Fusion Image Translation via Large Language Model Priors for Downstream Visual Tasks](https://arxiv.org/abs/2508.07803)
*Yushen Xu,Xiaosong Li,Zhenyu Kuang,Xiaoqi Cheng,Haishu Tan,Huafeng Li*

Main category: cs.CV

TL;DR: MambaTrans是一种新颖的多模态融合图像模态转换器，通过结合多模态大语言模型的描述和语义分割模型的掩码，提高下游任务性能，而无需调整预训练模型的参数。


<details>
  <summary>Details</summary>
Motivation: 由于可见图像和多模态融合图像之间的像素分布差异显著，现有预训练模型在下游任务中的性能可能下降，甚至低于仅使用可见图像的情况。本文旨在解决这一问题。

Method: 提出了MambaTrans，其核心是多模型状态空间块，结合掩码-图像-文本跨注意力机制和3D选择性扫描模块，利用目标检测的先验知识最小化训练中的检测损失。

Result: 在公共数据集上的实验表明，MambaTrans能有效提升多模态图像在下游任务中的性能。

Conclusion: MambaTrans通过新颖的模态转换方法，显著改善了多模态融合图像在下游任务中的适应性。

Abstract: The goal of multimodal image fusion is to integrate complementary information
from infrared and visible images, generating multimodal fused images for
downstream tasks. Existing downstream pre-training models are typically trained
on visible images. However, the significant pixel distribution differences
between visible and multimodal fusion images can degrade downstream task
performance, sometimes even below that of using only visible images. This paper
explores adapting multimodal fused images with significant modality differences
to object detection and semantic segmentation models trained on visible images.
To address this, we propose MambaTrans, a novel multimodal fusion image
modality translator. MambaTrans uses descriptions from a multimodal large
language model and masks from semantic segmentation models as input. Its core
component, the Multi-Model State Space Block, combines mask-image-text
cross-attention and a 3D-Selective Scan Module, enhancing pure visual
capabilities. By leveraging object detection prior knowledge, MambaTrans
minimizes detection loss during training and captures long-term dependencies
among text, masks, and images. This enables favorable results in pre-trained
models without adjusting their parameters. Experiments on public datasets show
that MambaTrans effectively improves multimodal image performance in downstream
tasks.

</details>


### [167] [Pose-RFT: Enhancing MLLMs for 3D Pose Generation via Hybrid Action Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.07804)
*Bao Li,Xiaomei Zhang,Miao Xu,Zhaoxin Fan,Xiangyu Zhu,Zhen Lei*

Main category: cs.CV

TL;DR: Pose-RFT提出了一种基于强化学习的框架，通过混合动作优化改进3D人体姿态生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督学习的多模态大语言模型在3D姿态生成任务中难以建模模糊性和任务对齐问题。

Method: 采用HyGRPO算法，结合离散语言预测和连续姿态生成的混合动作强化学习，并通过任务特定奖励函数优化。

Result: 实验显示Pose-RFT在多个基准测试中显著优于现有模型。

Conclusion: 混合动作强化微调在3D姿态生成任务中表现出高效性。

Abstract: Generating 3D human poses from multimodal inputs such as images or text
requires models to capture both rich spatial and semantic correspondences.
While pose-specific multimodal large language models (MLLMs) have shown promise
in this task, they are typically trained with supervised objectives such as
SMPL parameter regression or token-level prediction, which struggle to model
the inherent ambiguity and achieve task-specific alignment required for
accurate 3D pose generation. To address these limitations, we propose Pose-RFT,
a reinforcement fine-tuning framework tailored for 3D human pose generation in
MLLMs. We formulate the task as a hybrid action reinforcement learning problem
that jointly optimizes discrete language prediction and continuous pose
generation. To this end, we introduce HyGRPO, a hybrid reinforcement learning
algorithm that performs group-wise reward normalization over sampled responses
to guide joint optimization of discrete and continuous actions. Pose-RFT
further incorporates task-specific reward functions to guide optimization
towards spatial alignment in image-to-pose generation and semantic consistency
in text-to-pose generation. Extensive experiments on multiple pose generation
benchmarks demonstrate that Pose-RFT significantly improves performance over
existing pose-specific MLLMs, validating the effectiveness of hybrid action
reinforcement fine-tuning for 3D pose generation.

</details>


### [168] [DiTVR: Zero-Shot Diffusion Transformer for Video Restoration](https://arxiv.org/abs/2508.07811)
*Sicheng Gao,Nancy Mehta,Zongwei Wu,Radu Timofte*

Main category: cs.CV

TL;DR: DiTVR是一个零样本视频恢复框架，结合扩散变换器与轨迹感知注意力机制，解决了传统回归方法和生成扩散模型在时间一致性和细节真实性上的问题。


<details>
  <summary>Details</summary>
Motivation: 传统视频恢复方法需要大量配对数据集且细节不真实，而现有生成扩散模型难以保证时间一致性，因此提出DiTVR框架。

Method: 使用扩散变换器与轨迹感知注意力机制，结合光流轨迹对齐标记，并通过小波引导的流一致性采样器注入数据一致性。

Result: DiTVR在视频恢复基准测试中取得了新的零样本最优结果，表现出卓越的时间一致性和细节保留能力。

Conclusion: DiTVR通过创新的注意力机制和采样策略，显著提升了视频恢复的质量和效率。

Abstract: Video restoration aims to reconstruct high quality video sequences from low
quality inputs, addressing tasks such as super resolution, denoising, and
deblurring. Traditional regression based methods often produce unrealistic
details and require extensive paired datasets, while recent generative
diffusion models face challenges in ensuring temporal consistency. We introduce
DiTVR, a zero shot video restoration framework that couples a diffusion
transformer with trajectory aware attention and a wavelet guided, flow
consistent sampler. Unlike prior 3D convolutional or frame wise diffusion
approaches, our attention mechanism aligns tokens along optical flow
trajectories, with particular emphasis on vital layers that exhibit the highest
sensitivity to temporal dynamics. A spatiotemporal neighbour cache dynamically
selects relevant tokens based on motion correspondences across frames. The flow
guided sampler injects data consistency only into low-frequency bands,
preserving high frequency priors while accelerating convergence. DiTVR
establishes a new zero shot state of the art on video restoration benchmarks,
demonstrating superior temporal consistency and detail preservation while
remaining robust to flow noise and occlusions.

</details>


### [169] [Semi-supervised Multiscale Matching for SAR-Optical Image](https://arxiv.org/abs/2508.07812)
*Jingze Gai,Changchun Li*

Main category: cs.CV

TL;DR: 论文提出了一种半监督的SAR-光学图像匹配方法（S2M2-SAR），解决了传统方法依赖大量标注数据的难题。


<details>
  <summary>Details</summary>
Motivation: 现有的SAR-光学图像匹配方法依赖像素级标注数据，标注过程耗时且复杂，难以获取足够的数据。

Method: 设计了半监督的匹配流程，利用伪标签技术对无标注图像进行标记，并通过跨模态特征增强模块提升匹配性能。

Result: 实验表明，S2M2-SAR的性能优于现有半监督方法，并与全监督方法相当。

Conclusion: S2M2-SAR在减少标注需求的同时，保持了高匹配性能，具有实际应用潜力。

Abstract: Driven by the complementary nature of optical and synthetic aperture radar
(SAR) images, SAR-optical image matching has garnered significant interest.
Most existing SAR-optical image matching methods aim to capture effective
matching features by employing the supervision of pixel-level matched
correspondences within SAR-optical image pairs, which, however, suffers from
time-consuming and complex manual annotation, making it difficult to collect
sufficient labeled SAR-optical image pairs. To handle this, we design a
semi-supervised SAR-optical image matching pipeline that leverages both scarce
labeled and abundant unlabeled image pairs and propose a semi-supervised
multiscale matching for SAR-optical image matching (S2M2-SAR). Specifically, we
pseudo-label those unlabeled SAR-optical image pairs with pseudo ground-truth
similarity heatmaps by combining both deep and shallow level matching results,
and train the matching model by employing labeled and pseudo-labeled similarity
heatmaps. In addition, we introduce a cross-modal feature enhancement module
trained using a cross-modality mutual independence loss, which requires no
ground-truth labels. This unsupervised objective promotes the separation of
modality-shared and modality-specific features by encouraging statistical
independence between them, enabling effective feature disentanglement across
optical and SAR modalities. To evaluate the effectiveness of S2M2-SAR, we
compare it with existing competitors on benchmark datasets. Experimental
results demonstrate that S2M2-SAR not only surpasses existing semi-supervised
methods but also achieves performance competitive with fully supervised SOTA
methods, demonstrating its efficiency and practical potential.

</details>


### [170] [Segmenting and Understanding: Region-aware Semantic Attention for Fine-grained Image Quality Assessment with Large Language Models](https://arxiv.org/abs/2508.07818)
*Chenyue Song,Chen Hui,Haiqi Zhu,Feng Jiang,Yachun Mi,Wei Zhang,Shaohui Liu*

Main category: cs.CV

TL;DR: RSFIQA模型通过动态分割语义区域并结合多模态大语言模型，关注局部质量变化与语义区域，提升了无参考图像质量评估的表现。


<details>
  <summary>Details</summary>
Motivation: 现有无参考图像质量评估（NR-IQA）方法对全局表征或均匀区域特征的处理能力有限，难以捕捉语义显著性区域和局部质量变化。

Method: 提出RSFIQA模型，利用SAM动态分割图像为非重叠语义区域，结合MLLM提取内容和感知多维度失真，并通过区域感知语义注意力机制（RSA）生成全局注意力图。

Result: 实验表明，RSFIQA在多个基准数据集上实现了竞争性的质量预测性能。

Conclusion: RSFIQA通过综合局部语义和质量退化信息，显著提升了NR-IQA的鲁棒性和有效性。

Abstract: No-reference image quality assessment (NR-IQA) aims to simulate the process
of perceiving image quality aligned with subjective human perception. However,
existing NR-IQA methods either focus on global representations that leads to
limited insights into the semantically salient regions or employ a uniform
weighting for region features that weakens the sensitivity to local quality
variations. In this paper, we propose a fine-grained image quality assessment
model, named RSFIQA, which integrates region-level distortion information to
perceive multi-dimensional quality discrepancies. To enhance regional quality
awareness, we first utilize the Segment Anything Model (SAM) to dynamically
partition the input image into non-overlapping semantic regions. For each
region, we teach a powerful Multi-modal Large Language Model (MLLM) to extract
descriptive content and perceive multi-dimensional distortions, enabling a
comprehensive understanding of both local semantics and quality degradations.
To effectively leverage this information, we introduce Region-Aware Semantic
Attention (RSA) mechanism, which generates a global attention map by
aggregating fine-grained representations from local regions. In addition,
RSFIQA is backbone-agnostic and can be seamlessly integrated into various deep
neural network architectures. Extensive experiments demonstrate the robustness
and effectiveness of the proposed method, which achieves competitive quality
prediction performance across multiple benchmark datasets.

</details>


### [171] [MIMIC: Multimodal Inversion for Model Interpretation and Conceptualization](https://arxiv.org/abs/2508.07833)
*Animesh Jain,Alexandros Stergiou*

Main category: cs.CV

TL;DR: MIMIC框架通过可视化VLMs内部编码，生成视觉概念以提升模型透明度和信任度。


<details>
  <summary>Details</summary>
Motivation: VLMs的多模态输入编码复杂且难以解释，限制了透明度和信任。

Method: 提出MIMIC框架，结合VLM反转和特征对齐目标，辅以三种正则化方法。

Result: 通过定性和定量评估，展示了高视觉质量和语义一致性的结果。

Conclusion: MIMIC是首个针对VLM视觉解释的模型反转方法，提升了可解释性。

Abstract: Vision Language Models (VLMs) encode multimodal inputs over large, complex,
and difficult-to-interpret architectures, which limit transparency and trust.
We propose a Multimodal Inversion for Model Interpretation and
Conceptualization (MIMIC) framework to visualize the internal representations
of VLMs by synthesizing visual concepts corresponding to internal encodings.
MIMIC uses a joint VLM-based inversion and a feature alignment objective to
account for VLM's autoregressive processing. It additionally includes a triplet
of regularizers for spatial alignment, natural image smoothness, and semantic
realism. We quantitatively and qualitatively evaluate MIMIC by inverting visual
concepts over a range of varying-length free-form VLM output texts. Reported
results include both standard visual quality metrics as well as semantic
text-based metrics. To the best of our knowledge, this is the first model
inversion approach addressing visual interpretations of VLM concepts.

</details>


### [172] [Effortless Vision-Language Model Specialization in Histopathology without Annotation](https://arxiv.org/abs/2508.07835)
*Jingna Qiu,Nishanth Jain,Jonas Ammeling,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: 研究通过无标注的持续预训练方法，提升视觉语言模型在组织病理学任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 通用视觉语言模型在特定下游任务中表现不佳，而监督微调需要手动标注数据，因此需要探索无标注的适应方法。

Method: 利用领域和任务相关的图像-文本对进行持续预训练，无需人工标注。

Result: 该方法显著提升了零样本和小样本性能，且在大规模训练时效果接近少样本方法。

Conclusion: 无标注的持续预训练是一种有效且通用的方法，适用于组织病理学任务。

Abstract: Recent advances in Vision-Language Models (VLMs) in histopathology, such as
CONCH and QuiltNet, have demonstrated impressive zero-shot classification
capabilities across various tasks. However, their general-purpose design may
lead to suboptimal performance in specific downstream applications. While
supervised fine-tuning methods address this issue, they require manually
labeled samples for adaptation. This paper investigates annotation-free
adaptation of VLMs through continued pretraining on domain- and task-relevant
image-caption pairs extracted from existing databases. Our experiments on two
VLMs, CONCH and QuiltNet, across three downstream tasks reveal that these pairs
substantially enhance both zero-shot and few-shot performance. Notably, with
larger training sizes, continued pretraining matches the performance of
few-shot methods while eliminating manual labeling. Its effectiveness,
task-agnostic design, and annotation-free workflow make it a promising pathway
for adapting VLMs to new histopathology tasks. Code is available at
https://github.com/DeepMicroscopy/Annotation-free-VLM-specialization.

</details>


### [173] [CBDES MoE: Hierarchically Decoupled Mixture-of-Experts for Functional Modules in Autonomous Driving](https://arxiv.org/abs/2508.07838)
*Qi Xiang,Kunsong Shi,Zhigui Lin,Lei He*

Main category: cs.CV

TL;DR: 该论文提出了一种名为CBDES MoE的分层解耦Mixture-of-Experts架构，解决了多模态BEV感知系统中输入适应性低、建模能力受限和泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于多传感器特征融合的BEV感知系统存在输入适应性差、建模能力有限和泛化性能不佳的问题，因此需要一种更高效的方法来改进这些问题。

Method: 采用分层解耦的Mixture-of-Experts架构，结合轻量级Self-Attention Router门控机制，实现动态专家路径选择和稀疏输入感知的高效推理。

Result: 在nuScenes数据集上，CBDES MoE在3D物体检测任务中比单一专家模型表现更优，mAP提升1.6个点，NDS提升4.1个点。

Conclusion: CBDES MoE通过模块化的专家网络架构显著提升了BEV感知系统的性能，为自动驾驶领域的多模态融合提供了新的解决方案。

Abstract: Bird's Eye View (BEV) perception systems based on multi-sensor feature fusion
have become a fundamental cornerstone for end-to-end autonomous driving.
However, existing multi-modal BEV methods commonly suffer from limited input
adaptability, constrained modeling capacity, and suboptimal generalization. To
address these challenges, we propose a hierarchically decoupled
Mixture-of-Experts architecture at the functional module level, termed
Computing Brain DEvelopment System Mixture-of-Experts (CBDES MoE). CBDES MoE
integrates multiple structurally heterogeneous expert networks with a
lightweight Self-Attention Router (SAR) gating mechanism, enabling dynamic
expert path selection and sparse, input-aware efficient inference. To the best
of our knowledge, this is the first modular Mixture-of-Experts framework
constructed at the functional module granularity within the autonomous driving
domain. Extensive evaluations on the real-world nuScenes dataset demonstrate
that CBDES MoE consistently outperforms fixed single-expert baselines in 3D
object detection. Compared to the strongest single-expert model, CBDES MoE
achieves a 1.6-point increase in mAP and a 4.1-point improvement in NDS,
demonstrating the effectiveness and practical advantages of the proposed
approach.

</details>


### [174] [Deep Space Weather Model: Long-Range Solar Flare Prediction from Multi-Wavelength Images](https://arxiv.org/abs/2508.07847)
*Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: Deep SWM 是一种基于多深度状态空间模型的太阳耀斑预测方法，通过稀疏掩码自编码器优化特征提取，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在太阳图像表示学习和长期时空依赖性建模上的不足。

Method: 采用多深度状态空间模型处理十通道太阳图像和长期时空依赖性，结合两阶段掩码策略的稀疏掩码自编码器。

Result: 在 FlareBench 基准测试中超越基线方法和人类专家表现。

Conclusion: Deep SWM 在太阳耀斑预测的准确性和可靠性上表现优异。

Abstract: Accurate, reliable solar flare prediction is crucial for mitigating potential
disruptions to critical infrastructure, while predicting solar flares remains a
significant challenge. Existing methods based on heuristic physical features
often lack representation learning from solar images. On the other hand,
end-to-end learning approaches struggle to model long-range temporal
dependencies in solar images. In this study, we propose Deep Space Weather
Model (Deep SWM), which is based on multiple deep state space models for
handling both ten-channel solar images and long-range spatio-temporal
dependencies. Deep SWM also features a sparse masked autoencoder, a novel
pretraining strategy that employs a two-phase masking approach to preserve
crucial regions such as sunspots while compressing spatial information.
Furthermore, we built FlareBench, a new public benchmark for solar flare
prediction covering a full 11-year solar activity cycle, to validate our
method. Our method outperformed baseline methods and even human expert
performance on standard metrics in terms of performance and reliability. The
project page can be found at https://keio-smilab25.github.io/DeepSWM.

</details>


### [175] [Morphological Analysis of Semiconductor Microstructures using Skeleton Graphs](https://arxiv.org/abs/2508.07850)
*Noriko Nitta,Rei Miyata,Naoto Oishi*

Main category: cs.CV

TL;DR: 利用图卷积网络和主成分分析研究了Ge表面微结构的拓扑特征，发现照射角度对形貌的影响大于照射通量。


<details>
  <summary>Details</summary>
Motivation: 研究离子束照射对Ge表面微结构形貌的影响，探索拓扑特征的提取和分析方法。

Method: 通过电子显微镜图像提取骨架图，使用图卷积网络嵌入，再通过主成分分析和Davies-Bouldin指数评估聚类可分性。

Result: 结果表明，照射角度的变化对Ge表面形貌的影响比照射通量的变化更显著。

Conclusion: 离子束照射角度是影响Ge表面微结构形貌的关键因素。

Abstract: In this paper, electron microscopy images of microstructures formed on Ge
surfaces by ion beam irradiation were processed to extract topological features
as skeleton graphs, which were then embedded using a graph convolutional
network. The resulting embeddings were analyzed using principal component
analysis, and cluster separability in the resulting PCA space was evaluated
using the Davies-Bouldin index. The results indicate that variations in
irradiation angle have a more significant impact on the morphological
properties of Ge surfaces than variations in irradiation fluence.

</details>


### [176] [Tracking Any Point Methods for Markerless 3D Tissue Tracking in Endoscopic Stereo Images](https://arxiv.org/abs/2508.07851)
*Konrad Reuter,Suresh Guttikonda,Sarah Latus,Lennart Maack,Christian Betz,Tobias Maurer,Alexander Schlaefer*

Main category: cs.CV

TL;DR: 提出了一种基于2D TAP网络的无标记3D组织追踪方法，结合CoTracker模型，在手术场景中实现了高精度追踪。


<details>
  <summary>Details</summary>
Motivation: 微创手术中组织动态运动和视野受限的问题需要解决，以提高手术导航和安全性。

Method: 结合两个CoTracker模型（时间追踪和立体匹配），从立体内窥镜图像估计3D运动。

Result: 在鸡肉组织模型上实现低至1.1 mm的欧几里得距离误差，速度为10 mm/s。

Conclusion: TAP模型在复杂手术场景中具有高精度无标记3D追踪的潜力。

Abstract: Minimally invasive surgery presents challenges such as dynamic tissue motion
and a limited field of view. Accurate tissue tracking has the potential to
support surgical guidance, improve safety by helping avoid damage to sensitive
structures, and enable context-aware robotic assistance during complex
procedures. In this work, we propose a novel method for markerless 3D tissue
tracking by leveraging 2D Tracking Any Point (TAP) networks. Our method
combines two CoTracker models, one for temporal tracking and one for stereo
matching, to estimate 3D motion from stereo endoscopic images. We evaluate the
system using a clinical laparoscopic setup and a robotic arm simulating tissue
motion, with experiments conducted on a synthetic 3D-printed phantom and a
chicken tissue phantom. Tracking on the chicken tissue phantom yielded more
reliable results, with Euclidean distance errors as low as 1.1 mm at a velocity
of 10 mm/s. These findings highlight the potential of TAP-based models for
accurate, markerless 3D tracking in challenging surgical scenarios.

</details>


### [177] [CATP: Contextually Adaptive Token Pruning for Efficient and Enhanced Multimodal In-Context Learning](https://arxiv.org/abs/2508.07871)
*Yanshu Li,Jianjiang Yang,Zhennan Shen,Ligong Han,Haoyan Xu,Ruixiang Tang*

Main category: cs.CV

TL;DR: 提出了一种针对多模态上下文学习的自适应图像令牌修剪方法（CATP），显著提高了效率并保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像令牌修剪方法仅针对单图像任务，忽视了多模态上下文学习中的高冗余和高效性需求。

Method: CATP采用两阶段逐步修剪，充分考虑输入序列中的跨模态交互，无需训练。

Result: 修剪77.8%图像令牌后，CATP在多个模型和基准测试中平均性能提升0.6%，推理延迟降低10.78%。

Conclusion: CATP提升了多模态上下文学习的实际价值，为未来图像-文本交织场景研究奠定了基础。

Abstract: Modern large vision-language models (LVLMs) convert each input image into a
large set of tokens, far outnumbering the text tokens. Although this improves
visual perception, it introduces severe image token redundancy. Because image
tokens carry sparse information, many add little to reasoning, yet greatly
increase inference cost. The emerging image token pruning methods tackle this
issue by identifying the most important tokens and discarding the rest. These
methods can raise efficiency with only modest performance loss. However, most
of them only consider single-image tasks and overlook multimodal in-context
learning (ICL), where redundancy is greater and efficiency is more critical.
Redundant tokens weaken the advantage of multimodal ICL for rapid domain
adaptation and cause unstable performance. Applying existing pruning methods in
this setting leads to large accuracy drops, exposing a clear gap and the need
for new techniques. Thus, we propose Contextually Adaptive Token Pruning
(CATP), a training-free pruning method targeted at multimodal ICL. CATP
consists of two stages that perform progressive pruning to fully account for
the complex cross-modal interactions in the input sequence. After removing
77.8\% of the image tokens, CATP produces an average performance gain of 0.6\%
over the vanilla model on four LVLMs and eight benchmarks, exceeding all
baselines remarkably. Meanwhile, it effectively improves efficiency by
achieving an average reduction of 10.78\% in inference latency. CATP enhances
the practical value of multimodal ICL and lays the groundwork for future
progress in interleaved image-text scenarios.

</details>


### [178] [Selective Contrastive Learning for Weakly Supervised Affordance Grounding](https://arxiv.org/abs/2508.07877)
*WonJun Moon,Hyun Seok Seong,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出了一种选择性原型和像素对比目标的弱监督学习方法，通过结合第一人称和第三人称视角，有效识别功能部件。


<details>
  <summary>Details</summary>
Motivation: 解决弱监督学习在功能部件定位中因分类器依赖而忽略相关线索的问题。

Method: 利用CLIP识别动作相关对象，通过跨视角对比提取精确的功能部件线索。

Result: 实验证明方法能有效激活相关功能区域，减少无关背景干扰。

Conclusion: 新方法提升了功能部件定位的准确性和鲁棒性。

Abstract: Facilitating an entity's interaction with objects requires accurately
identifying parts that afford specific actions. Weakly supervised affordance
grounding (WSAG) seeks to imitate human learning from third-person
demonstrations, where humans intuitively grasp functional parts without needing
pixel-level annotations. To achieve this, grounding is typically learned using
a shared classifier across images from different perspectives, along with
distillation strategies incorporating part discovery process. However, since
affordance-relevant parts are not always easily distinguishable, models
primarily rely on classification, often focusing on common class-specific
patterns that are unrelated to affordance. To address this limitation, we move
beyond isolated part-level learning by introducing selective prototypical and
pixel contrastive objectives that adaptively learn affordance-relevant cues at
both the part and object levels, depending on the granularity of the available
information. Initially, we find the action-associated objects in both
egocentric (object-focused) and exocentric (third-person example) images by
leveraging CLIP. Then, by cross-referencing the discovered objects of
complementary views, we excavate the precise part-level affordance clues in
each perspective. By consistently learning to distinguish affordance-relevant
regions from affordance-irrelevant background context, our approach effectively
shifts activation from irrelevant areas toward meaningful affordance cues.
Experimental results demonstrate the effectiveness of our method. Codes are
available at github.com/hynnsk/SelectiveCL.

</details>


### [179] [TAP: Parameter-efficient Task-Aware Prompting for Adverse Weather Removal](https://arxiv.org/abs/2508.07878)
*Hanting Wang,Shengpeng Ji,Shulei Wang,Hai Huang,Xiao Jin,Qifei Zhang,Tao Jin*

Main category: cs.CV

TL;DR: 提出了一种参数高效的All-in-One图像修复框架，利用任务感知增强提示处理多种天气退化，实现高性能且参数高效。


<details>
  <summary>Details</summary>
Motivation: 现有All-in-One方法依赖专用网络模块，参数开销大且忽视任务间相关性。

Method: 采用两阶段训练（预训练和提示调优），通过任务感知增强提示和低秩分解捕捉任务共性和特性。

Result: 方法仅用2.75M参数，在不同修复任务中表现优异。

Conclusion: 提出的框架高效且性能优越，验证了任务感知提示的有效性。

Abstract: Image restoration under adverse weather conditions has been extensively
explored, leading to numerous high-performance methods. In particular, recent
advances in All-in-One approaches have shown impressive results by training on
multi-task image restoration datasets. However, most of these methods rely on
dedicated network modules or parameters for each specific degradation type,
resulting in a significant parameter overhead. Moreover, the relatedness across
different restoration tasks is often overlooked. In light of these issues, we
propose a parameter-efficient All-in-One image restoration framework that
leverages task-aware enhanced prompts to tackle various adverse weather
degradations.Specifically, we adopt a two-stage training paradigm consisting of
a pretraining phase and a prompt-tuning phase to mitigate parameter conflicts
across tasks. We first employ supervised learning to acquire general
restoration knowledge, and then adapt the model to handle specific degradation
via trainable soft prompts. Crucially, we enhance these task-specific prompts
in a task-aware manner. We apply low-rank decomposition to these prompts to
capture both task-general and task-specific characteristics, and impose
contrastive constraints to better align them with the actual inter-task
relatedness. These enhanced prompts not only improve the parameter efficiency
of the restoration model but also enable more accurate task modeling, as
evidenced by t-SNE analysis. Experimental results on different restoration
tasks demonstrate that the proposed method achieves superior performance with
only 2.75M parameters.

</details>


### [180] [NeeCo: Image Synthesis of Novel Instrument States Based on Dynamic and Deformable 3D Gaussian Reconstruction](https://arxiv.org/abs/2508.07897)
*Tianle Zeng,Junlei Hu,Gerardo Loza Galindo,Sharib Ali,Duygu Sarikaya,Pietro Valdastri,Dominic Jones*

Main category: cs.CV

TL;DR: 提出一种新颖的动态高斯渲染技术，解决手术图像数据集稀缺问题，生成高质量合成图像，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于数据驱动的方法需要大量标注数据集，在手术数据科学中受限。

Method: 采用动态高斯模型表示手术场景，结合动态训练调整策略和自动标注方法。

Result: 生成照片级逼真的标注数据集（PSNR 29.87），模型性能提升15%。

Conclusion: 该方法显著缓解数据稀缺问题，提升手术自动化技术的实用性和性能。

Abstract: Computer vision-based technologies significantly enhance surgical automation
by advancing tool tracking, detection, and localization. However, Current
data-driven approaches are data-voracious, requiring large, high-quality
labeled image datasets, which limits their application in surgical data
science. Our Work introduces a novel dynamic Gaussian Splatting technique to
address the data scarcity in surgical image datasets. We propose a dynamic
Gaussian model to represent dynamic surgical scenes, enabling the rendering of
surgical instruments from unseen viewpoints and deformations with real tissue
backgrounds. We utilize a dynamic training adjustment strategy to address
challenges posed by poorly calibrated camera poses from real-world scenarios.
Additionally, we propose a method based on dynamic Gaussians for automatically
generating annotations for our synthetic data. For evaluation, we constructed a
new dataset featuring seven scenes with 14,000 frames of tool and camera motion
and tool jaw articulation, with a background of an ex-vivo porcine model. Using
this dataset, we synthetically replicate the scene deformation from the ground
truth data, allowing direct comparisons of synthetic image quality.
Experimental results illustrate that our method generates photo-realistic
labeled image datasets with the highest values in Peak-Signal-to-Noise Ratio
(29.87). We further evaluate the performance of medical-specific neural
networks trained on real and synthetic images using an unseen real-world image
dataset. Our results show that the performance of models trained on synthetic
images generated by the proposed method outperforms those trained with
state-of-the-art standard data augmentation by 10%, leading to an overall
improvement in model performances by nearly 15%.

</details>


### [181] [Stand-In: A Lightweight and Plug-and-Play Identity Control for Video Generation](https://arxiv.org/abs/2508.07901)
*Bowen Xue,Qixin Yan,Wenjing Wang,Hao Liu,Chen Li*

Main category: cs.CV

TL;DR: Stand-In是一个轻量级、即插即用的视频生成框架，旨在高效保持用户指定身份，仅需少量训练数据和参数即可实现高质量视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要大量训练参数且与其他AIGC工具不兼容，无法高效生成符合特定身份的高保真视频。

Method: 通过向预训练视频生成模型添加条件图像分支，利用受限自注意力机制和条件位置映射实现身份控制，仅需2000对数据即可快速训练。

Result: 仅增加1%的参数，Stand-In在视频质量和身份保持上优于其他全参数训练方法，并支持多种任务无缝集成。

Conclusion: Stand-In提供了一种高效、轻量且通用的身份保持视频生成解决方案，适用于多种应用场景。

Abstract: Generating high-fidelity human videos that match user-specified identities is
important yet challenging in the field of generative AI. Existing methods often
rely on an excessive number of training parameters and lack compatibility with
other AIGC tools. In this paper, we propose Stand-In, a lightweight and
plug-and-play framework for identity preservation in video generation.
Specifically, we introduce a conditional image branch into the pre-trained
video generation model. Identity control is achieved through restricted
self-attentions with conditional position mapping, and can be learned quickly
with only 2000 pairs. Despite incorporating and training just $\sim$1\%
additional parameters, our framework achieves excellent results in video
quality and identity preservation, outperforming other full-parameter training
methods. Moreover, our framework can be seamlessly integrated for other tasks,
such as subject-driven video generation, pose-referenced video generation,
stylization, and face swapping.

</details>


### [182] [CTC Transcription Alignment of the Bullinger Letters: Automatic Improvement of Annotation Quality](https://arxiv.org/abs/2508.07904)
*Marco Peer,Anna Scius-Bertrand,Andreas Fischer*

Main category: cs.CV

TL;DR: 论文提出一种基于CTC对齐算法的自训练方法，用于解决历史文献手写文本识别中的标注错误问题，显著提升了性能和对齐精度。


<details>
  <summary>Details</summary>
Motivation: 历史文献中的手写文本识别由于字体多变、文献退化及标注不足而困难，尤其是连字符错误。本文旨在解决16世纪Bullinger信集中的此类问题。

Method: 采用CTC对齐算法的自训练方法，通过动态编程和CTC损失训练的模型输出概率，将完整转录与文本行图像匹配。

Result: 方法提升了识别性能（如CER提高1.1个百分点），并提高了对齐精度。有趣的是，较弱模型反而对齐更准，支持迭代训练策略。

Conclusion: 发布了一个手动校正的100页Bullinger数据集子集及代码。该方法可迭代应用，进一步提升识别和对齐质量。

Abstract: Handwritten text recognition for historical documents remains challenging due
to handwriting variability, degraded sources, and limited layout-aware
annotations. In this work, we address annotation errors - particularly
hyphenation issues - in the Bullinger correspondence, a large 16th-century
letter collection. We introduce a self-training method based on a CTC alignment
algorithm that matches full transcriptions to text line images using dynamic
programming and model output probabilities trained with the CTC loss. Our
approach improves performance (e.g., by 1.1 percentage points CER with PyLaia)
and increases alignment accuracy. Interestingly, we find that weaker models
yield more accurate alignments, enabling an iterative training strategy. We
release a new manually corrected subset of 100 pages from the Bullinger
dataset, along with our code and benchmarks. Our approach can be applied
iteratively to further improve the CER as well as the alignment quality for
text recognition pipelines. Code and data are available via
https://github.com/andreas-fischer-unifr/nntp.

</details>


### [183] [Generative Video Matting](https://arxiv.org/abs/2508.07905)
*Yongtao Ge,Kangyang Xie,Guangkai Xu,Mingyu Liu,Li Ke,Longtao Huang,Hui Xue,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: 本文提出一种解决视频抠图中缺乏高质量真实数据问题的方法，通过大规模预训练和合成数据生成，并结合视频扩散模型的先验知识，实现了更优的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视频抠图因缺乏高质量真实数据而受限，传统方法泛化能力差，本文从预训练和合成数据两方面解决问题。

Method: 开发可扩展的合成数据生成管道和新型视频抠图方法，利用预训练视频扩散模型的先验知识，增强时序一致性。

Result: 在三个基准数据集上表现优异，且在多样真实场景中展现出强泛化能力。

Conclusion: 结合大规模预训练和视频扩散模型的方法显著提升了视频抠图的性能与泛化能力，代码已开源。

Abstract: Video matting has traditionally been limited by the lack of high-quality
ground-truth data. Most existing video matting datasets provide only
human-annotated imperfect alpha and foreground annotations, which must be
composited to background images or videos during the training stage. Thus, the
generalization capability of previous methods in real-world scenarios is
typically poor. In this work, we propose to solve the problem from two
perspectives. First, we emphasize the importance of large-scale pre-training by
pursuing diverse synthetic and pseudo-labeled segmentation datasets. We also
develop a scalable synthetic data generation pipeline that can render diverse
human bodies and fine-grained hairs, yielding around 200 video clips with a
3-second duration for fine-tuning. Second, we introduce a novel video matting
approach that can effectively leverage the rich priors from pre-trained video
diffusion models. This architecture offers two key advantages. First, strong
priors play a critical role in bridging the domain gap between synthetic and
real-world scenes. Second, unlike most existing methods that process video
matting frame-by-frame and use an independent decoder to aggregate temporal
information, our model is inherently designed for video, ensuring strong
temporal consistency. We provide a comprehensive quantitative evaluation across
three benchmark datasets, demonstrating our approach's superior performance,
and present comprehensive qualitative results in diverse real-world scenes,
illustrating the strong generalization capability of our method. The code is
available at https://github.com/aim-uofa/GVM.

</details>


### [184] [Mem4D: Decoupling Static and Dynamic Memory for Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.07908)
*Xudong Cai,Shuo Wang,Peng Wang,Yongcai Wang,Zhaoxin Fan,Wanting Li,Tianbao Zhang,Jianrong Tao,Yeying Jin,Deying Li*

Main category: cs.CV

TL;DR: Mem4D提出了一种双记忆架构，分别处理静态和动态场景，解决了内存需求困境，实现了高保真重建。


<details>
  <summary>Details</summary>
Motivation: 解决动态场景单目视频重建中内存需求困境（静态结构长期稳定与动态运动高保真细节保留的冲突）。

Method: 设计双记忆架构：瞬态动态记忆（TDM）捕捉高频动态细节，持久结构记忆（PSM）压缩保存长期静态信息。

Result: 在挑战性基准测试中表现优异或具有竞争力，同时保持高效率。

Conclusion: Mem4D通过双记忆架构成功解决了内存需求困境，实现了静态与动态场景的高保真重建。

Abstract: Reconstructing dense geometry for dynamic scenes from a monocular video is a
critical yet challenging task. Recent memory-based methods enable efficient
online reconstruction, but they fundamentally suffer from a Memory Demand
Dilemma: The memory representation faces an inherent conflict between the
long-term stability required for static structures and the rapid, high-fidelity
detail retention needed for dynamic motion. This conflict forces existing
methods into a compromise, leading to either geometric drift in static
structures or blurred, inaccurate reconstructions of dynamic objects. To
address this dilemma, we propose Mem4D, a novel framework that decouples the
modeling of static geometry and dynamic motion. Guided by this insight, we
design a dual-memory architecture: 1) The Transient Dynamics Memory (TDM)
focuses on capturing high-frequency motion details from recent frames, enabling
accurate and fine-grained modeling of dynamic content; 2) The Persistent
Structure Memory (PSM) compresses and preserves long-term spatial information,
ensuring global consistency and drift-free reconstruction for static elements.
By alternating queries to these specialized memories, Mem4D simultaneously
maintains static geometry with global consistency and reconstructs dynamic
elements with high fidelity. Experiments on challenging benchmarks demonstrate
that our method achieves state-of-the-art or competitive performance while
maintaining high efficiency. Codes will be publicly available.

</details>


### [185] [RSVLM-QA: A Benchmark Dataset for Remote Sensing Vision Language Model-based Question Answering](https://arxiv.org/abs/2508.07918)
*Xing Zi,Jinghao Xiao,Yunxiao Shi,Xian Tao,Jun Li,Ali Braytee,Mukesh Prasad*

Main category: cs.CV

TL;DR: 本文介绍了RSVLM-QA数据集，一个面向遥感视觉问答（RS VQA）的大规模、内容丰富的数据集，旨在解决现有数据集在标注丰富性、问题多样性和特定推理能力评估方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感VQA数据集在标注丰富性、问题多样性和推理能力评估方面存在不足，需要一个新的高质量数据集以推动研究。

Method: 结合多个遥感分割和检测数据集，利用GPT-4.1设计双轨标注生成流程：自动生成详细标注（如图像描述、空间关系等）和专门针对遥感图像计数的问答对。

Result: RSVLM-QA包含13,820张图像和162,373个VQA对，涵盖广泛标注和多样问题类型，实验表明其能有效评估现有视觉语言模型的推理能力。

Conclusion: RSVLM-QA将成为遥感VQA和视觉语言模型研究的重要资源，推动领域进步。

Abstract: Visual Question Answering (VQA) in remote sensing (RS) is pivotal for
interpreting Earth observation data. However, existing RS VQA datasets are
constrained by limitations in annotation richness, question diversity, and the
assessment of specific reasoning capabilities. This paper introduces RSVLM-QA
dataset, a new large-scale, content-rich VQA dataset for the RS domain.
RSVLM-QA is constructed by integrating data from several prominent RS
segmentation and detection datasets: WHU, LoveDA, INRIA, and iSAID. We employ
an innovative dual-track annotation generation pipeline. Firstly, we leverage
Large Language Models (LLMs), specifically GPT-4.1, with meticulously designed
prompts to automatically generate a suite of detailed annotations including
image captions, spatial relations, and semantic tags, alongside complex
caption-based VQA pairs. Secondly, to address the challenging task of object
counting in RS imagery, we have developed a specialized automated process that
extracts object counts directly from the original segmentation data; GPT-4.1
then formulates natural language answers from these counts, which are paired
with preset question templates to create counting QA pairs. RSVLM-QA comprises
13,820 images and 162,373 VQA pairs, featuring extensive annotations and
diverse question types. We provide a detailed statistical analysis of the
dataset and a comparison with existing RS VQA benchmarks, highlighting the
superior depth and breadth of RSVLM-QA's annotations. Furthermore, we conduct
benchmark experiments on Six mainstream Vision Language Models (VLMs),
demonstrating that RSVLM-QA effectively evaluates and challenges the
understanding and reasoning abilities of current VLMs in the RS domain. We
believe RSVLM-QA will serve as a pivotal resource for the RS VQA and VLM
research communities, poised to catalyze advancements in the field.

</details>


### [186] [TAG: A Simple Yet Effective Temporal-Aware Approach for Zero-Shot Video Temporal Grounding](https://arxiv.org/abs/2508.07925)
*Jin-Seop Lee,SungJoon Lee,Jaehan Ahn,YunSeok Choi,Jee-Hyong Lee*

Main category: cs.CV

TL;DR: 论文提出了一种名为TAG的零样本视频时间定位方法，通过引入时间池化、时间连贯性聚类和相似性调整，解决了现有方法中的语义碎片化和相似性分布偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本视频时间定位方法存在语义碎片化和相似性分布偏差问题，且依赖昂贵的LLMs推理，这限制了其效率和准确性。

Method: 提出TAG方法，结合时间池化、时间连贯性聚类和相似性调整，无需额外训练即可有效捕捉视频的时间上下文并修正相似性分布。

Result: 在Charades-STA和ActivityNet Captions基准数据集上取得了最先进的结果，且不依赖LLMs。

Conclusion: TAG方法通过简单而有效的设计，显著提升了零样本视频时间定位的性能，同时降低了计算成本。

Abstract: Video Temporal Grounding (VTG) aims to extract relevant video segments based
on a given natural language query. Recently, zero-shot VTG methods have gained
attention by leveraging pretrained vision-language models (VLMs) to localize
target moments without additional training. However, existing approaches suffer
from semantic fragmentation, where temporally continuous frames sharing the
same semantics are split across multiple segments. When segments are
fragmented, it becomes difficult to predict an accurate target moment that
aligns with the text query. Also, they rely on skewed similarity distributions
for localization, making it difficult to select the optimal segment.
Furthermore, they heavily depend on the use of LLMs which require expensive
inferences. To address these limitations, we propose a \textit{TAG}, a simple
yet effective Temporal-Aware approach for zero-shot video temporal Grounding,
which incorporates temporal pooling, temporal coherence clustering, and
similarity adjustment. Our proposed method effectively captures the temporal
context of videos and addresses distorted similarity distributions without
training. Our approach achieves state-of-the-art results on Charades-STA and
ActivityNet Captions benchmark datasets without rely on LLMs. Our code is
available at https://github.com/Nuetee/TAG

</details>


### [187] [VOIDFace: A Privacy-Preserving Multi-Network Face Recognition With Enhanced Security](https://arxiv.org/abs/2508.07960)
*Ajnas Muhammed,Iurri Medvedev,Nuno Gonçalves*

Main category: cs.CV

TL;DR: VOIDFace是一个新型面部识别框架，通过视觉秘密共享和基于多训练的网络，解决数据复制和隐私问题，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有的面部识别系统因数据复制和隐私控制不足，引发管理和伦理问题，需创新解决方案。

Method: 使用视觉秘密共享避免数据复制，并提出基于多训练的网络，以保护隐私。

Result: 在VGGFace2数据集上，VOIDFace实现了数据可控、安全和隐私保护，同时保持竞争性性能。

Conclusion: VOIDFace有效平衡了面部识别的性能与隐私保护需求，为用户提供数据控制权。

Abstract: Advancement of machine learning techniques, combined with the availability of
large-scale datasets, has significantly improved the accuracy and efficiency of
facial recognition. Modern facial recognition systems are trained using large
face datasets collected from diverse individuals or public repositories.
However, for training, these datasets are often replicated and stored in
multiple workstations, resulting in data replication, which complicates
database management and oversight. Currently, once a user submits their face
for dataset preparation, they lose control over how their data is used, raising
significant privacy and ethical concerns. This paper introduces VOIDFace, a
novel framework for facial recognition systems that addresses two major issues.
First, it eliminates the need of data replication and improves data control to
securely store training face data by using visual secret sharing. Second, it
proposes a patch-based multi-training network that uses this novel training
data storage mechanism to develop a robust, privacy-preserving facial
recognition system. By integrating these advancements, VOIDFace aims to improve
the privacy, security, and efficiency of facial recognition training, while
ensuring greater control over sensitive personal face data. VOIDFace also
enables users to exercise their Right-To-Be-Forgotten property to control their
personal data. Experimental evaluations on the VGGFace2 dataset show that
VOIDFace provides Right-To-Be-Forgotten, improved data control, security, and
privacy while maintaining competitive facial recognition performance. Code is
available at: https://github.com/ajnasmuhammed89/VOIDFace

</details>


### [188] [TrackOR: Towards Personalized Intelligent Operating Rooms Through Robust Tracking](https://arxiv.org/abs/2508.07968)
*Tony Danjun Wang,Christian Heiliger,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: TrackOR框架利用3D几何特征实现手术室中多人的长期追踪和重识别，提升跟踪精度并启用离线修复，为个性化智能系统提供支持。


<details>
  <summary>Details</summary>
Motivation: 手术团队需要智能化支持以改善患者结果，但长期追踪和身份一致性仍具挑战。

Method: TrackOR使用3D几何特征进行在线追踪与离线修复。

Result: 在线追踪性能提升11%，并生成可用于分析的轨迹数据。

Conclusion: 3D几何信息使身份追踪成为可能，为个性化智能系统提供新应用。

Abstract: Providing intelligent support to surgical teams is a key frontier in
automated surgical scene understanding, with the long-term goal of improving
patient outcomes. Developing personalized intelligence for all staff members
requires maintaining a consistent state of who is located where for long
surgical procedures, which still poses numerous computational challenges. We
propose TrackOR, a framework for tackling long-term multi-person tracking and
re-identification in the operating room. TrackOR uses 3D geometric signatures
to achieve state-of-the-art online tracking performance (+11% Association
Accuracy over the strongest baseline), while also enabling an effective offline
recovery process to create analysis-ready trajectories. Our work shows that by
leveraging 3D geometric information, persistent identity tracking becomes
attainable, enabling a critical shift towards the more granular, staff-centric
analyses required for personalized intelligent systems in the operating room.
This new capability opens up various applications, including our proposed
temporal pathway imprints that translate raw tracking data into actionable
insights for improving team efficiency and safety and ultimately providing
personalized support.

</details>


### [189] [Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation](https://arxiv.org/abs/2508.07981)
*Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu*

Main category: cs.CV

TL;DR: 论文提出了一种名为Omni-Effects的统一框架，解决了现有视觉特效（VFX）生成方法在多效果合成与空间控制上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在VFX生产中存在单效果生成和空间控制不足的问题，难以满足复合效果需求。

Method: 提出LoRA-MoE和SAP技术，结合IIF模块，实现多效果集成与精确空间控制，并构建Omni-VFX数据集。

Result: 实验表明，Omni-Effects能够精确控制效果类别和位置，实现多样性生成。

Conclusion: 该方法为VFX领域提供了高效的统一解决方案，支持复合效果生成和空间控制。

Abstract: Visual effects (VFX) are essential visual enhancements fundamental to modern
cinematic production. Although video generation models offer cost-efficient
solutions for VFX production, current methods are constrained by per-effect
LoRA training, which limits generation to single effects. This fundamental
limitation impedes applications that require spatially controllable composite
effects, i.e., the concurrent generation of multiple effects at designated
locations. However, integrating diverse effects into a unified framework faces
major challenges: interference from effect variations and spatial
uncontrollability during multi-VFX joint training. To tackle these challenges,
we propose Omni-Effects, a first unified framework capable of generating
prompt-guided effects and spatially controllable composite effects. The core of
our framework comprises two key innovations: (1) LoRA-based Mixture of Experts
(LoRA-MoE), which employs a group of expert LoRAs, integrating diverse effects
within a unified model while effectively mitigating cross-task interference.
(2) Spatial-Aware Prompt (SAP) incorporates spatial mask information into the
text token, enabling precise spatial control. Furthermore, we introduce an
Independent-Information Flow (IIF) module integrated within the SAP, isolating
the control signals corresponding to individual effects to prevent any unwanted
blending. To facilitate this research, we construct a comprehensive VFX dataset
Omni-VFX via a novel data collection pipeline combining image editing and
First-Last Frame-to-Video (FLF2V) synthesis, and introduce a dedicated VFX
evaluation framework for validating model performance. Extensive experiments
demonstrate that Omni-Effects achieves precise spatial control and diverse
effect generation, enabling users to specify both the category and location of
desired effects.

</details>


### [190] [The Escalator Problem: Identifying Implicit Motion Blindness in AI for Accessibility](https://arxiv.org/abs/2508.07989)
*Xiantao Zhang*

Main category: cs.CV

TL;DR: 论文讨论了多模态大语言模型（MLLMs）在盲人和视障群体中的潜在应用，但指出其因“隐式运动盲区”而无法感知电梯运行方向的缺陷，呼吁转向物理感知和开发新评测标准。


<details>
  <summary>Details</summary>
Motivation: 研究发现MLLMs因帧采样范式无法感知低信号运动，严重影响视障用户的信任和安全性。

Method: 提出“电梯问题”作为案例，分析了现有模型对连续运动的感知缺陷。

Result: 揭示了帧采样范式对动态场景理解的局限性，呼吁重视物理感知和用户需求。

Conclusion: 主张从语义识别转向物理感知，并开发以用户安全为中心的新评测体系。

Abstract: Multimodal Large Language Models (MLLMs) hold immense promise as assistive
technologies for the blind and visually impaired (BVI) community. However, we
identify a critical failure mode that undermines their trustworthiness in
real-world applications. We introduce the Escalator Problem -- the inability of
state-of-the-art models to perceive an escalator's direction of travel -- as a
canonical example of a deeper limitation we term Implicit Motion Blindness.
This blindness stems from the dominant frame-sampling paradigm in video
understanding, which, by treating videos as discrete sequences of static
images, fundamentally struggles to perceive continuous, low-signal motion. As a
position paper, our contribution is not a new model but rather to: (I) formally
articulate this blind spot, (II) analyze its implications for user trust, and
(III) issue a call to action. We advocate for a paradigm shift from purely
semantic recognition towards robust physical perception and urge the
development of new, human-centered benchmarks that prioritize safety,
reliability, and the genuine needs of users in dynamic environments.

</details>


### [191] [Prompt-Guided Relational Reasoning for Social Behavior Understanding with Vision Foundation Models](https://arxiv.org/abs/2508.07996)
*Thinesh Thiyakesan Ponbagavathi,Chengzheng Yang,Alina Roitberg*

Main category: cs.CV

TL;DR: ProGraD是一种通过可学习的分组提示和轻量级GroupContext Transformer改进VFM用于群体活动检测的方法，在复杂多群体场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision Foundation Models（VFMs）在群体活动检测（GAD）中表现不足，简单替换CNN骨干网络效果有限，需要更结构化的群体感知推理。

Method: 提出ProGraD方法，包含1）可学习的分组提示引导VFM关注社交配置，2）轻量级两层GroupContext Transformer推断参与者与群体的关联及集体行为。

Result: 在两个GAD基准测试（Cafe和Social-CAD）中超越现有最佳方法，特别是在复杂多群体场景中提升显著（Group mAP@1.0提高6.5%，Group mAP@0.5提高8.2%），且参数仅10M。

Conclusion: ProGraD不仅性能优越，还提供了可解释的注意力映射，有助于理解参与者与群体的关联推理。代码和模型将开源。

Abstract: Group Activity Detection (GAD) involves recognizing social groups and their
collective behaviors in videos. Vision Foundation Models (VFMs), like DinoV2,
offer excellent features, but are pretrained primarily on object-centric data
and remain underexplored for modeling group dynamics. While they are a
promising alternative to highly task-specific GAD architectures that require
full fine-tuning, our initial investigation reveals that simply swapping CNN
backbones used in these methods with VFMs brings little gain, underscoring the
need for structured, group-aware reasoning on top.
  We introduce Prompt-driven Group Activity Detection (ProGraD) -- a method
that bridges this gap through 1) learnable group prompts to guide the VFM
attention toward social configurations, and 2) a lightweight two-layer
GroupContext Transformer that infers actor-group associations and collective
behavior. We evaluate our approach on two recent GAD benchmarks: Cafe, which
features multiple concurrent social groups, and Social-CAD, which focuses on
single-group interactions. While we surpass state-of-the-art in both settings,
our method is especially effective in complex multi-group scenarios, where we
yield a gain of 6.5\% (Group mAP\@1.0) and 8.2\% (Group mAP\@0.5) using only
10M trainable parameters. Furthermore, our experiments reveal that ProGraD
produces interpretable attention maps, offering insights into actor-group
reasoning. Code and models will be released.

</details>


### [192] [Sample-aware RandAugment: Search-free Automatic Data Augmentation for Effective Image Recognition](https://arxiv.org/abs/2508.08004)
*Anqi Xiao,Weichen Yu,Hongyuan Yu*

Main category: cs.CV

TL;DR: Sample-aware RandAugment (SRA)是一种无需搜索的自动数据增强方法，通过动态调整增强策略和评估数据复杂性，显著提升了性能，并在多个实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 主流AutoDA方法存在搜索耗时或性能不足的问题，SRA旨在解决这些问题，提供更简单有效的解决方案。

Method: SRA采用启发式评分模块评估数据复杂性，并结合非对称增强策略，动态调整增强策略。

Result: 在ImageNet上，SRA达到78.31%的Top-1准确率，并在下游任务中表现出良好的泛化能力。

Conclusion: SRA为更简单、有效和实用的AutoDA设计提供了有前景的方向。

Abstract: Automatic data augmentation (AutoDA) plays an important role in enhancing the
generalization of neural networks. However, mainstream AutoDA methods often
encounter two challenges: either the search process is excessively
time-consuming, hindering practical application, or the performance is
suboptimal due to insufficient policy adaptation during training. To address
these issues, we propose Sample-aware RandAugment (SRA), an asymmetric,
search-free AutoDA method that dynamically adjusts augmentation policies while
maintaining straightforward implementation. SRA incorporates a heuristic
scoring module that evaluates the complexity of the original training data,
enabling the application of tailored augmentations for each sample.
Additionally, an asymmetric augmentation strategy is employed to maximize the
potential of this scoring module. In multiple experimental settings, SRA
narrows the performance gap between search-based and search-free AutoDA
methods, achieving a state-of-the-art Top-1 accuracy of 78.31\% on ImageNet
with ResNet-50. Notably, SRA demonstrates good compatibility with existing
augmentation pipelines and solid generalization across new tasks, without
requiring hyperparameter tuning. The pretrained models leveraging SRA also
enhance recognition in downstream object detection tasks. SRA represents a
promising step towards simpler, more effective, and practical AutoDA designs
applicable to a variety of future tasks. Our code is available at
\href{https://github.com/ainieli/Sample-awareRandAugment}{https://github.com/ainieli/Sample-awareRandAugment

</details>


### [193] [Mitigating Biases in Surgical Operating Rooms with Geometry](https://arxiv.org/abs/2508.08028)
*Tony Danjun Wang,Tobias Czempiel,Nassir Navab,Lennart Bastian*

Main category: cs.CV

TL;DR: 深度学习模型在手术室场景中容易学习虚假关联，导致模型偏差。通过3D点云序列方法，可以避免外观干扰，捕捉更有意义的生物特征。


<details>
  <summary>Details</summary>
Motivation: 手术室中标准化服装掩盖了关键特征，导致模型依赖偶然视觉线索。为避免这种偏差，研究提出几何表示方法。

Method: 使用梯度显著图分析CNN模型的偏差，并提出基于3D点云序列的方法分离形状和运动特征。

Result: 实验显示，几何方法在真实临床场景中表现优于RGB模型，准确率差距达12%。

Conclusion: 几何表示能有效捕捉生物特征，为手术室智能系统的稳健建模提供可行方案。

Abstract: Deep neural networks are prone to learning spurious correlations, exploiting
dataset-specific artifacts rather than meaningful features for prediction. In
surgical operating rooms (OR), these manifest through the standardization of
smocks and gowns that obscure robust identifying landmarks, introducing model
bias for tasks related to modeling OR personnel. Through gradient-based
saliency analysis on two public OR datasets, we reveal that CNN models succumb
to such shortcuts, fixating on incidental visual cues such as footwear beneath
surgical gowns, distinctive eyewear, or other role-specific identifiers.
Avoiding such biases is essential for the next generation of intelligent
assistance systems in the OR, which should accurately recognize personalized
workflow traits, such as surgical skill level or coordination with other staff
members. We address this problem by encoding personnel as 3D point cloud
sequences, disentangling identity-relevant shape and motion patterns from
appearance-based confounders. Our experiments demonstrate that while RGB and
geometric methods achieve comparable performance on datasets with apparent
simulation artifacts, RGB models suffer a 12% accuracy drop in realistic
clinical settings with decreased visual diversity due to standardizations. This
performance gap confirms that geometric representations capture more meaningful
biometric features, providing an avenue to developing robust methods of
modeling humans in the OR.

</details>


### [194] [TRIDE: A Text-assisted Radar-Image weather-aware fusion network for Depth Estimation](https://arxiv.org/abs/2508.08038)
*Huawei Sun,Zixu Wang,Hao Feng,Julius Ott,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 该论文提出了一种结合雷达和相机融合的深度估计方法TRIDE，通过引入天气感知融合块和文本特征增强，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有雷达-相机融合算法忽视天气条件对传感器性能的影响，且未充分利用语言描述信息。

Method: 提出文本生成策略和特征融合技术，结合雷达点信息增强文本特征，并设计天气感知融合块动态调整雷达权重。

Result: 在nuScenes数据集上相比现有最佳方法，MAE和RMSE分别提升了12.87%和9.08%。

Conclusion: TRIDE通过多模态融合和天气自适应机制，显著提升了深度估计性能，尤其在恶劣天气下表现更优。

Abstract: Depth estimation, essential for autonomous driving, seeks to interpret the 3D
environment surrounding vehicles. The development of radar sensors, known for
their cost-efficiency and robustness, has spurred interest in radar-camera
fusion-based solutions. However, existing algorithms fuse features from these
modalities without accounting for weather conditions, despite radars being
known to be more robust than cameras under adverse weather. Additionally, while
Vision-Language models have seen rapid advancement, utilizing language
descriptions alongside other modalities for depth estimation remains an open
challenge. This paper first introduces a text-generation strategy along with
feature extraction and fusion techniques that can assist monocular depth
estimation pipelines, leading to improved accuracy across different algorithms
on the KITTI dataset. Building on this, we propose TRIDE, a radar-camera fusion
algorithm that enhances text feature extraction by incorporating radar point
information. To address the impact of weather on sensor performance, we
introduce a weather-aware fusion block that adaptively adjusts radar weighting
based on current weather conditions. Our method, benchmarked on the nuScenes
dataset, demonstrates performance gains over the state-of-the-art, achieving a
12.87% improvement in MAE and a 9.08% improvement in RMSE. Code:
https://github.com/harborsarah/TRIDE

</details>


### [195] [S^2VG: 3D Stereoscopic and Spatial Video Generation via Denoising Frame Matrix](https://arxiv.org/abs/2508.08048)
*Peng Dai,Feitong Tan,Qiangeng Xu,Yihua Huang,David Futschik,Ruofei Du,Sean Fanello,Yinda Zhang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 提出一种无需额外训练的方法，利用现有单目视频生成模型生成沉浸式3D视频，通过深度估计和帧矩阵修复框架实现多视角一致性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 目前视频生成模型主要专注于单目视频，而3D立体和空间视频的生成仍是一个未充分探索的挑战，需要一种无需训练的方法来提升生成效果。

Method: 利用深度估计将单目视频映射到预定义视角，通过帧矩阵修复框架和双重更新方案合成缺失内容，确保时空一致性。

Result: 实验表明，该方法在多种生成模型（如Sora、Lumiere等）上表现优于现有方法，显著提升了3D视频生成质量。

Conclusion: 该方法有效解决了3D视频生成的时空一致性问题，为沉浸式应用提供了高质量的视频生成解决方案。

Abstract: While video generation models excel at producing high-quality monocular
videos, generating 3D stereoscopic and spatial videos for immersive
applications remains an underexplored challenge. We present a pose-free and
training-free method that leverages an off-the-shelf monocular video generation
model to produce immersive 3D videos. Our approach first warps the generated
monocular video into pre-defined camera viewpoints using estimated depth
information, then applies a novel \textit{frame matrix} inpainting framework.
This framework utilizes the original video generation model to synthesize
missing content across different viewpoints and timestamps, ensuring spatial
and temporal consistency without requiring additional model fine-tuning.
Moreover, we develop a \dualupdate~scheme that further improves the quality of
video inpainting by alleviating the negative effects propagated from
disoccluded areas in the latent space. The resulting multi-view videos are then
adapted into stereoscopic pairs or optimized into 4D Gaussians for spatial
video synthesis. We validate the efficacy of our proposed method by conducting
experiments on videos from various generative models, such as Sora, Lumiere,
WALT, and Zeroscope. The experiments demonstrate that our method has a
significant improvement over previous methods. Project page at:
https://daipengwa.github.io/S-2VG_ProjectPage/

</details>


### [196] [Information Bottleneck-based Causal Attention for Multi-label Medical Image Recognition](https://arxiv.org/abs/2508.08069)
*Xiaoxiao Cui,Yiran Li,Kai He,Shanzhi Jiang,Mengli Xue,Wentao Li,Junhong Leng,Zhi Liu,Lizhen Cui,Shuo Li*

Main category: cs.CV

TL;DR: 提出了一种基于信息瓶颈的因果注意力方法（IBCA），用于医学图像的多标签分类，通过过滤无关特征和增强因果注意力提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以解释真正的原因，因为它们会无意关注与类别无关的特征。

Method: 提出结构因果模型和IBCA，利用高斯混合多标签空间注意力过滤无关信息，并通过对比增强干预减少噪声。

Result: 在Endo和MuReD数据集上表现优异，各项指标均有显著提升。

Conclusion: IBCA能有效学习区分性特征，提升医学图像多标签分类的准确性和可解释性。

Abstract: Multi-label classification (MLC) of medical images aims to identify multiple
diseases and holds significant clinical potential. A critical step is to learn
class-specific features for accurate diagnosis and improved interpretability
effectively. However, current works focus primarily on causal attention to
learn class-specific features, yet they struggle to interpret the true cause
due to the inadvertent attention to class-irrelevant features. To address this
challenge, we propose a new structural causal model (SCM) that treats
class-specific attention as a mixture of causal, spurious, and noisy factors,
and a novel Information Bottleneck-based Causal Attention (IBCA) that is
capable of learning the discriminative class-specific attention for MLC of
medical images. Specifically, we propose learning Gaussian mixture multi-label
spatial attention to filter out class-irrelevant information and capture each
class-specific attention pattern. Then a contrastive enhancement-based causal
intervention is proposed to gradually mitigate the spurious attention and
reduce noise information by aligning multi-head attention with the Gaussian
mixture multi-label spatial. Quantitative and ablation results on Endo and
MuReD show that IBCA outperforms all methods. Compared to the second-best
results for each metric, IBCA achieves improvements of 6.35\% in CR, 7.72\% in
OR, and 5.02\% in mAP for MuReD, 1.47\% in CR, and 1.65\% in CF1, and 1.42\% in
mAP for Endo.

</details>


### [197] [ME-TST+: Micro-expression Analysis via Temporal State Transition with ROI Relationship Awareness](https://arxiv.org/abs/2508.08082)
*Zizheng Guo,Bochao Zou,Junbao Zhuo,Huimin Ma*

Main category: cs.CV

TL;DR: 提出ME-TST和ME-TST+模型，通过状态空间模型改进微表情分析的时序动态建模，结合多粒度ROI和慢快Mamba框架减少信息损失，并通过特征和结果级的协同策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统滑动窗口分类方法在微表情分析中固定窗口长度和硬分类的局限性，以及忽视微表情检测与识别任务内在联系的问题。

Method: ME-TST和ME-TST+利用时间状态转移机制进行视频级回归，ME-TST+引入多粒度ROI建模和慢快Mamba框架，并提出特征和结果级的协同策略。

Result: 实验表明，提出的方法在性能上达到最先进水平。

Conclusion: ME-TST和ME-TST+通过改进时序建模和任务协同，显著提升了微表情分析的准确性和实用性。

Abstract: Micro-expressions (MEs) are regarded as important indicators of an
individual's intrinsic emotions, preferences, and tendencies. ME analysis
requires spotting of ME intervals within long video sequences and recognition
of their corresponding emotional categories. Previous deep learning approaches
commonly employ sliding-window classification networks. However, the use of
fixed window lengths and hard classification presents notable limitations in
practice. Furthermore, these methods typically treat ME spotting and
recognition as two separate tasks, overlooking the essential relationship
between them. To address these challenges, this paper proposes two state space
model-based architectures, namely ME-TST and ME-TST+, which utilize temporal
state transition mechanisms to replace conventional window-level classification
with video-level regression. This enables a more precise characterization of
the temporal dynamics of MEs and supports the modeling of MEs with varying
durations. In ME-TST+, we further introduce multi-granularity ROI modeling and
the slowfast Mamba framework to alleviate information loss associated with
treating ME analysis as a time-series task. Additionally, we propose a synergy
strategy for spotting and recognition at both the feature and result levels,
leveraging their intrinsic connection to enhance overall analysis performance.
Extensive experiments demonstrate that the proposed methods achieve
state-of-the-art performance. The codes are available at
https://github.com/zizheng-guo/ME-TST.

</details>


### [198] [Matrix-3D: Omnidirectional Explorable 3D World Generation](https://arxiv.org/abs/2508.08086)
*Zhongqi Yang,Wenhang Ge,Yuqi Li,Jiaqi Chen,Haoyuan Li,Mengyin An,Fei Kang,Hua Xue,Baixin Xu,Yuyang Yin,Eric Li,Yang Liu,Yikai Wang,Hao-Xiang Guo,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-3D 是一个通过全景表示生成可探索 3D 世界的框架，结合了条件视频生成和全景 3D 重建，显著提升了生成场景的范围和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成 3D 场景时范围有限，希望提出一个更广泛覆盖且几何一致的解决方案。

Method: 利用轨迹引导的全景视频扩散模型生成高质量场景视频，并通过两种方法（前馈式重建和优化重建）将其提升为 3D 世界。

Result: Matrix-3D 在全景视频生成和 3D 世界生成中达到最先进的性能。

Conclusion: Matrix-3D 提供了一种高效且高质量的 3D 世界生成方法，具有广泛的应用潜力。

Abstract: Explorable 3D world generation from a single image or text prompt forms a
cornerstone of spatial intelligence. Recent works utilize video model to
achieve wide-scope and generalizable 3D world generation. However, existing
approaches often suffer from a limited scope in the generated scenes. In this
work, we propose Matrix-3D, a framework that utilize panoramic representation
for wide-coverage omnidirectional explorable 3D world generation that combines
conditional video generation and panoramic 3D reconstruction. We first train a
trajectory-guided panoramic video diffusion model that employs scene mesh
renders as condition, to enable high-quality and geometrically consistent scene
video generation. To lift the panorama scene video to 3D world, we propose two
separate methods: (1) a feed-forward large panorama reconstruction model for
rapid 3D scene reconstruction and (2) an optimization-based pipeline for
accurate and detailed 3D scene reconstruction. To facilitate effective
training, we also introduce the Matrix-Pano dataset, the first large-scale
synthetic collection comprising 116K high-quality static panoramic video
sequences with depth and trajectory annotations. Extensive experiments
demonstrate that our proposed framework achieves state-of-the-art performance
in panoramic video generation and 3D world generation. See more in
https://matrix-3d.github.io.

</details>


### [199] [3D Plant Root Skeleton Detection and Extraction](https://arxiv.org/abs/2508.08094)
*Jiakai Lin,Jinchang Zhang,Ge Jin,Wenzhan Song,Tianming Liu,Guoyu Lu*

Main category: cs.CV

TL;DR: 介绍了一种从少量图像中提取植物根系3D骨架结构的方法，解决了根系复杂性和缺乏纹理信息的难题，验证了方法的有效性，并可应用于自动化育种机器人。


<details>
  <summary>Details</summary>
Motivation: 植物根系结构复杂且缺乏纹理信息，传统2D研究难以捕捉其完整结构，3D信息对研究遗传特性和根系发育更为关键。

Method: 通过检测和匹配侧根、三角化提取侧根骨架结构，并将侧根与主根整合，实现3D根系骨架提取。

Result: 在复杂根系数据集上测试，提取的3D骨架与真实结构高度相似，验证了方法的有效性。

Conclusion: 该方法为自动化育种机器人提供了精确的3D根系结构分析能力，提高了育种效率并减少人工干预，推动现代农业发展。

Abstract: Plant roots typically exhibit a highly complex and dense architecture,
incorporating numerous slender lateral roots and branches, which significantly
hinders the precise capture and modeling of the entire root system.
Additionally, roots often lack sufficient texture and color information, making
it difficult to identify and track root traits using visual methods. Previous
research on roots has been largely confined to 2D studies; however, exploring
the 3D architecture of roots is crucial in botany. Since roots grow in real 3D
space, 3D phenotypic information is more critical for studying genetic traits
and their impact on root development. We have introduced a 3D root skeleton
extraction method that efficiently derives the 3D architecture of plant roots
from a few images. This method includes the detection and matching of lateral
roots, triangulation to extract the skeletal structure of lateral roots, and
the integration of lateral and primary roots. We developed a highly complex
root dataset and tested our method on it. The extracted 3D root skeletons
showed considerable similarity to the ground truth, validating the
effectiveness of the model. This method can play a significant role in
automated breeding robots. Through precise 3D root structure analysis, breeding
robots can better identify plant phenotypic traits, especially root structure
and growth patterns, helping practitioners select seeds with superior root
systems. This automated approach not only improves breeding efficiency but also
reduces manual intervention, making the breeding process more intelligent and
efficient, thus advancing modern agriculture.

</details>


### [200] [TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning](https://arxiv.org/abs/2508.08098)
*Junzhe Xu,Yuyang Yin,Xi Chen*

Main category: cs.CV

TL;DR: TBAC-UniImage提出了一种新型的多模态理解与生成统一模型，通过深度整合预训练的扩散模型与多模态大语言模型（MLLM），克服了以往方法的浅层连接及计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的统一模型存在两个主要问题：一是仅依赖MLLM的最终隐藏状态作为生成条件，导致生成器与MLLM中间层丰富表示的联系不足；二是从头训练统一生成架构计算成本高。

Method: 利用MLLM多个不同层的表示作为扩散模型的生成条件，将预训练的生成器视为阶梯，接收MLLM理解过程中各层次的指导。

Result: TBAC-UniImage实现了更深层次、更精细化的理解与生成统一。

Conclusion: 该模型通过多层次的生成条件输入，显著提升了多模态任务的性能，为后续研究提供了新的范式。

Abstract: This paper introduces TBAC-UniImage, a novel unified model for multimodal
understanding and generation. We achieve this by deeply integrating a
pre-trained Diffusion Model, acting as a generative ladder, with a Multimodal
Large Language Model (MLLM). Previous diffusion-based unified models face two
primary limitations. One approach uses only the MLLM's final hidden state as
the generative condition. This creates a shallow connection, as the generator
is isolated from the rich, hierarchical representations within the MLLM's
intermediate layers. The other approach, pretraining a unified generative
architecture from scratch, is computationally expensive and prohibitive for
many researchers. To overcome these issues, our work explores a new paradigm.
Instead of relying on a single output, we use representations from multiple,
diverse layers of the MLLM as generative conditions for the diffusion model.
This method treats the pre-trained generator as a ladder, receiving guidance
from various depths of the MLLM's understanding process. Consequently,
TBAC-UniImage achieves a much deeper and more fine-grained unification of
understanding and generation.

</details>


### [201] [Hyperspectral Imaging](https://arxiv.org/abs/2508.08107)
*Danfeng Hong,Chenyu Li,Naoto Yokoya,Bing Zhang,Xiuping Jia,Antonio Plaza,Paolo Gamba,Jon Atli Benediktsson,Jocelyn Chanussot*

Main category: cs.CV

TL;DR: 高光谱成像（HSI）是一种先进的多模态传感技术，可同时获取空间和光谱信息，用于无创、无标记的材料、化学和生物分析。本文介绍了HSI的基础原理、传感器架构、数据处理方法及典型应用。


<details>
  <summary>Details</summary>
Motivation: 推动HSI技术的普及和应用，强调其在多学科领域中的潜力及其面临的挑战与解决方案。

Method: 介绍了HSI的物理原理、传感器设计、数据校准和分析方法，包括经典和现代技术（如深度学习）。

Result: HSI在多个领域（如农业、医疗、工业）展现出独特优势，能够揭示亚视觉特征。

Conclusion: HSI有望成为跨学科通用平台，未来发展将聚焦于实时化、嵌入式系统和自监督学习。

Abstract: Hyperspectral imaging (HSI) is an advanced sensing modality that
simultaneously captures spatial and spectral information, enabling
non-invasive, label-free analysis of material, chemical, and biological
properties. This Primer presents a comprehensive overview of HSI, from the
underlying physical principles and sensor architectures to key steps in data
acquisition, calibration, and correction. We summarize common data structures
and highlight classical and modern analysis methods, including dimensionality
reduction, classification, spectral unmixing, and AI-driven techniques such as
deep learning. Representative applications across Earth observation, precision
agriculture, biomedicine, industrial inspection, cultural heritage, and
security are also discussed, emphasizing HSI's ability to uncover sub-visual
features for advanced monitoring, diagnostics, and decision-making. Persistent
challenges, such as hardware trade-offs, acquisition variability, and the
complexity of high-dimensional data, are examined alongside emerging solutions,
including computational imaging, physics-informed modeling, cross-modal fusion,
and self-supervised learning. Best practices for dataset sharing,
reproducibility, and metadata documentation are further highlighted to support
transparency and reuse. Looking ahead, we explore future directions toward
scalable, real-time, and embedded HSI systems, driven by sensor
miniaturization, self-supervised learning, and foundation models. As HSI
evolves into a general-purpose, cross-disciplinary platform, it holds promise
for transformative applications in science, technology, and society.

</details>


### [202] [GRASPTrack: Geometry-Reasoned Association via Segmentation and Projection for Multi-Object Tracking](https://arxiv.org/abs/2508.08117)
*Xudong Han,Pengcheng Fang,Yueying Tian,Jianhui Yu,Xiaohao Cai,Daniel Roggen,Philip Birch*

Main category: cs.CV

TL;DR: GRASPTrack 是一种新型的深度感知多目标跟踪框架，通过结合单目深度估计和实例分割，提升了传统跟踪方法的几何感知能力，从而在复杂场景中显著提高了跟踪的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于检测的跟踪方法（TBD）在面对遮挡和深度模糊时表现不佳，因为它们缺乏几何感知能力。本文旨在通过引入深度信息来解决这些问题。

Method: GRASPTrack 集成了单目深度估计和实例分割，生成高保真3D点云，并通过基于体素的3D IoU 进行空间关联。此外，还提出了深度感知自适应噪声补偿和深度增强的观测中心动量，以提升状态估计和运动关联的精度。

Result: 在 MOT17、MOT20 和 DanceTrack 基准测试中，GRASPTrack 表现出色，显著提升了复杂场景中的跟踪鲁棒性。

Conclusion: 通过引入深度信息和3D几何推理，GRASPTrack 有效地解决了遮挡和深度模糊问题，为多目标跟踪任务提供了更可靠的解决方案。

Abstract: Multi-object tracking (MOT) in monocular videos is fundamentally challenged
by occlusions and depth ambiguity, issues that conventional
tracking-by-detection (TBD) methods struggle to resolve owing to a lack of
geometric awareness. To address these limitations, we introduce GRASPTrack, a
novel depth-aware MOT framework that integrates monocular depth estimation and
instance segmentation into a standard TBD pipeline to generate high-fidelity 3D
point clouds from 2D detections, thereby enabling explicit 3D geometric
reasoning. These 3D point clouds are then voxelized to enable a precise and
robust Voxel-Based 3D Intersection-over-Union (IoU) for spatial association. To
further enhance tracking robustness, our approach incorporates Depth-aware
Adaptive Noise Compensation, which dynamically adjusts the Kalman filter
process noise based on occlusion severity for more reliable state estimation.
Additionally, we propose a Depth-enhanced Observation-Centric Momentum, which
extends the motion direction consistency from the image plane into 3D space to
improve motion-based association cues, particularly for objects with complex
trajectories. Extensive experiments on the MOT17, MOT20, and DanceTrack
benchmarks demonstrate that our method achieves competitive performance,
significantly improving tracking robustness in complex scenes with frequent
occlusions and intricate motion patterns.

</details>


### [203] [Follow-Your-Shape: Shape-Aware Image Editing via Trajectory-Guided Region Control](https://arxiv.org/abs/2508.08134)
*Zeqian Long,Mingzhe Zheng,Kunyu Feng,Xinhua Zhang,Hongyu Liu,Harry Yang,Linfeng Zhang,Qifeng Chen,Yue Ma*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练和掩码的图像编辑框架Follow-Your-Shape，通过计算轨迹差异图（TDM）和计划KV注入机制，实现精确可控的物体形状编辑，同时严格保护非目标内容。


<details>
  <summary>Details</summary>
Motivation: 现有流式图像编辑模型在需要大面积形状变换的复杂场景中表现不佳，易导致目标形状未达预期或非目标区域被误改。

Method: 通过比较反演和去噪路径的令牌速度差异计算TDM，定位可编辑区域，并结合计划KV注入机制实现稳定编辑。

Result: 实验表明，该方法在任务中展现出优异的可编辑性和视觉保真度，特别是在大尺寸形状替换任务中。

Conclusion: 该方法在复杂形状编辑中实现了高精度的控制和内容保护，为后续研究提供了新方向。

Abstract: While recent flow-based image editing models demonstrate general-purpose
capabilities across diverse tasks, they often struggle to specialize in
challenging scenarios -- particularly those involving large-scale shape
transformations. When performing such structural edits, these methods either
fail to achieve the intended shape change or inadvertently alter non-target
regions, resulting in degraded background quality. We propose
Follow-Your-Shape, a training-free and mask-free framework that supports
precise and controllable editing of object shapes while strictly preserving
non-target content. Motivated by the divergence between inversion and editing
trajectories, we compute a Trajectory Divergence Map (TDM) by comparing
token-wise velocity differences between the inversion and denoising paths. The
TDM enables precise localization of editable regions and guides a Scheduled KV
Injection mechanism that ensures stable and faithful editing. To facilitate a
rigorous evaluation, we introduce ReShapeBench, a new benchmark comprising 120
new images and enriched prompt pairs specifically curated for shape-aware
editing. Experiments demonstrate that our method achieves superior editability
and visual fidelity, particularly in tasks requiring large-scale shape
replacement.

</details>


### [204] [FantasyStyle: Controllable Stylized Distillation for 3D Gaussian Splatting](https://arxiv.org/abs/2508.08136)
*Yitong Yang,Yinglin Wang,Changshuo Wang,Huajie Wang,Shuting He*

Main category: cs.CV

TL;DR: 论文介绍了FantasyStyle，一种基于3DGS的风格迁移框架，通过扩散模型蒸馏解决了多视图不一致性和VGG特征依赖问题，提升了风格迁移质量和视觉真实感。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS风格迁移方法存在多视图不一致和VGG特征难以解耦的问题，导致风格冲突和内容泄露。

Method: 提出了多视图频率一致性和可控风格化蒸馏两大组件，利用3D滤波和负引导优化3D高斯。

Result: 实验表明，该方法在多种场景和风格下均优于现有技术，实现了更高的风格质量和真实感。

Conclusion: FantasyStyle通过创新性设计有效解决了现有问题，为3D风格迁移提供了新思路。

Abstract: The success of 3DGS in generative and editing applications has sparked
growing interest in 3DGS-based style transfer. However, current methods still
face two major challenges: (1) multi-view inconsistency often leads to style
conflicts, resulting in appearance smoothing and distortion; and (2) heavy
reliance on VGG features, which struggle to disentangle style and content from
style images, often causing content leakage and excessive stylization. To
tackle these issues, we introduce \textbf{FantasyStyle}, a 3DGS-based style
transfer framework, and the first to rely entirely on diffusion model
distillation. It comprises two key components: (1) \textbf{Multi-View Frequency
Consistency}. We enhance cross-view consistency by applying a 3D filter to
multi-view noisy latent, selectively reducing low-frequency components to
mitigate stylized prior conflicts. (2) \textbf{Controllable Stylized
Distillation}. To suppress content leakage from style images, we introduce
negative guidance to exclude undesired content. In addition, we identify the
limitations of Score Distillation Sampling and Delta Denoising Score in 3D
style transfer and remove the reconstruction term accordingly. Building on
these insights, we propose a controllable stylized distillation that leverages
negative guidance to more effectively optimize the 3D Gaussians. Extensive
experiments demonstrate that our method consistently outperforms
state-of-the-art approaches, achieving higher stylization quality and visual
realism across various scenes and styles.

</details>


### [205] [Pindrop it! Audio and Visual Deepfake Countermeasures for Robust Detection and Fine Grained-Localization](https://arxiv.org/abs/2508.08141)
*Nicholas Klein,Hemlata Tak,James Fullwood,Krishna Regmi,Leonidas Spinoulas,Ganesh Sivaraman,Tianxiang Chen,Elie Khoury*

Main category: cs.CV

TL;DR: 该论文提出了针对深度伪造视频分类和定位的解决方案，并在ACM 1M深度伪造检测挑战赛中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 随着视觉和音频生成技术的快速发展，检测合成内容的需求日益迫切，尤其是当视觉或音频领域中存在细微修改时，对检测算法提出了更高挑战。

Method: 论文提出的方法参加了ACM 1M深度伪造检测挑战赛，专注于视频分类和时域定位任务。

Result: 在测试数据集TestA中，该方法在时域定位任务中表现最佳，在分类任务中排名前四。

Conclusion: 研究表明，该方法在检测深度伪造视频方面具有竞争力，尤其在定位任务中表现突出。

Abstract: The field of visual and audio generation is burgeoning with new
state-of-the-art methods. This rapid proliferation of new techniques
underscores the need for robust solutions for detecting synthetic content in
videos. In particular, when fine-grained alterations via localized
manipulations are performed in visual, audio, or both domains, these subtle
modifications add challenges to the detection algorithms. This paper presents
solutions for the problems of deepfake video classification and localization.
The methods were submitted to the ACM 1M Deepfakes Detection Challenge,
achieving the best performance in the temporal localization task and a top four
ranking in the classification task for the TestA split of the evaluation
dataset.

</details>


### [206] [ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction](https://arxiv.org/abs/2508.08170)
*Chaojun Ni,Guosheng Zhao,Xiaofeng Wang,Zheng Zhu,Wenkang Qin,Xinze Chen,Guanghong Jia,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: 提出ReconDreamer-RL框架，结合视频扩散先验和动力学模型进行场景重建，提升自动驾驶训练效果，降低碰撞率。


<details>
  <summary>Details</summary>
Motivation: 现有仿真环境与真实条件差异大，生成新轨迹或极端场景数据困难，需缩小sim2real差距。

Method: 引入ReconSimulator整合视频扩散先验和动力学模型，Dynamic Adversary Agent生成极端场景，Cousin Trajectory Generator解决数据分布偏差。

Result: 实验显示ReconDreamer-RL优于模仿学习方法，碰撞率降低5倍。

Conclusion: ReconDreamer-RL通过创新框架有效提升自动驾驶训练效果，缩小仿真与现实的差距。

Abstract: Reinforcement learning for training end-to-end autonomous driving models in
closed-loop simulations is gaining growing attention. However, most simulation
environments differ significantly from real-world conditions, creating a
substantial simulation-to-reality (sim2real) gap. To bridge this gap, some
approaches utilize scene reconstruction techniques to create photorealistic
environments as a simulator. While this improves realistic sensor simulation,
these methods are inherently constrained by the distribution of the training
data, making it difficult to render high-quality sensor data for novel
trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a
framework designed to integrate video diffusion priors into scene
reconstruction to aid reinforcement learning, thereby enhancing end-to-end
autonomous driving training. Specifically, in ReconDreamer-RL, we introduce
ReconSimulator, which combines the video diffusion prior for appearance
modeling and incorporates a kinematic model for physical modeling, thereby
reconstructing driving scenarios from real-world data. This narrows the
sim2real gap for closed-loop evaluation and reinforcement learning. To cover
more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA),
which adjusts the trajectories of surrounding vehicles relative to the ego
vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in).
Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue
of training data distribution, which is often biased toward simple
straight-line movements. Experiments show that ReconDreamer-RL improves
end-to-end autonomous driving training, outperforming imitation learning
methods with a 5x reduction in the Collision Ratio.

</details>


### [207] [CD-TVD: Contrastive Diffusion for 3D Super-Resolution with Scarce High-Resolution Time-Varying Data](https://arxiv.org/abs/2508.08173)
*Chongke Bi,Xin Gao,Jiangkang Deng,Guan*

Main category: cs.CV

TL;DR: CD-TVD是一种新颖的框架，结合对比学习和改进的扩散模型，仅需少量高分辨率数据即可实现3D超分辨率，显著减少对大规模数据集的依赖。


<details>
  <summary>Details</summary>
Motivation: 大规模科学模拟生成高分辨率时变数据（TVD）成本高昂，现有超分辨率方法依赖大量训练数据，限制了其适用性。

Method: 提出CD-TVD框架，通过对历史数据预训练对比编码器和扩散模型，学习降级模式和细节特征，仅需一个新生成的高分辨率时间步即可微调模型。

Result: 在流体和大气模拟数据集上的实验表明，CD-TVD能高效准确地实现3D超分辨率。

Conclusion: CD-TVD为大规模科学模拟的数据增强提供了显著进步，代码已开源。

Abstract: Large-scale scientific simulations require significant resources to generate
high-resolution time-varying data (TVD). While super-resolution is an efficient
post-processing strategy to reduce costs, existing methods rely on a large
amount of HR training data, limiting their applicability to diverse simulation
scenarios. To address this constraint, we proposed CD-TVD, a novel framework
that combines contrastive learning and an improved diffusion-based
super-resolution model to achieve accurate 3D super-resolution from limited
time-step high-resolution data. During pre-training on historical simulation
data, the contrastive encoder and diffusion superresolution modules learn
degradation patterns and detailed features of high-resolution and
low-resolution samples. In the training phase, the improved diffusion model
with a local attention mechanism is fine-tuned using only one newly generated
high-resolution timestep, leveraging the degradation knowledge learned by the
encoder. This design minimizes the reliance on large-scale high-resolution
datasets while maintaining the capability to recover fine-grained details.
Experimental results on fluid and atmospheric simulation datasets confirm that
CD-TVD delivers accurate and resource-efficient 3D super-resolution, marking a
significant advancement in data augmentation for large-scale scientific
simulations. The code is available at
https://github.com/Xin-Gao-private/CD-TVD.

</details>


### [208] [MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision](https://arxiv.org/abs/2508.08177)
*Zhonghao Yan,Muxi Diao,Yuxuan Yang,Jiayuan Xu,Kaizhou Zhang,Ruoyan Jing,Lele Yang,Yanxi Liu,Kongming Liang,Zhanyu Ma*

Main category: cs.CV

TL;DR: 论文提出了一种新型医学视觉语言任务UMRG及数据集U-MRG-14K，并开发了模块化框架MedReasoner，通过强化学习优化推理能力，实现医学图像区域的精准定位。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的兴趣区域（ROI）精准定位对诊断和治疗至关重要，但现有方法依赖显式空间提示，难以应对临床实践中的隐式查询需求。

Method: 定义UMRG任务并构建数据集U-MRG-14K；提出MedReasoner框架，分离推理与分割步骤，通过强化学习优化推理模块。

Result: MedReasoner在U-MRG-14K上取得最优性能，并能泛化至未见过的临床查询。

Conclusion: 该方法证明了强化学习在可解释医学定位中的潜力，为临床实践提供了新工具。

Abstract: Accurately grounding regions of interest (ROIs) is critical for diagnosis and
treatment planning in medical imaging. While multimodal large language models
(MLLMs) combine visual perception with natural language, current
medical-grounding pipelines still rely on supervised fine-tuning with explicit
spatial hints, making them ill-equipped to handle the implicit queries common
in clinical practice. This work makes three core contributions. We first define
Unified Medical Reasoning Grounding (UMRG), a novel vision-language task that
demands clinical reasoning and pixel-level grounding. Second, we release
U-MRG-14K, a dataset of 14K samples featuring pixel-level masks alongside
implicit clinical queries and reasoning traces, spanning 10 modalities, 15
super-categories, and 108 specific categories. Finally, we introduce
MedReasoner, a modular framework that distinctly separates reasoning from
segmentation: an MLLM reasoner is optimized with reinforcement learning, while
a frozen segmentation expert converts spatial prompts into masks, with
alignment achieved through format and accuracy rewards. MedReasoner achieves
state-of-the-art performance on U-MRG-14K and demonstrates strong
generalization to unseen clinical queries, underscoring the significant promise
of reinforcement learning for interpretable medical grounding.

</details>


### [209] [3D Human Mesh Estimation from Single View RGBD](https://arxiv.org/abs/2508.08178)
*Ozhan Suat,Bedirhan Uguz,Batuhan Karagoz,Muhammed Can Keles,Emre Akbas*

Main category: cs.CV

TL;DR: 论文提出了一种利用RGBD相机进行3D人体网格估计的方法M$^3$，通过模拟虚拟相机视图和掩码自编码器克服数据稀缺问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用RGBD相机的深度数据提升3D人体网格估计的精度和实用性，同时解决现有数据集小且多样性不足的问题。

Method: 从MoCap数据集获取完整3D网格，模拟虚拟相机视图生成部分单视图网格，训练掩码自编码器完成缺失部分。

Result: 在SURREAL和CAPE数据集上分别达到16.8 mm和22.0 mm的PVE，性能优于现有方法。

Conclusion: M$^3$方法有效利用深度数据，显著提升3D人体网格估计的精度和实用性。

Abstract: Despite significant progress in 3D human mesh estimation from RGB images;
RGBD cameras, offering additional depth data, remain underutilized. In this
paper, we present a method for accurate 3D human mesh estimation from a single
RGBD view, leveraging the affordability and widespread adoption of RGBD cameras
for real-world applications. A fully supervised approach for this problem,
requires a dataset with RGBD image and 3D mesh label pairs. However, collecting
such a dataset is costly and challenging, hence, existing datasets are small,
and limited in pose and shape diversity. To overcome this data scarcity, we
leverage existing Motion Capture (MoCap) datasets. We first obtain complete 3D
meshes from the body models found in MoCap datasets, and create partial,
single-view versions of them by projection to a virtual camera. This simulates
the depth data provided by an RGBD camera from a single viewpoint. Then, we
train a masked autoencoder to complete the partial, single-view mesh. During
inference, our method, which we name as M$^3$ for ``Masked Mesh Modeling'',
matches the depth values coming from the sensor to vertices of a template human
mesh, which creates a partial, single-view mesh. We effectively recover parts
of the 3D human body mesh model that are not visible, resulting in a full body
mesh. M$^3$ achieves 16.8 mm and 22.0 mm per-vertex-error (PVE) on the SURREAL
and CAPE datasets, respectively; outperforming existing methods that use
full-body point clouds as input. We obtain a competitive 70.9 PVE on the BEHAVE
dataset, outperforming a recently published RGB based method by 18.4 mm,
highlighting the usefulness of depth data. Code will be released.

</details>


### [210] [THAT: Token-wise High-frequency Augmentation Transformer for Hyperspectral Pansharpening](https://arxiv.org/abs/2508.08183)
*Hongkun Jin,Hongcheng Jiang,Zejun Zhang,Yuan Zhang,Jia Fu,Tingfeng Li,Kai Luo*

Main category: cs.CV

TL;DR: 该论文提出了一种名为THAT的新框架，通过增强高频特征表示和令牌选择，解决了Vision Transformers在超光谱图像融合中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer方法在超光谱图像融合中因冗余令牌表示和缺乏多尺度特征建模而受限，且忽视高频信号和局部细节。

Method: THAT采用PTSA来筛选信息令牌并抑制冗余，并结合MVFN增强高频细节学习。

Result: 在标准基准测试中，THAT实现了最先进的性能，提升了重建质量和效率。

Conclusion: THAT框架有效解决了超光谱图像融合中的高频细节和冗余问题，性能优越。

Abstract: Transformer-based methods have demonstrated strong potential in hyperspectral
pansharpening by modeling long-range dependencies. However, their effectiveness
is often limited by redundant token representations and a lack of multi-scale
feature modeling. Hyperspectral images exhibit intrinsic spectral priors (e.g.,
abundance sparsity) and spatial priors (e.g., non-local similarity), which are
critical for accurate reconstruction. From a spectral-spatial perspective,
Vision Transformers (ViTs) face two major limitations: they struggle to
preserve high-frequency components--such as material edges and texture
transitions--and suffer from attention dispersion across redundant tokens.
These issues stem from the global self-attention mechanism, which tends to
dilute high-frequency signals and overlook localized details. To address these
challenges, we propose the Token-wise High-frequency Augmentation Transformer
(THAT), a novel framework designed to enhance hyperspectral pansharpening
through improved high-frequency feature representation and token selection.
Specifically, THAT introduces: (1) Pivotal Token Selective Attention (PTSA) to
prioritize informative tokens and suppress redundancy; (2) a Multi-level
Variance-aware Feed-forward Network (MVFN) to enhance high-frequency detail
learning. Experiments on standard benchmarks show that THAT achieves
state-of-the-art performance with improved reconstruction quality and
efficiency. The source code is available at https://github.com/kailuo93/THAT.

</details>


### [211] [KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning](https://arxiv.org/abs/2508.08186)
*Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: KARMA是一种高效的语义分割框架，用于结构缺陷检测，通过新颖的模块和设计大幅减少参数需求，同时保持性能，适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法参数过多、不适合实时检测的问题。

Method: 引入KARMA框架，包括TiKAN模块、优化的特征金字塔结构和静态-动态原型机制。

Result: 在基准数据集上表现优秀，参数量减少97%，适合实时应用。

Conclusion: KARMA为基础设施检测提供了一种高效且实用的解决方案。

Abstract: Semantic segmentation of structural defects in civil infrastructure remains
challenging due to variable defect appearances, harsh imaging conditions, and
significant class imbalance. Current deep learning methods, despite their
effectiveness, typically require millions of parameters, rendering them
impractical for real-time inspection systems. We introduce KARMA
(Kolmogorov-Arnold Representation Mapping Architecture), a highly efficient
semantic segmentation framework that models complex defect patterns through
compositions of one-dimensional functions rather than conventional
convolutions. KARMA features three technical innovations: (1) a
parameter-efficient Tiny Kolmogorov-Arnold Network (TiKAN) module leveraging
low-rank factorization for KAN-based feature transformation; (2) an optimized
feature pyramid structure with separable convolutions for multi-scale defect
analysis; and (3) a static-dynamic prototype mechanism that enhances feature
representation for imbalanced classes. Extensive experiments on benchmark
infrastructure inspection datasets demonstrate that KARMA achieves competitive
or superior mean IoU performance compared to state-of-the-art approaches, while
using significantly fewer parameters (0.959M vs. 31.04M, a 97% reduction).
Operating at 0.264 GFLOPS, KARMA maintains inference speeds suitable for
real-time deployment, enabling practical automated infrastructure inspection
systems without compromising accuracy. The source code can be accessed at the
following URL: https://github.com/faeyelab/karma.

</details>


### [212] [Reinforcement Learning in Vision: A Survey](https://arxiv.org/abs/2508.08189)
*Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 该论文是一篇关于视觉强化学习（RL）的综述，介绍了从RLHF到可验证奖励范式的策略优化演进，并将200多篇代表性工作分为四个主题支柱，探讨了算法设计、奖励工程和基准测试，同时指出了开放挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了全面梳理视觉强化学习领域的最新进展，提供研究与实践的指南，并指出未来的研究方向。

Method: 通过形式化视觉RL问题，分析策略优化策略的演进，并将代表性工作分为四大主题支柱进行详细探讨。

Result: 综述了视觉RL的多样化和进步，包括多模态大语言模型、视觉生成、统一模型框架和视觉-语言-行动模型等方向的发展。

Conclusion: 总结了视觉RL领域的现状和挑战，呼吁进一步关注样本效率、泛化性和安全部署等问题，为未来研究提供方向。

Abstract: Recent advances at the intersection of reinforcement learning (RL) and visual
intelligence have enabled agents that not only perceive complex visual scenes
but also reason, generate, and act within them. This survey offers a critical
and up-to-date synthesis of the field. We first formalize visual RL problems
and trace the evolution of policy-optimization strategies from RLHF to
verifiable reward paradigms, and from Proximal Policy Optimization to Group
Relative Policy Optimization. We then organize more than 200 representative
works into four thematic pillars: multi-modal large language models, visual
generation, unified model frameworks, and vision-language-action models. For
each pillar we examine algorithmic design, reward engineering, benchmark
progress, and we distill trends such as curriculum-driven training,
preference-aligned diffusion, and unified reward modeling. Finally, we review
evaluation protocols spanning set-level fidelity, sample-level preference, and
state-level stability, and we identify open challenges that include sample
efficiency, generalization, and safe deployment. Our goal is to provide
researchers and practitioners with a coherent map of the rapidly expanding
landscape of visual RL and to highlight promising directions for future
inquiry. Resources are available at:
https://github.com/weijiawu/Awesome-Visual-Reinforcement-Learning.

</details>


### [213] [Spatial-ORMLLM: Improve Spatial Relation Understanding in the Operating Room with Multimodal Large Language Model](https://arxiv.org/abs/2508.08199)
*Peiqi He,Zhenhao Zhang,Yixiang Zhang,Xiongjun Zhao,Shaoliang Peng*

Main category: cs.CV

TL;DR: 提出了Spatial-ORMLLM，首个仅使用RGB模态进行3D空间推理的大型视觉语言模型，用于手术室中的详细空间上下文分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多模态数据集学习空间关系，但手术室中多传感器数据难以获取，且2D数据无法捕捉复杂场景的细节。

Method: 引入Spatial-Enhanced Feature Fusion Block，结合2D输入与3D空间知识，通过端到端框架实现3D场景推理。

Result: 在多个临床数据集上表现优异，泛化能力强，适用于未见过的任务。

Conclusion: Spatial-ORMLLM为手术室中的3D空间建模提供了高效解决方案，无需额外传感器或标注。

Abstract: Precise spatial modeling in the operating room (OR) is foundational to many
clinical tasks, supporting intraoperative awareness, hazard avoidance, and
surgical decision-making. While existing approaches leverage large-scale
multimodal datasets for latent-space alignment to implicitly learn spatial
relationships, they overlook the 3D capabilities of MLLMs. However, this
approach raises two issues: (1) Operating rooms typically lack multiple video
and audio sensors, making multimodal 3D data difficult to obtain; (2) Training
solely on readily available 2D data fails to capture fine-grained details in
complex scenes. To address this gap, we introduce Spatial-ORMLLM, the first
large vision-language model for 3D spatial reasoning in operating rooms using
only RGB modality to infer volumetric and semantic cues, enabling downstream
medical tasks with detailed and holistic spatial context. Spatial-ORMLLM
incorporates a Spatial-Enhanced Feature Fusion Block, which integrates 2D
modality inputs with rich 3D spatial knowledge extracted by the estimation
algorithm and then feeds the combined features into the visual tower. By
employing a unified end-to-end MLLM framework, it combines powerful spatial
features with textual features to deliver robust 3D scene reasoning without any
additional expert annotations or sensor inputs. Experiments on multiple
benchmark clinical datasets demonstrate that Spatial-ORMLLM achieves
state-of-the-art performance and generalizes robustly to previously unseen
surgical scenarios and downstream tasks.

</details>


### [214] [SAGOnline: Segment Any Gaussians Online](https://arxiv.org/abs/2508.08219)
*Wentao Sun,Quanyun Wu,Hanqing Xu,Kyle Gao,Zhengsen Xu,Yiping Chen,Dedong Zhang,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: 3D高斯点云分割框架SAGOnline通过视频基础模型和GPU加速算法实现实时多目标分割与跟踪，性能优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D点云分割方法计算成本高、空间推理能力有限及无法同时跟踪多目标的问题。

Method: 结合视频基础模型（如SAM2）进行2D掩码传播，并采用GPU加速的3D掩码生成与高斯实例标记算法。

Result: 在NVOS和Spin-NeRF基准测试中表现优异，推理速度提升15-1500倍。

Conclusion: SAGOnline为实时3D场景理解提供了轻量级、零样本解决方案，适用于AR/VR和机器人应用。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for explicit
3D scene representation, yet achieving efficient and consistent 3D segmentation
remains challenging. Current methods suffer from prohibitive computational
costs, limited 3D spatial reasoning, and an inability to track multiple objects
simultaneously. We present Segment Any Gaussians Online (SAGOnline), a
lightweight and zero-shot framework for real-time 3D segmentation in Gaussian
scenes that addresses these limitations through two key innovations: (1) a
decoupled strategy that integrates video foundation models (e.g., SAM2) for
view-consistent 2D mask propagation across synthesized views; and (2) a
GPU-accelerated 3D mask generation and Gaussian-level instance labeling
algorithm that assigns unique identifiers to 3D primitives, enabling lossless
multi-object tracking and segmentation across views. SAGOnline achieves
state-of-the-art performance on NVOS (92.7% mIoU) and Spin-NeRF (95.2% mIoU)
benchmarks, outperforming Feature3DGS, OmniSeg3D-gs, and SA3D by 15--1500 times
in inference speed (27 ms/frame). Qualitative results demonstrate robust
multi-object segmentation and tracking in complex scenes. Our contributions
include: (i) a lightweight and zero-shot framework for 3D segmentation in
Gaussian scenes, (ii) explicit labeling of Gaussian primitives enabling
simultaneous segmentation and tracking, and (iii) the effective adaptation of
2D video foundation models to the 3D domain. This work allows real-time
rendering and 3D scene understanding, paving the way for practical AR/VR and
robotic applications.

</details>


### [215] [Learning User Preferences for Image Generation Model](https://arxiv.org/abs/2508.08220)
*Wenyi Mo,Ying Ba,Tianyu Zhang,Yalong Bai,Biye Li*

Main category: cs.CV

TL;DR: 该论文提出了一种基于多模态大型语言模型的方法，通过对比偏好损失和可学习偏好标记来预测用户偏好，有效区分用户喜好并捕捉共享兴趣，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖通用偏好或静态用户画像，忽略了用户偏好的动态性和多样性，因此需要一种更全面且个性化的预测方法。

Method: 采用多模态大型语言模型，引入对比偏好损失和可学习偏好标记，从历史交互中学习个性化偏好并捕捉共享兴趣。

Result: 模型在偏好预测准确率上优于其他方法，能有效识别相似审美倾向的用户，并为生成符合个人口味的图像提供更精确的指导。

Conclusion: 该方法显著提升了用户偏好预测的准确性和个性化水平，为个性化内容生成提供了有效支持。

Abstract: User preference prediction requires a comprehensive and accurate
understanding of individual tastes. This includes both surface-level
attributes, such as color and style, and deeper content-related aspects, such
as themes and composition. However, existing methods typically rely on general
human preferences or assume static user profiles, often neglecting individual
variability and the dynamic, multifaceted nature of personal taste. To address
these limitations, we propose an approach built upon Multimodal Large Language
Models, introducing contrastive preference loss and preference tokens to learn
personalized user preferences from historical interactions. The contrastive
preference loss is designed to effectively distinguish between user ''likes''
and ''dislikes'', while the learnable preference tokens capture shared interest
representations among existing users, enabling the model to activate
group-specific preferences and enhance consistency across similar users.
Extensive experiments demonstrate our model outperforms other methods in
preference prediction accuracy, effectively identifying users with similar
aesthetic inclinations and providing more precise guidance for generating
images that align with individual tastes. The project page is
\texttt{https://learn-user-pref.github.io/}.

</details>


### [216] [OMGSR: You Only Need One Mid-timestep Guidance for Real-World Image Super-Resolution](https://arxiv.org/abs/2508.08227)
*Zhiqiang Wu,Zhaomang Sun,Tong Zhou,Bingtao Fu,Ji Cong,Yitong Dong,Huaqi Zhang,Xuan Tang,Mingsong Chen,Xian Wei*

Main category: cs.CV

TL;DR: OMGSR是一种通用的图像超分辨率框架，通过在DDPM/FM生成模型的中期时间步注入低质量图像潜在分布，并引入损失函数优化潜在分布差距，显著提升图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的一步式Real-ISR模型在初始时间步注入低质量图像潜在分布与高斯噪声潜在分布存在差距，限制了生成先验的有效利用。

Method: 提出OMGSR框架，在中期时间步注入低质量图像潜在分布，使用Latent Distribution Refinement损失优化潜在分布差距，并设计Overlap-Chunked LPIPS/GAN损失消除棋盘伪影。

Result: 实验证明OMGSR-S和OMGSR-F在512分辨率下表现优异，尤其是OMGSR-F在所有参考指标中表现突出；1k分辨率版本在细节生成上效果更佳。

Conclusion: OMGSR框架通过优化潜在分布和消除伪影，显著提升了图像超分辨率的质量和效果。

Abstract: Denoising Diffusion Probabilistic Models (DDPM) and Flow Matching (FM)
generative models show promising potential for one-step Real-World Image
Super-Resolution (Real-ISR). Recent one-step Real-ISR models typically inject a
Low-Quality (LQ) image latent distribution at the initial timestep. However, a
fundamental gap exists between the LQ image latent distribution and the
Gaussian noisy latent distribution, limiting the effective utilization of
generative priors. We observe that the noisy latent distribution at DDPM/FM
mid-timesteps aligns more closely with the LQ image latent distribution. Based
on this insight, we present One Mid-timestep Guidance Real-ISR (OMGSR), a
universal framework applicable to DDPM/FM-based generative models. OMGSR
injects the LQ image latent distribution at a pre-computed mid-timestep,
incorporating the proposed Latent Distribution Refinement loss to alleviate the
latent distribution gap. We also design the Overlap-Chunked LPIPS/GAN loss to
eliminate checkerboard artifacts in image generation. Within this framework, we
instantiate OMGSR for DDPM/FM-based generative models with two variants:
OMGSR-S (SD-Turbo) and OMGSR-F (FLUX.1-dev). Experimental results demonstrate
that OMGSR-S/F achieves balanced/excellent performance across quantitative and
qualitative metrics at 512-resolution. Notably, OMGSR-F establishes
overwhelming dominance in all reference metrics. We further train a
1k-resolution OMGSR-F to match the default resolution of FLUX.1-dev, which
yields excellent results, especially in the details of the image generation. We
also generate 2k-resolution images by the 1k-resolution OMGSR-F using our
two-stage Tiled VAE & Diffusion.

</details>


### [217] [Cut2Next: Generating Next Shot via In-Context Tuning](https://arxiv.org/abs/2508.08244)
*Jingwen He,Hongbo Liu,Jiajun Li,Ziqi Huang,Yu Qiao,Wanli Ouyang,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出了一种名为NSG的方法，结合了Cut2Next框架，利用Diffusion Transformer和分层多提示策略，生成符合专业编辑模式且保持电影连续性的高质量镜头。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于关注基础视觉一致性，忽视了叙事编辑模式，导致输出缺乏叙事复杂性和电影完整性。

Method: 采用了Diffusion Transformer (DiT)，结合Hierarchical Multi-Prompting策略，包括Relational Prompts和Individual Prompts，并通过Context-Aware Condition Injection (CACI)和Hierarchical Attention Mask (HAM)集成信号。

Result: 实验表明Cut2Next在视觉一致性和文本保真度上表现优异，用户研究更偏好其编辑模式和电影连续性。

Conclusion: Cut2Next能够生成高质量、叙事表达丰富且电影连贯的后续镜头。

Abstract: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.

</details>


### [218] [StableAvatar: Infinite-Length Audio-Driven Avatar Video Generation](https://arxiv.org/abs/2508.08248)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Chong Luo,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 该论文提出了StableAvatar，一种端到端的视频扩散Transformer，能够生成无限长度的高质量视频，解决了现有音频驱动视频生成模型在长时间视频合成中的音频同步和身份一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动的虚拟化身视频生成模型难以合成具有自然音频同步和身份一致性的长视频，主要原因是音频建模的局限性。

Method: StableAvatar通过专门设计的训练和推理模块，结合新颖的Time-step-aware Audio Adapter和Audio Native Guidance Mechanism，防止误差累积并增强音频同步，同时采用Dynamic Weighted Sliding-window Strategy提升视频平滑度。

Result: 实验证明，StableAvatar在质量和数量上均表现出色，能够生成高质量的长视频。

Conclusion: StableAvatar通过创新的音频处理和推理策略，实现了音频驱动的无限长度视频生成，为相关领域提供了新的解决方案。

Abstract: Current diffusion models for audio-driven avatar video generation struggle to
synthesize long videos with natural audio synchronization and identity
consistency. This paper presents StableAvatar, the first end-to-end video
diffusion transformer that synthesizes infinite-length high-quality videos
without post-processing. Conditioned on a reference image and audio,
StableAvatar integrates tailored training and inference modules to enable
infinite-length video generation. We observe that the main reason preventing
existing models from generating long videos lies in their audio modeling. They
typically rely on third-party off-the-shelf extractors to obtain audio
embeddings, which are then directly injected into the diffusion model via
cross-attention. Since current diffusion backbones lack any audio-related
priors, this approach causes severe latent distribution error accumulation
across video clips, leading the latent distribution of subsequent segments to
drift away from the optimal distribution gradually. To address this,
StableAvatar introduces a novel Time-step-aware Audio Adapter that prevents
error accumulation via time-step-aware modulation. During inference, we propose
a novel Audio Native Guidance Mechanism to further enhance the audio
synchronization by leveraging the diffusion's own evolving joint audio-latent
prediction as a dynamic guidance signal. To enhance the smoothness of the
infinite-length videos, we introduce a Dynamic Weighted Sliding-window Strategy
that fuses latent over time. Experiments on benchmarks show the effectiveness
of StableAvatar both qualitatively and quantitatively.

</details>


### [219] [ReferSplat: Referring Segmentation in 3D Gaussian Splatting](https://arxiv.org/abs/2508.08252)
*Shuting He,Guangquan Jie,Changshuo Wang,Yun Zhou,Shuming Hu,Guanbin Li,Henghui Ding*

Main category: cs.CV

TL;DR: 该论文介绍了R3DGS任务，通过自然语言描述对3D高斯场景中的目标对象进行分割，提出了Ref-LERF数据集和ReferSplat框架，以解决3D多模态理解和空间关系建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了推动具身AI的发展，需要解决3D多模态理解和空间关系建模的关键挑战。

Method: 提出了ReferSplat框架，显式建模3D高斯点与自然语言表达的空间感知范式。

Result: ReferSplat在R3DGS任务和3D开放词汇分割基准上实现了最先进的性能。

Conclusion: R3DGS任务的提出和ReferSplat框架的开发，为3D场景理解和语言引导分割提供了新的研究方向。

Abstract: We introduce Referring 3D Gaussian Splatting Segmentation (R3DGS), a new task
that aims to segment target objects in a 3D Gaussian scene based on natural
language descriptions, which often contain spatial relationships or object
attributes. This task requires the model to identify newly described objects
that may be occluded or not directly visible in a novel view, posing a
significant challenge for 3D multi-modal understanding. Developing this
capability is crucial for advancing embodied AI. To support research in this
area, we construct the first R3DGS dataset, Ref-LERF. Our analysis reveals that
3D multi-modal understanding and spatial relationship modeling are key
challenges for R3DGS. To address these challenges, we propose ReferSplat, a
framework that explicitly models 3D Gaussian points with natural language
expressions in a spatially aware paradigm. ReferSplat achieves state-of-the-art
performance on both the newly proposed R3DGS task and 3D open-vocabulary
segmentation benchmarks. Dataset and code are available at
https://github.com/heshuting555/ReferSplat.

</details>


### [220] [Learning an Implicit Physics Model for Image-based Fluid Simulation](https://arxiv.org/abs/2508.08254)
*Emily Yue-Ting Jia,Jiageng Mao,Zhiyuan Gao,Yajie Zhao,Yue Wang*

Main category: cs.CV

TL;DR: 提出了一种基于物理原理的神经网络方法，从单张图像生成4D场景（含3D几何与运动），显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 人类能从静态图像想象出4D场景（含运动和3D几何），而现有方法常违背物理规律，导致不真实动画。本文旨在通过神经网络复现这一能力，并以自然流体图像为例。

Method: 提出物理启发的神经网络，通过Navier-Stokes方程等物理原理指导运动预测，并基于特征3D高斯模型渲染动画。

Result: 实验结果表明，该方法能生成物理一致的动画，性能显著优于现有方法。

Conclusion: 结合物理约束的神经网络方法有效提升了单图生成4D场景的逼真度和物理合理性。

Abstract: Humans possess an exceptional ability to imagine 4D scenes, encompassing both
motion and 3D geometry, from a single still image. This ability is rooted in
our accumulated observations of similar scenes and an intuitive understanding
of physics. In this paper, we aim to replicate this capacity in neural
networks, specifically focusing on natural fluid imagery. Existing methods for
this task typically employ simplistic 2D motion estimators to animate the
image, leading to motion predictions that often defy physical principles,
resulting in unrealistic animations. Our approach introduces a novel method for
generating 4D scenes with physics-consistent animation from a single image. We
propose the use of a physics-informed neural network that predicts motion for
each surface point, guided by a loss term derived from fundamental physical
principles, including the Navier-Stokes equations. To capture appearance, we
predict feature-based 3D Gaussians from the input image and its estimated
depth, which are then animated using the predicted motions and rendered from
any desired camera perspective. Experimental results highlight the
effectiveness of our method in producing physically plausible animations,
showcasing significant performance improvements over existing methods. Our
project page is https://physfluid.github.io/ .

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [221] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: 利用预训练的卷积神经网络（CNN）进行迁移学习，结合数据增强技术，显著提高了急性淋巴细胞白血病（ALL）的血液涂片图像分类准确性，其中EfficientNet-B3表现最佳。


<details>
  <summary>Details</summary>
Motivation: 早期准确诊断ALL对治疗规划至关重要，但现有方法在血液涂片图像分类上仍有提升空间。

Method: 采用迁移学习方法，使用ResNet50、ResNet101及EfficientNet-B0/B1/B3等预训练CNN模型，并通过数据增强平衡数据集。

Result: EfficientNet-B3表现最佳，F1分数94.30%，准确率92.02%，AUC 94.79%，优于现有方法。

Conclusion: 该研究展示了数据增强与先进迁移学习模型结合在血液恶性肿瘤诊断中的有效性。

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>


### [222] [LWT-ARTERY-LABEL: A Lightweight Framework for Automated Coronary Artery Identification](https://arxiv.org/abs/2508.06874)
*Shisheng Zhang,Ramtin Gharleghi,Sonit Singh,Daniel Moses,Dona Adikari,Arcot Sowmya,Susann Beier*

Main category: eess.IV

TL;DR: 提出了一种轻量级方法，通过结合解剖学知识和基于规则的拓扑约束，实现高效自动化冠状动脉标记。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉疾病的诊断依赖CTCA，但人工分析耗时耗力，现有自动化方法在资源利用和临床知识整合上存在不足。

Method: 整合解剖学知识与基于规则的拓扑约束，开发轻量级冠状动脉标记方法。

Result: 在基准数据集上达到最先进的性能。

Conclusion: 该方法为自动化冠状动脉标记提供了高效且实用的解决方案。

Abstract: Coronary artery disease (CAD) remains the leading cause of death globally,
with computed tomography coronary angiography (CTCA) serving as a key
diagnostic tool. However, coronary arterial analysis using CTCA, such as
identifying artery-specific features from computational modelling, is
labour-intensive and time-consuming. Automated anatomical labelling of coronary
arteries offers a potential solution, yet the inherent anatomical variability
of coronary trees presents a significant challenge. Traditional knowledge-based
labelling methods fall short in leveraging data-driven insights, while recent
deep-learning approaches often demand substantial computational resources and
overlook critical clinical knowledge. To address these limitations, we propose
a lightweight method that integrates anatomical knowledge with rule-based
topology constraints for effective coronary artery labelling. Our approach
achieves state-of-the-art performance on benchmark datasets, providing a
promising alternative for automated coronary artery labelling.

</details>


### [223] [Fusion-Based Brain Tumor Classification Using Deep Learning and Explainable AI, and Rule-Based Reasoning](https://arxiv.org/abs/2508.06891)
*Melika Filvantorkaman,Mohsen Piri,Maral Filvan Torkaman,Ashkan Zabihi,Hamidreza Moradi*

Main category: eess.IV

TL;DR: 该研究提出了一种基于MobileNetV2和DenseNet121的深度学习框架，通过软投票策略分类三种常见脑肿瘤，并结合可解释AI模块增强临床信任。


<details>
  <summary>Details</summary>
Motivation: 准确且可解释的脑肿瘤MRI分类对临床诊断和治疗至关重要。

Method: 结合MobileNetV2和DenseNet121的集成框架，使用Grad-CAM++和临床决策规则增强可解释性。

Result: 集成分类器性能优越（准确率91.7%），可解释性评估获放射科医师高度认可。

Conclusion: 该框架为脑肿瘤分类提供了稳健且可解释的解决方案，适合临床神经诊断。

Abstract: Accurate and interpretable classification of brain tumors from magnetic
resonance imaging (MRI) is critical for effective diagnosis and treatment
planning. This study presents an ensemble-based deep learning framework that
combines MobileNetV2 and DenseNet121 convolutional neural networks (CNNs) using
a soft voting strategy to classify three common brain tumor types: glioma,
meningioma, and pituitary adenoma. The models were trained and evaluated on the
Figshare dataset using a stratified 5-fold cross-validation protocol. To
enhance transparency and clinical trust, the framework integrates an
Explainable AI (XAI) module employing Grad-CAM++ for class-specific saliency
visualization, alongside a symbolic Clinical Decision Rule Overlay (CDRO) that
maps predictions to established radiological heuristics. The ensemble
classifier achieved superior performance compared to individual CNNs, with an
accuracy of 91.7%, precision of 91.9%, recall of 91.7%, and F1-score of 91.6%.
Grad-CAM++ visualizations revealed strong spatial alignment between model
attention and expert-annotated tumor regions, supported by Dice coefficients up
to 0.88 and IoU scores up to 0.78. Clinical rule activation further validated
model predictions in cases with distinct morphological features. A
human-centered interpretability assessment involving five board-certified
radiologists yielded high Likert-scale scores for both explanation usefulness
(mean = 4.4) and heatmap-region correspondence (mean = 4.0), reinforcing the
framework's clinical relevance. Overall, the proposed approach offers a robust,
interpretable, and generalizable solution for automated brain tumor
classification, advancing the integration of deep learning into clinical
neurodiagnostics.

</details>


### [224] [Spatio-Temporal Conditional Diffusion Models for Forecasting Future Multiple Sclerosis Lesion Masks Conditioned on Treatments](https://arxiv.org/abs/2508.07006)
*Gian Mario Favero,Ge Ya Luo,Nima Fathi,Justin Szeto,Douglas L. Arnold,Brennan Nichyporuk,Chris Pal,Tal Arbel*

Main category: eess.IV

TL;DR: 本文提出了一种基于多模态患者数据的空间时间扩散模型，用于预测多发性硬化症（MS）病灶的未来演变，并在临床试验数据上验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 图像驱动的个性化医疗在异质性疾病如MS中具有潜力，但目前缺乏预测性工具。

Method: 采用体素空间方法，结合MRI和治疗信息，构建治疗感知的扩散模型，预测未来病灶。

Result: 在2131例患者数据上验证，模型能准确预测六种治疗下病灶变化，并展示临床应用的潜力。

Conclusion: 图像生成模型有望成为MS数据驱动预测的有力工具。

Abstract: Image-based personalized medicine has the potential to transform healthcare,
particularly for diseases that exhibit heterogeneous progression such as
Multiple Sclerosis (MS). In this work, we introduce the first treatment-aware
spatio-temporal diffusion model that is able to generate future masks
demonstrating lesion evolution in MS. Our voxel-space approach incorporates
multi-modal patient data, including MRI and treatment information, to forecast
new and enlarging T2 (NET2) lesion masks at a future time point. Extensive
experiments on a multi-centre dataset of 2131 patient 3D MRIs from randomized
clinical trials for relapsing-remitting MS demonstrate that our generative
model is able to accurately predict NET2 lesion masks for patients across six
different treatments. Moreover, we demonstrate our model has the potential for
real-world clinical applications through downstream tasks such as future lesion
count and location estimation, binary lesion activity classification, and
generating counterfactual future NET2 masks for several treatments with
different efficacies. This work highlights the potential of causal, image-based
generative models as powerful tools for advancing data-driven prognostics in
MS.

</details>


### [225] [Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities](https://arxiv.org/abs/2508.07031)
*Anindya Bijoy Das,Shahnewaz Karim Sakib,Shibbir Ahmed*

Main category: eess.IV

TL;DR: 研究分析大型语言模型在医学影像任务中的幻觉现象，包括图像到文本和文本到图像任务，揭示常见错误模式及其临床影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学影像应用中存在幻觉问题，可能误导临床决策，需系统研究其安全性和可靠性。

Method: 研究通过图像到文本（如生成报告）和文本到图像（如生成影像）任务，分析幻觉现象，使用专家标准评估错误。

Result: 发现幻觉在解释和生成任务中的常见模式，并探讨模型架构和训练数据的影响。

Conclusion: 为提升医学影像系统中LLM的安全性和可信度提供了改进方向。

Abstract: Large Language Models (LLMs) are increasingly applied to medical imaging
tasks, including image interpretation and synthetic image generation. However,
these models often produce hallucinations, which are confident but incorrect
outputs that can mislead clinical decisions. This study examines hallucinations
in two directions: image to text, where LLMs generate reports from X-ray, CT,
or MRI scans, and text to image, where models create medical images from
clinical prompts. We analyze errors such as factual inconsistencies and
anatomical inaccuracies, evaluating outputs using expert informed criteria
across imaging modalities. Our findings reveal common patterns of hallucination
in both interpretive and generative tasks, with implications for clinical
reliability. We also discuss factors contributing to these failures, including
model architecture and training data. By systematically studying both image
understanding and generation, this work provides insights into improving the
safety and trustworthiness of LLM driven medical imaging systems.

</details>


### [226] [3DGS-VBench: A Comprehensive Video Quality Evaluation Benchmark for 3DGS Compression](https://arxiv.org/abs/2508.07038)
*Yuke Xing,William Gordon,Qi Yang,Kaifa Yang,Jiarui Wang,Yiling Xu*

Main category: eess.IV

TL;DR: 摘要提出3DGS-VBench数据集，用于评估3D高斯泼溅（3DGS）压缩算法的视觉质量和存储效率。


<details>
  <summary>Details</summary>
Motivation: 由于3DGS压缩技术缺乏系统化的质量评估研究，本文旨在填补这一空白。

Method: 通过构建包含660个压缩3DGS模型和视频序列的大规模数据集，并结合50名参与者的MOS评分，对6种SOTA压缩算法进行了系统评估。

Result: 研究验证了数据集的可靠性，并对15种质量评估指标进行了基准测试。

Conclusion: 该工作为3DGS压缩和质量评估研究提供了重要工具，推动了相关领域的发展。

Abstract: 3D Gaussian Splatting (3DGS) enables real-time novel view synthesis with high
visual fidelity, but its substantial storage requirements hinder practical
deployment, prompting state-of-the-art (SOTA) 3DGS methods to incorporate
compression modules. However, these 3DGS generative compression techniques
introduce unique distortions lacking systematic quality assessment research. To
this end, we establish 3DGS-VBench, a large-scale Video Quality Assessment
(VQA) Dataset and Benchmark with 660 compressed 3DGS models and video sequences
generated from 11 scenes across 6 SOTA 3DGS compression algorithms with
systematically designed parameter levels. With annotations from 50
participants, we obtained MOS scores with outlier removal and validated dataset
reliability. We benchmark 6 3DGS compression algorithms on storage efficiency
and visual quality, and evaluate 15 quality assessment metrics across multiple
paradigms. Our work enables specialized VQA model training for 3DGS, serving as
a catalyst for compression and quality assessment research. The dataset is
available at https://github.com/YukeXing/3DGS-VBench.

</details>


### [227] [SAGCNet: Spatial-Aware Graph Completion Network for Missing Slice Imputation in Population CMR Imaging](https://arxiv.org/abs/2508.07041)
*Junkai Liu,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: eess.IV

TL;DR: SAGCNet提出了一种新的MRI缺失切片补全方法，通过图结构和空间适配器解决3D MRI数据补全的挑战，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MRI缺失或不可用切片影响诊断准确性，现有方法在建模3D数据局部依赖和全局空间信息方面存在不足。

Method: 提出SAGCNet，包含体积切片图补全模块和体积空间适配器，用于捕捉3D空间上下文和切片间关系。

Result: 在心脏MRI数据集上，SAGCNet定量和定性均优于现有方法，且在切片数据有限时仍表现出色。

Conclusion: SAGCNet通过创新设计显著提升了MRI缺失切片的补全效果，支持临床诊断。

Abstract: Magnetic resonance imaging (MRI) provides detailed soft-tissue
characteristics that assist in disease diagnosis and screening. However, the
accuracy of clinical practice is often hindered by missing or unusable slices
due to various factors. Volumetric MRI synthesis methods have been developed to
address this issue by imputing missing slices from available ones. The inherent
3D nature of volumetric MRI data, such as cardiac magnetic resonance (CMR),
poses significant challenges for missing slice imputation approaches, including
(1) the difficulty of modeling local inter-slice correlations and dependencies
of volumetric slices, and (2) the limited exploration of crucial 3D spatial
information and global context. In this study, to mitigate these issues, we
present Spatial-Aware Graph Completion Network (SAGCNet) to overcome the
dependency on complete volumetric data, featuring two main innovations: (1) a
volumetric slice graph completion module that incorporates the inter-slice
relationships into a graph structure, and (2) a volumetric spatial adapter
component that enables our model to effectively capture and utilize various
forms of 3D spatial context. Extensive experiments on cardiac MRI datasets
demonstrate that SAGCNet is capable of synthesizing absent CMR slices,
outperforming competitive state-of-the-art MRI synthesis methods both
quantitatively and qualitatively. Notably, our model maintains superior
performance even with limited slice data.

</details>


### [228] [Large-scale Multi-sequence Pretraining for Generalizable MRI Analysis in Versatile Clinical Applications](https://arxiv.org/abs/2508.07165)
*Zelin Qiu,Xi Wang,Zhuoyao Xie,Juan Zhou,Yu Wang,Lingjie Yang,Xinrui Jiang,Juyoung Bae,Moo Hyun Son,Qiang Ye,Dexuan Chen,Rui Zhang,Tao Li,Neeraj Ramesh Mahboobani,Varut Vardhanabhuti,Xiaohui Duan,Yinghua Zhao,Hao Chen*

Main category: eess.IV

TL;DR: PRISM是一个基于大规模多序列MRI预训练的基础模型，通过解耦解剖不变特征和序列特异性变化，提升了模型在多样化MRI协议下的泛化能力，在44个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: MRI序列间的异质性限制了深度学习模型的泛化能力和临床实用性，需要一种能够适应多样化采集参数的解决方案。

Method: 利用34个数据集的336,476个MRI扫描构建预训练语料库，提出一种新的预训练范式，解耦解剖不变特征与序列特异性变化。

Result: PRISM在39/44个下游任务中排名第一，显著优于非预训练模型及其他基础模型，展现出对多样化MRI协议的强泛化能力。

Conclusion: PRISM为多序列MRI分析提供了可扩展框架，增强了AI在放射学中的临床转化潜力。

Abstract: Multi-sequence Magnetic Resonance Imaging (MRI) offers remarkable
versatility, enabling the distinct visualization of different tissue types.
Nevertheless, the inherent heterogeneity among MRI sequences poses significant
challenges to the generalization capability of deep learning models. These
challenges undermine model performance when faced with varying acquisition
parameters, thereby severely restricting their clinical utility. In this study,
we present PRISM, a foundation model PRe-trained with large-scale
multI-Sequence MRI. We collected a total of 64 datasets from both public and
private sources, encompassing a wide range of whole-body anatomical structures,
with scans spanning diverse MRI sequences. Among them, 336,476 volumetric MRI
scans from 34 datasets (8 public and 26 private) were curated to construct the
largest multi-organ multi-sequence MRI pretraining corpus to date. We propose a
novel pretraining paradigm that disentangles anatomically invariant features
from sequence-specific variations in MRI, while preserving high-level semantic
representations. We established a benchmark comprising 44 downstream tasks,
including disease diagnosis, image segmentation, registration, progression
prediction, and report generation. These tasks were evaluated on 32 public
datasets and 5 private cohorts. PRISM consistently outperformed both
non-pretrained models and existing foundation models, achieving first-rank
results in 39 out of 44 downstream benchmarks with statistical significance
improvements. These results underscore its ability to learn robust and
generalizable representations across unseen data acquired under diverse MRI
protocols. PRISM provides a scalable framework for multi-sequence MRI analysis,
thereby enhancing the translational potential of AI in radiology. It delivers
consistent performance across diverse imaging protocols, reinforcing its
clinical applicability.

</details>


### [229] [HaDM-ST: Histology-Assisted Differential Modeling for Spatial Transcriptomics Generation](https://arxiv.org/abs/2508.07225)
*Xuepeng Liu,Zheng Jiang,Pinan Zhu,Hanyu Liu,Chao Li*

Main category: eess.IV

TL;DR: HaDM-ST是一种基于H&E图像和低分辨率空间转录组学(ST)的高分辨率ST生成框架，解决了当前方法在特征提取、多模态对齐和基因特异性建模上的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前的空间转录组学方法在分辨率上受限于平台，且虽然已有方法利用H&E染色病理学增强分辨率，但仍面临提取表达相关特征、精确多模态对齐和基因特异性建模的挑战。

Method: HaDM-ST框架包含三个模块：(i)语义蒸馏网络从H&E中提取预测线索，(ii)空间对齐模块确保与低分辨率ST的像素级对应，(iii)通道感知对抗学习器用于细粒度基因级建模。

Result: 实验显示，HaDM-ST在200个基因的多样组织和物种中表现优于现有方法，提高了高分辨率ST预测的空间保真度和基因级一致性。

Conclusion: HaDM-ST通过结合H&E图像和低分辨率ST，有效提升了空间转录组学的高分辨率预测能力。

Abstract: Spatial transcriptomics (ST) reveals spatial heterogeneity of gene
expression, yet its resolution is limited by current platforms. Recent methods
enhance resolution via H&E-stained histology, but three major challenges
persist: (1) isolating expression-relevant features from visually complex H&E
images; (2) achieving spatially precise multimodal alignment in diffusion-based
frameworks; and (3) modeling gene-specific variation across expression
channels. We propose HaDM-ST (Histology-assisted Differential Modeling for ST
Generation), a high-resolution ST generation framework conditioned on H&E
images and low-resolution ST. HaDM-ST includes: (i) a semantic distillation
network to extract predictive cues from H&E; (ii) a spatial alignment module
enforcing pixel-wise correspondence with low-resolution ST; and (iii) a
channel-aware adversarial learner for fine-grained gene-level modeling.
Experiments on 200 genes across diverse tissues and species show HaDM-ST
consistently outperforms prior methods, enhancing spatial fidelity and
gene-level coherence in high-resolution ST predictions.

</details>


### [230] [DiffVC-OSD: One-Step Diffusion-based Perceptual Neural Video Compression Framework](https://arxiv.org/abs/2508.07682)
*Wenzhuo Ma,Zhenzhong Chen*

Main category: eess.IV

TL;DR: 提出DiffVC-OSD，一种基于一步扩散的感知神经视频压缩框架，通过单步扩散提升感知质量，显著加速解码并降低比特率。


<details>
  <summary>Details</summary>
Motivation: 传统多步扩散方法复杂度高，DiffVC-OSD旨在通过单步扩散降低计算成本，同时提升视频压缩的感知质量。

Method: 设计一步扩散模型直接处理重建潜在表示，引入时域上下文适配器优化去噪过程，并通过端到端微调提升性能。

Result: 实验表明，DiffVC-OSD在感知压缩性能上达到最优，解码速度提升约20倍，比特率降低86.92%。

Conclusion: DiffVC-OSD证明了单步扩散在视频压缩中的高效性，为感知优化提供了新思路。

Abstract: In this work, we first propose DiffVC-OSD, a One-Step Diffusion-based
Perceptual Neural Video Compression framework. Unlike conventional multi-step
diffusion-based methods, DiffVC-OSD feeds the reconstructed latent
representation directly into a One-Step Diffusion Model, enhancing perceptual
quality through a single diffusion step guided by both temporal context and the
latent itself. To better leverage temporal dependencies, we design a Temporal
Context Adapter that encodes conditional inputs into multi-level features,
offering more fine-grained guidance for the Denoising Unet. Additionally, we
employ an End-to-End Finetuning strategy to improve overall compression
performance. Extensive experiments demonstrate that DiffVC-OSD achieves
state-of-the-art perceptual compression performance, offers about 20$\times$
faster decoding and a 86.92\% bitrate reduction compared to the corresponding
multi-step diffusion-based variant.

</details>


### [231] [Towards Human-AI Collaboration System for the Detection of Invasive Ductal Carcinoma in Histopathology Images](https://arxiv.org/abs/2508.07875)
*Shuo Han,Ahmed Karam Eldaly,Solomon Sunday Oyelere*

Main category: eess.IV

TL;DR: 提出了一种人机交互的深度学习系统，结合EfficientNetV2S模型与专家反馈，用于提高浸润性导管癌诊断的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 浸润性导管癌（IDC）是乳腺癌的主要类型，早期准确诊断对治疗决策至关重要。AI与医学专家结合有望提升诊断精度。

Method: 采用人类参与的深度学习系统，先由EfficientNetV2S模型提供初步诊断，专家修正误分类图像，并通过反馈循环优化模型。

Result: EfficientNetV2S模型准确率达93.65%，融合人类反馈后进一步提升了模型性能。

Conclusion: 人机协作方法显著提升了AI诊断系统的性能，为未来医疗AI应用提供了新方向。

Abstract: Invasive ductal carcinoma (IDC) is the most prevalent form of breast cancer,
and early, accurate diagnosis is critical to improving patient survival rates
by guiding treatment decisions. Combining medical expertise with artificial
intelligence (AI) holds significant promise for enhancing the precision and
efficiency of IDC detection. In this work, we propose a human-in-the-loop
(HITL) deep learning system designed to detect IDC in histopathology images.
The system begins with an initial diagnosis provided by a high-performance
EfficientNetV2S model, offering feedback from AI to the human expert. Medical
professionals then review the AI-generated results, correct any misclassified
images, and integrate the revised labels into the training dataset, forming a
feedback loop from the human back to the AI. This iterative process refines the
model's performance over time. The EfficientNetV2S model itself achieves
state-of-the-art performance compared to existing methods in the literature,
with an overall accuracy of 93.65\%. Incorporating the human-in-the-loop system
further improves the model's accuracy using four experimental groups with
misclassified images. These results demonstrate the potential of this
collaborative approach to enhance AI performance in diagnostic systems. This
work contributes to advancing automated, efficient, and highly accurate methods
for IDC detection through human-AI collaboration, offering a promising
direction for future AI-assisted medical diagnostics.

</details>


### [232] [Anatomy-Aware Low-Dose CT Denoising via Pretrained Vision Models and Semantic-Guided Contrastive Learning](https://arxiv.org/abs/2508.07788)
*Runze Wang,Zeli Chen,Zhiyun Song,Wei Fang,Jiajin Zhang,Danyang Tu,Yuxing Tang,Minfeng Xu,Xianghua Ye,Le Lu,Dakai Jin*

Main category: eess.IV

TL;DR: ALDEN是一种结合解剖学语义和深度学习的方法，通过对抗和对比学习优化低剂量CT去噪，显著提升图像质量并减少过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 现有低剂量CT去噪方法忽略解剖学语义，导致去噪效果不佳。ALDEN旨在通过引入解剖学感知提升去噪质量。

Method: ALDEN结合预训练视觉模型的语义特征，采用解剖学感知判别器和语义引导的对比学习模块，实现组织特异性去噪。

Result: 实验表明ALDEN在去噪和保留解剖结构方面表现最佳，并在下游多器官分割任务中验证其解剖学感知能力。

Conclusion: ALDEN通过整合解剖学语义和深度学习，显著提升了低剂量CT的图像质量，具有实际应用价值。

Abstract: To reduce radiation exposure and improve the diagnostic efficacy of low-dose
computed tomography (LDCT), numerous deep learning-based denoising methods have
been developed to mitigate noise and artifacts. However, most of these
approaches ignore the anatomical semantics of human tissues, which may
potentially result in suboptimal denoising outcomes. To address this problem,
we propose ALDEN, an anatomy-aware LDCT denoising method that integrates
semantic features of pretrained vision models (PVMs) with adversarial and
contrastive learning. Specifically, we introduce an anatomy-aware discriminator
that dynamically fuses hierarchical semantic features from reference
normal-dose CT (NDCT) via cross-attention mechanisms, enabling tissue-specific
realism evaluation in the discriminator. In addition, we propose a
semantic-guided contrastive learning module that enforces anatomical
consistency by contrasting PVM-derived features from LDCT, denoised CT and
NDCT, preserving tissue-specific patterns through positive pairs and
suppressing artifacts via dual negative pairs. Extensive experiments conducted
on two LDCT denoising datasets reveal that ALDEN achieves the state-of-the-art
performance, offering superior anatomy preservation and substantially reducing
over-smoothing issue of previous work. Further validation on a downstream
multi-organ segmentation task (encompassing 117 anatomical structures) affirms
the model's ability to maintain anatomical awareness.

</details>


### [233] [Diffusing the Blind Spot: Uterine MRI Synthesis with Diffusion Models](https://arxiv.org/abs/2508.07903)
*Johanna P. Müller,Anika Knupfer,Pedro Blöss,Edoardo Berardi Vittur,Bernhard Kainz,Jana Hutter*

Main category: eess.IV

TL;DR: 提出了一种基于扩散模型的框架，用于生成女性盆腔MRI图像，解决了数据稀缺和隐私问题，并验证了其临床价值。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在生成解剖学精确的女性盆腔图像方面存在困难，限制了其在妇科影像中的应用。为了解决数据稀缺和隐私问题，作者提出了一种新方法。

Method: 结合了无条件和有条件DDPMs及LDMs的扩散框架，生成2D和3D的子宫MRI合成图像。

Result: 生成的图像具有解剖学一致性和高保真度，显著提升了分类任务的诊断准确性，并通过专家评估验证了临床真实性。

Conclusion: 该方法为妇科影像提供了高质量的合成数据，支持可重复性研究和公平AI的发展。

Abstract: Despite significant progress in generative modelling, existing diffusion
models often struggle to produce anatomically precise female pelvic images,
limiting their application in gynaecological imaging, where data scarcity and
patient privacy concerns are critical. To overcome these barriers, we introduce
a novel diffusion-based framework for uterine MRI synthesis, integrating both
unconditional and conditioned Denoising Diffusion Probabilistic Models (DDPMs)
and Latent Diffusion Models (LDMs) in 2D and 3D. Our approach generates
anatomically coherent, high fidelity synthetic images that closely mimic real
scans and provide valuable resources for training robust diagnostic models. We
evaluate generative quality using advanced perceptual and distributional
metrics, benchmarking against standard reconstruction methods, and demonstrate
substantial gains in diagnostic accuracy on a key classification task. A
blinded expert evaluation further validates the clinical realism of our
synthetic images. We release our models with privacy safeguards and a
comprehensive synthetic uterine MRI dataset to support reproducible research
and advance equitable AI in gynaecology.

</details>


### [234] [A Physics-Driven Neural Network with Parameter Embedding for Generating Quantitative MR Maps from Weighted Images](https://arxiv.org/abs/2508.08123)
*Lingjing Chen,Chengxiu Zhang,Yinqiao Yi,Yida Wang,Yang Song,Xu Yan,Shengfang Xu,Dalin Zhu,Mengqiu Cao,Yan Zhou,Chenglong Wang,Guang Yang*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的MRI图像合成方法，通过嵌入MRI序列参数提升定量图像合成的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提高临床加权MRI的定量图像合成精度和泛化性，使其适用于不同MRI设备和解剖结构。

Method: 使用物理驱动的神经网络，嵌入MRI序列参数（TR、TE、TI），以传统T1加权、T2加权和T2-FLAIR图像为输入，生成T1、T2和质子密度（PD）定量图。

Result: 模型在内外测试数据集上表现优异，PSNR超过34 dB，SSIM高于0.92，且在未见过的脑结构和病灶区域表现出色。

Conclusion: 该方法通过参数嵌入增强MRI信号物理特性学习，显著提升定量MRI合成的性能和可靠性，具有加速qMRI和提高临床实用性的潜力。

Abstract: We propose a deep learning-based approach that integrates MRI sequence
parameters to improve the accuracy and generalizability of quantitative image
synthesis from clinical weighted MRI. Our physics-driven neural network embeds
MRI sequence parameters -- repetition time (TR), echo time (TE), and inversion
time (TI) -- directly into the model via parameter embedding, enabling the
network to learn the underlying physical principles of MRI signal formation.
The model takes conventional T1-weighted, T2-weighted, and T2-FLAIR images as
input and synthesizes T1, T2, and proton density (PD) quantitative maps.
Trained on healthy brain MR images, it was evaluated on both internal and
external test datasets. The proposed method achieved high performance with PSNR
values exceeding 34 dB and SSIM values above 0.92 for all synthesized parameter
maps. It outperformed conventional deep learning models in accuracy and
robustness, including data with previously unseen brain structures and lesions.
Notably, our model accurately synthesized quantitative maps for these unseen
pathological regions, highlighting its superior generalization capability.
Incorporating MRI sequence parameters via parameter embedding allows the neural
network to better learn the physical characteristics of MR signals,
significantly enhancing the performance and reliability of quantitative MRI
synthesis. This method shows great potential for accelerating qMRI and
improving its clinical utility.

</details>


### [235] [RedDino: A foundation model for red blood cell analysis](https://arxiv.org/abs/2508.08180)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto,Carsten Marr*

Main category: eess.IV

TL;DR: RedDino是一个专为红细胞（RBC）图像分析设计的自监督基础模型，通过改进的DINOv2框架训练，在1.25百万张RBC图像上表现出色，优于现有先进模型。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学诊断中表现出潜力，但RBC分析的全面AI解决方案仍不足。RedDino旨在解决这一缺口。

Method: RedDino采用了DINOv2的自监督学习框架，并针对RBC分析进行了优化，使用了来自多种获取方式的1.25百万张RBC图像训练。

Result: RedDino在RBC形状分类中优于现有模型，通过线性探测和最近邻分类验证了其强大的特征表示和泛化能力。

Conclusion: RedDino通过捕捉细微的形态特征，推动了可靠诊断工具的发展，解决了计算血液学中的关键挑战。

Abstract: Red blood cells (RBCs) are essential to human health, and their precise
morphological analysis is important for diagnosing hematological disorders.
Despite the promise of foundation models in medical diagnostics, comprehensive
AI solutions for RBC analysis remain scarce. We present RedDino, a
self-supervised foundation model designed for RBC image analysis. RedDino uses
an RBC-specific adaptation of the DINOv2 self-supervised learning framework and
is trained on a curated dataset of 1.25 million RBC images from diverse
acquisition modalities and sources. Extensive evaluations show that RedDino
outperforms existing state-of-the-art models on RBC shape classification.
Through assessments including linear probing and nearest neighbor
classification, we confirm its strong feature representations and
generalization ability. Our main contributions are: (1) a foundation model
tailored for RBC analysis, (2) ablation studies exploring DINOv2 configurations
for RBC modeling, and (3) a detailed evaluation of generalization performance.
RedDino addresses key challenges in computational hematology by capturing
nuanced morphological features, advancing the development of reliable
diagnostic tools. The source code and pretrained models for RedDino are
available at https://github.com/Snarci/RedDino, and the pretrained models can
be downloaded from our Hugging Face collection at
https://huggingface.co/collections/Snarcy/reddino-689a13e29241d2e5690202fc

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [236] [Narrative Memory in Machines: Multi-Agent Arc Extraction in Serialized TV](https://arxiv.org/abs/2508.07010)
*Roberto Balestri,Guglielmo Pescatore*

Main category: cs.MM

TL;DR: 该论文提出了一种多代理系统（MAS），通过计算记忆架构分析电视剧的复杂叙事弧，结合人机协作提升叙事理解。


<details>
  <summary>Details</summary>
Motivation: 解决电视连续剧因时间分布复杂而难以分析的问题，探索计算记忆架构在叙事分析中的应用。

Method: 利用多代理系统模拟人类记忆过程，包括语义记忆（LLM）和情景记忆（向量数据库），并开发图形界面供人工干预。

Result: 系统成功识别了三种叙事弧类型，但在重叠弧和不透明动态分析上存在局限性，依赖文本副文本（如剧集摘要）。

Conclusion: 该方法展示了AI记忆处理与人类专业知识结合的潜力，为进一步研究多模态输入和记忆整合机制提供了方向。

Abstract: Serialized television narratives present significant analytical challenges
due to their complex, temporally distributed storylines that necessitate
sophisticated information management. This paper introduces a multi-agent
system (MAS) designed to extract and analyze narrative arcs by implementing
principles of computational memory architectures. The system conceptualizes
narrative understanding through analogues of human memory: Large Language
Models (LLMs) provide a form of semantic memory for general narrative patterns,
while a vector database stores specific arc progressions as episodic memories.
A multi-agent workflow simulates working memory processes to integrate these
information types. Tested on the first season of Grey's Anatomy (ABC 2005-),
the MAS identifies three arc types: Anthology (self-contained), Soap
(relationship-focused), and Genre-Specific. These arcs and their episodic
developments are stored in a vector database, facilitating structured analysis
and semantic comparison. To bridge automation with critical interpretation, a
graphical interface enables human oversight and refinement of the system's
narrative memory. While demonstrating strong performance in identifying
Anthology Arcs and character entities, the system's reliance on textual
paratexts (episode summaries) revealed limitations in discerning overlapping
arcs and opaque dynamics, underscoring the challenges in computational memory
consolidation versus human holistic understanding. This memory-centric approach
highlights the potential of combining AI-driven memory processing with human
expertise. Beyond television, it offers promise for serialized written formats
where narrative is entirely text-based. Future work will focus on integrating
multimodal inputs to enrich episodic memory, refining memory integration
mechanisms within the MAS, and expanding testing across diverse genres.

</details>


### [237] [Reversible Video Steganography Using Quick Response Codes and Modified ElGamal Cryptosystem](https://arxiv.org/abs/2508.07289)
*Ramadhan J. Mstafa*

Main category: cs.MM

TL;DR: 本文提出了一种基于DWT和QR码的可逆视频隐写方案，结合改进的ElGamal加密系统，提高了安全性和视觉不可察觉性。


<details>
  <summary>Details</summary>
Motivation: 多媒体信息传输的快速发展引发了隐私和数据安全问题，需要更高效的视频隐写技术来保护机密信息。

Method: 采用改进的ElGamal算法加密QR码，并结合二维DWT和LSB技术在视频帧的HL和HH子带中嵌入加密数据。

Result: 该方法在视觉不可察觉性、抗攻击能力（如噪声）和嵌入容量（1 bpp）方面表现出色，PSNR平均值达52.143 dB，SSIM超过0.91。

Conclusion: 所提出的方法在安全性、隐写容量和鲁棒性方面优于现有技术，适用于高安全需求的多媒体数据保护。

Abstract: The rapid transmission of multimedia information has been achieved mainly by
recent advancements in the Internet's speed and information technology. In
spite of this, advancements in technology have resulted in breaches of privacy
and data security. When it comes to protecting private information in today's
Internet era, digital steganography is vital. Many academics are interested in
digital video because it has a great capability for concealing important data.
There have been a vast number of video steganography solutions developed lately
to guard against the theft of confidential data. The visual imperceptibility,
robustness, and embedding capacity of these approaches are all challenges that
must be addressed. In this paper, a novel solution to reversible video
steganography based on DWT and QR codes is proposed to address these concerns.
In order to increase the security level of the suggested method, an enhanced
ElGamal cryptosystem has also been proposed. Prior to the embedding stage, the
suggested method uses the modified ElGamal algorithm to encrypt secret QR
codes. Concurrently, it applies two-dimensional DWT on the Y-component of each
video frame resulting in LL, LH, HL, and HH sub-bands. Then, the encrypted Low
(L), Medium (M), Quantile (Q), and High (H) QR codes are embedded into the HL
sub-band, HH sub-band, U-component, and V-component of video frames,
respectively, using the LSB technique. As a consequence of extensive testing of
the approach, it was shown to be very secure and highly invisible, as well as
highly resistant to attacks from Salt & Pepper, Gaussian, Poisson, and Speckle
noises, which has an average SSIM of more than 0.91. Aside from visual
imperceptibility, the suggested method exceeds current methods in terms of PSNR
average of 52.143 dB, and embedding capacity 1 bpp.

</details>


### [238] [FineBadminton: A Multi-Level Dataset for Fine-Grained Badminton Video Understanding](https://arxiv.org/abs/2508.07554)
*Xusheng He,Wei Liu,Shanshan Ma,Qian Liu,Chenghao Ma,Jianlong Wu*

Main category: cs.MM

TL;DR: 论文介绍了FineBadminton数据集和FBBench基准，用于解决MLLMs在高速度和复杂运动的细粒度分析中的挑战，通过多级语义注释和创新标注流程，结合人类优化，推动了体育智能的研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏丰富且特定领域的注释数据集，MLLMs在精细运动分析中面临挑战。研究旨在通过FineBadminton和FBBench填补这一空白，促进细粒度视频理解。

Method: 提出FineBadminton数据集，采用多级语义注释（基础动作、战术语义和决策评估），并通过MLLM生成建议与人类优化结合的标注流程。FBBench用于评估MLLMs的时空推理和战术理解能力。还提出优化的基线方法。

Result: 当前MLLMs在深度体育视频分析中仍面临挑战，但提出的策略显著提升了性能。

Conclusion: FineBadminton和FBBench为细粒度视频理解提供了关键生态系统，推动了MLLMs在体育智能中的发展。

Abstract: Fine-grained analysis of complex and high-speed sports like badminton
presents a significant challenge for Multimodal Large Language Models (MLLMs),
despite their notable advancements in general video understanding. This
difficulty arises primarily from the scarcity of datasets with sufficiently
rich and domain-specific annotations. To bridge this gap, we introduce
FineBadminton, a novel and large-scale dataset featuring a unique multi-level
semantic annotation hierarchy (Foundational Actions, Tactical Semantics, and
Decision Evaluation) for comprehensive badminton understanding. The
construction of FineBadminton is powered by an innovative annotation pipeline
that synergistically combines MLLM-generated proposals with human refinement.
We also present FBBench, a challenging benchmark derived from FineBadminton, to
rigorously evaluate MLLMs on nuanced spatio-temporal reasoning and tactical
comprehension. Together, FineBadminton and FBBench provide a crucial ecosystem
to catalyze research in fine-grained video understanding and advance the
development of MLLMs in sports intelligence. Furthermore, we propose an
optimized baseline approach incorporating Hit-Centric Keyframe Selection to
focus on pivotal moments and Coordinate-Guided Condensation to distill salient
visual information. The results on FBBench reveal that while current MLLMs
still face significant challenges in deep sports video analysis, our proposed
strategies nonetheless achieve substantial performance gains. The project
homepage is available at https://finebadminton.github.io/FineBadminton/.

</details>


### [239] [MSPT: A Lightweight Face Image Quality Assessment Method with Multi-stage Progressive Training](https://arxiv.org/abs/2508.07590)
*Xiongwei Xiao,Baoying Chen,Jishen Zeng,Jianquan Yang*

Main category: cs.MM

TL;DR: 提出了一种轻量级的人脸质量评估网络（MSPT），通过多阶段渐进训练策略，实现了高性能和高效推理。


<details>
  <summary>Details</summary>
Motivation: 传统的人脸质量评估方法在通用性上受限，而学习型方法虽性能优越但计算和存储成本高，因此需要一种更高效的解决方案。

Method: 采用三阶段渐进训练策略，逐步引入多样化数据样本并提高输入图像分辨率，有效学习复杂质量特征并减少灾难性遗忘。

Result: 在VQualA 2025数据集上获得第二高分，性能与最优方法相当或更好，同时保持推理效率。

Conclusion: MSPT是一种高性能且高效的人脸质量评估方法，适合实际部署。

Abstract: Accurately assessing the perceptual quality of face images is crucial,
especially with the rapid progress in face restoration and generation.
Traditional quality assessment methods often struggle with the unique
characteristics of face images, limiting their generalizability. While
learning-based approaches demonstrate superior performance due to their strong
fitting capabilities, their high complexity typically incurs significant
computational and storage costs, hindering practical deployment. To address
this, we propose a lightweight face quality assessment network with Multi-Stage
Progressive Training (MSPT). Our network employs a three-stage progressive
training strategy that gradually introduces more diverse data samples and
increases input image resolution. This novel approach enables lightweight
networks to achieve high performance by effectively learning complex quality
features while significantly mitigating catastrophic forgetting. Our MSPT
achieved the second highest score on the VQualA 2025 face image quality
assessment benchmark dataset, demonstrating that MSPT achieves comparable or
better performance than state-of-the-art methods while maintaining efficient
inference.

</details>


### [240] [AD-AVSR: Asymmetric Dual-stream Enhancement for Robust Audio-Visual Speech Recognition](https://arxiv.org/abs/2508.07608)
*Junxiao Xue,Xiaozhen Liu,Xuecheng Wu,Xinyi Yin,Danlei Huang,Fei Yu*

Main category: cs.MM

TL;DR: AD-AVSR提出了一种基于双向模态增强的音频-视觉语音识别框架，通过音频双流编码和交叉模态噪声抑制模块，显著提升了噪声环境下的识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有AVSR方法多为单向增强或对称融合，难以捕捉音频-视觉数据的异质性和互补性，尤其是在不对称信息条件下。

Method: 引入音频双流编码策略和两个关键模块（音频感知的视觉细化模块和交叉模态噪声抑制掩码模块），实现双向信息流和闭环增强。

Result: 在LRS2和LRS3数据集上，AD-AVSR在性能和噪声鲁棒性上均优于现有方法。

Conclusion: AD-AVSR框架通过双向模态增强和相关性筛选机制，有效提升了AVSR的识别效果，尤其在噪声环境中表现优异。

Abstract: Audio-visual speech recognition (AVSR) combines audio-visual modalities to
improve speech recognition, especially in noisy environments. However, most
existing methods deploy the unidirectional enhancement or symmetric fusion
manner, which limits their capability to capture heterogeneous and
complementary correlations of audio-visual data-especially under asymmetric
information conditions. To tackle these gaps, we introduce a new AVSR framework
termed AD-AVSR based on bidirectional modality enhancement. Specifically, we
first introduce the audio dual-stream encoding strategy to enrich audio
representations from multiple perspectives and intentionally establish
asymmetry to support subsequent cross-modal interactions. The enhancement
process involves two key components, Audio-aware Visual Refinement Module for
enhanced visual representations under audio guidance, and Cross-modal Noise
Suppression Masking Module which refines audio representations using visual
cues, collaboratively leading to the closed-loop and bidirectional information
flow. To further enhance correlation robustness, we adopt a threshold-based
selection mechanism to filter out irrelevant or weakly correlated audio-visual
pairs. Extensive experimental results on the LRS2 and LRS3 datasets indicate
that our AD-AVSR consistently surpasses SOTA methods in both performance and
noise robustness, highlighting the effectiveness of our model design.

</details>


### [241] [Towards Multimodal Sentiment Analysis via Contrastive Cross-modal Retrieval Augmentation and Hierachical Prompts](https://arxiv.org/abs/2508.07666)
*Xianbing Zhao,Shengzun Yang,Buzhou Tang,Ronghuan Jiang*

Main category: cs.MM

TL;DR: 该论文提出了一种多模态检索增强框架，结合跨样本和样本内的上下文信息来提升多模态情感分析的效果。


<details>
  <summary>Details</summary>
Motivation: 当前跨模态方法主要依赖样本内部的模态级上下文，忽略了跨样本的样本级上下文潜力。

Method: 设计对比跨模态检索模块和两种提示（模态级和样本级），结合两种上下文增强目标模态特征。

Result: 在两个公开数据集上的实验证明了模型的有效性和优越性。

Conclusion: 多模态检索增强框架能同时利用跨样本和样本内上下文，显著提升情感分析性能。

Abstract: Multimodal sentiment analysis is a fundamental problem in the field of
affective computing. Although significant progress has been made in cross-modal
interaction, it remains a challenge due to the insufficient reference context
in cross-modal interactions. Current cross-modal approaches primarily focus on
leveraging modality-level reference context within a individual sample for
cross-modal feature enhancement, neglecting the potential cross-sample
relationships that can serve as sample-level reference context to enhance the
cross-modal features. To address this issue, we propose a novel multimodal
retrieval-augmented framework to simultaneously incorporate inter-sample
modality-level reference context and cross-sample sample-level reference
context to enhance the multimodal features. In particular, we first design a
contrastive cross-modal retrieval module to retrieve semantic similar samples
and enhance target modality. To endow the model to capture both inter-sample
and intra-sample information, we integrate two different types of prompts,
modality-level prompts and sample-level prompts, to generate modality-level and
sample-level reference contexts, respectively. Finally, we design a cross-modal
retrieval-augmented encoder that simultaneously leverages modality-level and
sample-level reference contexts to enhance the target modality. Extensive
experiments demonstrate the effectiveness and superiority of our model on two
publicly available datasets.

</details>


### [242] [Mining the Social Fabric: Unveiling Communities for Fake News Detection in Short Videos](https://arxiv.org/abs/2508.07992)
*Haisong Gong,Bolan Su,Xinrong Zhang,Jing Li,Qiang Liu,Shu Wu,Liang Wang*

Main category: cs.MM

TL;DR: 论文提出了一种名为DugFND的新方法，通过建模上传者社区和事件驱动社区的双重模式，结合异构图和图注意力网络，提升了短视频平台中假新闻检测的性能。


<details>
  <summary>Details</summary>
Motivation: 短视频平台中假新闻的快速传播和多模态特性使得检测难度增加，传统方法忽略了视频、上传者和事件之间的隐含关系。

Method: 使用异构图连接上传者、视频和事件节点，设计时间感知的图注意力网络，并通过重构预训练优化节点表示。

Result: 在公开数据集上的实验表明，DugFND显著提升了假新闻检测的性能。

Conclusion: DugFND通过双重社区建模，为短视频中的假新闻检测提供了有效解决方案。

Abstract: Short video platforms have become a major medium for information sharing, but
their rapid content generation and algorithmic amplification also enable the
widespread dissemination of fake news. Detecting misinformation in short videos
is challenging due to their multi-modal nature and the limited context of
individual videos. While recent methods focus on analyzing content
signals-visual, textual, and audio-they often overlook implicit relationships
among videos, uploaders, and events. To address this gap, we propose DugFND
(Dual-community graph for fake news detection), a novel method that enhances
existing video classifiers by modeling two key community patterns: (1) uploader
communities, where uploaders with shared interests or similar content creation
patterns group together, and (2) event-driven communities, where videos related
to the same or semantically similar public events form localized clusters. We
construct a heterogeneous graph connecting uploader, video, and event nodes,
and design a time-aware heterogeneous graph attention network to enable
effective message passing. A reconstruction-based pretraining phase further
improves node representation learning. DugFND can be applied to any pre-trained
classifier. Experiments on public datasets show that our method achieves
significant performance gains, demonstrating the value of dual-community
modeling for fake news detection in short videos.

</details>


### [243] [VGGSounder: Audio-Visual Evaluations for Foundation Models](https://arxiv.org/abs/2508.08237)
*Daniil Zverev,Thaddäus Wiedemer,Ameya Prabhu,Matthias Bethge,Wieland Brendel,A. Sophia Koepke*

Main category: cs.MM

TL;DR: VGGSounder数据集用于评估音频-视觉分类，但存在标记不全、类别重叠和模态不对齐等问题。作者提出VGGSounder2，一个重新标注的多标签测试集，以更精准评估音频-视觉基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有VGGSounder数据集在评估多模态理解时存在缺陷，导致对模型能力的评估失真，因此需要改进。

Method: 作者重新标注了VGGSounder数据集，扩展为VGGSounder2，增加详细模态标注和多标签支持，并引入新的模态混淆指标。

Result: 新数据集提供了更精确的模态性能分析，并通过混淆指标揭示了模型在多模态输入时的性能下降。

Conclusion: VGGSounder2解决了原数据集的局限性，为音频-视觉基础模型的评估提供了更可靠的基准。

Abstract: The emergence of audio-visual foundation models underscores the importance of
reliably assessing their multi-modal understanding. The VGGSounder dataset is
commonly used as a benchmark for evaluation audio-visual classification.
However, our analysis identifies several limitations of VGGSounder, including
incomplete labelling, partially overlapping classes, and misaligned modalities.
These lead to distorted evaluations of auditory and visual capabilities. To
address these limitations, we introduce VGGSounder, a comprehensively
re-annotated, multi-label test set that extends VGGSound and is specifically
designed to evaluate audio-visual foundation models. VGGSounder features
detailed modality annotations, enabling precise analyses of modality-specific
performance. Furthermore, we reveal model limitations by analysing performance
degradation when adding another input modality with our new modality confusion
metric.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [244] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

TL;DR: 该论文提出了一种新的生存模型理论，将生存视为生物状态空间中的几何属性而非外部标注的目标，引入了自组织生存流形的概念，并通过几何流稳定性和最小曲率来建模生存动态。


<details>
  <summary>Details</summary>
Motivation: 传统生存模型依赖外部标注和固定协变量，忽略了生物状态空间的内在几何特性。本文旨在从几何角度重新定义生存，并探索其在物理定律中的基础。

Method: 提出了自组织生存流形（SOSM）理论，基于低曲率测地流和生存能量泛函，推导了离散和连续的目标公式，并从理论上证明了其收敛性。

Result: 理论证明了在生物条件下生存对齐轨迹的涌现和收敛，将健康、疾病和衰老等视为流形结构的几何相变。

Conclusion: 该理论为无标注的生存建模提供了通用基础，连接了机器学习、生物物理学和生命几何学。

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [245] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

TL;DR: 提出了一种两阶段学习框架，结合无监督异常检测与半监督支持向量机，用于供应链欺诈检测，效果显著且误报率低。


<details>
  <summary>Details</summary>
Motivation: 全球供应链网络复杂且标记数据稀缺，传统方法因类别不平衡和监督有限而效果不佳。

Method: 一阶段使用Isolation Forest无监督检测异常，二阶段采用自训练SVM结合标记和高置信度伪标记样本进行半监督学习。

Result: 在真实供应链数据集上F1-score达0.817，误报率低于3.0%。

Conclusion: 无监督预过滤与半监督细化结合有效，但仍需解决概念漂移问题并与深度学习方法比较。

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [246] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

TL;DR: 提出了一种结合GFlowNet和VGAE的框架，用于生成稀有类别的合成样本，以改善药物相互作用预测中的类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 药物相互作用预测中严重的类别不平衡问题导致模型对稀有但关键的相互作用表现不佳。

Method: 结合生成流网络（GFlowNet）和变分图自编码器（VGAE），生成稀有类别的合成样本以提高模型平衡性。

Result: 改善了预测性能，增强了临床可靠性，并生成了有效的药物相互作用对。

Conclusion: 该方法通过解决类别不平衡问题，显著提升了药物相互作用预测的准确性。

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [247] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: 提出了一种新型超图神经网络HGMN，通过集成角色感知表示和状态空间模型，解决了传统GNN忽略角色特征的问题，并在节点分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统GNN主要关注节点间的邻接关系，忽视了角色特征的重要性，导致表达性不足。现有方法多为无监督，无法在下游任务中取得最优性能。

Method: HGMN结合超图构建技术（基于节点度和邻域层级）和可学习的mamba transformer机制，融合角色与邻接信息，并引入残差网络防止过平滑。

Result: 新数据集和四个基准数据集上的实验表明，HGMN在节点分类任务中显著优于现有GNN方法。

Conclusion: HGMN通过高效嵌入角色特征与邻接信息，丰富了节点表示，成为图学习中的多功能强大工具。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [248] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

TL;DR: VQ在图形数据中易出现码本崩塌问题，论文提出了RGVQ框架通过软分配和对比正则化来解决。


<details>
  <summary>Details</summary>
Motivation: 探索图形数据中VQ的码本崩塌问题及其原因，并提出解决方案。

Method: 提出RGVQ框架，结合软分配和结构感知对比正则化，提升码本利用率。

Result: RGVQ显著提高了码本利用率并提升了下游任务的性能。

Conclusion: RGVQ能有效提升图形VQ的表达能力和泛化性。

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [249] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

TL;DR: 提出一种针对神经影像CAD系统的联邦学习框架，通过动态导航模块和元集成模块，显著提升诊断准确性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 解决小样本研究低重现性和大规模数据中疾病亚型混杂的问题。

Method: 提出动态导航模块和元集成模块的联邦学习框架。

Result: 在多站点fMRI数据上实现74.06%的平均准确率，显著优于传统方法。

Conclusion: 该框架能有效处理数据异质性，提升神经影像CAD系统的可靠性和重现性。

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [250] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 论文提出了一种结合生成式AI和多学科文献的新框架，用于设计生物启发材料，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在跨学科实验科学（如材料科学）中的应用潜力，解决传统方法难以处理的复杂问题。

Method: 采用BioinspiredLLM、RAG、代理系统和分层采样策略，从多学科文献中提取结构-性能关系，生成实验方案。

Result: 成功设计并测试了一种新型花粉基粘合剂，验证了AI辅助设计的可行性。

Conclusion: AI辅助创新可推动实际材料设计，并促进人机协作。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [251] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 通过过滤训练数据中的双用途主题文本，研究提出了一种抵抗篡改攻击的预训练数据筛选方法，显著提升了模型的抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 开放权重的AI系统易受篡改攻击，现有安全微调方法效果有限，需要更健壮的风险管理手段。

Method: 引入多阶段数据筛选管道，预训练6.9B参数模型，并测试其对生物威胁相关文本的抗攻击能力。

Result: 筛选后的模型在10,000步对抗微调中表现出显著抗性，性能优于现有方法，且不影响其他能力。

Conclusion: 预训练数据筛选是开放权重AI系统的有效防御层，但仍需结合深度防御策略。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [252] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

TL;DR: 扩散模型在生成复杂数据分布方面表现出色，但传统方法忽略数据的空间局部结构，计算成本高。本文提出数据分布相的概念，提出局部降噪器以降低计算成本，并通过实验验证其效果。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在计算全局评分函数时效率低下，且忽视数据的空间局部结构。本文旨在通过引入数据分布相的概念，优化模型结构，提高计算效率。

Method: 提出数据分布相的定义，即通过局部操作互连的数据分布属于同一相。利用局部降噪器在数据相中工作，全局网络仅在相变时使用，降低计算成本。

Result: 实验证明，局部降噪器在数据相中有效，全局网络仅在相变时必需。信息理论边界和数值实验验证了这一方法的可行性。

Conclusion: 本文提出了一种更高效的扩散模型架构，利用局部降噪器降低计算成本，同时开辟了研究数据分布相的新方向，为生成式AI的设计提供新思路。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [253] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

TL;DR: 论文提出了一种适用于密集和稀疏大型语言模型的通用扩展定律，以统一现有架构特定的扩展定律。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的规模和训练成本急剧增长，需要提高训练效率，但现有扩展定律多为架构特定，缺乏统一框架。

Method: 重新审视现有扩展定律，提出一种通用扩展定律，适用于密集和稀疏模型，并通过评估与比较验证其有效性。

Result: 提出的通用扩展定律在密集和稀疏模型中均表现出有效性。

Conclusion: 通用扩展定律为不同架构的语言模型提供了一个统一的效率优化框架。

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [254] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

TL;DR: ANTIDOTE是一种新的目标函数，用于在噪声标签下学习，通过信息差异邻域的松弛定义，并通过对抗训练实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据中固有或人为引入的标签噪声问题，提高模型在噪声环境下的鲁棒性。

Method: 利用凸对偶性将目标函数重新表述为类似交叉熵的对抗训练方法，降低噪声标签样本的影响。

Result: 在不同类型的噪声（对称、非对称、人工标注和真实噪声）下，ANTIDOTE表现优于同类方法，且计算效率接近交叉熵损失。

Conclusion: ANTIDOTE在噪声标签学习场景中表现出高效性和适应性，是一种实用的解决方案。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [255] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

TL;DR: 提出了一种多模态方法，结合电子健康记录中的诊断代码和实验室数据，用于早期检测胰腺导管腺癌（PDAC），相比现有方法AUC提升了6.5%到15.5%，并识别了相关生物标志物。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌（PDAC）死亡率高且早期检测困难，目前缺乏特异性症状和可靠的生物标志物，因此需要一种更有效的方法来提前预测疾病。

Method: 结合纵向诊断代码历史和实验室数据，使用神经控制微分方程建模不规则实验室时间序列，预训练语言模型和循环网络学习诊断代码轨迹表示，并通过交叉注意力机制捕捉两种模态的交互作用。

Result: 在近4700名患者的真实数据集中，该方法显著优于现有方法，AUC提升6.5%至15.5%，并识别了与PDAC高风险相关的诊断代码和实验室面板。

Conclusion: 该方法在早期检测PDAC方面具有显著优势，并为生物标志物研究提供了新的见解，代码已开源。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [256] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

TL;DR: 提出了一种基于广义矩方法的估计器，结合合成数据和真实数据，提升计算社会科学中的参数估计效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何结合大语言模型生成的合成数据和真实数据，以在有限数据条件下提供统计有效的结论。

Method: 采用广义矩方法设计了一种无需超参数的估计器，利用合成数据与真实数据之间的矩残差交互作用。

Result: 发现合成数据与真实数据的矩残差交互可以改进目标参数估计，实证验证了该估计器在计算社会科学中的优越性能。

Conclusion: 提出的估计器在有限数据条件下表现优异，为结合合成数据的研究提供了统计可靠的解决方案。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [257] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

TL;DR: 论文提出两种新型自适应阈值框架（SCS和MACS），用于非平稳环境下的时间序列异常检测，显著提升了F1分数。


<details>
  <summary>Details</summary>
Motivation: 针对传统静态阈值在非平稳环境下失效的问题，研究自适应阈值以提高异常检测的鲁棒性和准确性。

Method: 采用基于统计在线学习和分段原理的自适应阈值框架SCS和MACS。

Result: 在晶圆制造数据集上实验显示，F1分数显著优于传统百分位和滚动分位数方法。

Conclusion: 自适应阈值方法能可靠、可解释且及时地检测多种现实世界异常。

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [258] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: 论文探讨了如何通过通用序列映射（USM）解决符号序列的多尺度数值表示问题，解决了迭代过程中的种子偏差，并揭示了USM作为一种高效数值过程的特性。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer语言模型的普及，探索符号序列的多尺度数值表示方法变得尤为重要，USM旨在解决如何保留符号序列上下文信息的问题。

Method: USM结合前向和后向的混沌游戏表示（CGR），通过频域投影（FCGR）实现序列的数值嵌入，并解决了迭代过程中的种子偏差。

Result: 1. 实现了序列身份与数值位置完全一致；2. 发现USM是一种高效的稳态序列嵌入方法，且适用于任意字母表基数。

Conclusion: USM提供了一种高效的符号序列数值表示方法，尤其适用于基因组序列，同时也适用于其他类型的符号序列。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [259] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

TL;DR: 提出了一种名为TabularARGN的神经网络架构，用于生成高质量的表格合成数据，平衡了数据保真度与隐私保护。


<details>
  <summary>Details</summary>
Motivation: 传统匿名化技术在保护隐私方面不足，需要一种既能生成高质量合成数据又能有效保护隐私的方法。

Method: 采用基于离散化的自回归方法，设计TabularARGN神经网络架构，生成高质量且计算高效的合成表格数据。

Result: TabularARGN在统计相似性、机器学习效用和检测鲁棒性方面表现优异，并通过系统性成员推断攻击验证了其隐私-效用平衡的鲁棒性。

Conclusion: TabularARGN是一种高效且隐私保护良好的表格数据生成方法，优于现有技术。

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [260] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: 该论文针对强化学习（RL）泛化能力差的问题，提出了一种名为CORAL的双智能体框架，通过解耦表示学习和控制来提升上下文RL（ICRL）能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习代理在未经参数更新的情况下难以适应新任务和环境，主要是因为其学习到的表示和策略过于依赖训练环境的特定细节。

Method: CORAL框架将ICRL建模为双智能体通信问题，包含一个信息代理（IA）和一个控制代理（CA）。IA预训练为世界模型，生成简洁消息，CA则利用这些消息快速学习新任务。

Result: 实验表明，CORAL能显著提升样本效率，并在未见过的稀疏奖励环境中实现零样本适应。

Conclusion: 学习可转移的通信表示是提升RL泛化能力的有效方法。

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [261] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 该论文提出了一种将KAN集成到GNN中的新方法，提升了节点分类精度，并通过知识融合框架进一步优化了图无关模型的性能。


<details>
  <summary>Details</summary>
Motivation: 针对GNN依赖图连接导致的可扩展性和效率问题，研究KAN在提升表达能力和推理效率方面的潜力。

Method: 将KAN整合到GAT、SGC和APPNP三种GNN架构中，形成KGAT、KSGC和KAPPNP新模型，并采用多教师知识融合框架。

Result: 实验表明，新模型提高了节点分类准确性，知识融合方法显著提升了学生模型的性能。

Conclusion: KAN能有效增强GNN的表达能力，并支持高效的图无关推理。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [262] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 提出了一种针对Kolmogorov-Arnold Networks (KAN)的离散余弦变换激活水印方法DCT-AW，解决了现有水印方法对KAN的适应性问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在社交网络分析等领域的广泛应用，保护模型知识产权的重要性日益突出。KAN因其独特的可学习激活函数具有潜力，但也带来了水印嵌入的新挑战。

Method: 利用KAN的可学习激活函数，设计了一种基于离散余弦变换的激活水印方法DCT-AW，通过扰动激活输出来嵌入水印。

Result: DCT-AW对模型性能影响小，且在对抗微调、剪枝和剪枝后重新训练等攻击时表现出优越的鲁棒性。

Conclusion: DCT-AW是一种适用于KAN的有效水印方法，为解决KAN的水印挑战提供了新思路。

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [263] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

TL;DR: 联邦学习（FL）因客户端数据多样性常导致训练不稳定。作者提出HeteRo-Select框架，通过智能选择客户子集提高性能和稳定性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决FL中因数据异构性导致的训练不稳定问题，提升长期训练效果。

Method: 提出HeteRo-Select框架，结合客户有用性、公平性、更新速度和数据多样性逐步评分，有强正则化的收敛保证。

Result: 在CIFAR-10数据集上，HeteRo-Select的峰值准确率74.75%，最终准确率72.76%，稳定性下降仅1.99%，优于Oort。

Conclusion: HeteRo-Select在理论和实验上均表现优异，适用于实际异构FL问题。

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [264] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

TL;DR: 提出了一种名为CISO的深度学习方法，用于在物种分布模型（SDMs）中融入不完全的物种观察数据，以提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统SDMs主要依赖环境变量而忽略物种间的生物相互作用，CISO旨在解决这一局限，即使数据不完整也能有效利用物种观察信息。

Method: CISO结合深度学习，允许输入可变数量的物种观察数据及环境变量，适应数据的稀疏性和不完整性。

Result: 在植物、鸟类和蝴蝶数据集上验证显示，CISO通过部分生物信息提高了预测性能，并能跨数据集提升效果。

Conclusion: CISO是一种有潜力的生态工具，能够整合不完整生物数据并识别跨分类群的潜在物种相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [265] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

TL;DR: 本文提出了一个鲁棒的Lyapunov框架，用于分析在非凸优化中的Schedule-Free方法，证明了其在仅需L-平滑和下界假设下的收敛性，并提供了多种步长策略下的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 传统的一阶方法依赖于预先已知的步长调度，而Schedule-Free方法则试图消除这一限制，但非凸情况下的分析仍不完善。本文旨在填补这一空白。

Method: 提出Lyapunov框架，结合Polyak--Ruppert平均和动量技术，分析非凸优化中Schedule-Free方法的收敛性。

Result: 证明了多种步长策略下（如常数步长、线性增长步长等）的收敛速率，并通过数值实验验证了结果的准确性。

Conclusion: 本文扩展了Schedule-Free方法的适用范围至非凸优化，并为未来研究非凸最优速率提供了方向。

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [266] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: Fed MobiLLM 是一种高效联邦学习方法，通过轻量级前向传播和服务器辅助的侧调优范式，显著降低了移动设备上的计算和通信开销。


<details>
  <summary>Details</summary>
Motivation: 为了解决异构移动设备上联邦学习大语言模型（LLM）时的计算和内存负担问题，以及同步模型聚合协议的效率瓶颈。

Method: 提出 Fed MobiLLM，采用服务器辅助的联邦侧调优范式，设备仅执行轻量级前向传播并上传中间激活值，服务器训练共享侧网络。此外，引入自适应层间特征对齐方法以处理设备间的模型异构性。

Result: 实验表明，Fed MobiLLM 在保持性能的同时，降低了 95.2% 的计算开销、93.2% 的通信成本，并且收敛速度提高 5.1 倍。

Conclusion: Fed MobiLLM 是一种高效且实用的方法，适用于异构移动设备上的 LLM 适应性问题。

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [267] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

TL;DR: 该论文探讨了数字孪生（DTs）在下一代技术中的关键作用，并提出了一种名为PANAMA的新型算法，用于多智能体路径规划（MAPF），通过异步架构优化数据共享和决策。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自动化系统的规模化，高效的数据共享框架和强大算法变得至关重要。

Method: 提出PANAMA算法，采用中心化训练与分散执行（CTDE）框架和异步演员-学习者架构。

Result: PANAMA在路径规划的准确性、速度和可扩展性上优于现有基准。

Conclusion: PANAMA填补了网络感知决策与多智能体协同之间的鸿沟，推动了数字孪生、无线网络与AI自动化之间的协同发展。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [268] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

TL;DR: Zero-Direction Probing (ZDP) 是一个无需任务标签或输出评估的理论框架，通过变压器激活的零方向检测模型漂移。论文提出了多个理论结果和指标。


<details>
  <summary>Details</summary>
Motivation: 解决模型漂移检测问题，尤其是在没有任务标签或输出评估的情况下，提供理论支持和方法。

Method: 基于变压器激活的零方向，提出了 Variance--Leak 定理、Fisher Null-Conservation 等理论结果，并推导了 Spectral Null-Leakage (SNL) 指标。

Result: 证明了监控层激活的左右零空间及其 Fisher 几何可以提供表征变化的具体、可测试的保证。

Conclusion: ZDP 框架为模型漂移检测提供了理论和实践基础，尤其适用于无标签场景。

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [269] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

TL;DR: 论文提出PROPS框架，实现LLM对齐时保护人类偏好标签的隐私，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 依赖人类反馈的LLM对齐会泄露标注者的个人价值观和偏好，现有隐私保护方法（如DP-SGD）可能过度保护且降低模型性能。

Method: 提出PROPS框架，通过多阶段自对齐，利用前一阶段的私有化模型为后续阶段补充训练数据。

Result: PROPS在相同隐私预算下，胜率比DP-SGD高3倍，比基于随机响应（RR）的方法高2.5倍。

Conclusion: PROPS在隐私和性能间取得平衡，为LLM对齐提供高效且隐私保护的新方法。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [270] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

TL;DR: MA-NTAE是一种新的非线性格塔克自动编码器，通过灵活的逐模编码策略解决高维张量在自监督学习中的问题，表现出优于传统方法的效果。


<details>
  <summary>Details</summary>
Motivation: 高维张量的非线性关系学习难题及现有方法的计算和优化限制。

Method: 提出MA-NTAE，结合非线性格塔克分解和逐模编码策略。

Result: MA-NTAE在压缩和聚类任务中表现优异，尤其对高阶高维张量更有效。

Conclusion: MA-NTAE为高维张量学习提供了一种高效且灵活的解决方案。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [271] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

TL;DR: 提出了一种名为HARDY-MER的新框架，通过动态课程学习策略解决多模态情感识别中缺失模态的问题，显著提升了模型对困难样本的处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能考虑不同样本重建难度的差异，导致模型对困难样本的处理效果不佳。

Method: 设计了多视角硬度评估机制和基于检索的动态课程学习策略，动态调整训练重点。

Result: 在基准数据集上的实验表明，HARDY-MER在缺失模态场景下优于现有方法。

Conclusion: HARDY-MER通过动态调整训练策略，有效提升了模型对困难样本的识别能力。

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [272] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的数据增强方法CFDG，用于解决离线到在线强化学习中生成数据与在线数据分布不一致的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在离线到在线强化学习中生成的离线数据与在线数据分布存在差距，限制了整体性能。

Method: 提出了Classifier-Free Diffusion Generation (CFDG)方法，利用无分类器引导扩散模型提升生成质量，并通过重新加权使生成数据更符合在线数据分布。

Result: 在D4RL基准测试中，CFDG平均提升了15%的性能，优于现有方法。

Conclusion: CFDG是一种通用且高效的方法，可显著提升离线到在线强化学习的性能。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [273] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: 提出了一种开源方法，将大型语言模型（LLM）适配到Q编程语言（金融量化工具），通过预训练、监督微调和强化学习训练模型，性能超越主流模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在冷门编程语言（如Q语言）和私有领域任务中的不足，填补了现有模型在专业领域的空白。

Method: 构建Q语言的Leetcode风格评估数据集，预训练、监督微调和强化学习训练基于Qwen-2.5系列的模型。

Result: 最佳模型在Q基准测试中达到59%的pass@1准确率，超越Claude Opus-4 29.5%，所有模型均优于GPT-4.1。

Conclusion: 方法可广泛适用于其他任务，提供了数据集构建、模型训练以及评估的详细指南。

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [274] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

TL;DR: 检测神经网络中的隐藏行为是一个挑战，研究通过对抗游戏（红队和蓝队）探索这一问题，实验表明基于对抗攻击的方法准确率高，但在LLM中需有提示信息。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决神经网络中隐藏行为的检测问题，尤其是在缺乏先验知识和对抗混淆的情况下。

Method: 采用对抗游戏框架，红队训练两个相似模型（一个干净，一个含隐藏行为），蓝队尝试识别问题模型。实验使用了CNN和多种蓝队策略。

Result: 基于对抗攻击的方法在提示下准确率达100%，其他方法表现不一。LLM审计需提示信息才能有效检测模型偏差。

Conclusion: 研究为设计更好的模型审计提供了支持，开源了审计游戏工具和模型数据。

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [275] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 探讨了在深度强化学习中，稀疏化方法（如GMP和SET）如何缓解多任务强化学习中的可塑性丧失问题，从而提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究多任务强化学习中可塑性丧失的挑战，探索稀疏化方法是否能增强适应性。

Method: 采用逐步幅度剪枝（GMP）和稀疏进化训练（SET），并在多种MTRL架构中验证其效果。

Result: 稀疏化方法有效减少神经元休眠和表示崩溃，显著提升多任务性能。

Conclusion: 稀疏化是提升MTRL系统适应性的有效工具，但其效果取决于具体情境。

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [276] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

TL;DR: 该论文回顾了共形预测在可信AI中的潜力，并讨论了其解决泛化风险和AI治理等问题的能力。


<details>
  <summary>Details</summary>
Motivation: 共形预测作为一种可靠的不确定性量化方法，有助于开发可信AI，这在近年来越来越受到关注。

Method: 论文综述了共形预测的潜力，并通过实验和示例展示了其作为校准预测工具的应用以及在偏识别和缓解方面的作用。

Result: 共形预测不仅具有边缘有效性，还能解决泛化风险和AI治理等问题，为可信AI提供了强大支持。

Conclusion: 共形预测在可信AI中具有广泛的应用前景，尤其是在不确定性量化和偏见管理方面。

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [277] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

TL;DR: QuiZSF是一个轻量级模块化框架，通过结合高效检索与表示学习，利用检索增强生成（RAG）技术提升零样本时间序列预测（ZSF）性能。


<details>
  <summary>Details</summary>
Motivation: 传统模型在数据稀缺场景（如领域迁移或极端条件预测）中表现不佳，而现有时间序列预训练模型（TSPMs）缺乏动态整合外部知识的能力。

Method: 提出QuiZSF框架，包括分层树结构ChronoRAG Base（CRB）用于存储与检索，多粒度序列交互学习器（MSIL）提取特征，以及双分支模型协作器（MCC）对齐知识与非LLM和LLM基模型。

Result: QuiZSF在75%（非LLM基）和87.5%（LLM基）的预测任务中排名第一，且内存和推理效率高。

Conclusion: QuiZSF成功整合RAG与TSPMs，显著提升了ZSF性能，证明动态知识注入的有效性。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [278] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

TL;DR: 论文提出了一种解决医学诊断中类特征偏差和类不平衡问题的方法，通过类间不平等损失和类权重优化来提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 医学诊断模型可能因类特征偏差和类不平衡问题导致性能偏差和泛化能力差，作者旨在同时解决这两个问题。

Method: 提出类间不平等损失以平衡正负类样本的分类损失贡献，并采用类分布鲁棒优化目标来加权表现差的类。

Result: 在合成和真实数据集上，验证了类特征偏差对模型性能的负面影响，所提方法能有效减轻偏差和类不平衡。

Conclusion: 该方法能显著提升模型的泛化能力，为医学诊断提供了更可靠的模型。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [279] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: AMFT是一种新型单阶段算法，通过动态平衡SFT和RL的奖励信号，优化LLM在推理任务中的性能，取得了多项基准测试的最先进结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有两阶段方法（SFT+RL）在微调过程中的灾难性遗忘和探索与模仿之间的次优权衡问题。

Method: 提出AMFT算法，利用元梯度自适应权重控制器动态平衡SFT和RL的奖励信号，并通过策略熵正则化实现稳定性。

Result: 在数学推理、抽象视觉推理和视觉语言导航等基准测试中取得最优性能，并在OOD任务中表现出更强的泛化能力。

Conclusion: AMFT提供了一种更原则性和有效的LLM对齐范式，通过动态平衡奖励信号显著提升了性能。

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [280] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

TL;DR: 论文提出了一种改进的低秩适应方法BoRA，通过块矩阵乘法和引入对角矩阵，在少量额外参数的情况下提高了LoRA的秩和性能。实验证明了其优越性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 低秩适应（LoRA）在大型语言模型中广泛使用，但提高秩通常会显著增加可训练参数数量。本文旨在通过改进LoRA方法，在保持参数效率的同时提升性能。

Method: 提出BoRA，将LoRA权重矩阵分解为块矩阵乘法，并为每个块乘法引入独特的对角矩阵，以增加权重多样性，提高秩。

Result: 实验表明，BoRA在多个数据集和模型中表现优异，仅需少量额外参数即可显著提升性能。

Conclusion: BoRA通过块多样化低秩适应，有效平衡了参数效率和模型性能，为LoRA方法提供了可扩展的改进方案。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [281] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

TL;DR: 该研究通过多任务学习利用遥感数据的多样性提升模型性能，同时保持可解释性，避免了多模态网络的复杂性。


<details>
  <summary>Details</summary>
Motivation: 利用多模态学习网络可以提升模型性能，但其复杂性降低了可解释性。研究探索如何通过多任务学习来内在地解释模型行为。

Method: 使用某些模态作为额外预测目标，与主任务一起进行多任务学习。

Result: 该方法在数据稀缺时无需额外模态数据，性能与多模态基线相当甚至更好，且可通过辅助任务解释主任务预测误差。

Conclusion: 多任务学习方法在保持性能的同时增强了模型的可解释性，适用于多种遥感任务。

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [282] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种基于结构保持降阶有限元模型和条件注意力机制的数字孪生框架，支持实时校准和复杂几何处理。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据稀疏或优化误差下的数值稳定性和守恒性问题，构建支持实时校准和闭环推理的数字孪生。

Method: 利用条件注意力机制和有限元外微积分框架，学习降阶有限元基和非线性守恒律。

Result: 在稀疏数据（25个LES模拟）下实现了复杂几何的准确预测，速度提升3.1×10^8倍。

Conclusion: 该方法为非侵入式数字孪生构建提供了高效且精确的解决方案，适用于多种物理问题。

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [283] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: 论文提出了一种名为“Discovery Learning”（DL）的科学机器学习范式，通过整合主动学习、物理引导学习和零样本学习，显著提高了电池设计的验证效率，无需额外数据标注即可预测新设计寿命，节省大量时间和能源。


<details>
  <summary>Details</summary>
Motivation: 电池研发中验证新设计的传统方法成本高、耗时长，亟需一种高效的方法来加速设计验证过程。

Method: DL结合了主动学习、物理引导学习和零样本学习，利用历史设计数据减少原型制作需求，实现对新设计寿命的快速预测。

Result: DL在123个工业级锂离子电池上测试，仅使用公开的小容量圆柱电池数据集，预测未知设计的平均循环寿命误差为7.2%，节省了98%的时间和95%的能源。

Conclusion: DL展示了一种高效的数据驱动建模方法，有望加速科学发现和工程技术创新。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


### [284] [UniMove: A Unified Model for Multi-city Human Mobility Prediction](https://arxiv.org/abs/2508.06986)
*Chonghua Han,Yuan Yuan,Yukun Liu,Jingtao Ding,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: UniMove是一个多城市人类移动预测的统一模型，通过双塔结构和MoE Transformer块解决空间表示和移动模式异质性问题，实验表明其准确性提升10.2%。


<details>
  <summary>Details</summary>
Motivation: 人类移动预测因随机性、时间间隔不均和城市结构异质性而复杂，现有方法需为每个城市单独训练模型。

Method: 提出轨迹-位置双塔结构，位置塔用于空间编码，轨迹塔用于序列建模；使用MoE Transformer块自适应处理不同移动模式。

Result: 在多城市数据集上，UniMove通过联合训练和数据增强，预测准确性提升超过10.2%。

Conclusion: UniMove展示了统一架构在人类移动预测中的潜力，为实现基础模型迈出关键一步。

Abstract: Human mobility prediction is vital for urban planning, transportation
optimization, and personalized services. However, the inherent randomness,
non-uniform time intervals, and complex patterns of human mobility, compounded
by the heterogeneity introduced by varying city structures, infrastructure, and
population densities, present significant challenges in modeling. Existing
solutions often require training separate models for each city due to distinct
spatial representations and geographic coverage. In this paper, we propose
UniMove, a unified model for multi-city human mobility prediction, addressing
two challenges: (1) constructing universal spatial representations for
effective token sharing across cities, and (2) modeling heterogeneous mobility
patterns from varying city characteristics. We propose a trajectory-location
dual-tower architecture, with a location tower for universal spatial encoding
and a trajectory tower for sequential mobility modeling. We also design MoE
Transformer blocks to adaptively select experts to handle diverse movement
patterns. Extensive experiments across multiple datasets from diverse cities
demonstrate that UniMove truly embodies the essence of a unified model. By
enabling joint training on multi-city data with mutual data enhancement, it
significantly improves mobility prediction accuracy by over 10.2\%. UniMove
represents a key advancement toward realizing a true foundational model with a
unified architecture for human mobility. We release the implementation at
https://github.com/tsinghua-fib-lab/UniMove/.

</details>


### [285] [A Comparative Study of Feature Selection in Tsetlin Machines](https://arxiv.org/abs/2508.06991)
*Vojtech Halenka,Ole-Christoffer Granmo,Lei Jiao,Per-Arne Andersen*

Main category: cs.LG

TL;DR: 该论文提出并评估了多种特征选择（FS）技术用于Tsetlin机器（TM），包括传统筛选和嵌入式方法，以及后解释方法，展示TM内部评分器在性能和可解释性上的竞争力。


<details>
  <summary>Details</summary>
Motivation: Tsetlin机器（TM）缺乏现成的特征重要性评估工具，因此需要开发适合TM的特征选择方法以提高模型的解释性和性能。

Method: 研究采用多种FS技术，包括经典筛选和嵌入式方法、后解释方法（如SHAP和LIME），以及从TM子句权重和Tsetlin自动机状态衍生的新型嵌入式评分器，并在12个数据集上进行了基准测试。

Result: TM内部评分器不仅具有竞争力，还能利用子句的可解释性揭示特征交互模式；简单的TM专用评分器能以较低计算成本实现相似的准确性保留。

Conclusion: 本研究为TM中的特征选择建立了首个全面基准，并为开发专门针对TM的可解释性技术奠定了基础。

Abstract: Feature Selection (FS) is crucial for improving model interpretability,
reducing complexity, and sometimes for enhancing accuracy. The recently
introduced Tsetlin machine (TM) offers interpretable clause-based learning, but
lacks established tools for estimating feature importance. In this paper, we
adapt and evaluate a range of FS techniques for TMs, including classical filter
and embedded methods as well as post-hoc explanation methods originally
developed for neural networks (e.g., SHAP and LIME) and a novel family of
embedded scorers derived from TM clause weights and Tsetlin automaton (TA)
states. We benchmark all methods across 12 datasets, using evaluation
protocols, like Remove and Retrain (ROAR) strategy and Remove and Debias
(ROAD), to assess causal impact. Our results show that TM-internal scorers not
only perform competitively but also exploit the interpretability of clauses to
reveal interacting feature patterns. Simpler TM-specific scorers achieve
similar accuracy retention at a fraction of the computational cost. This study
establishes the first comprehensive baseline for FS in TM and paves the way for
developing specialized TM-specific interpretability techniques.

</details>


### [286] [Conformal Set-based Human-AI Complementarity with Multiple Experts](https://arxiv.org/abs/2508.06997)
*Helbert Paat,Guohao Shen*

Main category: cs.LG

TL;DR: 研究提出一种基于贪心算法的专家子集选择方法，利用共形预测集提升多专家合作下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注单专家与AI的合作，本研究旨在探讨如何从多专家池中选择与实例相关的专家子集以优化分类性能。

Method: 通过共形预测集识别相关专家子集，并引入贪心算法进行子集选择，对比了CIFAR-10H和ImageNet-16H数据集上的真实专家预测。

Result: 模拟实验表明，贪心算法能选出接近最优的专家子集，显著提升多专家合作下的分类性能。

Conclusion: 多专家合作中，实例特定的专家子集选择至关重要，贪心算法在此场景下表现优异。

Abstract: Decision support systems are designed to assist human experts in
classification tasks by providing conformal prediction sets derived from a
pre-trained model. This human-AI collaboration has demonstrated enhanced
classification performance compared to using either the model or the expert
independently. In this study, we focus on the selection of instance-specific
experts from a pool of multiple human experts, contrasting it with existing
research that typically focuses on single-expert scenarios. We characterize the
conditions under which multiple experts can benefit from the conformal sets.
With the insight that only certain experts may be relevant for each instance,
we explore the problem of subset selection and introduce a greedy algorithm
that utilizes conformal sets to identify the subset of expert predictions that
will be used in classifying an instance. This approach is shown to yield better
performance compared to naive methods for human subset selection. Based on real
expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation
study indicates that our proposed greedy algorithm achieves near-optimal
subsets, resulting in improved classification performance among multiple
experts.

</details>


### [287] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

TL;DR: 提出了一种基于时滞交叉相关性的序列预测框架（TLCCSP），通过整合时滞相关序列提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型忽视时滞交叉相关性，而这对捕捉复杂时序关系至关重要。

Method: 使用SSDTW算法捕获时滞相关性，结合对比学习编码器高效近似SSDTW距离。

Result: 实验表明，TLCCSP显著降低MSE，对比学习编码器还大幅减少计算时间。

Conclusion: TLCCSP能高效提升多领域时间序列预测的准确性和实用性。

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [288] [From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving](https://arxiv.org/abs/2508.07029)
*Antonio Guillen-Perez*

Main category: cs.LG

TL;DR: 论文提出了一种结合离线强化学习（CQL）的方法，显著提升了自动驾驶策略的鲁棒性和成功率，比传统的行为克隆（BC）方法表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了解决行为克隆（BC）在闭环执行中错误累积和脆弱性问题，论文探索了离线强化学习的潜力。

Method: 首先开发了一系列BC基线模型，包括基于Transformer的模型，然后应用离线强化学习算法（CQL）改进策略鲁棒性。

Result: CQL方法在1,000个测试场景中，成功率提升了3.2倍，碰撞率降低了7.4倍。

Conclusion: 离线强化学习是从静态专家数据中学习鲁棒、长期驾驶策略的关键。

Abstract: Learning robust driving policies from large-scale, real-world datasets is a
central challenge in autonomous driving, as online data collection is often
unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward
approach to imitation learning, policies trained with BC are notoriously
brittle and suffer from compounding errors in closed-loop execution. This work
presents a comprehensive pipeline and a comparative study to address this
limitation. We first develop a series of increasingly sophisticated BC
baselines, culminating in a Transformer-based model that operates on a
structured, entity-centric state representation. While this model achieves low
imitation loss, we show that it still fails in long-horizon simulations. We
then demonstrate that by applying a state-of-the-art Offline Reinforcement
Learning algorithm, Conservative Q-Learning (CQL), to the same data and
architecture, we can learn a significantly more robust policy. Using a
carefully engineered reward function, the CQL agent learns a conservative value
function that enables it to recover from minor errors and avoid
out-of-distribution states. In a large-scale evaluation on 1,000 unseen
scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a
3.2x higher success rate and a 7.4x lower collision rate than the strongest BC
baseline, proving that an offline RL approach is critical for learning robust,
long-horizon driving policies from static expert data.

</details>


### [289] [A Stage-Aware Mixture of Experts Framework for Neurodegenerative Disease Progression Modelling](https://arxiv.org/abs/2508.07032)
*Tiantian He,Keyue Jiang,An Zhao,Anna Schroder,Elinor Thompson,Sonja Soskic,Frederik Barkhof,Daniel C. Alexander*

Main category: cs.LG

TL;DR: 提出一种新的阶段感知混合专家框架（IGND-MoE），结合不均匀图神经扩散模型和局部神经反应模块，动态建模神经退行性疾病的进展机制。


<details>
  <summary>Details</summary>
Motivation: 神经退行性疾病的进展通常被视为时空扩散过程，但缺乏纵向数据和复杂病理机制的动态变化使得建模困难。

Method: 采用迭代双优化方法估计个体观测时间位置，构建队列级进展轨迹；提出不均匀图神经扩散模型和局部神经反应模块，动态整合不同阶段的机制。

Result: 模型显示图相关过程在早期更显著，而未知物理过程在后期占主导地位，与文献一致。

Conclusion: IGND-MoE提供了动态建模疾病进展的新方法，揭示了阶段特异性病理机制的作用。

Abstract: The long-term progression of neurodegenerative diseases is commonly
conceptualized as a spatiotemporal diffusion process that consists of a graph
diffusion process across the structural brain connectome and a localized
reaction process within brain regions. However, modeling this progression
remains challenging due to 1) the scarcity of longitudinal data obtained
through irregular and infrequent subject visits and 2) the complex interplay of
pathological mechanisms across brain regions and disease stages, where
traditional models assume fixed mechanisms throughout disease progression. To
address these limitations, we propose a novel stage-aware Mixture of Experts
(MoE) framework that explicitly models how different contributing mechanisms
dominate at different disease stages through time-dependent expert
weighting.Data-wise, we utilize an iterative dual optimization method to
properly estimate the temporal position of individual observations,
constructing a co hort-level progression trajectory from irregular snapshots.
Model-wise, we enhance the spatial component with an inhomogeneous graph neural
diffusion model (IGND) that allows diffusivity to vary based on node states and
time, providing more flexible representations of brain networks. We also
introduce a localized neural reaction module to capture complex dynamics beyond
standard processes.The resulting IGND-MoE model dynamically integrates these
components across temporal states, offering a principled way to understand how
stage-specific pathological mechanisms contribute to progression. The
stage-wise weights yield novel clinical insights that align with literature,
suggesting that graph-related processes are more influential at early stages,
while other unknown physical processes become dominant later on.

</details>


### [290] [Differentiable Adaptive Kalman Filtering via Optimal Transport](https://arxiv.org/abs/2508.07037)
*Yangguang He,Wenhao Li,Minzhe Li,Juan Zhang,Xiangfeng Wang,Bo Jin*

Main category: cs.LG

TL;DR: OTAKNet是一种在线解决方案，解决了学习型自适应卡尔曼滤波中的噪声统计漂移问题，通过一步预测测量似然结合最优传输实现无需地面标签的在线适应。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，环境因素（如风力变化或电磁干扰）会导致噪声统计漂移，导致学习型方法性能下降，需要一种在线适应方法。

Method: OTAKNet通过一步预测测量似然建立状态估计与漂移的联系，利用最优传输的几何感知成本和稳定梯度实现完全在线适应。

Result: 在合成和真实NCLT数据集上表现优异，尤其在训练数据有限的情况下优于传统模型和离线学习型方法。

Conclusion: OTAKNet为噪声统计漂移问题提供了高效的在线学习解决方案，无需地面标签或重新训练。

Abstract: Learning-based filtering has demonstrated strong performance in non-linear
dynamical systems, particularly when the statistics of noise are unknown.
However, in real-world deployments, environmental factors, such as changing
wind conditions or electromagnetic interference, can induce unobserved
noise-statistics drift, leading to substantial degradation of learning-based
methods. To address this challenge, we propose OTAKNet, the first online
solution to noise-statistics drift within learning-based adaptive Kalman
filtering. Unlike existing learning-based methods that perform offline
fine-tuning using batch pointwise matching over entire trajectories, OTAKNet
establishes a connection between the state estimate and the drift via one-step
predictive measurement likelihood, and addresses it using optimal transport.
This leverages OT's geometry - aware cost and stable gradients to enable fully
online adaptation without ground truth labels or retraining. We compare OTAKNet
against classical model-based adaptive Kalman filtering and offline
learning-based filtering. The performance is demonstrated on both synthetic and
real-world NCLT datasets, particularly under limited training data.

</details>


### [291] [Membership and Memorization in LLM Knowledge Distillation](https://arxiv.org/abs/2508.07054)
*Ziqi Zhang,Ali Shahin Shamsabadi,Hanxiao Lu,Yifeng Cai,Hamed Haddadi*

Main category: cs.LG

TL;DR: 本研究系统地分析了六种大语言模型知识蒸馏技术中的隐私风险，发现所有方法都存在教师模型向学生模型传递成员和记忆隐私风险，且风险程度因技术不同而异。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）虽然可以降低大语言模型的计算成本，但可能导致学生模型继承教师模型的隐私问题。

Method: 通过指令调优设置，覆盖七大NLP任务、三种教师模型家族（GPT-2、LLAMA-2、OPT）及不同大小的学生模型，研究KD技术中的隐私风险。

Result: 所有KD方法均存在隐私风险，且风险程度和技术组件（如目标函数、训练数据、任务）相关；记忆和成员隐私风险之间存在显著差异。

Conclusion: 需进一步研究以减轻KD中的隐私风险，尤其是在不同模块间风险差异显著的情况下。

Abstract: Recent advances in Knowledge Distillation (KD) aim to mitigate the high
computational demands of Large Language Models (LLMs) by transferring knowledge
from a large ''teacher'' to a smaller ''student'' model. However, students may
inherit the teacher's privacy when the teacher is trained on private data. In
this work, we systematically characterize and investigate membership and
memorization privacy risks inherent in six LLM KD techniques. Using
instruction-tuning settings that span seven NLP tasks, together with three
teacher model families (GPT-2, LLAMA-2, and OPT), and various size student
models, we demonstrate that all existing LLM KD approaches carry membership and
memorization privacy risks from the teacher to its students. However, the
extent of privacy risks varies across different KD techniques. We
systematically analyse how key LLM KD components (KD objective functions,
student training data and NLP tasks) impact such privacy risks. We also
demonstrate a significant disagreement between memorization and membership
privacy risks of LLM KD techniques. Finally, we characterize per-block privacy
risk and demonstrate that the privacy risk varies across different blocks by a
large margin.

</details>


### [292] [Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation](https://arxiv.org/abs/2508.07075)
*Stanley Ngugi*

Main category: cs.LG

TL;DR: 该论文提出了一种“先遗忘后学习”的两阶段策略，结合参数高效的微调技术（IA³），通过电路定位阶段精准编辑大语言模型中的冲突知识，显著提升了新知识的准确率并减少了无关知识的遗忘。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在动态知识更新时存在困难，尤其是当新信息与已有知识冲突时，容易导致对新知识的抗拒以及对无关知识的严重遗忘。

Method: 采用“先遗忘后学习”的两阶段策略，结合Infused Adapter by Inhibiting and Amplifying Inner Activations（IA³）技术，通过电路定位精准定位并修改冲突知识的内部组件。

Result: 实验显示，该方法新知识的准确率达到98.50%，冲突知识的遗忘率为96.00%，且显著缓解了直接微调导致的灾难性遗忘问题（F_control准确率从20%提升至72%）。

Conclusion: 该策略实现了精准、局部且安全的知识管理，为大语言模型的动态知识更新提供了重要进展。

Abstract: Large Language Models (LLMs) struggle with dynamic knowledge updates,
especially when new information conflicts with deeply embedded facts. Such
conflicting factual edits often lead to two critical issues: resistance to
adopting the new fact and severe catastrophic forgetting of unrelated
knowledge. This paper introduces and evaluates a novel "unlearn-then-learn"
strategy for precise knowledge editing in LLMs, leveraging the
parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting
and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach
is powered by an initial circuit localization phase that identifies and targets
the specific internal components responsible for encoding the conflicting fact.
Through a rigorous experimental methodology on
microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically
informed two-stage approach achieves near-perfect accuracy (98.50%) for the
new, modulated fact while simultaneously effectively suppressing the original
conflicting fact (96.00% forget rate). Critically, our strategy exhibits
unprecedented localization (72.00% F_control accuracy), dramatically mitigating
catastrophic forgetting observed in direct fine-tuning approaches (which showed
as low as ~20% F_control accuracy), a direct benefit of our targeted
interpretability-guided intervention. Furthermore, qualitative analysis reveals
a nuanced mechanism of "soft forgetting," where original knowledge is
suppressed from default retrieval but remains latent and conditionally
accessible, enhancing model safety and control. These findings represent a
significant advancement towards precise, localized, and safe knowledge
management in compact LLMs.

</details>


### [293] [Improving Real-Time Concept Drift Detection using a Hybrid Transformer-Autoencoder Framework](https://arxiv.org/abs/2508.07085)
*N Harshit,K Mounvik*

Main category: cs.LG

TL;DR: 本文提出了一种结合Transformer和Autoencoder的混合框架，用于在线检测数据分布变化（概念漂移），并通过Trust Score方法提高了检测的敏感性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 应用机器学习中，概念漂移（数据分布的变化）会显著降低模型性能，而传统检测方法通常是反应性的且对早期检测不敏感。

Method: 研究提出了一种混合框架，结合Transformer和Autoencoder建模复杂时序动态，并开发了Trust Score方法，包括统计和重构漂移指标、预测不确定性、规则违反及分类器误差趋势。

Result: 在航空乘客数据集上，该方法比基准方法更早且更敏感地检测到漂移，并提供了更好的建模效果。

Conclusion: 开发了一个可靠监控概念漂移的鲁棒框架。

Abstract: In applied machine learning, concept drift, which is either gradual or abrupt
changes in data distribution, can significantly reduce model performance.
Typical detection methods,such as statistical tests or reconstruction-based
models,are generally reactive and not very sensitive to early detection. Our
study proposes a hybrid framework consisting of Transformers and Autoencoders
to model complex temporal dynamics and provide online drift detection. We
create a distinct Trust Score methodology, which includes signals on (1)
statistical and reconstruction-based drift metrics, more specifically, PSI,
JSD, Transformer-AE error, (2) prediction uncertainty, (3) rules violations,
and (4) trend of classifier error aligned with the combined metrics defined by
the Trust Score. Using a time sequenced airline passenger data set with
synthetic drift, our proposed model allows for a better detection of drift
using as a whole and at different detection thresholds for both sensitivity and
interpretability compared to baseline methods and provides a strong pipeline
for drift detection in real time for applied machine learning. We evaluated
performance using a time-sequenced airline passenger dataset having the
gradually injected stimulus of drift in expectations,e.g. permuted ticket
prices in later batches, broken into 10 time segments [1].In the data, our
results support that the Transformation-Autoencoder detected drift earlier and
with more sensitivity than the autoencoders commonly used in the literature,
and provided improved modeling over more error rates and logical violations.
Therefore, a robust framework was developed to reliably monitor concept drift.

</details>


### [294] [Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria](https://arxiv.org/abs/2508.07102)
*Yang Cao,Yubin Chen,Zhao Song,Jiahao Zhang*

Main category: cs.LG

TL;DR: 本文介绍了Second-Order MeanFlow，一种通过引入平均加速度扩展MeanFlow的方法，证明了其可行性、表达能力，并提出了高效计算的标准。


<details>
  <summary>Details</summary>
Motivation: 生成建模通过无模拟方法（如MeanFlow）取得显著进展，但需要更高阶的动态模型结合效率。

Method: 引入Second-Order MeanFlow，分析其一致性、电路复杂性，并提出近似注意力的高效计算方法。

Result: 证明了平均加速度的稳定性与表达能力，并提出了高效实现的标准。

Conclusion: Second-Order MeanFlow为高阶流匹配模型奠定了理论基础，结合了丰富动态与实践效率。

Abstract: Generative modelling has seen significant advances through simulation-free
paradigms such as Flow Matching, and in particular, the MeanFlow framework,
which replaces instantaneous velocity fields with average velocities to enable
efficient single-step sampling. In this work, we introduce a theoretical study
on Second-Order MeanFlow, a novel extension that incorporates average
acceleration fields into the MeanFlow objective. We first establish the
feasibility of our approach by proving that the average acceleration satisfies
a generalized consistency condition analogous to first-order MeanFlow, thereby
supporting stable, one-step sampling and tractable loss functions. We then
characterize its expressivity via circuit complexity analysis, showing that
under mild assumptions, the Second-Order MeanFlow sampling process can be
implemented by uniform threshold circuits within the $\mathsf{TC}^0$ class.
Finally, we derive provably efficient criteria for scalable implementation by
leveraging fast approximate attention computations: we prove that attention
operations within the Second-Order MeanFlow architecture can be approximated to
within $1/\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results
lay the theoretical foundation for high-order flow matching models that combine
rich dynamics with practical sampling efficiency.

</details>


### [295] [BrainATCL: Adaptive Temporal Brain Connectivity Learning for Functional Link Prediction and Age Estimation](https://arxiv.org/abs/2508.07106)
*Yiran Huang,Amirhossein Nouranizadeh,Christine Ahrends,Mengjia Xu*

Main category: cs.LG

TL;DR: 提出了一个名为BrainATCL的无监督、非参数框架，用于自适应学习动态fMRI数据中的时间脑连接，结合GINE-Mamba2骨干网络和脑结构信息，提升了功能连接预测和年龄估计的性能。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络在捕捉动态fMRI数据中的长时间依赖关系时表现不佳，因此需要一种能够自适应学习动态脑连接的方法，以更好地理解大脑功能连接的动态性和相关行为或疾病。

Method: 提出了BrainATCL框架，通过动态调整每个时间快照的回溯窗口，结合GINE-Mamba2网络和脑结构信息（如半球身份和子网络成员）来学习空间-时间表示。

Result: 在功能连接预测和年龄估计任务中表现出优异的性能，并具有良好的泛化能力，包括跨会话预测场景。

Conclusion: BrainATCL提供了一种有效的动态脑连接建模方法，能够捕捉有意义的生物拓扑模式，为行为研究和神经精神疾病提供了新的工具。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an imaging technique widely
used to study human brain activity. fMRI signals in areas across the brain
transiently synchronise and desynchronise their activity in a highly structured
manner, even when an individual is at rest. These functional connectivity
dynamics may be related to behaviour and neuropsychiatric disease. To model
these dynamics, temporal brain connectivity representations are essential, as
they reflect evolving interactions between brain regions and provide insight
into transient neural states and network reconfigurations. However,
conventional graph neural networks (GNNs) often struggle to capture long-range
temporal dependencies in dynamic fMRI data. To address this challenge, we
propose BrainATCL, an unsupervised, nonparametric framework for adaptive
temporal brain connectivity learning, enabling functional link prediction and
age estimation. Our method dynamically adjusts the lookback window for each
snapshot based on the rate of newly added edges. Graph sequences are
subsequently encoded using a GINE-Mamba2 backbone to learn spatial-temporal
representations of dynamic functional connectivity in resting-state fMRI data
of 1,000 participants from the Human Connectome Project. To further improve
spatial modeling, we incorporate brain structure and function-informed edge
attributes, i.e., the left/right hemispheric identity and subnetwork membership
of brain regions, enabling the model to capture biologically meaningful
topological patterns. We evaluate our BrainATCL on two tasks: functional link
prediction and age estimation. The experimental results demonstrate superior
performance and strong generalization, including in cross-session prediction
scenarios.

</details>


### [296] [Approaching Maximal Information Extraction in Low-Signal Regimes via Multiple Instance Learning](https://arxiv.org/abs/2508.07114)
*Atakan Azakli,Bernd Stelzer*

Main category: cs.LG

TL;DR: 该论文提出了一种新的机器学习方法，旨在提高假设测试问题中对感兴趣参数的预测精度，并通过多实例学习（MIL）增强模型的判别能力。


<details>
  <summary>Details</summary>
Motivation: 针对现有分类器在极端情况下预测准确率不足的问题，研究如何通过MIL方法提升预测能力并系统性地减少误差。

Method: 采用多实例学习（MIL）方法，并通过数学理论分析其相对于单实例方法的优势，同时研究MIL模型的缩放行为。

Result: 在实际应用中，利用LHC的亚原子粒子碰撞事件数据约束SMEFT的Wilson系数，证明了在某些条件下可以提取数据集中的理论最大Fisher信息。

Conclusion: MIL方法在极端挑战性场景下能显著提升预测能力，并为高能物理等领域的参数估计提供了有效工具。

Abstract: In this work, we propose a new machine learning (ML) methodology to obtain
more precise predictions for some parameters of interest in a given hypotheses
testing problem. Our proposed method also allows ML models to have more
discriminative power in cases where it is extremely challenging for
state-of-the-art classifiers to have any level of accurate predictions. This
method can also allow us to systematically decrease the error from ML models in
their predictions. In this paper, we provide a mathematical motivation why
Multiple Instance Learning (MIL) would have more predictive power over their
single-instance counterparts. We support our theoretical claims by analyzing
the behavior of the MIL models through their scaling behaviors with respect to
the number of instances on which the model makes predictions. As a concrete
application, we constrain Wilson coefficients of the Standard Model Effective
Field Theory (SMEFT) using kinematic information from subatomic particle
collision events at the Large Hadron Collider (LHC). We show that under certain
circumstances, it might be possible to extract the theoretical maximum Fisher
Information latent in a dataset.

</details>


### [297] [From Nodes to Narratives: Explaining Graph Neural Networks with LLMs and Graph Context](https://arxiv.org/abs/2508.07117)
*Peyman Baghershahi,Gregoire Fournier,Pranav Nyati,Sourav Medya*

Main category: cs.LG

TL;DR: LOGIC是一个轻量级框架，利用大语言模型为GNN预测生成解释，提升可解释性和人类理解度。


<details>
  <summary>Details</summary>
Motivation: GNN在结构化数据学习中的强大能力与其缺乏内在可解释性之间的矛盾，尤其是节点属性包含丰富自然语言时。

Method: LOGIC通过将GNN节点嵌入投影到LLM嵌入空间，并构建混合提示（软提示与图结构文本输入交织），使LLM能推理GNN内部表示并生成自然语言解释。

Result: 在四个真实TAG数据集上的实验显示，LOGIC在保真度和稀疏性之间取得平衡，并显著提升人类中心指标（如洞察性）。

Conclusion: LOGIC为基于LLM的图学习可解释性开辟了新方向，通过将GNN内部表示与人类推理对齐。

Abstract: Graph Neural Networks (GNNs) have emerged as powerful tools for learning over
structured data, including text-attributed graphs, which are common in domains
such as citation networks, social platforms, and knowledge graphs. GNNs are not
inherently interpretable and thus, many explanation methods have been proposed.
However, existing explanation methods often struggle to generate interpretable,
fine-grained rationales, especially when node attributes include rich natural
language. In this work, we introduce LOGIC, a lightweight, post-hoc framework
that uses large language models (LLMs) to generate faithful and interpretable
explanations for GNN predictions. LOGIC projects GNN node embeddings into the
LLM embedding space and constructs hybrid prompts that interleave soft prompts
with textual inputs from the graph structure. This enables the LLM to reason
about GNN internal representations and produce natural language explanations
along with concise explanation subgraphs. Our experiments across four
real-world TAG datasets demonstrate that LOGIC achieves a favorable trade-off
between fidelity and sparsity, while significantly improving human-centric
metrics such as insightfulness. LOGIC sets a new direction for LLM-based
explainability in graph learning by aligning GNN internals with human
reasoning.

</details>


### [298] [Multi-Level Service Performance Forecasting via Spatiotemporal Graph Neural Networks](https://arxiv.org/abs/2508.07122)
*Zhihao Xue,Yun Zi,Nia Qi,Ming Gong,Yujun Zou*

Main category: cs.LG

TL;DR: 提出了一种基于时空图神经网络的性能预测算法，用于多级服务调用结构的分布式后端系统的性能波动预测。


<details>
  <summary>Details</summary>
Motivation: 解决分布式后端系统中多级服务调用结构的性能波动预测难题。

Method: 将系统状态抽象为图结构序列，结合运行时特征和调用关系，使用图卷积网络和高门限循环网络进行时空建模。

Result: 在公开数据集上的实验表明，该模型在MAE、RMSE和R2等关键指标上优于现有方法，且在不同负载和结构下表现稳健。

Conclusion: 该模型为后端服务性能管理提供了实用潜力。

Abstract: This paper proposes a spatiotemporal graph neural network-based performance
prediction algorithm to address the challenge of forecasting performance
fluctuations in distributed backend systems with multi-level service call
structures. The method abstracts system states at different time slices into a
sequence of graph structures. It integrates the runtime features of service
nodes with the invocation relationships among services to construct a unified
spatiotemporal modeling framework. The model first applies a graph
convolutional network to extract high-order dependency information from the
service topology. Then it uses a gated recurrent network to capture the dynamic
evolution of performance metrics over time. A time encoding mechanism is also
introduced to enhance the model's ability to represent non-stationary temporal
sequences. The architecture is trained in an end-to-end manner, optimizing the
multi-layer nested structure to achieve high-precision regression of future
service performance metrics. To validate the effectiveness of the proposed
method, a large-scale public cluster dataset is used. A series of
multi-dimensional experiments are designed, including variations in time
windows and concurrent load levels. These experiments comprehensively evaluate
the model's predictive performance and stability. The experimental results show
that the proposed model outperforms existing representative methods across key
metrics such as MAE, RMSE, and R2. It maintains strong robustness under varying
load intensities and structural complexities. These results demonstrate the
model's practical potential for backend service performance management tasks.

</details>


### [299] [Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning](https://arxiv.org/abs/2508.07126)
*Zhengran Ji,Boyuan Chen*

Main category: cs.LG

TL;DR: Pref-GUIDE框架通过将实时标量反馈转化为偏好数据，提升持续强化学习中奖励模型的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在在线强化学习中，任务目标难以通过密集奖励函数明确表达，而现有方法依赖离线轨迹比较或易受标量反馈噪声限制。

Method: Pref-GUIDE将标量反馈转化为偏好数据，通过个体和群体两种方式优化奖励模型：个体法过滤模糊反馈，群体法聚合用户共识。

Result: 在三个复杂环境中，Pref-GUIDE显著优于标量反馈基线，群体投票版本甚至超过专家设计的密集奖励。

Conclusion: Pref-GUIDE通过结构化偏好和群体反馈，为在线强化学习中的人类输入提供了可扩展且原理化的解决方案。

Abstract: Training reinforcement learning agents with human feedback is crucial when
task objectives are difficult to specify through dense reward functions. While
prior methods rely on offline trajectory comparisons to elicit human
preferences, such data is unavailable in online learning scenarios where agents
must adapt on the fly. Recent approaches address this by collecting real-time
scalar feedback to guide agent behavior and train reward models for continued
learning after human feedback becomes unavailable. However, scalar feedback is
often noisy and inconsistent, limiting the accuracy and generalization of
learned rewards. We propose Pref-GUIDE, a framework that transforms real-time
scalar feedback into preference-based data to improve reward model learning for
continual policy training. Pref-GUIDE Individual mitigates temporal
inconsistency by comparing agent behaviors within short windows and filtering
ambiguous feedback. Pref-GUIDE Voting further enhances robustness by
aggregating reward models across a population of users to form consensus
preferences. Across three challenging environments, Pref-GUIDE significantly
outperforms scalar-feedback baselines, with the voting variant exceeding even
expert-designed dense rewards. By reframing scalar feedback as structured
preferences with population feedback, Pref-GUIDE offers a scalable and
principled approach for harnessing human input in online reinforcement
learning.

</details>


### [300] [How Effectively Can Large Language Models Connect SNP Variants and ECG Phenotypes for Cardiovascular Risk Prediction?](https://arxiv.org/abs/2508.07127)
*Niranjana Arun Menon,Iqra Farooq,Yulong Li,Sara Ahmed,Yutong Xie,Muhammad Awais,Imran Razzak*

Main category: cs.LG

TL;DR: 使用微调的大型语言模型（LLMs）预测心血管疾病（CVD）风险和相关SNPs，通过遗传标记数据探索潜在生物学关系，并展示LLMs在早期检测和个性化医疗中的潜力。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病的预测因其多因素病因和高发病率及死亡率而具有挑战性，但基因组数据的高维度和噪声限制了其应用。LLMs在生物学序列中的成功应用为其在CVD预测中提供了新思路。

Method: 通过微调LLMs，利用高吞吐量基因组分析数据，将问题转化为链式思考（CoT）推理任务，预测疾病标签并生成临床推论。

Result: 研究发现LLMs能够从结构化与半结构化基因组数据中学习潜在生物学关系，为CVD的早期检测和风险评估提供了新途径。

Conclusion: LLMs在心血管疾病的预测和个性化医疗中展现出显著潜力，有望推动心脏病管理的进步。

Abstract: Cardiovascular disease (CVD) prediction remains a tremendous challenge due to
its multifactorial etiology and global burden of morbidity and mortality.
Despite the growing availability of genomic and electrophysiological data,
extracting biologically meaningful insights from such high-dimensional, noisy,
and sparsely annotated datasets remains a non-trivial task. Recently, LLMs has
been applied effectively to predict structural variations in biological
sequences. In this work, we explore the potential of fine-tuned LLMs to predict
cardiac diseases and SNPs potentially leading to CVD risk using genetic markers
derived from high-throughput genomic profiling. We investigate the effect of
genetic patterns associated with cardiac conditions and evaluate how LLMs can
learn latent biological relationships from structured and semi-structured
genomic data obtained by mapping genetic aspects that are inherited from the
family tree. By framing the problem as a Chain of Thought (CoT) reasoning task,
the models are prompted to generate disease labels and articulate informed
clinical deductions across diverse patient profiles and phenotypes. The
findings highlight the promise of LLMs in contributing to early detection, risk
assessment, and ultimately, the advancement of personalized medicine in cardiac
care.

</details>


### [301] [A Globally Optimal Analytic Solution for Semi-Nonnegative Matrix Factorization with Nonnegative or Mixed Inputs](https://arxiv.org/abs/2508.07134)
*Lu Chenggang*

Main category: cs.LG

TL;DR: 本文提出了一种新的半非负矩阵分解方法，通过正交分解实现全局最优解，优于现有NMF和semi-NMF方法。


<details>
  <summary>Details</summary>
Motivation: 传统semi-NMF方法存在迭代、非凸和易陷局部最优的问题，本文旨在提供一种全局最优的解决方案。

Method: 利用输入数据的散布矩阵进行正交分解，得到Frobenius范数下的全局最优解。

Result: 实验验证了新方法在合成数据和UCI Wine数据集上重建误差更低，性能优于现有方法。

Conclusion: 新方法不仅理论上有保证，且在实际应用中表现优异，为矩阵分解提供了新视角。

Abstract: Semi-Nonnegative Matrix Factorization (semi-NMF) extends classical
Nonnegative Matrix Factorization (NMF) by allowing the basis matrix to contain
both positive and negative entries, making it suitable for decomposing data
with mixed signs. However, most existing semi-NMF algorithms are iterative,
non-convex, and prone to local minima. In this paper, we propose a novel method
that yields a globally optimal solution to the semi-NMF problem under the
Frobenius norm, through an orthogonal decomposition derived from the scatter
matrix of the input data. We rigorously prove that our solution attains the
global minimum of the reconstruction error. Furthermore, we demonstrate that
when the input matrix is nonnegative, our method often achieves lower
reconstruction error than standard NMF algorithms, although unfortunately the
basis matrix may not satisfy nonnegativity. In particular, in low-rank cases
such as rank 1 or 2, our solution reduces exactly to a nonnegative
factorization, recovering the NMF structure. We validate our approach through
experiments on both synthetic data and the UCI Wine dataset, showing that our
method consistently outperforms existing NMF and semi-NMF methods in terms of
reconstruction accuracy. These results confirm that our globally optimal,
non-iterative formulation offers both theoretical guarantees and empirical
advantages, providing a new perspective on matrix factorization in optimization
and data analysis.

</details>


### [302] [A Stable and Principled Loss Function for Direct Language Model Alignment](https://arxiv.org/abs/2508.07137)
*Yuandong Tan*

Main category: cs.LG

TL;DR: 本文提出了一种新的损失函数，用于改进直接偏好优化（DPO）的理论缺陷，避免训练不稳定和奖励漏洞，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: DPO虽然简化了RLHF范式，但其损失函数与理论推导不一致，可能导致训练不稳定和奖励漏洞，因此需要改进。

Method: 作者提出了一种基于RLHF最优条件的新损失函数，直接瞄准有限的logits差异值，而非最大化。

Result: 实验表明，新方法在Qwen2.5-7B模型上显著优于标准DPO基线，并与Llama-3.1-8B等更大模型竞争。

Conclusion: 新损失函数解决了DPO的理论问题，提升了训练稳定性和对齐效果。

Abstract: The alignment of large language models (LLMs) with human preferences is
commonly achieved through Reinforcement Learning from Human Feedback (RLHF).
Direct Preference Optimization (DPO) simplified this paradigm by establishing a
direct mapping between the optimal policy and a reward function, eliminating
the need for an explicit reward model. However, we argue that the DPO loss
function is theoretically misaligned with its own derivation, as it promotes
the indefinite maximization of a logits difference, which can lead to training
instability and reward hacking. In this paper, we propose a novel loss function
derived directly from the RLHF optimality condition. Our proposed loss targets
a specific, finite value for the logits difference, which is dictated by the
underlying reward, rather than its maximization. We provide a theoretical
analysis, including a gradient-based comparison, to demonstrate that our method
avoids the large gradients that plague DPO when the probability of dispreferred
responses approaches zero. This inherent stability prevents reward hacking and
leads to more effective alignment. We validate our approach by fine-tuning a
Qwen2.5-7B model, showing significant win-rate improvements over a standard DPO
baseline and achieving competitive performance against larger models like
Llama-3.1-8B.

</details>


### [303] [Strategic Incentivization for Locally Differentially Private Federated Learning](https://arxiv.org/abs/2508.07138)
*Yashwant Krishna Pagoti,Arunesh Sinha,Shamik Sural*

Main category: cs.LG

TL;DR: 该论文研究了联邦学习中的隐私与准确性之间的权衡，引入了基于令牌的激励机制来平衡客户端隐私保护与全局模型准确性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，客户端通过共享梯度信息训练模型，但梯度信息可能泄漏隐私。虽然本地差分隐私（LDP）可以保护隐私，但会降低模型准确性。论文旨在解决这一权衡问题。

Method: 将隐私与准确性的权衡建模为博弈，服务器通过令牌机制激励客户端减少噪声添加，客户端则权衡隐私与准确性。博弈分析包括玩家、行动与收益。

Result: 通过实验验证了不同参数对博弈结果的影响，证明了令牌机制在平衡隐私与准确性方面的有效性。

Conclusion: 论文提出的激励机制为联邦学习中的隐私-准确性权衡提供了一种可行的解决方案，并展示了其潜力。

Abstract: In Federated Learning (FL), multiple clients jointly train a machine learning
model by sharing gradient information, instead of raw data, with a server over
multiple rounds. To address the possibility of information leakage in spite of
sharing only the gradients, Local Differential Privacy (LDP) is often used. In
LDP, clients add a selective amount of noise to the gradients before sending
the same to the server. Although such noise addition protects the privacy of
clients, it leads to a degradation in global model accuracy. In this paper, we
model this privacy-accuracy trade-off as a game, where the sever incentivizes
the clients to add a lower degree of noise for achieving higher accuracy, while
the clients attempt to preserve their privacy at the cost of a potential loss
in accuracy. A token based incentivization mechanism is introduced in which the
quantum of tokens credited to a client in an FL round is a function of the
degree of perturbation of its gradients. The client can later access a newly
updated global model only after acquiring enough tokens, which are to be
deducted from its balance. We identify the players, their actions and payoff,
and perform a strategic analysis of the game. Extensive experiments were
carried out to study the impact of different parameters.

</details>


### [304] [SGD Convergence under Stepsize Shrinkage in Low-Precision Training](https://arxiv.org/abs/2508.07142)
*Vincent-Daniel Yun*

Main category: cs.LG

TL;DR: 论文研究了低精度训练中梯度收缩对SGD收敛的影响，发现收缩等效于降低步长，会减慢收敛速度并引入量化噪声导致的误差。


<details>
  <summary>Details</summary>
Motivation: 低精度训练能降低计算和内存成本，但梯度量化的收缩和噪声会影响SGD的收敛行为，需理论分析其影响。

Method: 通过梯度收缩模型，将量化梯度视为缩放和噪声扰动，分析其对SGD收敛的影响。

Result: 证明低精度SGD仍收敛，但收敛速度因收缩因子减慢，且由于噪声存在渐近误差。

Conclusion: 量化梯度通过收缩和噪声影响收敛，理论分析为低精度训练提供了收敛性依据。

Abstract: Low-precision training has become essential for reducing the computational
and memory costs of large-scale deep learning. However, quantization of
gradients introduces both magnitude shrinkage and additive noise, which can
alter the convergence behavior of stochastic gradient descent (SGD). In this
work, we study the convergence of SGD under a gradient shrinkage model, where
each stochastic gradient is scaled by a factor $q_k \in (0,1]$ and perturbed by
zero-mean quantization noise. We show that this shrinkage is equivalent to
replacing the nominal stepsize $\mu_k$ with an effective stepsize $\mu_k q_k$,
which slows convergence when $q_{\min} < 1$. Under standard smoothness and
bounded-variance assumptions, we prove that low-precision SGD still converges,
but at a reduced rate determined by $q_{\min}$, and with an increased
asymptotic error floor due to quantization noise. We theoretically analyze how
reduced numerical precision slows down training by modeling it as gradient
shrinkage in the standard SGD convergence framework.

</details>


### [305] [What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains](https://arxiv.org/abs/2508.07208)
*Chanakya Ekbote,Marco Bondaschi,Nived Rajaraman,Jason D. Lee,Michael Gastpar,Ashok Vardhan Makkuva,Paul Pu Liang*

Main category: cs.LG

TL;DR: 论文研究了双层单头Transformer是否能表示任意k阶马尔可夫过程，并理论证明其可以表示条件k-gram，深化了对Transformer上下文学习能力的理解。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer架构的深度与其上下文学习（ICL）能力的关系，尤其是在表示高阶马尔可夫过程中的表现。

Method: 理论分析双层面单头Transformer的架构能力，通过简化的一阶马尔可夫链变体分析学习动态。

Result: 证明双层面单头Transformer可以表示任意条件k-gram，为Transformer深度与马尔可夫阶数的关系提供了最严格的理论描述。

Conclusion: 浅层Transformer架构在结构化序列建模任务中表现出强大的上下文学习能力，扩展了对ICL机制的理解。

Abstract: In-context learning (ICL) is a hallmark capability of transformers, through
which trained models learn to adapt to new tasks by leveraging information from
the input context. Prior work has shown that ICL emerges in transformers due to
the presence of special circuits called induction heads. Given the equivalence
between induction heads and conditional k-grams, a recent line of work modeling
sequential inputs as Markov processes has revealed the fundamental impact of
model depth on its ICL capabilities: while a two-layer transformer can
efficiently represent a conditional 1-gram model, its single-layer counterpart
cannot solve the task unless it is exponentially large. However, for higher
order Markov sources, the best known constructions require at least three
layers (each with a single attention head) - leaving open the question: can a
two-layer single-head transformer represent any kth-order Markov process? In
this paper, we precisely address this and theoretically show that a two-layer
transformer with one head per layer can indeed represent any conditional
k-gram. Thus, our result provides the tightest known characterization of the
interplay between transformer depth and Markov order for ICL. Building on this,
we further analyze the learning dynamics of our two-layer construction,
focusing on a simplified variant for first-order Markov chains, illustrating
how effective in-context representations emerge during training. Together,
these results deepen our current understanding of transformer-based ICL and
illustrate how even shallow architectures can surprisingly exhibit strong ICL
capabilities on structured sequence modeling tasks.

</details>


### [306] [Neural Bridge Processes](https://arxiv.org/abs/2508.07220)
*Jian Xu,Yican Liu,Qibin Zhao,John Paisley,Delu Zeng*

Main category: cs.LG

TL;DR: 论文提出了一种名为Neural Bridge Processes (NBPs)的新方法，用于建模随机函数。通过将输入x作为扩散轨迹的动态锚点，NBP显著改善了梯度信号和端点一致性，并在多个任务中超越了基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法如高斯过程（GPs）在大规模数据集上存在可扩展性问题，且假设高斯分布限制了其适用性。神经过程（NPs）灵活性更强，但难以捕捉复杂的多模态目标分布。神经扩散过程（NDPs）虽然提升了表达能力，却因输入耦合弱和语义不匹配而表现不佳。因此，需要一种更有效的方法来建模随机函数。

Method: 作者提出了Neural Bridge Processes (NBPs)，将输入x作为扩散轨迹的动态锚点，并重新定义前向核以显式依赖x。这种方法约束了扩散路径，确保其严格终止于监督目标，从而增强梯度信号并保证端点一致性。

Result: 在合成数据、EEG信号回归和图像回归任务上，NBP比基线方法有显著提升，验证了其有效性和理论一致性。

Conclusion: NBP通过结合扩散桥采样技术，在结构化预测任务中表现出更好的性能和理论一致性，为随机函数建模提供了一种新思路。

Abstract: Learning stochastic functions from partially observed context-target pairs is
a fundamental problem in probabilistic modeling. Traditional models like
Gaussian Processes (GPs) face scalability issues with large datasets and assume
Gaussianity, limiting their applicability. While Neural Processes (NPs) offer
more flexibility, they struggle with capturing complex, multi-modal target
distributions. Neural Diffusion Processes (NDPs) enhance expressivity through a
learned diffusion process but rely solely on conditional signals in the
denoising network, resulting in weak input coupling from an unconditional
forward process and semantic mismatch at the diffusion endpoint. In this work,
we propose Neural Bridge Processes (NBPs), a novel method for modeling
stochastic functions where inputs x act as dynamic anchors for the entire
diffusion trajectory. By reformulating the forward kernel to explicitly depend
on x, NBP enforces a constrained path that strictly terminates at the
supervised target. This approach not only provides stronger gradient signals
but also guarantees endpoint coherence. We validate NBPs on synthetic data, EEG
signal regression and image regression tasks, achieving substantial
improvements over baselines. These results underscore the effectiveness of
DDPM-style bridge sampling in enhancing both performance and theoretical
consistency for structured prediction tasks.

</details>


### [307] [LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference](https://arxiv.org/abs/2508.07221)
*Po-Han Lee,Yu-Cheng Lin,Chan-Tung Ku,Chan Hsu,Pei-Cing Huang,Ping-Hsun Wu,Yihuang Kang*

Main category: cs.LG

TL;DR: 论文提出了一种利用大型语言模型（LLM）进行自动混杂因素发现和亚组分析的方法，以解决观察数据中个体化治疗效果估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 观察数据中的个体化治疗效果估计因未测量混杂因素和结构偏差而困难。现有因果机器学习方法因依赖专家且难以处理复杂环境而受限。

Method: 通过LLM模拟领域专家，自动发现混杂因素和进行亚组分析，整合到因果机器学习流程中，减少人工依赖。

Result: 在真实医疗数据集上，该方法增强了治疗效果估计的稳健性，缩小了置信区间并揭示未识别的混杂偏差。

Conclusion: LLM为基础的代理为可扩展、可信且语义感知的因果推断提供了新途径。

Abstract: Estimating individualized treatment effects from observational data presents
a persistent challenge due to unmeasured confounding and structural bias.
Causal Machine Learning (causal ML) methods, such as causal trees and doubly
robust estimators, provide tools for estimating conditional average treatment
effects. These methods have limited effectiveness in complex real-world
environments due to the presence of latent confounders or those described in
unstructured formats. Moreover, reliance on domain experts for confounder
identification and rule interpretation introduces high annotation cost and
scalability concerns. In this work, we proposed Large Language Model-based
agents for automated confounder discovery and subgroup analysis that integrate
agents into the causal ML pipeline to simulate domain expertise. Our framework
systematically performs subgroup identification and confounding structure
discovery by leveraging the reasoning capabilities of LLM-based agents, which
reduces human dependency while preserving interpretability. Experiments on
real-world medical datasets show that our proposed approach enhances treatment
effect estimation robustness by narrowing confidence intervals and uncovering
unrecognized confounding biases. Our findings suggest that LLM-based agents
offer a promising path toward scalable, trustworthy, and semantically aware
causal inference.

</details>


### [308] [EDGE: A Theoretical Framework for Misconception-Aware Adaptive Learning](https://arxiv.org/abs/2508.07224)
*Ananda Prakash Verma*

Main category: cs.LG

TL;DR: EDGE是一个基于误区的自适应学习框架，通过评估、诊断、生成和练习四阶段实现心理测量与认知诊断的结合。


<details>
  <summary>Details</summary>
Motivation: 解决学习者误区问题，通过自适应学习提高学习效果。

Method: 结合心理测量、认知诊断、对比项生成和调度策略。

Result: 提出EdgeScore度量，证明其单调性和连续性，并实现近优调度策略。

Conclusion: EDGE在理论上验证了其有效性，未来需实证研究。

Abstract: We present EDGE, a general-purpose, misconception-aware adaptive learning
framework composed of four stages: Evaluate (ability and state estimation),
Diagnose (posterior infer-ence of misconceptions), Generate (counterfactual
item synthesis), and Exercise (index-based retrieval scheduling). EDGE unifies
psychometrics (IRT/Bayesian state space models), cog-nitive diagnostics
(misconception discovery from distractor patterns and response latencies),
contrastive item generation (minimal perturbations that invalidate learner
shortcuts while pre-serving psychometric validity), and principled scheduling
(a restless bandit approximation to spaced retrieval). We formalize a composite
readiness metric, EdgeScore, prove its monotonicity and Lipschitz continuity,
and derive an index policy that is near-optimal under mild assumptions on
forgetting and learning gains. We further establish conditions under which
counterfactual items provably reduce the posterior probability of a targeted
misconception faster than standard practice. The paper focuses on theory and
implementable pseudocode; empirical study is left to future work.

</details>


### [309] [Causal Negative Sampling via Diffusion Model for Out-of-Distribution Recommendation](https://arxiv.org/abs/2508.07243)
*Chu Zhao,Eneng Yang,Yizhou Dang,Jianzhe Zhao,Guibing Guo,Xingwei Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为CNSDiff的新方法，通过潜在空间的条件扩散过程生成负样本，避免预定义候选池的偏差，并引入因果正则化项以减少环境混杂因素的影响，从而提升推荐系统的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有启发式负采样方法可能因环境混杂因素（如曝光或流行度偏差）引入虚假硬负样本（FHNS），导致模型学习虚假相关性，从而损害其在分布变化下的泛化能力。

Method: 提出CNSDiff方法，通过条件扩散过程在潜在空间合成负样本，避免候选池的偏差，并加入因果正则化项以减少混杂因素的影响。

Result: 实验表明，CNSDiff在四种代表性分布变化场景下，平均提升13.96%的性能，优于现有基线方法。

Conclusion: CNSDiff有效减少了FHNS的生成，提高了推荐系统的稳健性和跨分布泛化能力。

Abstract: Heuristic negative sampling enhances recommendation performance by selecting
negative samples of varying hardness levels from predefined candidate pools to
guide the model toward learning more accurate decision boundaries. However, our
empirical and theoretical analyses reveal that unobserved environmental
confounders (e.g., exposure or popularity biases) in candidate pools may cause
heuristic sampling methods to introduce false hard negatives (FHNS). These
misleading samples can encourage the model to learn spurious correlations
induced by such confounders, ultimately compromising its generalization ability
under distribution shifts. To address this issue, we propose a novel method
named Causal Negative Sampling via Diffusion (CNSDiff). By synthesizing
negative samples in the latent space via a conditional diffusion process,
CNSDiff avoids the bias introduced by predefined candidate pools and thus
reduces the likelihood of generating FHNS. Moreover, it incorporates a causal
regularization term to explicitly mitigate the influence of environmental
confounders during the negative sampling process, leading to robust negatives
that promote out-of-distribution (OOD) generalization. Comprehensive
experiments under four representative distribution shift scenarios demonstrate
that CNSDiff achieves an average improvement of 13.96% across all evaluation
metrics compared to state-of-the-art baselines, verifying its effectiveness and
robustness in OOD recommendation tasks.

</details>


### [310] [Policy Newton methods for Distortion Riskmetrics](https://arxiv.org/abs/2508.07249)
*Soumen Pachal,Mizhaan Prajit Maniyar,Prashanth L. A*

Main category: cs.LG

TL;DR: 提出了一种在强化学习中解决风险敏感控制问题的新方法，通过最大化扭曲风险度量（DRM）来寻找最优策略，并证明了算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法主要集中在风险中性目标，很少关注风险敏感控制。本文旨在填补这一空白，提供一种能够处理DRM类风险度量的方法。

Method: 使用似然比方法推导DRM目标的策略Hessian定理，提出一种基于样本轨迹的DRM Hessian估计器，并设计了一个立方正则化策略牛顿算法。

Result: 算法能够收敛到DRM目标的二阶稳定点（ε-SOSP），并确保逃离鞍点，样本复杂度为O(ε^{-3.5})。实验验证了理论结果。

Conclusion: 本文是首个展示风险敏感目标收敛到二阶稳定点的工作，扩展了现有方法的能力范围。

Abstract: We consider the problem of risk-sensitive control in a reinforcement learning
(RL) framework. In particular, we aim to find a risk-optimal policy by
maximizing the distortion riskmetric (DRM) of the discounted reward in a finite
horizon Markov decision process (MDP). DRMs are a rich class of risk measures
that include several well-known risk measures as special cases. We derive a
policy Hessian theorem for the DRM objective using the likelihood ratio method.
Using this result, we propose a natural DRM Hessian estimator from sample
trajectories of the underlying MDP. Next, we present a cubic-regularized policy
Newton algorithm for solving this problem in an on-policy RL setting using
estimates of the DRM gradient and Hessian. Our proposed algorithm is shown to
converge to an $\epsilon$-second-order stationary point ($\epsilon$-SOSP) of
the DRM objective, and this guarantee ensures the escaping of saddle points.
The sample complexity of our algorithms to find an $ \epsilon$-SOSP is
$\mathcal{O}(\epsilon^{-3.5})$. Our experiments validate the theoretical
findings. To the best of our knowledge, our is the first work to present
convergence to an $\epsilon$-SOSP of a risk-sensitive objective, while existing
works in the literature have either shown convergence to a first-order
stationary point of a risk-sensitive objective, or a SOSP of a risk-neutral
one.

</details>


### [311] [PySeizure: A single machine learning classifier framework to detect seizures in diverse datasets](https://arxiv.org/abs/2508.07253)
*Bartlomiej Chybowski,Shima Abdullateef,Hollan Haule,Alfredo Gonzalez-Sulser,Javier Escudero*

Main category: cs.LG

TL;DR: 提出了一种开源机器学习框架，用于跨不同临床数据集实现稳健且可泛化的癫痫发作检测。


<details>
  <summary>Details</summary>
Motivation: 解决现有癫痫检测方法依赖数据集特定优化的问题，提高其实用性和可重复性。

Method: 结合自动预处理流水线和多数投票机制，从多个独立模型中综合结果。

Result: 在CHB-MIT和TUSZ数据集上取得高内数据集性能（AUC分别为0.904和0.864），并展示了跨数据集强泛化能力（AUC分别为0.615和0.762）。

Conclusion: 该方法为临床实用的癫痫检测系统提供了基础，具有广泛应用的潜力。

Abstract: Reliable seizure detection is critical for diagnosing and managing epilepsy,
yet clinical workflows remain dependent on time-consuming manual EEG
interpretation. While machine learning has shown promise, existing approaches
often rely on dataset-specific optimisations, limiting their real-world
applicability and reproducibility. Here, we introduce an innovative,
open-source machine-learning framework that enables robust and generalisable
seizure detection across varied clinical datasets. We evaluate our approach on
two publicly available EEG datasets that differ in patient populations and
electrode configurations. To enhance robustness, the framework incorporates an
automated pre-processing pipeline to standardise data and a majority voting
mechanism, in which multiple models independently assess each second of EEG
before reaching a final decision. We train, tune, and evaluate models within
each dataset, assessing their cross-dataset transferability. Our models achieve
high within-dataset performance (AUC 0.904+/-0.059 for CHB-MIT and
0.864+/-0.060 for TUSZ) and demonstrate strong generalisation across datasets
despite differences in EEG setups and populations (AUC 0.615+/-0.039 for models
trained on CHB-MIT and tested on TUSZ and 0.762+/-0.175 in the reverse case)
without any post-processing. Furthermore, a mild post-processing improved the
within-dataset results to 0.913+/-0.064 and 0.867+/-0.058 and cross-dataset
results to 0.619+/-0.036 and 0.768+/-0.172. These results underscore the
potential of, and essential considerations for, deploying our framework in
diverse clinical settings. By making our methodology fully reproducible, we
provide a foundation for advancing clinically viable, dataset-agnostic seizure
detection systems. This approach has the potential for widespread adoption,
complementing rather than replacing expert interpretation, and accelerating
clinical integration.

</details>


### [312] [Revisiting Data Attribution for Influence Functions](https://arxiv.org/abs/2508.07297)
*Hongbo Zhu,Angelo Cangelosi*

Main category: cs.LG

TL;DR: 本文综述了深度学习中影响函数的数据归因能力，探讨其理论基础、高效逆Hessian-向量积估计算法，并评估其在数据归因和错误标记检测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解模型预测与训练数据之间的关系，提升机器学习的可解释性、数据调试和模型问责制。

Method: 利用源自稳健统计学的影响函数，通过一阶近似估计训练数据点对模型参数和预测的边际影响，避免昂贵的重新训练。

Result: 验证了影响函数在数据归因和错误标记检测中的有效性，并提出了其在大规模深度学习应用中的潜力。

Conclusion: 影响函数在深度学习中有巨大潜力，但仍需解决当前挑战以充分发挥其在实际应用中的价值。

Abstract: The goal of data attribution is to trace the model's predictions through the
learning algorithm and back to its training data. thereby identifying the most
influential training samples and understanding how the model's behavior leads
to particular predictions. Understanding how individual training examples
influence a model's predictions is fundamental for machine learning
interpretability, data debugging, and model accountability. Influence
functions, originating from robust statistics, offer an efficient, first-order
approximation to estimate the impact of marginally upweighting or removing a
data point on a model's learned parameters and its subsequent predictions,
without the need for expensive retraining. This paper comprehensively reviews
the data attribution capability of influence functions in deep learning. We
discuss their theoretical foundations, recent algorithmic advances for
efficient inverse-Hessian-vector product estimation, and evaluate their
effectiveness for data attribution and mislabel detection. Finally,
highlighting current challenges and promising directions for unleashing the
huge potential of influence functions in large-scale, real-world deep learning
scenarios.

</details>


### [313] [When Is Prior Knowledge Helpful? Exploring the Evaluation and Selection of Unsupervised Pretext Tasks from a Neuro-Symbolic Perspective](https://arxiv.org/abs/2508.07299)
*Lin-Han Jia,Si-Yu Han,Wen-Chao Hu,Jie-Jing Shao,Wen-Da Wei,Zhi Zhou,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 该论文提出了一种将神经符号学习(Nesy)与半/自监督学习(SSL)理论框架统一的方法，基于三个因素（知识的可学习性、可靠性和完备性）分析任务性能的影响，并提出了预测预训练任务有效性的方法。


<details>
  <summary>Details</summary>
Motivation: 改进目标任务的性能，将神经符号学习理论扩展到不可靠知识的场景，统一SSL与Nesy的理论框架。

Method: 通过理论分析确定影响任务性能的三个关键因素，并提出操作性指标和预测方法。

Result: 实验验证了预测性能与实际性能的高度相关性，证明了理论和评估方法的有效性。

Conclusion: 该方法为预训练任务的选择提供了理论依据，改变了以往基于启发式的选择方式。

Abstract: Neuro-symbolic (Nesy) learning improves the target task performance of models
by enabling them to satisfy knowledge, while semi/self-supervised learning
(SSL) improves the target task performance by designing unsupervised pretext
tasks for unlabeled data to make models satisfy corresponding assumptions. We
extend the Nesy theory based on reliable knowledge to the scenario of
unreliable knowledge (i.e., assumptions), thereby unifying the theoretical
frameworks of SSL and Nesy. Through rigorous theoretical analysis, we
demonstrate that, in theory, the impact of pretext tasks on target performance
hinges on three factors: knowledge learnability with respect to the model,
knowledge reliability with respect to the data, and knowledge completeness with
respect to the target. We further propose schemes to operationalize these
theoretical metrics, and thereby develop a method that can predict the
effectiveness of pretext tasks in advance. This will change the current status
quo in practical applications, where the selections of unsupervised tasks are
heuristic-based rather than theory-based, and it is difficult to evaluate the
rationality of unsupervised pretext task selection before testing the model on
the target task. In experiments, we verify a high correlation between the
predicted performance-estimated using minimal data-and the actual performance
achieved after large-scale semi-supervised or self-supervised learning, thus
confirming the validity of the theory and the effectiveness of the evaluation
method.

</details>


### [314] [Efficient Edge LLMs Deployment via HessianAware Quantization and CPU GPU Collaborative](https://arxiv.org/abs/2508.07329)
*Tuo Zhang,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.LG

TL;DR: 论文提出了一种基于Hessian感知量化（HAQ）和CPU-GPU协同推理的高效MoE边缘部署方案，解决量化精度损失和专家模块调度问题。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在边缘设备上的部署面临量化精度损失和资源限制的挑战，研究旨在提高MoE架构的部署效率。

Method: 引入平滑Hessian矩阵量化实现8位量化，并设计专家级协同卸载与推理机制，优化CPU-GPU资源利用。

Result: 实验显示低比特量化模型的推理精度接近全精度模型，GPU内存使用减少60%，推理延迟显著降低。

Conclusion: 所提方法有效解决了MoE部署中的量化与资源调度问题，显著提升了边缘设备上的推理性能。

Abstract: With the breakthrough progress of large language models (LLMs) in natural
language processing and multimodal tasks, efficiently deploying them on
resource-constrained edge devices has become a critical challenge. The Mixture
of Experts (MoE) architecture enhances model capacity through sparse
activation, but faces two major difficulties in practical deployment: (1) The
presence of numerous outliers in activation distributions leads to severe
degradation in quantization accuracy for both activations and weights,
significantly impairing inference performance; (2) Under limited memory,
efficient offloading and collaborative inference of expert modules struggle to
balance latency and throughput. To address these issues, this paper proposes an
efficient MoE edge deployment scheme based on Hessian-Aware Quantization (HAQ)
and CPU-GPU collaborative inference. First, by introducing smoothed Hessian
matrix quantization, we achieve joint 8-bit quantization of activations and
weights, which significantly alleviates the accuracy loss caused by outliers
while ensuring efficient implementation on mainstream hardware. Second, we
design an expert-level collaborative offloading and inference mechanism, which,
combined with expert activation path statistics, enables efficient deployment
and scheduling of expert modules between CPU and GPU, greatly reducing memory
footprint and inference latency. Extensive experiments validate the
effectiveness of our method on mainstream large models such as the OPT series
and Mixtral 8*7B: on datasets like Wikitext2 and C4, the inference accuracy of
the low-bit quantized model approaches that of the full-precision model, while
GPU memory usage is reduced by about 60%, and inference latency is
significantly improved.

</details>


### [315] [Finite-Time Convergence Analysis of ODE-based Generative Models for Stochastic Interpolants](https://arxiv.org/abs/2508.07333)
*Yuhao Liu,Rui Hu,Yu Chen,Longbo Huang*

Main category: cs.LG

TL;DR: 本文分析了随机插值在生成建模中的应用，并首次提出了实用的数值ODE方法的有限时间收敛性保证，为计算效率优化提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 随机插值在数据分布转换中表现出色，但其数值实现的有限时间收敛性尚未充分研究。

Method: 通过一阶前向欧拉法和二阶Heun法，建立了总变差距离的有限时间误差界。

Result: 理论分析通过数值实验验证，提出了优化计算效率的调度方案。

Conclusion: 研究为随机插值的实际应用提供了坚实的理论基础和优化方向。

Abstract: Stochastic interpolants offer a robust framework for continuously
transforming samples between arbitrary data distributions, holding significant
promise for generative modeling. Despite their potential, rigorous finite-time
convergence guarantees for practical numerical schemes remain largely
unexplored. In this work, we address the finite-time convergence analysis of
numerical implementations for ordinary differential equations (ODEs) derived
from stochastic interpolants. Specifically, we establish novel finite-time
error bounds in total variation distance for two widely used numerical
integrators: the first-order forward Euler method and the second-order Heun's
method. Furthermore, our analysis on the iteration complexity of specific
stochastic interpolant constructions provides optimized schedules to enhance
computational efficiency. Our theoretical findings are corroborated by
numerical experiments, which validate the derived error bounds and complexity
analyses.

</details>


### [316] [ProteoKnight: Convolution-based phage virion protein classification and uncertainty analysis](https://arxiv.org/abs/2508.07345)
*Samiha Afaf Neha,Abir Ahammed Bhuiyan,Md. Ishrak Khan*

Main category: cs.LG

TL;DR: 本文提出了一种新的图像编码方法ProteoKnight，用于噬菌体病毒蛋白（PVP）的分类预测，并通过蒙特卡洛Dropout（MCD）评估预测不确定性。


<details>
  <summary>Details</summary>
Motivation: 噬菌体病毒蛋白（PVP）在基因组研究中扮演重要角色，但现有方法存在空间信息丢失问题，需要新的编码方法改进预测效果。

Method: ProteoKnight改编DNA-Walk算法，结合像素颜色和调整步行距离来捕捉蛋白质特征。使用预训练CNN进行分类，并通过方差和熵度量评估不确定性。

Result: 二进制分类准确率达90.8%，与现有技术相当。多类分类效果欠佳。不确定性分析揭示了预测信心受蛋白质类别和序列长度影响。

Conclusion: ProteoKnight优于频率混沌游戏表示（FCGR），通过新编码方法解决了空间信息损失问题，提供了准确且稳健的PVP预测。

Abstract: \textbf{Introduction:} Accurate prediction of Phage Virion Proteins (PVP) is
essential for genomic studies due to their crucial role as structural elements
in bacteriophages. Computational tools, particularly machine learning, have
emerged for annotating phage protein sequences from high-throughput sequencing.
However, effective annotation requires specialized sequence encodings. Our
paper introduces ProteoKnight, a new image-based encoding method that addresses
spatial constraints in existing techniques, yielding competitive performance in
PVP classification using pre-trained convolutional neural networks.
Additionally, our study evaluates prediction uncertainty in binary PVP
classification through Monte Carlo Dropout (MCD). \textbf{Methods:}
ProteoKnight adapts the classical DNA-Walk algorithm for protein sequences,
incorporating pixel colors and adjusting walk distances to capture intricate
protein features. Encoded sequences were classified using multiple pre-trained
CNNs. Variance and entropy measures assessed prediction uncertainty across
proteins of various classes and lengths. \textbf{Results:} Our experiments
achieved 90.8% accuracy in binary classification, comparable to
state-of-the-art methods. Multi-class classification accuracy remains
suboptimal. Our uncertainty analysis unveils variability in prediction
confidence influenced by protein class and sequence length.
\textbf{Conclusions:} Our study surpasses frequency chaos game representation
(FCGR) by introducing novel image encoding that mitigates spatial information
loss limitations. Our classification technique yields accurate and robust PVP
predictions while identifying low-confidence predictions.

</details>


### [317] [Intrinsic training dynamics of deep neural networks](https://arxiv.org/abs/2508.07370)
*Sibylle Marcotte,Gabriel Peyré,Rémi Gribonval*

Main category: cs.LG

TL;DR: 研究了深度学习中的梯度流是否可以被低维结构捕获，提出了一种基于核包含准则的简单条件，并应用于ReLU网络和线性网络。


<details>
  <summary>Details</summary>
Motivation: 理解高维参数空间中基于梯度的训练是否可以通过更简单的低维结构来描述，以揭示隐式偏差。

Method: 通过研究梯度流在高维变量和低维变量之间的映射关系，提出一个基于核包含的简单准则，并应用于ReLU网络和线性网络。

Result: 证明了在任意初始条件下，ReLU网络的梯度流可以表示为低维内在动态，并推广了线性网络的平衡初始化条件。

Conclusion: 通过低维结构可以捕获高维梯度流，为理解深度学习的隐式偏差提供了理论基础。

Abstract: A fundamental challenge in the theory of deep learning is to understand
whether gradient-based training in high-dimensional parameter spaces can be
captured by simpler, lower-dimensional structures, leading to so-called
implicit bias. As a stepping stone, we study when a gradient flow on a
high-dimensional variable $\theta$ implies an intrinsic gradient flow on a
lower-dimensional variable $z = \phi(\theta)$, for an architecture-related
function $\phi$. We express a so-called intrinsic dynamic property and show how
it is related to the study of conservation laws associated with the
factorization $\phi$. This leads to a simple criterion based on the inclusion
of kernels of linear maps which yields a necessary condition for this property
to hold. We then apply our theory to general ReLU networks of arbitrary depth
and show that, for any initialization, it is possible to rewrite the flow as an
intrinsic dynamic in a lower dimension that depends only on $z$ and the
initialization, when $\phi$ is the so-called path-lifting. In the case of
linear networks with $\phi$ the product of weight matrices, so-called balanced
initializations are also known to enable such a dimensionality reduction; we
generalize this result to a broader class of {\em relaxed balanced}
initializations, showing that, in certain configurations, these are the
\emph{only} initializations that ensure the intrinsic dynamic property.
Finally, for the linear neural ODE associated with the limit of infinitely deep
linear networks, with relaxed balanced initialization, we explicitly express
the corresponding intrinsic dynamics.

</details>


### [318] [Tight Bounds for Schrödinger Potential Estimation in Unpaired Image-to-Image Translation Problems](https://arxiv.org/abs/2508.07392)
*Nikita Puchkin,Denis Suchkov,Alexey Naumov,Denis Belomestny*

Main category: cs.LG

TL;DR: 本文提出了基于Schrödinger桥和随机最优控制理论的生成建模和无配对图像转换方法，通过优化初始和目标分布之间的转换，实现高效数据生成和转换。


<details>
  <summary>Details</summary>
Motivation: 研究目的是在仅能获取初始和最终分布的独立同分布样本的情况下，开发一种适用于生成建模和无配对图像转换的方法。通过随机最优控制理论，优化转换过程。

Method: 采用Ornstein-Uhlenbeck过程作为参考过程，估计对应的Schrödinger势能。引入Kullback-Leibler散度作为风险函数，推导了Schrödinger势能类中经验风险最小化器的泛化能力边界。

Result: 由于Ornstein-Uhlenbeck过程的混合性质，在有利场景下几乎实现了快速收敛速率（忽略对数因子）。数值实验验证了方法的有效性。

Conclusion: 通过随机最优控制理论和Schrödinger桥，本文方法在样本有限的情况下实现了高效的数据生成和转换，适用于多种实际应用场景。

Abstract: Modern methods of generative modelling and unpaired image-to-image
translation based on Schr\"odinger bridges and stochastic optimal control
theory aim to transform an initial density to a target one in an optimal way.
In the present paper, we assume that we only have access to i.i.d. samples from
initial and final distributions. This makes our setup suitable for both
generative modelling and unpaired image-to-image translation. Relying on the
stochastic optimal control approach, we choose an Ornstein-Uhlenbeck process as
the reference one and estimate the corresponding Schr\"odinger potential.
Introducing a risk function as the Kullback-Leibler divergence between
couplings, we derive tight bounds on generalization ability of an empirical
risk minimizer in a class of Schr\"odinger potentials including Gaussian
mixtures. Thanks to the mixing properties of the Ornstein-Uhlenbeck process, we
almost achieve fast rates of convergence up to some logarithmic factors in
favourable scenarios. We also illustrate performance of the suggested approach
with numerical experiments.

</details>


### [319] [Parity Requires Unified Input Dependence and Negative Eigenvalues in SSMs](https://arxiv.org/abs/2508.07395)
*Behnoush Khavari,Mehran Shakerinava,Jayesh Khullar,Jerry Huang,François Rivest,Siamak Ravanbakhsh,Sarath Chandar*

Main category: cs.LG

TL;DR: 研究发现，结合输入无关和非负SSM的多层结构仍无法解决状态跟踪任务，表明有效的递归层需同时具备输入依赖和负特征值。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，如S4D、Mamba和DeltaNet等LRNN模型因时间不变转移矩阵或受限特征值范围而缺乏状态跟踪能力。为此，提出输入依赖的转移矩阵以提高SSM性能，但未探讨多层SSM结合输入无关和非负SSM的可能性。

Method: 研究采用高效SSM，探索输入无关和非负SSM的多层组合是否能解决状态跟踪任务（如奇偶校验）。

Result: 实验表明，即使多层组合，这些SSM仍无法完成奇偶校验任务。

Conclusion: 有效的递归层需同时具备输入依赖和负特征值。实验通过结合S4D和Mamba层的SSM模型验证了这一结论。

Abstract: Recent work has shown that LRNN models such as S4D, Mamba, and DeltaNet lack
state-tracking capability due to either time-invariant transition matrices or
restricted eigenvalue ranges. To address this, input-dependent transition
matrices, particularly those that are complex or non-triangular, have been
proposed to enhance SSM performance on such tasks. While existing theorems
demonstrate that both input-independent and non-negative SSMs are incapable of
solving simple state-tracking tasks, such as parity, regardless of depth, they
do not explore whether combining these two types in a multilayer SSM could
help. We investigate this question for efficient SSMs with diagonal transition
matrices and show that such combinations still fail to solve parity. This
implies that a recurrence layer must both be input-dependent and include
negative eigenvalues. Our experiments support this conclusion by analyzing an
SSM model that combines S4D and Mamba layers.

</details>


### [320] [Efficient Reward Identification In Max Entropy Reinforcement Learning with Sparsity and Rank Priors](https://arxiv.org/abs/2508.07400)
*Mohamad Louai Shehab,Alperen Tercan,Necmiye Ozay*

Main category: cs.LG

TL;DR: 论文研究了从最优策略或演示数据中恢复时变奖励函数的问题，提出了两种奖励函数的先验假设，并将其转化为稀疏化和秩最小化问题，最终开发了高效的优化算法。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，从策略或演示数据中恢复奖励函数是一个高度不适定的问题，但实际应用中奖励函数通常具有稀疏性或可表示为少量特征的线性组合。因此，研究如何利用这些先验信息高效恢复奖励函数具有重要意义。

Method: 提出两种奖励函数的先验假设：1）奖励函数多为常数且变化稀少，转化为稀疏化问题；2）奖励函数可表示为少量特征的线性组合，转化为秩最小化问题。并分别给出了多项式时间算法和基于凸松弛的优化方法。

Result: 实验结果表明，所提出的方法能够高精度地恢复奖励函数，并展示了其良好的泛化能力。

Conclusion: 通过利用奖励函数的先验信息，将奖励恢复问题转化为稀疏化和秩最小化问题，能够高效且准确地恢复奖励函数。

Abstract: In this paper, we consider the problem of recovering time-varying reward
functions from either optimal policies or demonstrations coming from a max
entropy reinforcement learning problem. This problem is highly ill-posed
without additional assumptions on the underlying rewards. However, in many
applications, the rewards are indeed parsimonious, and some prior information
is available. We consider two such priors on the rewards: 1) rewards are mostly
constant and they change infrequently, 2) rewards can be represented by a
linear combination of a small number of feature functions. We first show that
the reward identification problem with the former prior can be recast as a
sparsification problem subject to linear constraints. Moreover, we give a
polynomial-time algorithm that solves this sparsification problem exactly.
Then, we show that identifying rewards representable with the minimum number of
features can be recast as a rank minimization problem subject to linear
constraints, for which convex relaxations of rank can be invoked. In both
cases, these observations lead to efficient optimization-based reward
identification algorithms. Several examples are given to demonstrate the
accuracy of the recovered rewards as well as their generalizability.

</details>


### [321] [Lightning Prediction under Uncertainty: DeepLight with Hazy Loss](https://arxiv.org/abs/2508.07428)
*Md Sultanul Arifin,Abu Nowshed Sakib,Yeasir Rayhan,Tanzima Hashem*

Main category: cs.LG

TL;DR: DeepLight是一种新型深度学习架构，用于预测雷击事件，利用多源气象数据并通过双编码器架构和Hazy Loss函数改进预测准确性。


<details>
  <summary>Details</summary>
Motivation: 雷击对人身安全和经济发展构成严重威胁，现有预测模型在动态空间上下文和不确定性处理方面表现不足，DeepLight旨在解决这些问题。

Method: DeepLight结合雷达反射率、云属性和历史雷击数据，采用双编码器架构和多分支卷积技术动态捕捉空间相关性，并引入Hazy Loss函数处理时空不确定性。

Result: 实验表明，DeepLight在公平威胁评分（ETS）上比现有方法提高了18%-30%。

Conclusion: DeepLight通过多源数据融合和不确定性处理，显著提升了雷击预测的准确性，成为可靠解决方案。

Abstract: Lightning, a common feature of severe meteorological conditions, poses
significant risks, from direct human injuries to substantial economic losses.
These risks are further exacerbated by climate change. Early and accurate
prediction of lightning would enable preventive measures to safeguard people,
protect property, and minimize economic losses. In this paper, we present
DeepLight, a novel deep learning architecture for predicting lightning
occurrences. Existing prediction models face several critical limitations: they
often struggle to capture the dynamic spatial context and inherent uncertainty
of lightning events, underutilize key observational data, such as radar
reflectivity and cloud properties, and rely heavily on Numerical Weather
Prediction (NWP) systems, which are both computationally expensive and highly
sensitive to parameter settings. To overcome these challenges, DeepLight
leverages multi-source meteorological data, including radar reflectivity, cloud
properties, and historical lightning occurrences through a dual-encoder
architecture. By employing multi-branch convolution techniques, it dynamically
captures spatial correlations across varying extents. Furthermore, its novel
Hazy Loss function explicitly addresses the spatio-temporal uncertainty of
lightning by penalizing deviations based on proximity to true events, enabling
the model to better learn patterns amidst randomness. Extensive experiments
show that DeepLight improves the Equitable Threat Score (ETS) by 18%-30% over
state-of-the-art methods, establishing it as a robust solution for lightning
prediction.

</details>


### [322] [Unsupervised operator learning approach for dissipative equations via Onsager principle](https://arxiv.org/abs/2508.07440)
*Zhipeng Chang,Zhenye Wen,Xiaofei Zhao*

Main category: cs.LG

TL;DR: 提出了一种名为DOOL的无监督学习方法，通过Onsager变分原理直接最小化Rayleighian泛函，无需标记数据，有效解决耗散方程问题。


<details>
  <summary>Details</summary>
Motivation: 现有算子学习方法依赖高保真仿真数据的监督训练，计算成本高昂。

Method: 采用时空解耦策略，空间坐标由主干网络处理，外部时间步进实现时间外推。

Result: 数值实验证明DOOL方法有效，且优于监督学习方法DeepONet和MIONet。

Conclusion: DOOL方法在解决耗散方程问题上表现出色，且适用于不直接遵循OVP的二阶波动模型。

Abstract: Existing operator learning methods rely on supervised training with
high-fidelity simulation data, introducing significant computational cost. In
this work, we propose the deep Onsager operator learning (DOOL) method, a novel
unsupervised framework for solving dissipative equations. Rooted in the Onsager
variational principle (OVP), DOOL trains a deep operator network by directly
minimizing the OVP-defined Rayleighian functional, requiring no labeled data,
and then proceeds in time explicitly through conservation/change laws for the
solution. Another key innovation here lies in the spatiotemporal decoupling
strategy: the operator's trunk network processes spatial coordinates
exclusively, thereby enhancing training efficiency, while integrated external
time stepping enables temporal extrapolation. Numerical experiments on typical
dissipative equations validate the effectiveness of the DOOL method, and
systematic comparisons with supervised DeepONet and MIONet demonstrate its
enhanced performance. Extensions are made to cover the second-order wave models
with dissipation that do not directly follow OVP.

</details>


### [323] [Stackelberg Coupling of Online Representation Learning and Reinforcement Learning](https://arxiv.org/abs/2508.07452)
*Fernando Martinez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: SCORER框架通过博弈论动态结构化感知与控制网络的交互，提升了深度强化学习的性能与样本效率，无需复杂辅助目标或架构。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励信号下学习有效特征的挑战，避免复杂辅助目标或完全解耦带来的设计复杂性。

Method: 提出SCORER框架，将感知与控制网络的交互建模为Stackelberg博弈，感知网络（领导者）学习对控制网络（追随者）有益的特征，后者最小化Bellman误差，并采用双时间尺度算法近似博弈均衡。

Result: 在标准DQN变体和基准任务中，SCORER提升了样本效率和最终性能。

Conclusion: 通过原理性算法设计感知-控制动态，可在无需复杂辅助目标或架构的情况下实现性能提升。

Abstract: Integrated, end-to-end learning of representations and policies remains a
cornerstone of deep reinforcement learning (RL). However, to address the
challenge of learning effective features from a sparse reward signal, recent
trends have shifted towards adding complex auxiliary objectives or fully
decoupling the two processes, often at the cost of increased design complexity.
This work proposes an alternative to both decoupling and naive end-to-end
learning, arguing that performance can be significantly improved by structuring
the interaction between distinct perception and control networks with a
principled, game-theoretic dynamic. We formalize this dynamic by introducing
the Stackelberg Coupled Representation and Reinforcement Learning (SCORER)
framework, which models the interaction between perception and control as a
Stackelberg game. The perception network (leader) strategically learns features
to benefit the control network (follower), whose own objective is to minimize
its Bellman error. We approximate the game's equilibrium with a practical
two-timescale algorithm. Applied to standard DQN variants on benchmark tasks,
SCORER improves sample efficiency and final performance. Our results show that
performance gains can be achieved through principled algorithmic design of the
perception-control dynamic, without requiring complex auxiliary objectives or
architectures.

</details>


### [324] [Towards Unveiling Predictive Uncertainty Vulnerabilities in the Context of the Right to Be Forgotten](https://arxiv.org/abs/2508.07458)
*Wei Qian,Chenxu Zhao,Yangyi Li,Wenqian Ye,Mengdi Huai*

Main category: cs.LG

TL;DR: 论文首次提出了一种针对预测不确定性的恶意遗忘攻击，并设计了优化框架。实验表明，这种攻击比传统标签错误分类攻击更有效，且现有防御方法对其无效。


<details>
  <summary>Details</summary>
Motivation: 随着机器遗忘技术的发展，预测不确定性的安全性问题尚未被探索，论文旨在填补这一空白。

Method: 提出了一种新的恶意遗忘攻击方法，设计了优化的攻击框架，并在黑盒场景下进行了广泛实验。

Result: 实验证明，该攻击能有效操纵预测不确定性，且现有防御措施对其无效。

Conclusion: 研究揭示了预测不确定性在恶意遗忘攻击下的脆弱性，为未来的防御研究提供了方向。

Abstract: Currently, various uncertainty quantification methods have been proposed to
provide certainty and probability estimates for deep learning models' label
predictions. Meanwhile, with the growing demand for the right to be forgotten,
machine unlearning has been extensively studied as a means to remove the impact
of requested sensitive data from a pre-trained model without retraining the
model from scratch. However, the vulnerabilities of such generated predictive
uncertainties with regard to dedicated malicious unlearning attacks remain
unexplored. To bridge this gap, for the first time, we propose a new class of
malicious unlearning attacks against predictive uncertainties, where the
adversary aims to cause the desired manipulations of specific predictive
uncertainty results. We also design novel optimization frameworks for our
attacks and conduct extensive experiments, including black-box scenarios.
Notably, our extensive experiments show that our attacks are more effective in
manipulating predictive uncertainties than traditional attacks that focus on
label misclassifications, and existing defenses against conventional attacks
are ineffective against our attacks.

</details>


### [325] [MOTGNN: Interpretable Graph Neural Networks for Multi-Omics Disease Classification](https://arxiv.org/abs/2508.07465)
*Tiantian Yang,Zhiqian Chen*

Main category: cs.LG

TL;DR: MOTGNN是一种新颖且可解释的多组学集成框架，用于疾病分类，通过XGBoost和GNN实现高效建模，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 整合多组学数据（如DNA甲基化、mRNA表达和miRNA表达）可以全面理解疾病机制，但高维度和复杂交互为建模带来挑战。

Method: MOTGNN结合XGBoost构建监督图，利用模态特异性GNN进行分层表示学习，并通过前馈网络实现跨组学集成。

Result: 在三个真实疾病数据集上，MOTGNN在准确率、ROC-AUC和F1分数上比基线提高5-10%，且对类别不平衡具有鲁棒性。

Conclusion: MOTGNN提升多组学疾病建模的预测准确性和可解释性，展示了其潜在应用价值。

Abstract: Integrating multi-omics data, such as DNA methylation, mRNA expression, and
microRNA (miRNA) expression, offers a comprehensive view of the biological
mechanisms underlying disease. However, the high dimensionality and complex
interactions among omics layers present major challenges for predictive
modeling. We propose Multi-Omics integration with Tree-generated Graph Neural
Network (MOTGNN), a novel and interpretable framework for binary disease
classification. MOTGNN employs eXtreme Gradient Boosting (XGBoost) to perform
omics-specific supervised graph construction, followed by modality-specific
Graph Neural Networks (GNNs) for hierarchical representation learning, and a
deep feedforward network for cross-omics integration. On three real-world
disease datasets, MOTGNN outperforms state-of-the-art baselines by 5-10% in
accuracy, ROC-AUC, and F1-score, and remains robust to severe class imbalance
(e.g., 87.2% vs. 33.4% F1 on imbalanced data). The model maintains
computational efficiency through sparse graphs (2.1-2.8 edges per node) and
provides built-in interpretability, revealing both top-ranked biomarkers and
the relative contributions of each omics modality. These results highlight
MOTGNN's potential to improve both predictive accuracy and interpretability in
multi-omics disease modeling.

</details>


### [326] [Online Convex Optimization with Heavy Tails: Old Algorithms, New Regrets, and Applications](https://arxiv.org/abs/2508.07473)
*Zijian Liu*

Main category: cs.LG

TL;DR: 论文研究了在线凸优化（OCO）中梯度估计存在重尾分布时的性能表现，证明了经典算法在不修改的情况下仍能实现最优遗憾界，并扩展应用到非光滑非凸优化等其他场景。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探讨梯度估计存在重尾（p阶中心矩有限）时，经典OCO算法的性能表现，以填补现有研究中针对此问题的空白。

Method: 研究通过理论分析，评估了经典OCO算法（如在线梯度下降）在重尾梯度下的性能，未对算法做任何修改。

Result: 结果显示这些算法在重尾梯度下仍能实现完全最优的遗憾界，且无需额外操作（如梯度截断）。

Conclusion: 研究得出结论，重尾梯度下的OCO问题无需额外操作即可有效解决，并扩展应用到非光滑非凸优化等其他场景，展示了广泛的适用性。

Abstract: In Online Convex Optimization (OCO), when the stochastic gradient has a
finite variance, many algorithms provably work and guarantee a sublinear
regret. However, limited results are known if the gradient estimate has a heavy
tail, i.e., the stochastic gradient only admits a finite $\mathsf{p}$-th
central moment for some $\mathsf{p}\in\left(1,2\right]$. Motivated by it, this
work examines different old algorithms for OCO (e.g., Online Gradient Descent)
in the more challenging heavy-tailed setting. Under the standard bounded domain
assumption, we establish new regrets for these classical methods without any
algorithmic modification. Remarkably, these regret bounds are fully optimal in
all parameters (can be achieved even without knowing $\mathsf{p}$), suggesting
that OCO with heavy tails can be solved effectively without any extra operation
(e.g., gradient clipping). Our new results have several applications. A
particularly interesting one is the first provable convergence result for
nonsmooth nonconvex optimization under heavy-tailed noise without gradient
clipping. Furthermore, we explore broader settings (e.g., smooth OCO) and
extend our ideas to optimistic algorithms to handle different cases
simultaneously.

</details>


### [327] [N-BEATS-MOE: N-BEATS with a Mixture-of-Experts Layer for Heterogeneous Time Series Forecasting](https://arxiv.org/abs/2508.07490)
*Ricardo Matos,Luis Roque,Vitor Cerqueira*

Main category: cs.LG

TL;DR: N-BEATS-MOE是一种基于N-BEATS的改进模型，通过引入Mixture-of-Experts层和动态块权重策略，提升了时间序列预测的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在时间序列预测中表现优异，但N-BEATS已展现出更好的可解释性。为进一步提升适应性和可解释性，作者提出了基于Mixture-of-Experts的扩展模型。

Method: N-BEATS-MOE在N-BEATS基础上引入Mixture-of-Experts层，通过门控网络动态调整块权重，使模型更好地适应不同时间序列的特征。

Result: 在12个基准数据集上的实验表明，N-BEATS-MOE在多个数据集上优于现有方法，尤其适用于异质时间序列。

Conclusion: N-BEATS-MOE不仅提高了预测性能，还通过门控机制增强了模型的可解释性，为时间序列预测提供了一种新思路。

Abstract: Deep learning approaches are increasingly relevant for time series
forecasting tasks. Methods such as N-BEATS, which is built on stacks of
multilayer perceptrons (MLPs) blocks, have achieved state-of-the-art results on
benchmark datasets and competitions. N-BEATS is also more interpretable
relative to other deep learning approaches, as it decomposes forecasts into
different time series components, such as trend and seasonality. In this work,
we present N-BEATS-MOE, an extension of N-BEATS based on a Mixture-of-Experts
(MoE) layer. N-BEATS-MOE employs a dynamic block weighting strategy based on a
gating network which allows the model to better adapt to the characteristics of
each time series. We also hypothesize that the gating mechanism provides
additional interpretability by identifying which expert is most relevant for
each series. We evaluate our method across 12 benchmark datasets against
several approaches, achieving consistent improvements on several datasets,
especially those composed of heterogeneous time series.

</details>


### [328] [Enhancing Privacy in Decentralized Min-Max Optimization: A Differentially Private Approach](https://arxiv.org/abs/2508.07505)
*Yueyang Quan,Chang Wang,Shengjie Zhai,Minghong Fang,Zhuqing Liu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DPMixSGD的隐私保护算法，用于解决非凸分散式最小-最大优化问题，同时确保差分隐私和收敛性能。


<details>
  <summary>Details</summary>
Motivation: 分散式最小-最大优化在多代理系统中存在隐私风险，传统差分隐私方法可能阻碍收敛，因此需要一种既能保护隐私又不显著影响收敛的新方法。

Method: 基于STORM的快速分散式最小-最大优化算法，通过添加噪声到局部梯度并证明其对收敛影响有限，同时提供理论隐私保证。

Result: 实验验证了DPMixSGD在不同任务和模型中的有效性，隐私保护和收敛性能均得到保证。

Conclusion: DPMixSGD是一种适用于非凸分散式最小-最大优化的高效隐私保护算法，解决了隐私与性能的平衡问题。

Abstract: Decentralized min-max optimization allows multi-agent systems to
collaboratively solve global min-max optimization problems by facilitating the
exchange of model updates among neighboring agents, eliminating the need for a
central server. However, sharing model updates in such systems carry a risk of
exposing sensitive data to inference attacks, raising significant privacy
concerns. To mitigate these privacy risks, differential privacy (DP) has become
a widely adopted technique for safeguarding individual data. Despite its
advantages, implementing DP in decentralized min-max optimization poses
challenges, as the added noise can hinder convergence, particularly in
non-convex scenarios with complex agent interactions in min-max optimization
problems. In this work, we propose an algorithm called DPMixSGD (Differential
Private Minmax Hybrid Stochastic Gradient Descent), a novel privacy-preserving
algorithm specifically designed for non-convex decentralized min-max
optimization. Our method builds on the state-of-the-art STORM-based algorithm,
one of the fastest decentralized min-max solutions. We rigorously prove that
the noise added to local gradients does not significantly compromise
convergence performance, and we provide theoretical bounds to ensure privacy
guarantees. To validate our theoretical findings, we conduct extensive
experiments across various tasks and models, demonstrating the effectiveness of
our approach.

</details>


### [329] [FairDRL-ST: Disentangled Representation Learning for Fair Spatio-Temporal Mobility Prediction](https://arxiv.org/abs/2508.07518)
*Sichen Zhao,Wei Shao,Jeffrey Chan,Ziqi Xu,Flora Salim*

Main category: cs.LG

TL;DR: 论文提出了一种基于解缠表示学习的新框架FairDRL-ST，旨在解决时空预测中的公平性问题，特别是在移动需求预测中。


<details>
  <summary>Details</summary>
Motivation: 由于时空预测模型的偏见可能加剧社会经济不平等，影响关键城市基础设施的用户，因此需要一种公平性解决方案。

Method: 通过对抗学习和解缠表示学习，框架无监督地分离敏感信息属性，避免现有监督方法的过度补偿和性能下降。

Result: 在真实城市移动数据集上验证，该框架能够缩小公平性差距，同时保持与最先进的公平感知方法相当的预测性能。

Conclusion: FairDRL-ST为时空预测中的公平性问题提供了一种有效且性能损失小的解决方案。

Abstract: As deep spatio-temporal neural networks are increasingly utilised in urban
computing contexts, the deployment of such methods can have a direct impact on
users of critical urban infrastructure, such as public transport, emergency
services, and traffic management systems. While many spatio-temporal methods
focus on improving accuracy, fairness has recently gained attention due to
growing evidence that biased predictions in spatio-temporal applications can
disproportionately disadvantage certain demographic or geographic groups,
thereby reinforcing existing socioeconomic inequalities and undermining the
ethical deployment of AI in public services. In this paper, we propose a novel
framework, FairDRL-ST, based on disentangled representation learning, to
address fairness concerns in spatio-temporal prediction, with a particular
focus on mobility demand forecasting. By leveraging adversarial learning and
disentangled representation learning, our framework learns to separate
attributes that contain sensitive information. Unlike existing methods that
enforce fairness through supervised learning, which may lead to
overcompensation and degraded performance, our framework achieves fairness in
an unsupervised manner with minimal performance loss. We apply our framework to
real-world urban mobility datasets and demonstrate its ability to close
fairness gaps while delivering competitive predictive performance compared to
state-of-the-art fairness-aware methods.

</details>


### [330] [Physics-Informed Multimodal Bearing Fault Classification under Variable Operating Conditions using Transfer Learning](https://arxiv.org/abs/2508.07536)
*Tasfiq E. Alam,Md Manjurul Ahsan,Shivakumar Raman*

Main category: cs.LG

TL;DR: 提出了一种物理信息多模态CNN，结合振动和电机电流信号，通过物理特征提取和新型损失函数，显著提高了轴承故障分类的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在多变工况下，轴承故障分类的准确性和可解释性对旋转机械可靠性至关重要。现有模型易受域偏移影响。

Method: 采用多模态CNN架构，融合振动和电流信号，结合物理特征提取分支和新颖的物理信息损失函数。评估了三种迁移学习策略。

Result: 在Paderborn数据集上优于非物理基线，最高达98%准确率。迁移学习的LAS策略表现最佳。统计测试验证显著改进。

Conclusion: 物理信息与数据驱动结合的方法在轴承故障诊断中展现出高效、鲁棒和可泛化的潜力。

Abstract: Accurate and interpretable bearing fault classification is critical for
ensuring the reliability of rotating machinery, particularly under variable
operating conditions where domain shifts can significantly degrade model
performance. This study proposes a physics-informed multimodal convolutional
neural network (CNN) with a late fusion architecture, integrating vibration and
motor current signals alongside a dedicated physics-based feature extraction
branch. The model incorporates a novel physics-informed loss function that
penalizes physically implausible predictions based on characteristic bearing
fault frequencies - Ball Pass Frequency Outer (BPFO) and Ball Pass Frequency
Inner (BPFI) - derived from bearing geometry and shaft speed. Comprehensive
experiments on the Paderborn University dataset demonstrate that the proposed
physics-informed approach consistently outperforms a non-physics-informed
baseline, achieving higher accuracy, reduced false classifications, and
improved robustness across multiple data splits. To address performance
degradation under unseen operating conditions, three transfer learning (TL)
strategies - Target-Specific Fine-Tuning (TSFT), Layer-Wise Adaptation Strategy
(LAS), and Hybrid Feature Reuse (HFR) - are evaluated. Results show that LAS
yields the best generalization, with additional performance gains when combined
with physics-informed modeling. Validation on the KAIST bearing dataset
confirms the framework's cross-dataset applicability, achieving up to 98
percent accuracy. Statistical hypothesis testing further verifies significant
improvements (p < 0.01) in classification performance. The proposed framework
demonstrates the potential of integrating domain knowledge with data-driven
learning to achieve robust, interpretable, and generalizable fault diagnosis
for real-world industrial applications.

</details>


### [331] [Multimodal Remote Inference](https://arxiv.org/abs/2508.07555)
*Keyuan Zhang,Yin Sun,Bo Ji*

Main category: cs.LG

TL;DR: 论文研究了多模态远程推理系统中的调度问题，提出了一种基于索引的阈值策略，以最小化推理误差，并在非单调、非加性的AoI函数和异构传输时间下证明了其最优性。


<details>
  <summary>Details</summary>
Motivation: 在多模态远程推理系统中，由于网络资源有限，动态变化的传感器数据难以实时传输，影响推理准确性。因此，研究如何调度多模态数据以最小化推理误差成为关键问题。

Method: 提出了一种基于索引的阈值调度策略，当当前模态的索引函数超过阈值时切换模态，并在一般AoI函数和异构传输时间下证明了其最优性。

Result: 数值结果显示，该策略比轮询和随机策略降低推理误差高达55%。

Conclusion: 研究结果表明，通过优化面向任务的AoI函数调度策略，可以有效提高远程推理的准确性。

Abstract: We consider a remote inference system with multiple modalities, where a
multimodal machine learning (ML) model performs real-time inference using
features collected from remote sensors. As sensor observations may change
dynamically over time, fresh features are critical for inference tasks.
However, timely delivering features from all modalities is often infeasible due
to limited network resources. To this end, we study a two-modality scheduling
problem to minimize the ML model's inference error, which is expressed as a
penalty function of AoI for both modalities. We develop an index-based
threshold policy and prove its optimality. Specifically, the scheduler switches
modalities when the current modality's index function exceeds a threshold. We
show that the two modalities share the same threshold, and both the index
functions and the threshold can be computed efficiently. The optimality of our
policy holds for (i) general AoI functions that are \emph{non-monotonic} and
\emph{non-additive} and (ii) \emph{heterogeneous} transmission times. Numerical
results show that our policy reduces inference error by up to 55% compared to
round-robin and uniform random policies, which are oblivious to the AoI-based
inference error function. Our results shed light on how to improve remote
inference accuracy by optimizing task-oriented AoI functions.

</details>


### [332] [Uncertainty-Driven Reliability: Selective Prediction and Trustworthy Deployment in Modern Machine Learning](https://arxiv.org/abs/2508.07556)
*Stephan Rabanser*

Main category: cs.LG

TL;DR: 该论文研究了如何通过不确定性估计提升机器学习的可靠性与信任度，特别是选择性预测。提出了一种利用模型训练轨迹的轻量级方法，适用于差分隐私场景，并分析了隐私与不确定性的权衡。此外，还分解了选择性分类差距，并设计了对抗防御机制。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域部署机器学习系统时，可靠性至关重要。研究旨在通过不确定性估计增强模型的安全性和可信度，特别是在模型选择性预测方面。

Method: 通过集成模型训练轨迹中的中间检查点，提出了一种轻量级的选择性预测方法，无需修改模型架构或损失函数。同时，研究了差分隐私下的不确定性质量，并开发了选择性分类差距的分解框架。

Result: 该方法在不增加成本的情况下实现了最优的选择性预测性能，且在差分隐私下表现稳健。此外，分解了选择性分类差距，并提出了对抗防御机制。

Conclusion: 研究通过改进、评估和保护不确定性估计，推动了可靠机器学习的发展，使模型不仅能够准确预测，还能在不确定时选择不预测。

Abstract: Machine learning (ML) systems are increasingly deployed in high-stakes
domains where reliability is paramount. This thesis investigates how
uncertainty estimation can enhance the safety and trustworthiness of ML,
focusing on selective prediction -- where models abstain when confidence is
low.
  We first show that a model's training trajectory contains rich uncertainty
signals that can be exploited without altering its architecture or loss. By
ensembling predictions from intermediate checkpoints, we propose a lightweight,
post-hoc abstention method that works across tasks, avoids the cost of deep
ensembles, and achieves state-of-the-art selective prediction performance.
Crucially, this approach is fully compatible with differential privacy (DP),
allowing us to study how privacy noise affects uncertainty quality. We find
that while many methods degrade under DP, our trajectory-based approach remains
robust, and we introduce a framework for isolating the privacy-uncertainty
trade-off. Next, we then develop a finite-sample decomposition of the selective
classification gap -- the deviation from the oracle accuracy-coverage curve --
identifying five interpretable error sources and clarifying which interventions
can close the gap. This explains why calibration alone cannot fix ranking
errors, motivating methods that improve uncertainty ordering. Finally, we show
that uncertainty signals can be adversarially manipulated to hide errors or
deny service while maintaining high accuracy, and we design defenses combining
calibration audits with verifiable inference.
  Together, these contributions advance reliable ML by improving, evaluating,
and safeguarding uncertainty estimation, enabling models that not only make
accurate predictions -- but also know when to say "I do not know".

</details>


### [333] [Towards Theoretical Understanding of Transformer Test-Time Computing: Investigation on In-Context Linear Regression](https://arxiv.org/abs/2508.07571)
*Xingwu Chen,Miao Lu,Beining Wu,Difan Zou*

Main category: cs.LG

TL;DR: 论文探讨通过增加语言模型推理时的计算（如生成更多中间思考或采样多个候选答案）提升性能，并通过理论和实验分析随机性与采样对推理行为的影响。


<details>
  <summary>Details</summary>
Motivation: 弥合实际语言模型推理与理论分析之间的差距，通过引入随机性和采样来研究推理行为。

Method: 在上下文线性回归任务中，通过噪声注入和二进制系数采样模拟语言模型解码，分析相关推理技术。

Result: 理论与实证结果表明，该方法有效揭示了现实语言模型推理行为的新见解。

Conclusion: 该框架为理解语言模型的实际推理行为提供了新视角，展示了理论与实践结合的潜力。

Abstract: Using more test-time computation during language model inference, such as
generating more intermediate thoughts or sampling multiple candidate answers,
has proven effective in significantly improving model performance. This paper
takes an initial step toward bridging the gap between practical language model
inference and theoretical transformer analysis by incorporating randomness and
sampling. We focus on in-context linear regression with continuous/binary
coefficients, where our framework simulates language model decoding through
noise injection and binary coefficient sampling. Through this framework, we
provide detailed analyses of widely adopted inference techniques. Supported by
empirical results, our theoretical framework and analysis demonstrate the
potential for offering new insights into understanding inference behaviors in
real-world language models.

</details>


### [334] [When and how can inexact generative models still sample from the data manifold?](https://arxiv.org/abs/2508.07581)
*Nisha Chandramoorthy,Adriaan de Clercq*

Main category: cs.LG

TL;DR: 论文探讨了生成模型中的支持稳健性现象，揭示了学习错误仅导致数据流形上的预测密度变化，并提出了Lyapunov向量对齐条件以实现稳健性。


<details>
  <summary>Details</summary>
Motivation: 研究生成模型中观察到的支持稳健性现象，即学习错误不会使生成样本偏离数据分布支持。

Method: 采用动力学系统方法分析生成过程的概率流，通过扰动分析和Lyapunov向量对齐条件揭示稳健性机制。

Result: 学习错误仅影响数据流形上的预测密度，Lyapunov向量对齐条件是实现支持稳健性的关键。

Conclusion: 该研究为理解生成模型的稳健性提供了理论依据，并可用于估计数据流形的切丛。

Abstract: A curious phenomenon observed in some dynamical generative models is the
following: despite learning errors in the score function or the drift vector
field, the generated samples appear to shift \emph{along} the support of the
data distribution but not \emph{away} from it. In this work, we investigate
this phenomenon of \emph{robustness of the support} by taking a dynamical
systems approach on the generating stochastic/deterministic process. Our
perturbation analysis of the probability flow reveals that infinitesimal
learning errors cause the predicted density to be different from the target
density only on the data manifold for a wide class of generative models.
Further, what is the dynamical mechanism that leads to the robustness of the
support? We show that the alignment of the top Lyapunov vectors (most sensitive
infinitesimal perturbation directions) with the tangent spaces along the
boundary of the data manifold leads to robustness and prove a sufficient
condition on the dynamics of the generating process to achieve this alignment.
Moreover, the alignment condition is efficient to compute and, in practice, for
robust generative models, automatically leads to accurate estimates of the
tangent bundle of the data manifold. Using a finite-time linear perturbation
analysis on samples paths as well as probability flows, our work complements
and extends existing works on obtaining theoretical guarantees for generative
models from a stochastic analysis, statistical learning and uncertainty
quantification points of view. Our results apply across different dynamical
generative models, such as conditional flow-matching and score-based generative
models, and for different target distributions that may or may not satisfy the
manifold hypothesis.

</details>


### [335] [Klear-Reasoner: Advancing Reasoning Capability via Gradient-Preserving Clipping Policy Optimization](https://arxiv.org/abs/2508.07629)
*Zhenpeng Su,Leiyu Pan,Xue Bai,Dening Liu,Guanting Dong,Jiaming Huang,Wenping Hu,Guorui Zhou*

Main category: cs.LG

TL;DR: Klear-Reasoner是一个具有长推理能力的模型，通过详细的训练流程分析和高性能优化，在数学和编程领域表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前社区中高性能推理模型的复现问题多因训练细节不完整，Klear-Reasoner旨在提供透明化的训练流程和优化方案。

Method: 从数据准备、长链思维监督微调（long CoT SFT）到强化学习（RL），详细分析训练流程，并提出梯度保留裁剪策略优化（GPPO）。

Result: 在多个基准测试中表现突出，如AIME 2024的90.5%，AIME 2025的83.2%等。

Conclusion: 高质量数据源和GPPO策略显著提升了模型的推理能力和学习效率。

Abstract: We present Klear-Reasoner, a model with long reasoning capabilities that
demonstrates careful deliberation during problem solving, achieving outstanding
performance across multiple benchmarks. Although there are already many
excellent works related to inference models in the current community, there are
still many problems with reproducing high-performance inference models due to
incomplete disclosure of training details. This report provides an in-depth
analysis of the reasoning model, covering the entire post-training workflow
from data preparation and long Chain-of-Thought supervised fine-tuning (long
CoT SFT) to reinforcement learning (RL), along with detailed ablation studies
for each experimental component. For SFT data, our experiments show that a
small number of high-quality data sources are more effective than a large
number of diverse data sources, and that difficult samples can achieve better
results without accuracy filtering. In addition, we investigate two key issues
with current clipping mechanisms in RL: Clipping suppresses critical
exploration signals and ignores suboptimal trajectories. To address these
challenges, we propose Gradient-Preserving clipping Policy Optimization (GPPO)
that gently backpropagates gradients from clipped tokens. GPPO not only
enhances the model's exploration capacity but also improves its efficiency in
learning from negative samples. Klear-Reasoner exhibits exceptional reasoning
abilities in mathematics and programming, scoring 90.5\% on AIME 2024, 83.2\%
on AIME 2025, 66.0\% on LiveCodeBench V5 and 58.1\% on LiveCodeBench V6.

</details>


### [336] [Efficient Approximate Posterior Sampling with Annealed Langevin Monte Carlo](https://arxiv.org/abs/2508.07631)
*Advait Parulekar,Litu Rout,Karthikeyan Shanmugam,Sanjay Shakkottai*

Main category: cs.LG

TL;DR: 研究了基于分数的生成模型中的后验采样问题，提出了一种在多项式时间内近似采样的方法，同时保证与测量和先验的一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管后验采样在KL散度下通常是难处理的，但实际应用中（如图像超分辨率、风格化等）的算法却取得了成功。因此，研究如何在更一般的“倾斜”问题框架下进行近似后验采样。

Method: 提出了一个最小假设下的方法，通过同时最小化KL散度和Fisher散度，从噪声先验的后验中采样。

Result: 证明了可以在多项式时间内采样出一个既接近噪声先验后验（KL散度）又接近真实后验（Fisher散度）的分布。

Conclusion: 该方法首次在多项式时间内实现了近似后验采样，为实际应用提供了理论基础。

Abstract: We study the problem of posterior sampling in the context of score based
generative models. We have a trained score network for a prior $p(x)$, a
measurement model $p(y|x)$, and are tasked with sampling from the posterior
$p(x|y)$. Prior work has shown this to be intractable in KL (in the worst case)
under well-accepted computational hardness assumptions. Despite this, popular
algorithms for tasks such as image super-resolution, stylization, and
reconstruction enjoy empirical success. Rather than establishing distributional
assumptions or restricted settings under which exact posterior sampling is
tractable, we view this as a more general "tilting" problem of biasing a
distribution towards a measurement. Under minimal assumptions, we show that one
can tractably sample from a distribution that is simultaneously close to the
posterior of a noised prior in KL divergence and the true posterior in Fisher
divergence. Intuitively, this combination ensures that the resulting sample is
consistent with both the measurement and the prior. To the best of our
knowledge these are the first formal results for (approximate) posterior
sampling in polynomial time.

</details>


### [337] [Attribution Explanations for Deep Neural Networks: A Theoretical Perspective](https://arxiv.org/abs/2508.07636)
*Huiqi Deng,Hongbin Pei,Quanshi Zhang,Mengnan Du*

Main category: cs.LG

TL;DR: 本文探讨了深度神经网络（DNNs）归因解释方法的忠实性问题，总结了三条核心挑战以及近期理论进展的三个关键方向。


<details>
  <summary>Details</summary>
Motivation: 归因解释方法是解释DNNs的重要工具，但其忠实性问题影响了可靠性和实用性。本文旨在澄清这些挑战并提出解决方案。

Method: 通过理论统一、理论基础和理论评估三个方向，系统地分析和比较现有归因方法。

Result: 揭示了归因方法的共性和差异，明确了理论基础，并提供了验证忠实性的方法。

Conclusion: 研究为归因方法的理论理解、方法选择和新方法设计提供了启示，同时指出了未来研究的方向。

Abstract: Attribution explanation is a typical approach for explaining deep neural
networks (DNNs), inferring an importance or contribution score for each input
variable to the final output. In recent years, numerous attribution methods
have been developed to explain DNNs. However, a persistent concern remains
unresolved, i.e., whether and which attribution methods faithfully reflect the
actual contribution of input variables to the decision-making process. The
faithfulness issue undermines the reliability and practical utility of
attribution explanations. We argue that these concerns stem from three core
challenges. First, difficulties arise in comparing attribution methods due to
their unstructured heterogeneity, differences in heuristics, formulations, and
implementations that lack a unified organization. Second, most methods lack
solid theoretical underpinnings, with their rationales remaining absent,
ambiguous, or unverified. Third, empirically evaluating faithfulness is
challenging without ground truth. Recent theoretical advances provide a
promising way to tackle these challenges, attracting increasing attention. We
summarize these developments, with emphasis on three key directions: (i)
Theoretical unification, which uncovers commonalities and differences among
methods, enabling systematic comparisons; (ii) Theoretical rationale,
clarifying the foundations of existing methods; (iii) Theoretical evaluation,
rigorously proving whether methods satisfy faithfulness principles. Beyond a
comprehensive review, we provide insights into how these studies help deepen
theoretical understanding, inform method selection, and inspire new attribution
methods. We conclude with a discussion of promising open problems for further
work.

</details>


### [338] [Extracting Complex Topology from Multivariate Functional Approximation: Contours, Jacobi Sets, and Ridge-Valley Graphs](https://arxiv.org/abs/2508.07637)
*Guanqun Ma,David Lenz,Hanqi Guo,Tom Peterka,Bei Wang*

Main category: cs.LG

TL;DR: 本文提出了一种直接从连续隐式模型（如MFA）中提取复杂拓扑特征的方法，无需离散化表示。该方法适用于支持函数值和高阶导数查询的任何连续隐式模型，为拓扑数据分析和可视化提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 连续隐式模型（如MFA）为科学数据的存储、传输和分析提供了新视角，但目前缺乏直接从中提取复杂拓扑特征的框架。本文旨在填补这一空白。

Method: 提出了一种直接从MFA模型中提取拓扑特征（如等高线、Jacobi集和脊谷图）的框架，利用了模型的连续性和可微性，无需离散化。

Result: 该方法成功地从MFA模型中提取了多种复杂拓扑特征，且适用于其他支持函数值和高阶导数查询的连续隐式模型。

Conclusion: 本文为连续隐式模型的拓扑分析奠定了基础，推动了科学数据的高效处理与可视化。

Abstract: Implicit continuous models, such as functional models and implicit neural
networks, are an increasingly popular method for replacing discrete data
representations with continuous, high-order, and differentiable surrogates.
These models offer new perspectives on the storage, transfer, and analysis of
scientific data. In this paper, we introduce the first framework to directly
extract complex topological features -- contours, Jacobi sets, and ridge-valley
graphs -- from a type of continuous implicit model known as multivariate
functional approximation (MFA). MFA replaces discrete data with continuous
piecewise smooth functions. Given an MFA model as the input, our approach
enables direct extraction of complex topological features from the model,
without reverting to a discrete representation of the model. Our work is easily
generalizable to any continuous implicit model that supports the queries of
function values and high-order derivatives. Our work establishes the building
blocks for performing topological data analysis and visualization on implicit
continuous models.

</details>


### [339] [Beyond Single: A Data Selection Principle for LLM Alignment via Fine-Grained Preference Signals](https://arxiv.org/abs/2508.07638)
*Jia Zhang,Yao Liu,Chen-Xi Zhang,Yi Liu,Yi-Xuan Jin,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.LG

TL;DR: 论文提出一种数据选择方法（DMPO），通过量化偏好冲突（PD项）来优化训练数据选择，提升LLM对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如DPO）在处理细粒度偏好数据时存在噪声和冲突问题，难以实现可靠和可扩展的对齐。

Method: 提出DMPO目标，引入PD项量化偏好冲突，设计数据选择原则，优先选择高共识数据（PD值最负的子集）进行训练。

Result: 在UltraFeedback数据集上，该方法比标准方法提升10%以上，且训练效率和鲁棒性更优。

Conclusion: 该方法通过高效数据选择解锁细粒度偏好信号的潜力，实现LLM更稳健的对齐。

Abstract: Aligning Large Language Models (LLMs) with diverse human values requires
moving beyond a single holistic "better-than" preference criterion. While
collecting fine-grained, aspect-specific preference data is more reliable and
scalable, existing methods like Direct Preference Optimization (DPO) struggle
with the severe noise and conflicts inherent in such aggregated datasets. In
this paper, we tackle this challenge from a data-centric perspective. We first
derive the Direct Multi-Preference Optimization (DMPO) objective, and uncover a
key Preference Divergence (PD) term that quantifies inter-aspect preference
conflicts. Instead of using this term for direct optimization, we leverage it
to formulate a novel, theoretically-grounded data selection principle. Our
principle advocates for selecting a subset of high-consensus data-identified by
the most negative PD values-for efficient DPO training. We prove the optimality
of this strategy by analyzing the loss bounds of the DMPO objective in the
selection problem. To operationalize our approach, we introduce practical
methods of PD term estimation and length bias mitigation, thereby proposing our
PD selection method. Evaluation on the UltraFeedback dataset with three varying
conflict levels shows that our simple yet effective strategy achieves over 10%
relative improvement against both the standard holistic preference and a
stronger oracle using aggregated preference signals, all while boosting
training efficiency and obviating the need for intractable holistic preference
annotating, unlocking the potential of robust LLM alignment via fine-grained
preference signals.

</details>


### [340] [Multi-Turn Jailbreaks Are Simpler Than They Seem](https://arxiv.org/abs/2508.07646)
*Xiaoxue Yang,Jaeha Lee,Anna-Katharina Dick,Jasper Timm,Fei Xie,Diogo Cruz*

Main category: cs.LG

TL;DR: 论文通过对多轮越狱攻击的实证分析，揭示了其实际复杂性与预期不符，发现其攻击成功率与单轮攻击重复采样相当，并对AI安全评估提出了新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管单轮越狱攻击的防御已显著改进，但多轮越狱攻击仍然是LLMs的主要漏洞，攻击成功率超过70%，因此需要对多轮攻击进行深入研究。

Method: 研究使用StrongREJECT基准对GPT-4、Claude和Gemini等前沿模型进行多轮越狱攻击的实证分析，探讨攻击者从模型拒绝有害请求中学习的能力。

Result: 研究发现多轮攻击并不比重复单轮攻击更复杂；攻击成功率在相似模型间相关；对推理模型，更高的推理努力反而可能导致更高的攻击成功率。

Conclusion: 研究结果对AI安全评估和设计抗越狱系统具有重要意义，并开源了相关代码。

Abstract: While defenses against single-turn jailbreak attacks on Large Language Models
(LLMs) have improved significantly, multi-turn jailbreaks remain a persistent
vulnerability, often achieving success rates exceeding 70% against models
optimized for single-turn protection. This work presents an empirical analysis
of automated multi-turn jailbreak attacks across state-of-the-art models
including GPT-4, Claude, and Gemini variants, using the StrongREJECT benchmark.
Our findings challenge the perceived sophistication of multi-turn attacks: when
accounting for the attacker's ability to learn from how models refuse harmful
requests, multi-turn jailbreaking approaches are approximately equivalent to
simply resampling single-turn attacks multiple times. Moreover, attack success
is correlated among similar models, making it easier to jailbreak newly
released ones. Additionally, for reasoning models, we find surprisingly that
higher reasoning effort often leads to higher attack success rates. Our results
have important implications for AI safety evaluation and the design of
jailbreak-resistant systems. We release the source code at
https://github.com/diogo-cruz/multi_turn_simpler

</details>


### [341] [Discovering Spatial Correlations between Earth Observations in Global Atmospheric State Estimation by using Adaptive Graph Structure Learning](https://arxiv.org/abs/2508.07659)
*Hyeon-Ju Jeon,Jeon-Ho Kang,In-Hyuk Kwon,O-Joun Lee*

Main category: cs.LG

TL;DR: 研究旨在通过时空图神经网络（STGNN）和结构学习方法，动态捕捉地球观测与大气状态的空间相关性，以提升数值天气预报（NWP）系统的准确性。通过自适应调节节点度数并考虑空间距离，解决了结构学习中的信息丢失和过平滑问题。


<details>
  <summary>Details</summary>
Motivation: 传统的数值天气预报系统（NWP）在固定网格点上预测未来大气状态，但地球观测数据的位置不固定，导致动态变化的空间相关性难以捕捉。研究希望通过STGNN和结构学习方法改进这一问题。

Method: 采用时空图神经网络（STGNN）结合结构学习方法，通过自适应调节节点度数和考虑空间距离，动态生成图结构，以准确捕捉大气状态与观测数据之间的空间相关性。

Result: 在东亚地区的真实数据测试中，提出的方法在高变异性区域表现优于传统STGNN模型（无论是否使用结构学习）。

Conclusion: 所提出的方法通过动态图结构调整，有效解决了空间相关性建模问题，显著提升了大气状态估计的准确性。

Abstract: This study aims to discover spatial correlations between Earth observations
and atmospheric states to improve the forecasting accuracy of global
atmospheric state estimation, which are usually conducted using conventional
numerical weather prediction (NWP) systems and is the beginning of weather
forecasting. NWP systems predict future atmospheric states at fixed locations,
which are called NWP grid points, by analyzing previous atmospheric states and
newly acquired Earth observations without fixed locations. Thus, surrounding
meteorological context and the changing locations of the observations make
spatial correlations between atmospheric states and observations over time. To
handle complicated spatial correlations, which change dynamically, we employ
spatiotemporal graph neural networks (STGNNs) with structure learning. However,
structure learning has an inherent limitation that this can cause structural
information loss and over-smoothing problem by generating excessive edges. To
solve this problem, we regulate edge sampling by adaptively determining node
degrees and considering the spatial distances between NWP grid points and
observations. We validated the effectiveness of the proposed method by using
real-world atmospheric state and observation data from East Asia. Even in areas
with high atmospheric variability, the proposed method outperformed existing
STGNN models with and without structure learning.

</details>


### [342] [GLiClass: Generalist Lightweight Model for Sequence Classification Tasks](https://arxiv.org/abs/2508.07662)
*Ihor Stepanov,Mykhailo Shtopko,Dmytro Vodianytskyi,Oleksandr Lukashov,Alexander Yavorskyi,Mykyta Yaroshenko*

Main category: cs.LG

TL;DR: 提出了一种名为GLiClass的新方法，针对分类任务中的高效性和灵活性需求，结合了GLiNER架构的优势，解决了生成模型和嵌入方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统需要处理大量输入数据，且分类需求动态变化，现有生成模型和嵌入方法在效率、准确性或灵活性上存在不足。

Method: 基于GLiNER架构调整的GLiClass方法，并结合PPO优化多标签分类任务，支持零样本和少样本学习。

Result: GLiClass在保持高效的同时，提供了与嵌入方法相当的准确性，并具备零样本学习的灵活性。

Conclusion: GLiClass为动态分类需求提供了高效的解决方案，同时扩展了PPO在数据稀疏条件下的应用。

Abstract: Classification is one of the most widespread tasks in AI applications,
serving often as the first step in filtering, sorting, and categorizing data.
Since modern AI systems must handle large volumes of input data and early
pipeline stages can propagate errors downstream, achieving high efficiency and
accuracy is critical. Moreover, classification requirements can change
dynamically based on user needs, necessitating models with strong zero-shot
capabilities. While generative LLMs have become mainstream for zero-shot
classification due to their versatility, they suffer from inconsistent
instruction following and computational inefficiency. Cross-encoders, commonly
used as rerankers in RAG pipelines, face a different bottleneck: they must
process text-label pairs sequentially, significantly reducing efficiency with
large label sets. Embedding-based approaches offer good efficiency but struggle
with complex scenarios involving logical and semantic constraints. We propose
GLiClass, a novel method that adapts the GLiNER architecture for sequence
classification tasks. Our approach achieves strong accuracy and efficiency
comparable to embedding-based methods, while maintaining the flexibility needed
for zero-shot and few-shot learning scenarios. Additionally, we adapted
proximal policy optimization (PPO) for multi-label text classification,
enabling training classifiers in data-sparse conditions or from human feedback.

</details>


### [343] [AIS-LLM: A Unified Framework for Maritime Trajectory Prediction, Anomaly Detection, and Collision Risk Assessment with Explainable Forecasting](https://arxiv.org/abs/2508.07668)
*Hyobin Park,Jinwook Jung,Minseok Seo,Hyunsoo Choi,Deukjae Cho,Sekil Park,Dong-Geol Choi*

Main category: cs.LG

TL;DR: AIS-LLM是一种新颖的框架，结合时间序列AIS数据和大型语言模型，实现船舶轨迹预测、异常检测和碰撞风险评估的多任务集成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以全面考虑复杂的海事情况，AIS-LLM旨在通过多任务集成提升海事交通管理的智能化和效率。

Method: AIS-LLM包含时间序列编码器、文本提示编码器、跨模态对齐模块和多任务解码器，实现多任务的端到端执行。

Result: 实验表明，AIS-LLM在各项任务中表现优于现有方法，并支持任务输出的综合分析。

Conclusion: AIS-LLM展示了在海事交通管理中实现更智能和高效管理的潜力。

Abstract: With the increase in maritime traffic and the mandatory implementation of the
Automatic Identification System (AIS), the importance and diversity of maritime
traffic analysis tasks based on AIS data, such as vessel trajectory prediction,
anomaly detection, and collision risk assessment, is rapidly growing. However,
existing approaches tend to address these tasks individually, making it
difficult to holistically consider complex maritime situations. To address this
limitation, we propose a novel framework, AIS-LLM, which integrates time-series
AIS data with a large language model (LLM). AIS-LLM consists of a Time-Series
Encoder for processing AIS sequences, an LLM-based Prompt Encoder, a
Cross-Modality Alignment Module for semantic alignment between time-series data
and textual prompts, and an LLM-based Multi-Task Decoder. This architecture
enables the simultaneous execution of three key tasks: trajectory prediction,
anomaly detection, and risk assessment of vessel collisions within a single
end-to-end system. Experimental results demonstrate that AIS-LLM outperforms
existing methods across individual tasks, validating its effectiveness.
Furthermore, by integratively analyzing task outputs to generate situation
summaries and briefings, AIS-LLM presents the potential for more intelligent
and efficient maritime traffic management.

</details>


### [344] [Semantic Caching for Low-Cost LLM Serving: From Offline Learning to Online Adaptation](https://arxiv.org/abs/2508.07675)
*Xutong Liu,Baran Atalar,Xiangxiang Dai,Jinhang Zuo,Siwei Wang,John C. S. Lui,Wei Chen,Carlee Joe-Wong*

Main category: cs.LG

TL;DR: 提出了一个基于学习的语义缓存淘汰框架，以解决LLM推理成本高的问题，应对未知查询和成本分布。


<details>
  <summary>Details</summary>
Motivation: LLM的高推理成本带来了可扩展性和可持续性挑战，现有语义缓存方法缺乏理论基础且无法适应实际不确定性。

Method: 设计了一个原则性的学习框架，包括离线优化和在线学习问题，并开发了高效的算法。

Result: 在合成数据集上的评估表明，所提算法的性能优于或与基线方法相当。

Conclusion: 该框架为语义缓存提供了理论基础，并能适应实际中的不确定性。

Abstract: Large Language Models (LLMs) are revolutionizing how users interact with
information systems, yet their high inference cost poses serious scalability
and sustainability challenges. Caching inference responses, allowing them to be
retrieved without another forward pass through the LLM, has emerged as one
possible solution. Traditional exact-match caching, however, overlooks the
semantic similarity between queries, leading to unnecessary recomputation.
Semantic caching addresses this by retrieving responses based on semantic
similarity, but introduces a fundamentally different cache eviction problem:
one must account for mismatch costs between incoming queries and cached
responses. Moreover, key system parameters, such as query arrival probabilities
and serving costs, are often unknown and must be learned over time. Existing
semantic caching methods are largely ad-hoc, lacking theoretical foundations
and unable to adapt to real-world uncertainty. In this paper, we present a
principled, learning-based framework for semantic cache eviction under unknown
query and cost distributions. We formulate both offline optimization and online
learning variants of the problem, and develop provably efficient algorithms
with state-of-the-art guarantees. We also evaluate our framework on a synthetic
dataset, showing that our proposed algorithms perform matching or superior
performance compared with baselines.

</details>


### [345] [Multi-Hop Privacy Propagation for Differentially Private Federated Learning in Social Networks](https://arxiv.org/abs/2508.07676)
*Chenchen Lin,Xuehe Wang*

Main category: cs.LG

TL;DR: 本文提出了一种社交网络感知的联邦学习隐私保护机制，通过多跳传播模型量化间接隐私泄露，并通过Stackelberg博弈优化激励策略和隐私预算选择，显著提升了客户端效用并降低了服务器成本。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，社会网络的引入导致隐私泄漏不仅取决于个体保护策略，还受到他人决策的多跳传播影响。传统方法忽视了这种社交外部性，导致隐私保护不足。

Method: 设计了一个两阶段Stackelberg博弈模型，服务器优化激励策略（领导者），客户端选择隐私预算（跟随者）。引入均值场估计器量化平均外部隐私风险，并理论证明了其收敛性和纳什均衡的存在。

Result: 实验表明，该方法显著提升了客户端效用和服务器效率，同时保持模型性能，优于社交无关（SA）基线和其他考虑社交外部性的方法。

Conclusion: 机制不仅从客户端激励角度优化隐私保护，还实现了近似最优的社会福利，为联邦学习中的社交隐私问题提供了有效解决方案。

Abstract: Federated learning (FL) enables collaborative model training across
decentralized clients without sharing local data, thereby enhancing privacy and
facilitating collaboration among clients connected via social networks.
However, these social connections introduce privacy externalities: a client's
privacy loss depends not only on its privacy protection strategy but also on
the privacy decisions of others, propagated through the network via multi-hop
interactions. In this work, we propose a socially-aware privacy-preserving FL
mechanism that systematically quantifies indirect privacy leakage through a
multi-hop propagation model. We formulate the server-client interaction as a
two-stage Stackelberg game, where the server, as the leader, optimizes
incentive policies, and clients, as followers, strategically select their
privacy budgets, which determine their privacy-preserving levels by controlling
the magnitude of added noise. To mitigate information asymmetry in networked
privacy estimation, we introduce a mean-field estimator to approximate the
average external privacy risk. We theoretically prove the existence and
convergence of the fixed point of the mean-field estimator and derive
closed-form expressions for the Stackelberg Nash Equilibrium. Despite being
designed from a client-centric incentive perspective, our mechanism achieves
approximately-optimal social welfare, as revealed by Price of Anarchy (PoA)
analysis. Experiments on diverse datasets demonstrate that our approach
significantly improves client utilities and reduces server costs while
maintaining model performance, outperforming both Social-Agnostic (SA)
baselines and methods that account for social externalities.

</details>


### [346] [MORE-CLEAR: Multimodal Offline Reinforcement learning for Clinical notes Leveraged Enhanced State Representation](https://arxiv.org/abs/2508.07681)
*Yooseok Lim,ByoungJun Jeon,Seong-A Park,Jisoo Lee,Sae Won Choi,Chang Wook Jeong,Ho-Geol Ryu,Hongyeol Lee,Hyun-Lim Yang*

Main category: cs.LG

TL;DR: 提出了MORE-CLEAR框架，利用多模态离线强化学习和LLM增强败血症管理的状态表示，显著提升了生存率和策略性能。


<details>
  <summary>Details</summary>
Motivation: 败血症早期检测和管理的重要性，以往RL方法依赖结构化数据且对患者状态理解不足。

Method: 使用预训练LLM提取临床笔记的语义表示，结合门控融合和跨模态注意力动态整合多模态数据。

Result: 在两个公开数据集和一个私有数据集上验证，MORE-CLEAR显著优于单模态RL方法。

Conclusion: 首次在医疗应用中结合LLM和多模态离线RL，提升了对患者状态的理解和治疗效率。

Abstract: Sepsis, a life-threatening inflammatory response to infection, causes organ
dysfunction, making early detection and optimal management critical. Previous
reinforcement learning (RL) approaches to sepsis management rely primarily on
structured data, such as lab results or vital signs, and on a dearth of a
comprehensive understanding of the patient's condition. In this work, we
propose a Multimodal Offline REinforcement learning for Clinical notes
Leveraged Enhanced stAte Representation (MORE-CLEAR) framework for sepsis
control in intensive care units. MORE-CLEAR employs pre-trained large-scale
language models (LLMs) to facilitate the extraction of rich semantic
representations from clinical notes, preserving clinical context and improving
patient state representation. Gated fusion and cross-modal attention allow
dynamic weight adjustment in the context of time and the effective integration
of multimodal data. Extensive cross-validation using two public (MIMIC-III and
MIMIC-IV) and one private dataset demonstrates that MORE-CLEAR significantly
improves estimated survival rate and policy performance compared to
single-modal RL approaches. To our knowledge, this is the first to leverage LLM
capabilities within a multimodal offline RL for better state representation in
medical applications. This approach can potentially expedite the treatment and
management of sepsis by enabling reinforcement learning models to propose
enhanced actions based on a more comprehensive understanding of patient
conditions.

</details>


### [347] [Semantic-Enhanced Time-Series Forecasting via Large Language Models](https://arxiv.org/abs/2508.07697)
*Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu*

Main category: cs.LG

TL;DR: 提出了一种语义增强的大型语言模型（SE-LLM），通过嵌入时间序列的周期性和异常特征来增强语义表示，并引入插件模块在自注意力中建模长短期依赖关系，显著提升时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在时间序列预测中侧重于令牌级模态对齐，但未能弥合语言知识结构与时间序列数据模式之间的内在模态差距，限制了语义表示。

Method: 提出SE-LLM，利用时间序列的周期性和异常特征增强语义空间嵌入，并在自注意力中引入插件模块建模长短期依赖。

Result: 实验表明，SE-LLM在性能上优于现有最先进方法，同时降低了计算消耗。

Conclusion: SE-LLM通过语义增强和长短期依赖建模，显著提升了LLM在时间序列分析中的潜力和性能。

Abstract: Time series forecasting plays a significant role in finance, energy,
meteorology, and IoT applications. Recent studies have leveraged the
generalization capabilities of large language models (LLMs) to adapt to time
series forecasting, achieving promising performance. However, existing studies
focus on token-level modal alignment, instead of bridging the intrinsic
modality gap between linguistic knowledge structures and time series data
patterns, greatly limiting the semantic representation. To address this issue,
we propose a novel Semantic-Enhanced LLM (SE-LLM) that explores the inherent
periodicity and anomalous characteristics of time series to embed into the
semantic space to enhance the token embedding. This process enhances the
interpretability of tokens for LLMs, thereby activating the potential of LLMs
for temporal sequence analysis. Moreover, existing Transformer-based LLMs excel
at capturing long-range dependencies but are weak at modeling short-term
anomalies in time-series data. Hence, we propose a plugin module embedded
within self-attention that models long-term and short-term dependencies to
effectively adapt LLMs to time-series analysis. Our approach freezes the LLM
and reduces the sequence dimensionality of tokens, greatly reducing
computational consumption. Experiments demonstrate the superiority performance
of our SE-LLM against the state-of-the-art (SOTA) methods.

</details>


### [348] [Energy Consumption in Parallel Neural Network Training](https://arxiv.org/abs/2508.07706)
*Philipp Huber,David Li,Juan Pedro Gutiérrez Hermosillo Muriedas,Deifilia Kieckhefen,Markus Götz,Achim Streit,Charlotte Debus*

Main category: cs.LG

TL;DR: 研究了数据并行训练对能源消耗的影响，分析了GPU数量、全局批次大小和局部批次大小对性能、训练时间和能耗的作用。


<details>
  <summary>Details</summary>
Motivation: 随着神经网络训练计算资源需求的增加，能源消耗问题日益突出，但并行化对能耗的影响未被充分研究。

Method: 通过对ResNet50和FourCastNet进行数据并行训练实验，评估不同并行化参数对性能、时间和能耗的影响。

Result: 能源消耗与GPU小时数近似线性相关，但不同模型和硬件间的缩放因子差异显著，且受样本数和梯度更新次数影响。

Conclusion: 研究揭示了神经网络训练规模扩大与能源消耗的复杂关系，为未来可持续AI研究提供了参考。

Abstract: The increasing demand for computational resources of training neural networks
leads to a concerning growth in energy consumption. While parallelization has
enabled upscaling model and dataset sizes and accelerated training, its impact
on energy consumption is often overlooked. To close this research gap, we
conducted scaling experiments for data-parallel training of two models,
ResNet50 and FourCastNet, and evaluated the impact of parallelization
parameters, i.e., GPU count, global batch size, and local batch size, on
predictive performance, training time, and energy consumption. We show that
energy consumption scales approximately linearly with the consumed resources,
i.e., GPU hours; however, the respective scaling factor differs substantially
between distinct model trainings and hardware, and is systematically influenced
by the number of samples and gradient updates per GPU hour. Our results shed
light on the complex interplay of scaling up neural network training and can
inform future developments towards more sustainable AI research.

</details>


### [349] [Training-Free ANN-to-SNN Conversion for High-Performance Spiking Transformer](https://arxiv.org/abs/2508.07710)
*Jingya Wang,Xin Deng,Wenjie Wei,Dehao Zhang,Shuai Wang,Qian Sun,Jieyuan Zhang,Hanwen Liu,Ning Xie,Malu Zhang*

Main category: cs.LG

TL;DR: 提出了一种高性能、无需训练的ANN-to-SNN转换框架，适用于Transformer架构，解决了现有方法处理非线性操作和需要微调的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在ANN-to-SNN转换中的局限性，如无法有效处理非线性操作和需要额外微调预训练ANNs的问题。

Method: 引入了多基指数衰减（MBE）神经元，通过指数衰减策略和多基编码方法高效近似各种非线性操作。

Result: 实验表明，该方法在多种任务（CV、NLU、NLG）和主流Transformer架构（ViT、RoBERTa、GPT-2）上实现了接近无损的转换精度，且延迟显著降低。

Conclusion: 提供了一种高效、可扩展的Spiking Transformers在实际应用中部署的途径。

Abstract: Leveraging the event-driven paradigm, Spiking Neural Networks (SNNs) offer a
promising approach for constructing energy-efficient Transformer architectures.
Compared to directly trained Spiking Transformers, ANN-to-SNN conversion
methods bypass the high training costs. However, existing methods still suffer
from notable limitations, failing to effectively handle nonlinear operations in
Transformer architectures and requiring additional fine-tuning processes for
pre-trained ANNs. To address these issues, we propose a high-performance and
training-free ANN-to-SNN conversion framework tailored for Transformer
architectures. Specifically, we introduce a Multi-basis Exponential Decay (MBE)
neuron, which employs an exponential decay strategy and multi-basis encoding
method to efficiently approximate various nonlinear operations. It removes the
requirement for weight modifications in pre-trained ANNs. Extensive experiments
across diverse tasks (CV, NLU, NLG) and mainstream Transformer architectures
(ViT, RoBERTa, GPT-2) demonstrate that our method achieves near-lossless
conversion accuracy with significantly lower latency. This provides a promising
pathway for the efficient and scalable deployment of Spiking Transformers in
real-world applications.

</details>


### [350] [Detecting Mislabeled and Corrupted Data via Pointwise Mutual Information](https://arxiv.org/abs/2508.07713)
*Jinghan Yang,Jiayu Weng*

Main category: cs.LG

TL;DR: 该论文提出了一种基于互信息的数据选择框架，用于处理混合噪声场景下的数据质量问题，能有效识别和过滤低质量样本。


<details>
  <summary>Details</summary>
Motivation: 现实数据集常因标签噪声和输入噪声导致模型性能下降，需要一种能同时处理这两种噪声的方法。

Method: 通过计算样本对整体互信息的点贡献值，量化输入与标签间的统计依赖性，贡献值低的样本被视为噪声或误标。

Result: 在MNIST数据集上验证，该方法能显著提升分类准确率（最高15%），并保持对良性输入修改的鲁棒性。

Conclusion: 提出的框架能高效过滤噪声样本，提升模型性能，适用于混合噪声环境。

Abstract: Deep neural networks can memorize corrupted labels, making data quality
critical for model performance, yet real-world datasets are frequently
compromised by both label noise and input noise. This paper proposes a mutual
information-based framework for data selection under hybrid noise scenarios
that quantifies statistical dependencies between inputs and labels. We compute
each sample's pointwise contribution to the overall mutual information and find
that lower contributions indicate noisy or mislabeled instances. Empirical
validation on MNIST with different synthetic noise settings demonstrates that
the method effectively filters low-quality samples. Under label corruption,
training on high-MI samples improves classification accuracy by up to 15\%
compared to random sampling. Furthermore, the method exhibits robustness to
benign input modifications, preserving semantically valid data while filtering
truly corrupted samples.

</details>


### [351] [Robust Reinforcement Learning over Wireless Networks with Homomorphic State Representations](https://arxiv.org/abs/2508.07722)
*Pietro Talli,Federico Mason,Federico Chiariotti,Andrea Zanella*

Main category: cs.LG

TL;DR: HR3L是一种新型架构，用于在非理想无线信道上训练远程强化学习（RL）代理，通过编码和解码环境信息来减少通信负担，无需交换梯度信息，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决在损失或延迟的无线通信系统中训练RL代理时因部分和间歇性信息导致的性能问题。

Method: 提出HR3L架构，包括发射器和接收器单元，分别编码环境信息和解码执行动作，无需交换梯度信息。

Result: 实验表明HR3L在样本效率和适应不同通信场景（如丢包、延迟和容量限制）上显著优于基线方法。

Conclusion: HR3L是一种高效且适应性强的解决方案，适用于非理想通信条件下的远程RL训练。

Abstract: In this work, we address the problem of training Reinforcement Learning (RL)
agents over communication networks. The RL paradigm requires the agent to
instantaneously perceive the state evolution to infer the effects of its
actions on the environment. This is impossible if the agent receives state
updates over lossy or delayed wireless systems and thus operates with partial
and intermittent information. In recent years, numerous frameworks have been
proposed to manage RL with imperfect feedback; however, they often offer
specific solutions with a substantial computational burden. To address these
limits, we propose a novel architecture, named Homomorphic Robust Remote
Reinforcement Learning (HR3L), that enables the training of remote RL agents
exchanging observations across a non-ideal wireless channel. HR3L considers two
units: the transmitter, which encodes meaningful representations of the
environment, and the receiver, which decodes these messages and performs
actions to maximize a reward signal. Importantly, HR3L does not require the
exchange of gradient information across the wireless channel, allowing for
quicker training and a lower communication overhead than state-of-the-art
solutions. Experimental results demonstrate that HR3L significantly outperforms
baseline methods in terms of sample efficiency and adapts to different
communication scenarios, including packet losses, delayed transmissions, and
capacity limitations.

</details>


### [352] [Separation and Collaboration: Two-Level Routing Grouped Mixture-of-Experts for Multi-Domain Continual Learning](https://arxiv.org/abs/2508.07738)
*Jialu Zhou,Dianxi Shi,Shaowu Yang,Xinyu Wei,Mingyue Yang,Leqian Li,Mengzhu Wang,Chunping Qiu*

Main category: cs.LG

TL;DR: 论文提出了一种名为TRGE的方法，通过动态扩展预训练的CLIP模型并分配专家组来解决多领域持续学习中的灾难性遗忘和前瞻性问题。


<details>
  <summary>Details</summary>
Motivation: 解决多领域持续学习中的灾难性遗忘和前瞻性问题，并在参数高效微调的基础上进一步提升性能。

Method: TRGE方法动态扩展CLIP模型，为每个任务分配专家组，设计组内和组间路由策略，并利用MLLM生成任务标识符。

Result: 实验表明，TRGE方法在多种设置下均优于其他先进方法，且使用的可训练参数更少。

Conclusion: TRGE方法有效解决了多领域持续学习中的双重异质性问题，同时减少了灾难性遗忘和前瞻性问题。

Abstract: Multi-Domain Continual Learning (MDCL) acquires knowledge from sequential
tasks with shifting class sets and distribution. Despite the
Parameter-Efficient Fine-Tuning (PEFT) methods can adapt for this dual
heterogeneity, they still suffer from catastrophic forgetting and forward
forgetting. To address these challenges, we propose a Two-Level Routing Grouped
Mixture-of-Experts (TRGE) method. Firstly, TRGE dynamically expands the
pre-trained CLIP model, assigning specific expert group for each task to
mitigate catastrophic forgetting. With the number of experts continually grows
in this process, TRGE maintains the static experts count within the group and
introduces the intra-group router to alleviate routing overfitting caused by
the increasing routing complexity. Meanwhile, we design an inter-group routing
policy based on task identifiers and task prototype distance, which dynamically
selects relevant expert groups and combines their outputs to enhance inter-task
collaboration. Secondly, to get the correct task identifiers, we leverage
Multimodal Large Language Models (MLLMs) which own powerful multimodal
comprehension capabilities to generate semantic task descriptions and recognize
the correct task identifier. Finally, to mitigate forward forgetting, we
dynamically fuse outputs for unseen samples from the frozen CLIP model and TRGE
adapter based on training progress, leveraging both pre-trained and learned
knowledge. Through extensive experiments across various settings, our method
outperforms other advanced methods with fewer trainable parameters.

</details>


### [353] [A Tutorial: An Intuitive Explanation of Offline Reinforcement Learning Theory](https://arxiv.org/abs/2508.07746)
*Fengdi Che*

Main category: cs.LG

TL;DR: 这是一篇关于离线强化学习（RL）的调查论文，探讨了其理论挑战与实用算法设计之间的桥梁，包括函数表示和数据覆盖的假设，以及解决这些挑战的技术和条件。


<details>
  <summary>Details</summary>
Motivation: 离线RL的目标是通过固定的代理轨迹数据集优化回报，无需与环境互动。尽管算法发展迅速，但理论进展与实用设计之间的差距仍需填补。

Method: 通过分析理论工作的关键直觉，包括函数表示条件和数据覆盖假设，以及讨论反例和解决挑战的技术，探讨离线RL的可行性。

Result: 论文总结了离线RL的理论条件及其对算法的限制，强调了在某些情况下需要寻找新的解决方案。

Conclusion: 离线RL的理论与实用设计之间存在显著差距，理解这些条件和限制有助于未来算法的改进和创新。

Abstract: Offline reinforcement learning (RL) aims to optimize the return given a fixed
dataset of agent trajectories without additional interactions with the
environment. While algorithm development has progressed rapidly, significant
theoretical advances have also been made in understanding the fundamental
challenges of offline RL. However, bridging these theoretical insights with
practical algorithm design remains an ongoing challenge. In this survey, we
explore key intuitions derived from theoretical work and their implications for
offline RL algorithms.
  We begin by listing the conditions needed for the proofs, including function
representation and data coverage assumptions. Function representation
conditions tell us what to expect for generalization, and data coverage
assumptions describe the quality requirement of the data. We then examine
counterexamples, where offline RL is not solvable without an impractically
large amount of data. These cases highlight what cannot be achieved for all
algorithms and the inherent hardness of offline RL. Building on techniques to
mitigate these challenges, we discuss the conditions that are sufficient for
offline RL. These conditions are not merely assumptions for theoretical proofs,
but they also reveal the limitations of these algorithms and remind us to
search for novel solutions when the conditions cannot be satisfied.

</details>


### [354] [Learning to Align, Aligning to Learn: A Unified Approach for Self-Optimized Alignment](https://arxiv.org/abs/2508.07750)
*Haowen Wang,Yun Yue,Zhiling Ye,Shuowen Zhang,Lei Fan,Jiaxin Liang,Jiadi Jiang,Cheng Wei,Jingyuan Deng,Xudong Han,Ji Li,Chunxiao Guo,Peng Wei,Jian Wang,Jinjie Gu*

Main category: cs.LG

TL;DR: GRAO提出了一种结合SFT和RL优势的统一框架，通过多样本生成、组直接对齐损失和参考感知参数更新等方法，显著提升了语言模型的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 解决SFT和RL在语言模型对齐中的局限性，SFT的离轨策略效率低，RL样本效率不足且依赖高质量基模型。

Method: 提出GRAO框架，包含多样本生成策略、组直接对齐损失和参考感知参数更新三项创新。

Result: 在复杂任务中表现优异，相对基线模型（SFT、DPO等）提升5.18%至57.70%。

Conclusion: GRAO提供了理论支持和实证证据，证明了其在语言模型能力进化中的高效性。

Abstract: Alignment methodologies have emerged as a critical pathway for enhancing
language model alignment capabilities. While SFT (supervised fine-tuning)
accelerates convergence through direct token-level loss intervention, its
efficacy is constrained by offline policy trajectory. In contrast,
RL(reinforcement learning) facilitates exploratory policy optimization, but
suffers from low sample efficiency and stringent dependency on high-quality
base models. To address these dual challenges, we propose GRAO (Group Relative
Alignment Optimization), a unified framework that synergizes the respective
strengths of SFT and RL through three key innovations: 1) A multi-sample
generation strategy enabling comparative quality assessment via reward
feedback; 2) A novel Group Direct Alignment Loss formulation leveraging
intra-group relative advantage weighting; 3) Reference-aware parameter updates
guided by pairwise preference dynamics. Our theoretical analysis establishes
GRAO's convergence guarantees and sample efficiency advantages over
conventional approaches. Comprehensive evaluations across complex human
alignment tasks demonstrate GRAO's superior performance, achieving
57.70\%,17.65\% 7.95\% and 5.18\% relative improvements over SFT, DPO, PPO and
GRPO baselines respectively. This work provides both a theoretically grounded
alignment framework and empirical evidence for efficient capability evolution
in language models.

</details>


### [355] [Sparse Probabilistic Graph Circuits](https://arxiv.org/abs/2508.07763)
*Martin Rektoris,Milan Papež,Václav Šmídl,Tomáš Pevný*

Main category: cs.LG

TL;DR: SPGCs (稀疏概率图电路) 通过稀疏图表示解决了传统概率图电路的复杂度问题，提升了推理速度和内存效率，同时在药物设计中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统深度生成模型因非线性导致难以解析计算概率推理，而现有概率图电路虽解决了可解析性问题，但复杂度高（O(n²)），不适用于稀疏图。

Method: 提出稀疏概率图电路（SPGCs），直接操作稀疏图表示，将复杂度降至O(n + m)，适用于边远少于节点数平方的情况。

Result: 实验表明，SPGCs在药物设计中保留了精确推理能力，提升了内存和速度效率，且性能与不可解析模型相当。

Conclusion: SPGCs通过稀疏化显著提升了概率图电路的实用性，适用于稀疏图场景，尤其在药物设计中展示了优越性。

Abstract: Deep generative models (DGMs) for graphs achieve impressively high expressive
power thanks to very efficient and scalable neural networks. However, these
networks contain non-linearities that prevent analytical computation of many
standard probabilistic inference queries, i.e., these DGMs are considered
\emph{intractable}. While recently proposed Probabilistic Graph Circuits (PGCs)
address this issue by enabling \emph{tractable} probabilistic inference, they
operate on dense graph representations with $\mathcal{O}(n^2)$ complexity for
graphs with $n$ nodes and \emph{$m$ edges}. To address this scalability issue,
we introduce Sparse PGCs, a new class of tractable generative models that
operate directly on sparse graph representation, reducing the complexity to
$\mathcal{O}(n + m)$, which is particularly beneficial for $m \ll n^2$. In the
context of de novo drug design, we empirically demonstrate that SPGCs retain
exact inference capabilities, improve memory efficiency and inference speed,
and match the performance of intractable DGMs in key metrics.

</details>


### [356] [Pareto Multi-Objective Alignment for Language Models](https://arxiv.org/abs/2508.07768)
*Qiang He,Setareh Maghsudi*

Main category: cs.LG

TL;DR: 提出了一种名为PAMA的高效多目标对齐算法，用于解决大语言模型在适应多样化人类偏好时的局限性，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前的对齐方法（如RLHF）仅优化单一目标，导致大语言模型的行为僵化，无法适应复杂的现实场景，亟需多目标对齐的解决方案。

Method: PAMA将多目标强化学习对齐问题转化为凸优化问题，并提供闭式解，将计算复杂度从O(n^2*d)降至O(n)。

Result: 实验证明PAMA在参数规模为125M到7B的语言模型中表现稳健，能够高效地实现多目标对齐。

Conclusion: PAMA为多目标对齐提供了高效且理论支持的方法，为大语言模型在现实中的多样化部署铺平了道路。

Abstract: Large language models (LLMs) are increasingly deployed in real-world
applications that require careful balancing of multiple, often conflicting,
objectives, such as informativeness versus conciseness, or helpfulness versus
creativity. However, current alignment methods, primarily based on RLHF,
optimize LLMs toward a single reward function, resulting in rigid behavior that
fails to capture the complexity and diversity of human preferences. This
limitation hinders the adaptability of LLMs to practical scenarios, making
multi-objective alignment (MOA) a critical yet underexplored area. To bridge
this gap, we propose Pareto Multi-Objective Alignment (PAMA), a principled and
computationally efficient algorithm designed explicitly for MOA in LLMs. In
contrast to computationally prohibitive multi-objective optimization (MOO)
methods, PAMA transforms multi-objective RLHF into a convex optimization with a
closed-form solution, significantly enhancing scalability. Traditional MOO
approaches suffer from prohibitive O(n^2*d) complexity, where d represents the
number of model parameters, typically in the billions for LLMs, rendering
direct optimization infeasible. PAMA reduces this complexity to O(n) where n is
the number of objectives, enabling optimization to be completed within
milliseconds. We provide theoretical guarantees that PAMA converges to a Pareto
stationary point, where no objective can be improved without degrading at least
one other. Extensive experiments across language models ranging from 125M to 7B
parameters demonstrate PAMA's robust and effective MOA capabilities, aligning
with its theoretical advantages. PAMA provides a highly efficient solution to
the MOA problem that was previously considered intractable, offering a
practical and theoretically grounded approach to aligning LLMs with diverse
human values, paving the way for versatile and adaptable real-world AI
deployments.

</details>


### [357] [Topological Feature Compression for Molecular Graph Neural Networks](https://arxiv.org/abs/2508.07807)
*Rahul Khorana*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的图神经网络架构，结合了高阶拓扑信号和标准分子特征，以在分子表示学习中平衡预测准确性、可解释性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决在分子表示学习中平衡预测准确性、可解释性和计算效率的难题。

Method: 提出了一种结合高阶拓扑信号和标准分子特征的图神经网络架构，保留全局几何信息且计算高效。

Result: 在多个基准测试中表现优异，几乎在所有任务中实现了最佳准确性和鲁棒性。

Conclusion: 该方法在分子表示学习中实现了高准确性和鲁棒性，同时保持了计算效率和可解释性。

Abstract: Recent advances in molecular representation learning have produced highly
effective encodings of molecules for numerous cheminformatics and
bioinformatics tasks. However, extracting general chemical insight while
balancing predictive accuracy, interpretability, and computational efficiency
remains a major challenge. In this work, we introduce a novel Graph Neural
Network (GNN) architecture that combines compressed higher-order topological
signals with standard molecular features. Our approach captures global
geometric information while preserving computational tractability and
human-interpretable structure. We evaluate our model across a range of
benchmarks, from small-molecule datasets to complex material datasets, and
demonstrate superior performance using a parameter-efficient architecture. We
achieve the best performing results in both accuracy and robustness across
almost all benchmarks. We open source all code \footnote{All code and results
can be found on Github https://github.com/rahulkhorana/TFC-PACT-Net}.

</details>


### [358] [EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning](https://arxiv.org/abs/2508.07809)
*Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,Hu XiaoLong,Ge Li*

Main category: cs.LG

TL;DR: RLVR用于提升LLM推理能力，但在难题上奖励稀疏导致学习效率低。EvoCoT通过自生成和验证CoT轨迹，逐步扩展探索空间，解决这一问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖更强LLM或过滤难题，限制了可扩展性和推理能力的探索提升。

Method: 提出EvoCoT，基于两阶段CoT推理优化的自进化课程学习框架，通过逐步缩短自生成CoT轨迹控制探索空间扩展。

Result: 在多种LLM上验证，EvoCoT能解决未解决问题，提升推理能力，且无需外部CoT监督，兼容多种RL微调方法。

Conclusion: EvoCoT有效解决了稀疏奖励下的学习瓶颈，为LLM推理能力提升提供了可扩展方案。

Abstract: Reinforcement learning with verifiable reward (RLVR) has become a promising
paradigm for post-training large language models (LLMs) to improve their
reasoning capability. However, when the rollout accuracy is low on hard
problems, the reward becomes sparse, limiting learning efficiency and causing
exploration bottlenecks. Existing approaches either rely on stronger LLMs for
distillation or filter out difficult problems, which limits scalability or
restricts reasoning improvement through exploration.
  We propose EvoCoT, a self-evolving curriculum learning framework based on
two-stage chain-of-thought (CoT) reasoning optimization. EvoCoT constrains the
exploration space by self-generating and verifying CoT trajectories, then
gradually shortens them to expand the space in a controlled way. This enables
LLMs to stably learn from initially unsolved hard problems under sparse
rewards. We apply EvoCoT to multiple LLM families, including Qwen, DeepSeek,
and Llama. Experiments show that EvoCoT enables LLMs to solve previously
unsolved problems, improves reasoning capability without external CoT
supervision, and is compatible with various RL fine-tuning methods. We release
the source code to support future research.

</details>


### [359] [Learning Satellite Attitude Dynamics with Physics-Informed Normalising Flow](https://arxiv.org/abs/2508.07841)
*Carlo Cena,Mauro Martini,Marcello Chiaberge*

Main category: cs.LG

TL;DR: 结合物理信息的神经网络在航天器姿态控制中优于纯数据驱动方法，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统数据驱动模型在航天器姿态控制中泛化性和稳定性不足的问题。

Method: 引入物理信息神经网络（PINN），与纯数据驱动方法对比，使用Real NVP架构和自注意力机制训练模型。

Result: PINN模型将最佳架构的平均相对误差降低27.08%，在MPC框架中表现更优，控制精度和鲁棒性提升42.86%。

Conclusion: 结合物理信息的方法在航天器姿态控制中表现更好，尤其在稳定性和鲁棒性方面。

Abstract: Attitude control is a fundamental aspect of spacecraft operations. Model
Predictive Control (MPC) has emerged as a powerful strategy for these tasks,
relying on accurate models of the system dynamics to optimize control actions
over a prediction horizon. In scenarios where physics models are incomplete,
difficult to derive, or computationally expensive, machine learning offers a
flexible alternative by learning the system behavior directly from data.
However, purely data-driven models often struggle with generalization and
stability, especially when applied to inputs outside their training domain. To
address these limitations, we investigate the benefits of incorporating
Physics-Informed Neural Networks (PINNs) into the learning of spacecraft
attitude dynamics, comparing their performance with that of purely data-driven
approaches. Using a Real-valued Non-Volume Preserving (Real NVP) neural network
architecture with a self-attention mechanism, we trained several models on
simulated data generated with the Basilisk simulator. Two training strategies
were considered: a purely data-driven baseline and a physics-informed variant
to improve robustness and stability. Our results demonstrate that the inclusion
of physics-based information significantly enhances the performance in terms of
the mean relative error of the best architectures found by 27.08%. These
advantages are particularly evident when the learned models are integrated into
an MPC framework, where PINN-based models consistently outperform their purely
data-driven counterparts in terms of control accuracy and robustness, yielding
improvements of up to 42.86% in performance stability error and increased
robustness-to-noise.

</details>


### [360] [Not Yet AlphaFold for the Mind: Evaluating Centaur as a Synthetic Participant](https://arxiv.org/abs/2508.07887)
*Sabrina Namazova,Alessandra Brondetta,Younes Strittmatter,Matthew Nassar,Sebastian Musslick*

Main category: cs.LG

TL;DR: 论文探讨了模拟器在自然科学和行为科学中的重要性，并以Centaur为例评估了其作为参与者模拟器的表现，发现其在生成行为上与人类数据存在系统性差异。


<details>
  <summary>Details</summary>
Motivation: 探索模拟器在加速科学研究和实验设计中的作用，特别关注行为科学中可靠的参与者模拟器的潜力。

Method: 评估Centaur这一大型语言模型在模拟人类行为方面的表现，分析其预测准确性和生成行为。

Result: Centaur在预测准确性上表现良好，但在生成行为上系统性偏离人类数据，不符合可靠参与者模拟器的标准。

Conclusion: Centaur虽在预测人类行为上迈出重要一步，但尚未达到可靠参与者模拟器或准确认知模型的标准。

Abstract: Simulators have revolutionized scientific practice across the natural
sciences. By generating data that reliably approximate real-world phenomena,
they enable scientists to accelerate hypothesis testing and optimize
experimental designs. This is perhaps best illustrated by AlphaFold, a
Nobel-prize winning simulator in chemistry that predicts protein structures
from amino acid sequences, enabling rapid prototyping of molecular
interactions, drug targets, and protein functions. In the behavioral sciences,
a reliable participant simulator - a system capable of producing human-like
behavior across cognitive tasks - would represent a similarly transformative
advance. Recently, Binz et al. introduced Centaur, a large language model (LLM)
fine-tuned on human data from 160 experiments, proposing its use not only as a
model of cognition but also as a participant simulator for "in silico
prototyping of experimental studies", e.g., to advance automated cognitive
science. Here, we review the core criteria for a participant simulator and
assess how well Centaur meets them. Although Centaur demonstrates strong
predictive accuracy, its generative behavior - a critical criterion for a
participant simulator - systematically diverges from human data. This suggests
that, while Centaur is a significant step toward predicting human behavior, it
does not yet meet the standards of a reliable participant simulator or an
accurate model of cognition.

</details>


### [361] [Score Augmentation for Diffusion Models](https://arxiv.org/abs/2508.07926)
*Liang Hou,Yuan Gao,Boyuan Jiang,Xin Tao,Qi Yan,Renjie Liao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.LG

TL;DR: 本文提出了一种名为ScoreAug的新型数据增强框架，专为扩散模型设计，通过操作噪声数据而非干净数据来缓解训练中的过拟合问题，并在多项基准测试中展现出显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中表现出色，但在数据有限的情况下容易过拟合，需要一种更有效的数据增强方法来应对这一挑战。

Method: 提出了ScoreAug框架，通过在噪声数据上应用变换并与原始目标增强相结合，建立起一个等变学习目标，使得扩散模型能够在不同的去噪空间中学习得分。

Result: 实验表明，ScoreAug在多个基准数据集上显著提升了性能，有效缓解了过拟合，并在不同数据规模和模型容量下表现出稳定的收敛性。

Conclusion: ScoreAug不仅优于传统数据增强方法，还能与其协同使用以进一步提升性能，同时避免了某些情况下的数据泄露问题。

Abstract: Diffusion models have achieved remarkable success in generative modeling.
However, this study confirms the existence of overfitting in diffusion model
training, particularly in data-limited regimes. To address this challenge, we
propose Score Augmentation (ScoreAug), a novel data augmentation framework
specifically designed for diffusion models. Unlike conventional augmentation
approaches that operate on clean data, ScoreAug applies transformations to
noisy data, aligning with the inherent denoising mechanism of diffusion.
Crucially, ScoreAug further requires the denoiser to predict the augmentation
of the original target. This design establishes an equivariant learning
objective, enabling the denoiser to learn scores across varied denoising
spaces, thereby realizing what we term score augmentation. We also
theoretically analyze the relationship between scores in different spaces under
general transformations. In experiments, we extensively validate ScoreAug on
multiple benchmarks including CIFAR-10, FFHQ, AFHQv2, and ImageNet, with
results demonstrating significant performance improvements over baselines.
Notably, ScoreAug effectively mitigates overfitting across diverse scenarios,
such as varying data scales and model capacities, while exhibiting stable
convergence properties. Another advantage of ScoreAug over standard data
augmentation lies in its ability to circumvent data leakage issues under
certain conditions. Furthermore, we show that ScoreAug can be synergistically
combined with traditional data augmentation techniques to achieve additional
performance gains.

</details>


### [362] [Adaptive Fine-Tuning via Pattern Specialization for Deep Time Series Forecasting](https://arxiv.org/abs/2508.07927)
*Amal Saadallah,Abdulaziz Al-Ademi*

Main category: cs.LG

TL;DR: 该论文提出了一种新颖的框架，通过模型适应和选择提升深度神经网络在非平稳环境中的时间序列预测性能。


<details>
  <summary>Details</summary>
Motivation: 非平稳环境中，时间序列的模式会随时间变化，这给预测带来了挑战。为了解决这一问题，需要一种能够适应模式变化的预测方法。

Method: 提出了一种基于深度神经网络的框架，包括离线训练基模型、模式聚类、针对集群微调模型、相似度匹配选择模型，以及概念漂移检测机制。

Result: 该框架在不同DNN架构中表现出普适性，并在GluonTS库中实现的传统和先进架构上均取得显著性能提升。

Conclusion: 通过模型适应和选择机制，该框架有效提升了非平稳环境中时间序列预测的准确性和适应性。

Abstract: Time series forecasting poses significant challenges in non-stationary
environments where underlying patterns evolve over time. In this work, we
propose a novel framework that enhances deep neural network (DNN) performance
by leveraging specialized model adaptation and selection. Initially, a base DNN
is trained offline on historical time series data. A reserved validation subset
is then segmented to extract and cluster the most dominant patterns within the
series, thereby identifying distinct regimes. For each identified cluster, the
base DNN is fine-tuned to produce a specialized version that captures unique
pattern characteristics. At inference, the most recent input is matched against
the cluster centroids, and the corresponding fine-tuned version is deployed
based on the closest similarity measure. Additionally, our approach integrates
a concept drift detection mechanism to identify and adapt to emerging patterns
caused by non-stationary behavior. The proposed framework is generalizable
across various DNN architectures and has demonstrated significant performance
gains on both traditional DNNs and recent advanced architectures implemented in
the GluonTS library.

</details>


### [363] [Shapley-Inspired Feature Weighting in $k$-means with No Additional Hyperparameters](https://arxiv.org/abs/2508.07952)
*Richard J. Fawley,Renato Cordeiro de Amorim*

Main category: cs.LG

TL;DR: 提出了一种名为SHARK的特征加权聚类算法，利用Shapley值量化特征相关性，无需额外参数调整，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统聚类算法假设所有特征对数据结构贡献均等，这在噪声或高维场景中不成立，需要无需额外参数调优的特征加权方法。

Method: SHARK通过Shapley值分解k均值目标，将计算复杂度降至多项式时间，并按Shapley贡献动态调整特征权重。

Result: 实验显示SHARK在合成和真实数据集上表现优于现有方法，尤其在噪声场景中更具鲁棒性和准确性。

Conclusion: SHARK为无监督特征相关性提供了理论支持，并在实践中展现出优越性能。

Abstract: Clustering algorithms often assume all features contribute equally to the
data structure, an assumption that usually fails in high-dimensional or noisy
settings. Feature weighting methods can address this, but most require
additional parameter tuning. We propose SHARK (Shapley Reweighted $k$-means), a
feature-weighted clustering algorithm motivated by the use of Shapley values
from cooperative game theory to quantify feature relevance, which requires no
additional parameters beyond those in $k$-means. We prove that the $k$-means
objective can be decomposed into a sum of per-feature Shapley values, providing
an axiomatic foundation for unsupervised feature relevance and reducing Shapley
computation from exponential to polynomial time. SHARK iteratively re-weights
features by the inverse of their Shapley contribution, emphasising informative
dimensions and down-weighting irrelevant ones. Experiments on synthetic and
real-world data sets show that SHARK consistently matches or outperforms
existing methods, achieving superior robustness and accuracy, particularly in
scenarios where noise may be present. Software:
https://github.com/rickfawley/shark.

</details>


### [364] [WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer](https://arxiv.org/abs/2508.07970)
*Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao*

Main category: cs.LG

TL;DR: 论文摘要简要概述了WeChat-YATT框架，解决了RLHF训练在复杂多模态工作流和动态负载中的挑战。


<details>
  <summary>Details</summary>
Motivation: RLHF训练在处理复杂多模态工作流和动态负载时存在控制器的可扩展性和效率问题。

Method: 提出了WeChat-YATT框架，采用并行控制器编程模型和动态资源分配策略。

Result: 实验表明，WeChat-YATT在吞吐量上优于现有框架，并在微信产品中成功部署。

Conclusion: WeChat-YATT为RLHF训练提供了一个高效、可扩展的解决方案，适用于实际应用场景。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has emerged as a prominent
paradigm for training large language models and multimodal systems. Despite
notable advances enabled by existing RLHF training frameworks, significant
challenges remain in scaling to complex multimodal workflows and adapting to
dynamic workloads. In particular, current systems often encounter limitations
related to controller scalability when managing large models, as well as
inefficiencies in orchestrating intricate RLHF pipelines, especially in
scenarios that require dynamic sampling and resource allocation. In this paper,
we introduce WeChat-YATT (Yet Another Transformer Trainer in WeChat), a simple,
scalable, and balanced RLHF training framework specifically designed to address
these challenges. WeChat-YATT features a parallel controller programming model
that enables flexible and efficient orchestration of complex RLHF workflows,
effectively mitigating the bottlenecks associated with centralized controller
architectures and facilitating scalability in large-scale data scenarios. In
addition, we propose a dynamic placement schema that adaptively partitions
computational resources and schedules workloads, thereby significantly reducing
hardware idle time and improving GPU utilization under variable training
conditions. We evaluate WeChat-YATT across a range of experimental scenarios,
demonstrating that it achieves substantial improvements in throughput compared
to state-of-the-art RLHF training frameworks. Furthermore, WeChat-YATT has been
successfully deployed to train models supporting WeChat product features for a
large-scale user base, underscoring its effectiveness and robustness in
real-world applications.

</details>


### [365] [A Physics-informed Deep Operator for Real-Time Freeway Traffic State Estimation](https://arxiv.org/abs/2508.08002)
*Hongxin Yu,Yibing Wang,Fengyue Jin,Meng Zhang,Anni Chen*

Main category: cs.LG

TL;DR: 论文提出了一种基于物理知识的深度算子网络（PI-DeepONet）的实时高速公路交通状态估计方法，结合模型与数据的双重驱动优势，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 交通状态估计（TSE）现有方法分为模型驱动和数据驱动两类，各有优缺点。研究旨在结合两者优势，提出一种更精确的实时TSE方法。

Method: 扩展了原始的PI-DeepONet架构，支持2D数据输入，引入非线性扩展层、注意力机制和MIMO机制，并设计了自适应识别交通流模型参数的神经网络。

Result: 在NGSIM短路段和中国大规模城市快速路上的实验表明，该方法在流量和平均速度估计上优于四种基线方法，结果更精确。

Conclusion: 扩展的PI-DeepONet架构为交通状态估计提供了一种高效且高精度的方法，结合了模型与数据的优势。

Abstract: Traffic state estimation (TSE) falls methodologically into three categories:
model-driven, data-driven, and model-data dual-driven. Model-driven TSE relies
on macroscopic traffic flow models originated from hydrodynamics. Data-driven
TSE leverages historical sensing data and employs statistical models or machine
learning methods to infer traffic state. Model-data dual-driven traffic state
estimation attempts to harness the strengths of both aspects to achieve more
accurate TSE. From the perspective of mathematical operator theory, TSE can be
viewed as a type of operator that maps available measurements of inerested
traffic state into unmeasured traffic state variables in real time. For the
first time this paper proposes to study real-time freeway TSE in the idea of
physics-informed deep operator network (PI-DeepONet), which is an
operator-oriented architecture embedding traffic flow models based on deep
neural networks. The paper has developed an extended architecture from the
original PI-DeepONet. The extended architecture is featured with: (1) the
acceptance of 2-D data input so as to support CNN-based computations; (2) the
introduction of a nonlinear expansion layer, an attention mechanism, and a MIMO
mechanism; (3) dedicated neural network design for adaptive identification of
traffic flow model parameters. A traffic state estimator built on the basis of
this extended PI-DeepONet architecture was evaluated with respect to a short
freeway stretch of NGSIM and a large-scale urban expressway in China, along
with other four baseline TSE methods. The evaluation results demonstrated that
this novel TSE method outperformed the baseline methods with high-precision
estimation results of flow and mean speed.

</details>


### [366] [Learning to Select MCP Algorithms: From Traditional ML to Dual-Channel GAT-MLP](https://arxiv.org/abs/2508.08005)
*Xiang Li,Shanshan Wang,Chenglong Xiao*

Main category: cs.LG

TL;DR: 提出一种学习型框架，结合传统机器学习和图神经网络，解决最大团问题的算法选择难题。实验表明随机森林表现稳定，而双通道GAT-MLP模型性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏针对最大团问题的算法选择方法，导致无法根据实例特征选择最优算法。

Method: 构建标记数据集，评估四种传统分类器，并设计双通道GAT-MLP模型结合图注意力网络和多层感知机。

Result: 随机森林表现稳定，GAT-MLP模型在所有指标上表现优异，验证了双通道架构的有效性。

Conclusion: 双通道架构和图神经网络在组合算法选择中具有潜力，可为最大团问题提供高效的算法选择方案。

Abstract: Extensive experiments and prior studies show that no single maximum clique
algorithm consistently performs best across all instances, highlighting the
importance of selecting suitable algorithms based on instance features. Through
an extensive analysis of relevant studies, it is found that there is a lack of
research work concerning algorithm selection oriented toward the Maximum Clique
Problem (MCP). In this work, we propose a learning-based framework that
integrates both traditional machine learning and graph neural networks to
address this gap. We construct a labeled dataset by running four exact MCP
algorithms on a diverse collection of graph instances, accompanied by
structural and global statistical features extracted from each graph. We first
evaluate four conventional classifiers: Support Vector Machine (SVM), Random
Forest (RF), Decision Tree (DT), and K-Nearest Neighbors (KNN), across multiple
dataset variants. Experimental results show that RF consistently shows strong
performance across metrics and dataset variants, making it a reliable baseline.
In addition, feature importance analysis indicates that connectivity and
topological structure are strong predictors of algorithm performance. Building
on these findings, we develop a dual-channel model named GAT-MLP, which
combines a Graph Attention Network (GAT) for local structural encoding with a
Multilayer Perceptron (MLP) for global feature modeling. The GAT-MLP model
shows strong and consistent performance across all metrics. Our results
highlight the effectiveness of dual-channel architectures and the promise of
graph neural networks in combinatorial algorithm selection.

</details>


### [367] [Communication-Efficient Zero-Order and First-Order Federated Learning Methods over Wireless Networks](https://arxiv.org/abs/2508.08013)
*Mohamad Assaad,Zeinab Nehme,Merouane Debbah*

Main category: cs.LG

TL;DR: 论文提出了两种通信高效的联邦学习方法，通过减少通信开销并支持多用户同时传输信息，优化了无线系统中的FL性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在无线系统中的通信开销过高，限制了其应用范围。本文旨在解决这一问题。

Method: 使用零阶优化技术（两点梯度估计器）和一阶梯度计算策略，利用信道信息，无需额外获取CSI资源。

Result: 提供了两种方法的严格分析框架，推导了收敛保证和性能界限。

Conclusion: 所提方法显著减少了通信开销，同时支持异步设备，提升了FL在无线系统中的可行性。

Abstract: Federated Learning (FL) is an emerging learning framework that enables edge
devices to collaboratively train ML models without sharing their local data. FL
faces, however, a significant challenge due to the high amount of information
that must be exchanged between the devices and the aggregator in the training
phase, which can exceed the limited capacity of wireless systems. In this
paper, two communication-efficient FL methods are considered where
communication overhead is reduced by communicating scalar values instead of
long vectors and by allowing high number of users to send information
simultaneously. The first approach employs a zero-order optimization technique
with two-point gradient estimator, while the second involves a first-order
gradient computation strategy. The novelty lies in leveraging channel
information in the learning algorithms, eliminating hence the need for
additional resources to acquire channel state information (CSI) and to remove
its impact, as well as in considering asynchronous devices. We provide a
rigorous analytical framework for the two methods, deriving convergence
guarantees and establishing appropriate performance bounds.

</details>


### [368] [Deep Learning-Based Analysis of Power Consumption in Gasoline, Electric, and Hybrid Vehicles](https://arxiv.org/abs/2508.08034)
*Roksana Yahyaabadi,Ghazal Farhani,Taufiq Rahman,Soodeh Nikan,Abdullah Jirjees,Fadi Araji*

Main category: cs.LG

TL;DR: 论文提出了一种基于数据驱动的可扩展方法，通过动力系统动态特征集和机器学习技术预测内燃机、电动车和混合动力车的瞬时及累计功耗。


<details>
  <summary>Details</summary>
Motivation: 传统功耗预测方法因依赖专业仪器或固定物理模型而难以大规模部署，需一种更高效且广泛适用的解决方案。

Method: 结合动力系统动态特征集，使用传统机器学习和深度神经网络模型进行功耗估计。

Result: 内燃机瞬时误差低至$10^{-3}$，累计误差<3%；电动车和混合动力车累计误差分别低于4.1%和2.1%。

Conclusion: 该方法在多种车型上表现优异，但电动车和混合动力车因复杂动力管理需更鲁棒的模型。

Abstract: Accurate power consumption prediction is crucial for improving efficiency and
reducing environmental impact, yet traditional methods relying on specialized
instruments or rigid physical models are impractical for large-scale,
real-world deployment. This study introduces a scalable data-driven method
using powertrain dynamic feature sets and both traditional machine learning and
deep neural networks to estimate instantaneous and cumulative power consumption
in internal combustion engine (ICE), electric vehicle (EV), and hybrid electric
vehicle (HEV) platforms. ICE models achieved high instantaneous accuracy with
mean absolute error and root mean squared error on the order of $10^{-3}$, and
cumulative errors under 3%. Transformer and long short-term memory models
performed best for EVs and HEVs, with cumulative errors below 4.1% and 2.1%,
respectively. Results confirm the approach's effectiveness across vehicles and
models. Uncertainty analysis revealed greater variability in EV and HEV
datasets than ICE, due to complex power management, emphasizing the need for
robust models for advanced powertrains.

</details>


### [369] [BadPromptFL: A Novel Backdoor Threat to Prompt-based Federated Learning in Multimodal Models](https://arxiv.org/abs/2508.08040)
*Maozhen Zhang,Mengnan Zhao,Bo Wang*

Main category: cs.LG

TL;DR: Prompt-based federated学习在视觉-语言模型中提供高效适应，但安全风险未被充分探索。本文提出BadPromptFL，一种针对多模态对比模型的后门攻击方法，通过优化本地后门触发器和提示嵌入注入毒化提示，攻击成功率高且隐蔽。


<details>
  <summary>Details</summary>
Motivation: 探讨提示聚合在联邦多模态学习中的安全风险，强调后门攻击的实际威胁。

Method: 提出BadPromptFL，利用CLIP式架构的上下文学习行为，联合优化本地后门触发器和提示嵌入注入毒化提示。

Result: 实验证明攻击成功率超过90%，且具有隐蔽性和通用性。

Conclusion: 揭示了提示联邦学习的脆弱性，呼吁加强现实部署中的鲁棒性。

Abstract: Prompt-based tuning has emerged as a lightweight alternative to full
fine-tuning in large vision-language models, enabling efficient adaptation via
learned contextual prompts. This paradigm has recently been extended to
federated learning settings (e.g., PromptFL), where clients collaboratively
train prompts under data privacy constraints. However, the security
implications of prompt-based aggregation in federated multimodal learning
remain largely unexplored, leaving a critical attack surface unaddressed. In
this paper, we introduce \textbf{BadPromptFL}, the first backdoor attack
targeting prompt-based federated learning in multimodal contrastive models. In
BadPromptFL, compromised clients jointly optimize local backdoor triggers and
prompt embeddings, injecting poisoned prompts into the global aggregation
process. These prompts are then propagated to benign clients, enabling
universal backdoor activation at inference without modifying model parameters.
Leveraging the contextual learning behavior of CLIP-style architectures,
BadPromptFL achieves high attack success rates (e.g., \(>90\%\)) with minimal
visibility and limited client participation. Extensive experiments across
multiple datasets and aggregation protocols validate the effectiveness,
stealth, and generalizability of our attack, raising critical concerns about
the robustness of prompt-based federated learning in real-world deployments.

</details>


### [370] [On Understanding of the Dynamics of Model Capacity in Continual Learning](https://arxiv.org/abs/2508.08052)
*Supriyo Chakraborty,Krishnan Raghavan*

Main category: cs.LG

TL;DR: 论文提出了一种称为CLEMC的方法，用于动态描述持续学习中的稳定性与可塑性平衡点，并通过实验验证了不同任务分布对神经网络表示能力的影响。


<details>
  <summary>Details</summary>
Motivation: 解决持续学习中的稳定性与可塑性平衡问题，研究神经网络在不同任务分布下的动态能力变化。

Method: 提出CLEMC概念，建立差分方程建模神经网络、任务数据和优化过程的动态交互。

Result: 有效容量和非平稳的平衡点特性得到了理论支持，并通过多种架构的实验验证。

Conclusion: 无论网络架构或优化方法如何，任务分布的差异都会影响神经网络的表示能力。

Abstract: The stability-plasticity dilemma, closely related to a neural network's (NN)
capacity-its ability to represent tasks-is a fundamental challenge in continual
learning (CL). Within this context, we introduce CL's effective model capacity
(CLEMC) that characterizes the dynamic behavior of the stability-plasticity
balance point. We develop a difference equation to model the evolution of the
interplay between the NN, task data, and optimization procedure. We then
leverage CLEMC to demonstrate that the effective capacity-and, by extension,
the stability-plasticity balance point is inherently non-stationary. We show
that regardless of the NN architecture or optimization method, a NN's ability
to represent new tasks diminishes when incoming task distributions differ from
previous ones. We conduct extensive experiments to support our theoretical
findings, spanning a range of architectures-from small feedforward network and
convolutional networks to medium-sized graph neural networks and
transformer-based large language models with millions of parameters.

</details>


### [371] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 该论文提出了一种基于迁移学习的预测性过程监控（PPM）技术，帮助缺乏足够事件数据的组织实现有效的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有PPM技术需要大量事件数据，而许多组织缺乏这些资源，因此需探索无需大量数据的方法。

Method: 提出基于迁移学习的PPM技术，将源业务流程的知识迁移到目标业务流程，并在IT服务管理的跨组织场景中进行了实例化与实验。

Result: 实验表明，在跨组织设置中，迁移学习可实现有效的PPM。

Conclusion: 该技术为组织提供了在跨环境条件下利用预训练模型进行PPM的新途径。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [372] [C-MAG: Cascade Multimodal Attributed Graphs for Supply Chain Link Prediction](https://arxiv.org/abs/2508.08071)
*Yunqing Li,Zixiang Tang,Jiaying Zhuang,Zhenyu Yang,Farhad Ameri,Jianbang Zhang*

Main category: cs.LG

TL;DR: 论文提出了PMGraph基准和C-MAG模型，用于解决供应链中制造商与产品匹配的复杂问题，通过多模态数据融合和图表示学习提升链接预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉供应链中复杂的制造商能力、认证和地理约束等多模态数据，限制了匹配的效率和弹性。

Method: 提出C-MAG两阶段架构，先对齐和聚合文本与视觉属性为中间组嵌入，再通过多尺度消息传递在图结构中传播，提升链接预测。

Result: C-MAG在多模态供应链图上表现出色，提供了噪声环境下模态感知融合的实用指南。

Conclusion: C-MAG为供应链中的制造商与产品匹配提供了高效且鲁棒的解决方案。

Abstract: Connecting an ever-expanding catalogue of products with suitable
manufacturers and suppliers is critical for resilient, efficient global supply
chains, yet traditional methods struggle to capture complex capabilities,
certifications, geographic constraints, and rich multimodal data of real-world
manufacturer profiles. To address these gaps, we introduce PMGraph, a public
benchmark of bipartite and heterogeneous multimodal supply-chain graphs linking
8,888 manufacturers, over 70k products, more than 110k manufacturer-product
edges, and over 29k product images. Building on this benchmark, we propose the
Cascade Multimodal Attributed Graph C-MAG, a two-stage architecture that first
aligns and aggregates textual and visual attributes into intermediate group
embeddings, then propagates them through a manufacturer-product hetero-graph
via multiscale message passing to enhance link prediction accuracy. C-MAG also
provides practical guidelines for modality-aware fusion, preserving predictive
performance in noisy, real-world settings.

</details>


### [373] [ELF: Efficient Logic Synthesis by Pruning Redundancy in Refactoring](https://arxiv.org/abs/2508.08073)
*Dimitris Tsaras,Xing Li,Lei Chen,Zhiyao Xie,Mingxuan Yuan*

Main category: cs.LG

TL;DR: 通过分类器预先剪枝无效切割，加速逻辑优化，相比ABC实现平均速度提升3.9倍。


<details>
  <summary>Details</summary>
Motivation: 逻辑优化运算计算需求高，传统方法失败率高（98%），需提升效率。

Method: 使用分类器预先识别并剪枝无效的切割，避免不必要的重合成操作。

Result: 在EPFL基准测试和10个大型工业设计中，平均速度提升3.9倍。

Conclusion: 分类器剪枝方法显著提升逻辑优化效率，适用于大规模电路设计。

Abstract: In electronic design automation, logic optimization operators play a crucial
role in minimizing the gate count of logic circuits. However, their computation
demands are high. Operators such as refactor conventionally form iterative cuts
for each node, striving for a more compact representation - a task which often
fails 98% on average. Prior research has sought to mitigate computational cost
through parallelization. In contrast, our approach leverages a classifier to
prune unsuccessful cuts preemptively, thus eliminating unnecessary resynthesis
operations. Experiments on the refactor operator using the EPFL benchmark suite
and 10 large industrial designs demonstrate that this technique can speedup
logic optimization by 3.9x on average compared with the state-of-the-art ABC
implementation.

</details>


### [374] [Symbolic Quantile Regression for the Interpretable Prediction of Conditional Quantiles](https://arxiv.org/abs/2508.08080)
*Cas Oude Hoekstra,Floris den Hengst*

Main category: cs.LG

TL;DR: 该论文提出了符号分位数回归（SQR），用于预测条件分位数，并在透明性和性能上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前符号回归（SR）主要用于预测目标的平均值，但缺乏对其他分布点（如中位数或极值）的估计方法。SQR旨在填补这一空白。

Method: 提出SQR方法，通过符号回归预测条件分位数，并在航空燃油案例中验证其效果。

Result: SQR在透明模型中表现最佳，与黑盒基线模型性能相当，且能解释目标分布差异。

Conclusion: SQR适用于预测条件分位数，并能帮助理解不同分位数的特征影响。

Abstract: Symbolic Regression (SR) is a well-established framework for generating
interpretable or white-box predictive models. Although SR has been successfully
applied to create interpretable estimates of the average of the outcome, it is
currently not well understood how it can be used to estimate the relationship
between variables at other points in the distribution of the target variable.
Such estimates of e.g. the median or an extreme value provide a fuller picture
of how predictive variables affect the outcome and are necessary in
high-stakes, safety-critical application domains. This study introduces
Symbolic Quantile Regression (SQR), an approach to predict conditional
quantiles with SR. In an extensive evaluation, we find that SQR outperforms
transparent models and performs comparably to a strong black-box baseline
without compromising transparency. We also show how SQR can be used to explain
differences in the target distribution by comparing models that predict extreme
and central outcomes in an airline fuel usage case study. We conclude that SQR
is suitable for predicting conditional quantiles and understanding interesting
feature influences at varying quantiles.

</details>


### [375] [Fast and Generalizable parameter-embedded Neural Operators for Lithium-Ion Battery Simulation](https://arxiv.org/abs/2508.08087)
*Amir Ali Panahi,Daniel Luder,Billy Wu,Gregory Offer,Dirk Uwe Sauer,Weihan Li*

Main category: cs.LG

TL;DR: 本文比较了三种用于锂离子电池数字孪生的算子学习替代模型，提出了一种新方法PE-FNO，在保持高速度和物理保真度的同时，展现出优异的性能和参数灵活性。


<details>
  <summary>Details</summary>
Motivation: 为实现锂离子电池数字孪生的高物理保真度和亚毫秒级速度，研究评估了三种算子学习方法的性能。

Method: 训练了DeepONet、FNO和新提出的PE-FNO模型，通过模拟四种电流负载和全SOC范围的轨迹来测试性能。

Result: PE-FNO在速度和精度上优于传统方法，能快速执行并支持参数估计，误差相对较低。

Conclusion: PE-FNO为实时电池管理和大规模推理提供了高保真度和高速的解决方案。

Abstract: Reliable digital twins of lithium-ion batteries must achieve high physical
fidelity with sub-millisecond speed. In this work, we benchmark three
operator-learning surrogates for the Single Particle Model (SPM): Deep Operator
Networks (DeepONets), Fourier Neural Operators (FNOs) and a newly proposed
parameter-embedded Fourier Neural Operator (PE-FNO), which conditions each
spectral layer on particle radius and solid-phase diffusivity. Models are
trained on simulated trajectories spanning four current families (constant,
triangular, pulse-train, and Gaussian-random-field) and a full range of
State-of-Charge (SOC) (0 % to 100 %). DeepONet accurately replicates
constant-current behaviour but struggles with more dynamic loads. The basic FNO
maintains mesh invariance and keeps concentration errors below 1 %, with
voltage mean-absolute errors under 1.7 mV across all load types. Introducing
parameter embedding marginally increases error, but enables generalisation to
varying radii and diffusivities. PE-FNO executes approximately 200 times faster
than a 16-thread SPM solver. Consequently, PE-FNO's capabilities in inverse
tasks are explored in a parameter estimation task with Bayesian optimisation,
recovering anode and cathode diffusivities with 1.14 % and 8.4 % mean absolute
percentage error, respectively, and 0.5918 percentage points higher error in
comparison with classical methods. These results pave the way for neural
operators to meet the accuracy, speed and parametric flexibility demands of
real-time battery management, design-of-experiments and large-scale inference.
PE-FNO outperforms conventional neural surrogates, offering a practical path
towards high-speed and high-fidelity electrochemical digital twins.

</details>


### [376] [Grid2Guide: A* Enabled Small Language Model for Indoor Navigation](https://arxiv.org/abs/2508.08100)
*Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: Grid2Guide结合A*搜索算法和小型语言模型（SLM）生成清晰的自然语言导航指令，提供轻量级、无基础设施的实时室内导航方案。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中缺少外部定位信号和专用基础设施，室内导航面临挑战。

Method: 利用二元占用矩阵和A*算法计算最优路径，并通过SLM转换为自然语言指令。

Result: 实验验证该方法能生成准确、及时的导航指引。

Conclusion: Grid2Guide是一种有效的轻量级解决方案，适用于无基础设施的室内导航。

Abstract: Reliable indoor navigation remains a significant challenge in complex
environments, particularly where external positioning signals and dedicated
infrastructures are unavailable. This research presents Grid2Guide, a hybrid
navigation framework that combines the A* search algorithm with a Small
Language Model (SLM) to generate clear, human-readable route instructions. The
framework first conducts a binary occupancy matrix from a given indoor map.
Using this matrix, the A* algorithm computes the optimal path between origin
and destination, producing concise textual navigation steps. These steps are
then transformed into natural language instructions by the SLM, enhancing
interpretability for end users. Experimental evaluations across various indoor
scenarios demonstrate the method's effectiveness in producing accurate and
timely navigation guidance. The results validate the proposed approach as a
lightweight, infrastructure-free solution for real-time indoor navigation
support.

</details>


### [377] [Vision-Based Localization and LLM-based Navigation for Indoor Environments](https://arxiv.org/abs/2508.08120)
*Keyan Rahimi,Md. Wasiul Haque,Sagar Dasgupta,Mizanur Rahman*

Main category: cs.LG

TL;DR: 论文提出了一种结合视觉定位和大语言模型（LLM）导航的室内导航方法，通过智能手机摄像头和预处理地图实现高精度定位与导航。


<details>
  <summary>Details</summary>
Motivation: 解决因GPS信号不可靠和建筑复杂性导致的室内导航难题。

Method: 使用ResNet-50进行视觉定位，结合LLM生成导航指令。

Result: 定位准确率96%，导航指令平均准确率75%。

Conclusion: 该方法展示了利用普通摄像头和公开地图实现无基础设施室内导航的潜力。

Abstract: Indoor navigation remains a complex challenge due to the absence of reliable
GPS signals and the architectural intricacies of large enclosed environments.
This study presents an indoor localization and navigation approach that
integrates vision-based localization with large language model (LLM)-based
navigation. The localization system utilizes a ResNet-50 convolutional neural
network fine-tuned through a two-stage process to identify the user's position
using smartphone camera input. To complement localization, the navigation
module employs an LLM, guided by a carefully crafted system prompt, to
interpret preprocessed floor plan images and generate step-by-step directions.
Experimental evaluation was conducted in a realistic office corridor with
repetitive features and limited visibility to test localization robustness. The
model achieved high confidence and an accuracy of 96% across all tested
waypoints, even under constrained viewing conditions and short-duration
queries. Navigation tests using ChatGPT on real building floor maps yielded an
average instruction accuracy of 75%, with observed limitations in zero-shot
reasoning and inference time. This research demonstrates the potential for
scalable, infrastructure-free indoor navigation using off-the-shelf cameras and
publicly available floor plans, particularly in resource-constrained settings
like hospitals, airports, and educational institutions.

</details>


### [378] [MemoryKT: An Integrative Memory-and-Forgetting Method for Knowledge Tracing](https://arxiv.org/abs/2508.08122)
*Mingrong Lin,Ke Deng,Zhengyang Wu,Zetao Zheng,Jie Li*

Main category: cs.LG

TL;DR: 提出一种基于时序变分自编码器的知识追踪模型memoryKT，通过三阶段过程模拟记忆动态，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型依赖单一遗忘机制，忽视了其他记忆过程及个性化遗忘模式。

Method: 采用时序变分自编码器，分三阶段建模：知识记忆特征分布学习、习题反馈重建、个性化遗忘模块嵌入。

Result: 在四个公开数据集上显著优于现有基线模型。

Conclusion: memoryKT通过完整编码-存储-检索循环建模，增强了对个体差异的感知能力。

Abstract: Knowledge Tracing (KT) is committed to capturing students' knowledge mastery
from their historical interactions. Simulating students' memory states is a
promising approach to enhance both the performance and interpretability of
knowledge tracing models. Memory consists of three fundamental processes:
encoding, storage, and retrieval. Although forgetting primarily manifests
during the storage stage, most existing studies rely on a single,
undifferentiated forgetting mechanism, overlooking other memory processes as
well as personalized forgetting patterns. To address this, this paper proposes
memoryKT, a knowledge tracing model based on a novel temporal variational
autoencoder. The model simulates memory dynamics through a three-stage process:
(i) Learning the distribution of students' knowledge memory features, (ii)
Reconstructing their exercise feedback, while (iii) Embedding a personalized
forgetting module within the temporal workflow to dynamically modulate memory
storage strength. This jointly models the complete encoding-storage-retrieval
cycle, significantly enhancing the model's perception capability for individual
differences. Extensive experiments on four public datasets demonstrate that our
proposed approach significantly outperforms state-of-the-art baselines.

</details>


### [379] [NeuroDx-LM: A Clinical Large-Scale Model for EEG-based Neurological Disorder Detection](https://arxiv.org/abs/2508.08124)
*Guanghao Jin,Yuan Liang,Yihan Ma,Jingpei Wu,Guoyang Liu*

Main category: cs.LG

TL;DR: NeuroDx-LM 是一种新型大规模模型，旨在通过选择性时频嵌入和渐进特征感知训练策略，解决 EEG 数据标记不足和性能不佳的问题，并在癫痫和精神分裂症检测中取得领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有 EEG 大规模模型在临床应用中面临标记数据不足和性能不佳的挑战，需要更高效的方法来优化 EEG 信号的模式捕捉和特征提取。

Method: NeuroDx-LM 采用选择性时频嵌入机制和两阶段的渐进特征感知训练策略，先学习 EEG 基础特征，再提取细粒度特征以提高诊断准确性。

Result: 在 CHB-MIT 和 Schizophrenia 数据集上，NeuroDx-LM 实现了癫痫和精神分裂症检测的最先进性能。

Conclusion: NeuroDx-LM 展示了 EEG 大规模模型在临床诊断中的潜力，为 EEG 信号的复杂模式捕捉和高效特征提取提供了新思路。

Abstract: Large-scale models pre-trained on Electroencephalography (EEG) have shown
promise in clinical applications such as neurological disorder detection.
However, the practical deployment of EEG-based large-scale models faces
critical challenges such as limited labeled EEG data and suboptimal performance
in clinical scenarios. To address these issues, we propose NeuroDx-LM, a novel
large-scale model specifically designed for detecting EEG-based neurological
disorders. Our key contributions include (i) a Selective Temporal-Frequency
Embedding mechanism that adaptively captures complex temporal and spectral
patterns in EEG signals; and (ii) a Progressive Feature-Aware Training strategy
that refines feature representation in a two-stage process. In the first stage,
our model learns the fundamental discriminative features of EEG activities; in
the second stage, the model further extracts more specialized fine-grained
features for accurate diagnostic performance. We evaluated NeuroDx-LM on the
CHB-MIT and Schizophrenia datasets, achieving state-of-the-art performance in
EEG-based seizure and schizophrenia detection, respectively. These results
demonstrate the great potential of EEG-based large-scale models to advance
clinical applicability. Our code is available at
https://github.com/LetItBe12345/NeuroDx-LM.

</details>


### [380] [OFAL: An Oracle-Free Active Learning Framework](https://arxiv.org/abs/2508.08126)
*Hadi Khorsand,Vahid Pourahmadi*

Main category: cs.LG

TL;DR: OFAL是一种无需人工标注的主动学习方法，通过利用神经网络的自身不确定性来生成信息丰富的样本，从而提升模型准确性。


<details>
  <summary>Details</summary>
Motivation: 传统主动学习依赖人工标注，成本高且复杂，希望能够在不依赖人工标注的情况下提升学习效果。

Method: 通过蒙特卡洛dropout量化模型不确定性，并利用变分自编码器从潜在空间生成不确定性样本。

Result: OFAL能够生成信息丰富的样本，提升模型准确性。

Conclusion: OFAL为主动学习提供了一种无需人工标注的高效替代方案。

Abstract: In the active learning paradigm, using an oracle to label data has always
been a complex and expensive task, and with the emersion of large unlabeled
data pools, it would be highly beneficial If we could achieve better results
without relying on an oracle. This research introduces OFAL, an oracle-free
active learning scheme that utilizes neural network uncertainty. OFAL uses the
model's own uncertainty to transform highly confident unlabeled samples into
informative uncertain samples. First, we start with separating and quantifying
different parts of uncertainty and introduce Monte Carlo Dropouts as an
approximation of the Bayesian Neural Network model. Secondly, by adding a
variational autoencoder, we go on to generate new uncertain samples by stepping
toward the uncertain part of latent space starting from a confidence seed
sample. By generating these new informative samples, we can perform active
learning and enhance the model's accuracy. Lastly, we try to compare and
integrate our method with other widely used active learning sampling methods.

</details>


### [381] [MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation](https://arxiv.org/abs/2508.08137)
*Pravallika Abbineni,Saoud Aldowaish,Colin Liechty,Soroosh Noorzad,Ali Ghazizadeh,Morteza Fayazi*

Main category: cs.LG

TL;DR: 该论文提出了MuaLLM，一种用于电路设计辅助的多模态大型语言模型（LLM）代理，结合了混合检索增强生成（RAG）框架和自适应电路设计文献向量数据库，显著提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 电路设计领域的文献综述因数据量大、表征不一致和设计目标复杂而极具挑战性。需要一种高效的工具来辅助研究人员整合和分析文献。

Method: MuaLLM采用Reason + Act（ReAct）工作流，结合多模态数据处理能力，支持文本和视觉数据的分析与推理，并利用动态检索工具和实时数据库更新。

Result: MuaLLM在RAG-250数据集上实现90.1%的召回率，在Reas-100数据集上达到86.8%的准确率，且成本更低、速度更快。

Conclusion: MuaLLM通过解耦检索与推理，克服了传统LLM的局限性，为电路设计提供了高效、低成本的文献分析与设计辅助工具。

Abstract: Conducting a comprehensive literature review is crucial for advancing circuit
design methodologies. However, the rapid influx of state-of-the-art research,
inconsistent data representation, and the complexity of optimizing circuit
design objectives make this task significantly challenging. In this paper, we
propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for
circuit design assistance that integrates a hybrid Retrieval-Augmented
Generation (RAG) framework with an adaptive vector database of circuit design
research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason +
Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step
information retrieval. It functions as a question-answering design assistant,
capable of interpreting complex queries and providing reasoned responses
grounded in circuit literature. Its multimodal capabilities enable processing
of both textual and visual data, facilitating more efficient and comprehensive
analysis. The system dynamically adapts using intelligent search tools,
automated document retrieval from the internet, and real-time database updates.
Unlike conventional approaches constrained by model context limits, MuaLLM
decouples retrieval from inference, enabling scalable reasoning over
arbitrarily large corpora. At the maximum context length supported by standard
LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining
the same accuracy. This allows rapid, no-human-in-the-loop database generation,
overcoming the bottleneck of simulation-based dataset creation for circuits. To
evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval
and citation performance, and Reasoning-100 (Reas-100), focused on multistep
reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8%
accuracy on Reas-100.

</details>


### [382] [FairFLRep: Fairness aware fault localization and repair of Deep Neural Networks](https://arxiv.org/abs/2508.08151)
*Moses Openja,Paolo Arcaini,Foutse Khomh,Fuyuki Ishikawa*

Main category: cs.LG

TL;DR: FairFLRep是一种自动化的公平性感知故障定位与修复技术，通过调整与敏感属性相关的神经元权重，改善DNN分类器的公平性。


<details>
  <summary>Details</summary>
Motivation: DNN在决策应用中可能放大数据中的偏见，导致不公平的分类结果，例如不同种族的误分类率差异。当前缺乏高效识别和纠正偏见的方法。

Method: FairFLRep通过分析网络中与敏感属性（如种族或性别）相关的神经元权重，定位并修复导致公平性差异的神经元。

Result: 在多个数据集和DNN模型上的实验表明，FairFLRep在提升公平性的同时保持了准确性，且效率高于基线方法。

Conclusion: FairFLRep通过综合考虑公平性的故障定位与修复，有效提高了DNN的公平性，为消除偏见提供了一种高效解决方案。

Abstract: Deep neural networks (DNNs) are being utilized in various aspects of our
daily lives, including high-stakes decision-making applications that impact
individuals. However, these systems reflect and amplify bias from the data used
during training and testing, potentially resulting in biased behavior and
inaccurate decisions. For instance, having different misclassification rates
between white and black sub-populations. However, effectively and efficiently
identifying and correcting biased behavior in DNNs is a challenge. This paper
introduces FairFLRep, an automated fairness-aware fault localization and repair
technique that identifies and corrects potentially bias-inducing neurons in DNN
classifiers. FairFLRep focuses on adjusting neuron weights associated with
sensitive attributes, such as race or gender, that contribute to unfair
decisions. By analyzing the input-output relationships within the network,
FairFLRep corrects neurons responsible for disparities in predictive quality
parity. We evaluate FairFLRep on four image classification datasets using two
DNN classifiers, and four tabular datasets with a DNN model. The results show
that FairFLRep consistently outperforms existing methods in improving fairness
while preserving accuracy. An ablation study confirms the importance of
considering fairness during both fault localization and repair stages. Our
findings also show that FairFLRep is more efficient than the baseline
approaches in repairing the network.

</details>


### [383] [Federated Learning for Epileptic Seizure Prediction Across Heterogeneous EEG Datasets](https://arxiv.org/abs/2508.08159)
*Cem Ata Baykara,Saurav Raj Pandey,Ali Burak Ünal,Harlin Lee,Mete Akgün*

Main category: cs.LG

TL;DR: 该论文提出了一种随机子集聚合策略，用于在异构多中心的癫痫发作预测中改进联邦学习的公平性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决癫痫发作预测模型在多个临床站点间训练的隐私保护和数据异质性（非IID特性）问题，并提出一种公平的联邦学习方法。

Method: 采用隐私保护的全局归一化和随机子集聚合策略，每轮训练中客户端使用固定大小的随机数据子集，确保公平贡献。

Result: 随机子集聚合显著提高了代表性不足的客户端的性能（赫尔辛基数据集准确率从50.8%提升至81.7%，NCH从50.6%提升至68.7%），并实现宏观平均准确率77.1%和总准确率80.0%。

Conclusion: 平衡的联邦学习方法在保护隐私的同时，能在异质多医院环境中构建更鲁棒、公平的癫痫发作预测系统。

Abstract: Developing accurate and generalizable epileptic seizure prediction models
from electroencephalography (EEG) data across multiple clinical sites is
hindered by patient privacy regulations and significant data heterogeneity
(non-IID characteristics). Federated Learning (FL) offers a privacy-preserving
framework for collaborative training, but standard aggregation methods like
Federated Averaging (FedAvg) can be biased by dominant datasets in
heterogeneous settings. This paper investigates FL for seizure prediction using
a single EEG channel across four diverse public datasets (Siena, CHB-MIT,
Helsinki, NCH), representing distinct patient populations (adult, pediatric,
neonate) and recording conditions. We implement privacy-preserving global
normalization and propose a Random Subset Aggregation strategy, where each
client trains on a fixed-size random subset of its data per round, ensuring
equal contribution during aggregation. Our results show that locally trained
models fail to generalize across sites, and standard weighted FedAvg yields
highly skewed performance (e.g., 89.0% accuracy on CHB-MIT but only 50.8% on
Helsinki and 50.6% on NCH). In contrast, Random Subset Aggregation
significantly improves performance on under-represented clients (accuracy
increases to 81.7% on Helsinki and 68.7% on NCH) and achieves a superior
macro-average accuracy of 77.1% and pooled accuracy of 80.0% across all sites,
demonstrating a more robust and fair global model. This work highlights the
potential of balanced FL approaches for building effective and generalizable
seizure prediction systems in realistic, heterogeneous multi-hospital
environments while respecting data privacy.

</details>


### [384] [Neural Logic Networks for Interpretable Classification](https://arxiv.org/abs/2508.08172)
*Vincent Perreault,Katsumi Inoue,Richard Labib,Alain Hertz*

Main category: cs.LG

TL;DR: 提出了一种可解释的逻辑神经网络，通过引入NOT操作和偏差因子，结合概率模型，改进了布尔网络的发现方法，并在医疗领域展示了其实际价值。


<details>
  <summary>Details</summary>
Motivation: 解决传统神经网络缺乏可解释性的问题，通过逻辑操作（AND、OR、NOT）和概率建模，提升模型的透明度和实用性。

Method: 提出了因子化的IF-THEN规则结构和改进的学习算法，结合逻辑与概率建模，学习输入与输出的关系。

Result: 在布尔网络发现任务中达到最先进水平，能在表格分类中学习到相关且可解释的规则，尤其在医疗领域表现突出。

Conclusion: 该方法不仅提升了模型的可解释性，还在实际应用中展示了重要价值，特别是在需要透明决策的领域。

Abstract: Traditional neural networks have an impressive classification performance,
but what they learn cannot be inspected, verified or extracted. Neural Logic
Networks on the other hand have an interpretable structure that enables them to
learn a logical mechanism relating the inputs and outputs with AND and OR
operations. We generalize these networks with NOT operations and biases that
take into account unobserved data and develop a rigorous logical and
probabilistic modeling in terms of concept combinations to motivate their use.
We also propose a novel factorized IF-THEN rule structure for the model as well
as a modified learning algorithm. Our method improves the state-of-the-art in
Boolean networks discovery and is able to learn relevant, interpretable rules
in tabular classification, notably on an example from the medical field where
interpretability has tangible value.

</details>


### [385] [Cross-Subject and Cross-Montage EEG Transfer Learning via Individual Tangent Space Alignment and Spatial-Riemannian Feature Fusion](https://arxiv.org/abs/2508.08216)
*Nicole Lai-Tan,Xiao Gu,Marios G. Philiastides,Fani Deligianni*

Main category: cs.LG

TL;DR: 该论文提出了一种名为ITSA的新策略，用于提高基于音乐的运动康复中BCI的跨受试者泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决脑机接口（BCI）在运动康复中由于受试者间EEG信号差异和运动伪影导致的泛化能力不足和校准过程冗长的问题。

Method: 提出了ITSA预对齐策略，结合了主题特定的重中心化、分布匹配和监督旋转对齐。还提出了一种融合RCSP与黎曼几何的混合架构，以提升类可分性和统计鲁棒性。

Result: ITSA在跨受试者和跨条件下的表现显著提升，尤其是并行融合方法表现最佳。

Conclusion: ITSA为BCI在个性化音乐干预中的实际应用提供了有效的解决方案，并表现出对数据和电极配置变化的鲁棒性。

Abstract: Personalised music-based interventions offer a powerful means of supporting
motor rehabilitation by dynamically tailoring auditory stimuli to provide
external timekeeping cues, modulate affective states, and stabilise gait
patterns. Generalisable Brain-Computer Interfaces (BCIs) thus hold promise for
adapting these interventions across individuals. However, inter-subject
variability in EEG signals, further compounded by movement-induced artefacts
and motor planning differences, hinders the generalisability of BCIs and
results in lengthy calibration processes. We propose Individual Tangent Space
Alignment (ITSA), a novel pre-alignment strategy incorporating subject-specific
recentering, distribution matching, and supervised rotational alignment to
enhance cross-subject generalisation. Our hybrid architecture fuses Regularised
Common Spatial Patterns (RCSP) with Riemannian geometry in parallel and
sequential configurations, improving class separability while maintaining the
geometric structure of covariance matrices for robust statistical computation.
Using leave-one-subject-out cross-validation, `ITSA' demonstrates significant
performance improvements across subjects and conditions. The parallel fusion
approach shows the greatest enhancement over its sequential counterpart, with
robust performance maintained across varying data conditions and electrode
configurations. The code will be made publicly available at the time of
publication.

</details>


### [386] [Part I: Tricks or Traps? A Deep Dive into RL for LLM Reasoning](https://arxiv.org/abs/2508.08221)
*Zihe Liu,Jiashun Liu,Yancheng He,Weixun Wang,Jiaheng Liu,Ling Pan,Xinyu Hu,Shaopan Xiong,Ju Huang,Jian Hu,Shengyi Huang,Siran Yang,Jiamang Wang,Wenbo Su,Bo Zheng*

Main category: cs.LG

TL;DR: 这篇论文系统回顾了LLM推理中的强化学习技术，通过统一框架下的实验分析，提出了技术选择指南，并发现了一种简单但高效的组合方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理中强化学习技术的研究缺乏标准化指南和统一理解，导致结论冲突和实践困惑。

Method: 采用统一的开放源码框架，通过细粒度实验分析不同技术的内部机制和适用场景。

Result: 提出了一种基于两种技术的简单组合，其性能优于GRPO和DAPO等现有策略。

Conclusion: 论文为LLM领域的强化学习技术选择提供了清晰指南，并展示了高效组合方法的潜力。

Abstract: Reinforcement learning for LLM reasoning has rapidly emerged as a prominent
research area, marked by a significant surge in related studies on both
algorithmic innovations and practical applications. Despite this progress,
several critical challenges remain, including the absence of standardized
guidelines for employing RL techniques and a fragmented understanding of their
underlying mechanisms. Additionally, inconsistent experimental settings,
variations in training data, and differences in model initialization have led
to conflicting conclusions, obscuring the key characteristics of these
techniques and creating confusion among practitioners when selecting
appropriate techniques. This paper systematically reviews widely adopted RL
techniques through rigorous reproductions and isolated evaluations within a
unified open-source framework. We analyze the internal mechanisms, applicable
scenarios, and core principles of each technique through fine-grained
experiments, including datasets of varying difficulty, model sizes, and
architectures. Based on these insights, we present clear guidelines for
selecting RL techniques tailored to specific setups, and provide a reliable
roadmap for practitioners navigating the RL for the LLM domain. Finally, we
reveal that a minimalist combination of two techniques can unlock the learning
capability of critic-free policies using vanilla PPO loss. The results
demonstrate that our simple combination consistently improves performance,
surpassing strategies like GRPO and DAPO.

</details>


### [387] [Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent](https://arxiv.org/abs/2508.08222)
*Tong Yang,Yu Huang,Yingbin Liang,Yuejie Chi*

Main category: cs.LG

TL;DR: 研究了Transformer如何通过训练学习解决符号多步推理问题，特别是树中的路径查找，分析了前向和后向推理任务，并证明了单层Transformer能泛化解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer通过训练获取多步推理能力的机制，特别是在符号推理任务中的表现，填补理论理解上的空白。

Method: 分析了后向和前向推理任务，并通过梯度下降动态理论研究单层Transformer的学习能力及泛化性。

Result: 证明了训练后的单层Transformer能有效解决两种推理任务，且注意力头能自主分工协作完成多步推理。

Conclusion: 任务结构化和中间步骤（如思维链）的引入，使得浅层多注意力头Transformer也能完成复杂推理，无需更深结构。

Abstract: Transformers have demonstrated remarkable capabilities in multi-step
reasoning tasks. However, understandings of the underlying mechanisms by which
they acquire these abilities through training remain limited, particularly from
a theoretical standpoint. This work investigates how transformers learn to
solve symbolic multi-step reasoning problems through chain-of-thought
processes, focusing on path-finding in trees. We analyze two intertwined tasks:
a backward reasoning task, where the model outputs a path from a goal node to
the root, and a more complex forward reasoning task, where the model implements
two-stage reasoning by first identifying the goal-to-root path and then
reversing it to produce the root-to-goal path. Our theoretical analysis,
grounded in the dynamics of gradient descent, shows that trained one-layer
transformers can provably solve both tasks with generalization guarantees to
unseen trees. In particular, our multi-phase training dynamics for forward
reasoning elucidate how different attention heads learn to specialize and
coordinate autonomously to solve the two subtasks in a single autoregressive
path. These results provide a mechanistic explanation of how trained
transformers can implement sequential algorithmic procedures. Moreover, they
offer insights into the emergence of reasoning abilities, suggesting that when
tasks are structured to take intermediate chain-of-thought steps, even shallow
multi-head transformers can effectively solve problems that would otherwise
require deeper architectures.

</details>
