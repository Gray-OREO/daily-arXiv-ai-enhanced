<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 122]
- [cs.MM](#cs.MM) [Total: 3]
- [cs.LG](#cs.LG) [Total: 94]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving](https://arxiv.org/abs/2508.09404)
*Guangxun Zhu,Shiyu Fan,Hang Dai,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: 论文介绍了Waymo-3DSkelMo，第一个大规模高质量、时间连续的3D骨骼运动数据集，基于Waymo感知数据集，用于复杂城市环境中细粒度人类行为理解。


<details>
  <summary>Details</summary>
Motivation: 现有3D运动数据集大多依赖单目RGB视频估计3D姿态，存在遮挡和时间不连续问题，导致运动质量低。

Method: 利用3D人体形状和运动先验，从LiDAR点云提取高质量的3D姿态序列，并标注交互语义。

Result: 数据集覆盖超14,000秒、800多个真实驾驶场景，平均每场景27个行人（最多250个），并建立3D姿态预测基准。

Conclusion: Waymo-3DSkelMo为复杂城市环境中人类行为理解提供了宝贵资源。

Abstract: Large-scale high-quality 3D motion datasets with multi-person interactions
are crucial for data-driven models in autonomous driving to achieve
fine-grained pedestrian interaction understanding in dynamic urban
environments. However, existing datasets mostly rely on estimating 3D poses
from monocular RGB video frames, which suffer from occlusion and lack of
temporal continuity, thus resulting in unrealistic and low-quality human
motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale
dataset providing high-quality, temporally coherent 3D skeletal motions with
explicit interaction semantics, derived from the Waymo Perception dataset. Our
key insight is to utilize 3D human body shape and motion priors to enhance the
quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The
dataset covers over 14,000 seconds across more than 800 real driving scenarios,
including rich interactions among an average of 27 agents per scene (with up to
250 agents in the largest scene). Furthermore, we establish 3D pose forecasting
benchmarks under varying pedestrian densities, and the results demonstrate its
value as a foundational resource for future research on fine-grained human
behavior understanding in complex urban environments. The dataset and code will
be available at https://github.com/GuangxunZhu/Waymo-3DSkelMo

</details>


### [2] [A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection](https://arxiv.org/abs/2508.09175)
*Mohammad Zia Ur Rehman,Sufyaan Zahoor,Areeb Manzoor,Musharaf Maqbool,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出了一种多模态框架，用于检测社交媒体上针对女性的厌女和性别歧视内容，通过三个模块实现，并在两个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的攻击性内容中有很大一部分针对女性，而通用检测方法难以有效识别厌女内容，因此需要针对性解决方案。

Method: 框架包含多模态注意力模块（MANM）、基于图的特征重构模块（GFRM）和内容特定特征学习模块（CFLM），结合自适应门控、图结构优化和测试时增强技术。

Result: 在两个数据集（MAMI和MMHS150K）上，平均宏F1分数分别提高了10.17%和8.88%。

Conclusion: 多模态框架显著提升了厌女和性别歧视内容的检测效果，优于现有方法。

Abstract: A substantial portion of offensive content on social media is directed
towards women. Since the approaches for general offensive content detection
face a challenge in detecting misogynistic content, it requires solutions
tailored to address offensive content against women. To this end, we propose a
novel multimodal framework for the detection of misogynistic and sexist
content. The framework comprises three modules: the Multimodal Attention module
(MANM), the Graph-based Feature Reconstruction Module (GFRM), and the
Content-specific Features Learning Module (CFLM). The MANM employs adaptive
gating-based multimodal context-aware attention, enabling the model to focus on
relevant visual and textual information and generating contextually relevant
features. The GFRM module utilizes graphs to refine features within individual
modalities, while the CFLM focuses on learning text and image-specific features
such as toxicity features and caption features. Additionally, we curate a set
of misogynous lexicons to compute the misogyny-specific lexicon score from the
text. We apply test-time augmentation in feature space to better generalize the
predictions on diverse inputs. The performance of the proposed approach has
been evaluated on two multimodal datasets, MAMI and MMHS150K, with 11,000 and
13,494 samples, respectively. The proposed method demonstrates an average
improvement of 10.17% and 8.88% in macro-F1 over existing methods on the MAMI
and MMHS150K datasets, respectively.

</details>


### [3] [Episodic Memory Representation for Long-form Video Understanding](https://arxiv.org/abs/2508.09486)
*Yun Wang,Long Zhang,Jingren Liu,Jiaqi Yan,Zhanjie Zhang,Jiahao Zheng,Xun Yang,Dapeng Wu,Xiangyu Chen,Xuelong Li*

Main category: cs.CV

TL;DR: Video-EM 是一种无需训练的框架，通过模拟人类情景记忆，改进长视频理解，性能提升 4-9%。


<details>
  <summary>Details</summary>
Motivation: 现有视频大模型在长视频理解中因上下文限制表现不佳，传统关键帧提取方法忽略时空关系，导致信息冗余和准确性下降。

Method: Video-EM 将关键帧建模为时序化情景事件，结合链式思维（CoT）优化关键帧选择，提升时空关系捕捉。

Result: 在多个基准测试中表现优异，性能提升 4-9%，且使用更少帧数。

Conclusion: Video-EM 通过情景记忆和 CoT 思维，显著提升了长视频理解的效率和准确性。

Abstract: Video Large Language Models (Video-LLMs) excel at general video understanding
but struggle with long-form videos due to context window limits. Consequently,
recent approaches focus on keyframe retrieval, condensing lengthy videos into a
small set of informative frames. Despite their practicality, these methods
simplify the problem to static text image matching, overlooking spatio temporal
relationships crucial for capturing scene transitions and contextual
continuity, and may yield redundant keyframes with limited information,
diluting salient cues essential for accurate video question answering. To
address these limitations, we introduce Video-EM, a training free framework
inspired by the principles of human episodic memory, designed to facilitate
robust and contextually grounded reasoning. Rather than treating keyframes as
isolated visual entities, Video-EM explicitly models them as temporally ordered
episodic events, capturing both spatial relationships and temporal dynamics
necessary for accurately reconstructing the underlying narrative. Furthermore,
the framework leverages chain of thought (CoT) thinking with LLMs to
iteratively identify a minimal yet highly informative subset of episodic
memories, enabling efficient and accurate question answering by Video-LLMs.
Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench
benchmarks confirm the superiority of Video-EM, which achieves highly
competitive results with performance gains of 4-9 percent over respective
baselines while utilizing fewer frames.

</details>


### [4] [IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection](https://arxiv.org/abs/2508.09178)
*Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang*

Main category: cs.CV

TL;DR: IAD-R1是一种通用后训练框架，通过两阶段训练策略提升视觉语言模型在工业异常检测中的表现，显著提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法因缺陷样本稀缺而受限，视觉语言模型虽有优势但表现不足。

Method: IAD-R1采用两阶段训练：PA-SFT阶段利用高质量数据集增强感知能力，SC-GRPO阶段通过奖励函数实现异常解释能力提升。

Result: 在7个视觉语言模型中显著提升性能，平均准确率最高提升43.3%，某些小模型甚至超过商业模型。

Conclusion: IAD-R1证明了其有效性和优越性，代码和模型将公开。

Abstract: Industrial anomaly detection is a critical component of modern manufacturing,
yet the scarcity of defective samples restricts traditional detection methods
to scenario-specific applications. Although Vision-Language Models (VLMs)
demonstrate significant advantages in generalization capabilities, their
performance in industrial anomaly detection remains limited. To address this
challenge, we propose IAD-R1, a universal post-training framework applicable to
VLMs of different architectures and parameter scales, which substantially
enhances their anomaly detection capabilities. IAD-R1 employs a two-stage
training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT)
stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset
(Expert-AD) for training, enhancing anomaly perception capabilities and
establishing reasoning-to-answer correlations; the Structured Control Group
Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward
functions to achieve a capability leap from "Anomaly Perception" to "Anomaly
Interpretation". Experimental results demonstrate that IAD-R1 achieves
significant improvements across 7 VLMs, attaining up to 43.3% enhancement in
average accuracy on 6 industrial anomaly detection benchmark datasets. Notably,
the 0.5B parameter model trained with IAD-R1 surpasses commercial models
including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the
effectiveness and superiority of IAD-R1. The dataset, code, and all model
weights will be publicly available at https://github.com/Yanhui-Lee/IAD-R1.

</details>


### [5] [A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality](https://arxiv.org/abs/2508.09185)
*Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan*

Main category: cs.CV

TL;DR: CADAR提出了一种结合神经符号方法的新技术，用于检测AR中的认知攻击，融合了视觉语言模型的适应性和粒子滤波的严谨推理能力，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于AR技术的普及，针对其内容的认知攻击日益增多。现有方法在语义推理和可解释性上存在局限，CADAR旨在解决这些问题。

Method: CADAR采用神经符号方法，结合视觉语言模型（VLM）获取符号化感知图，并通过粒子滤波进行统计推理，检测认知攻击。

Result: 在扩展的AR攻击数据集上，CADAR比基线方法在检测精度上提高了10.7%，证明了其有效性。

Conclusion: CADAR展示了神经符号方法在AR认知攻击检测中的潜力，兼具高性能和可解释性。

Abstract: Augmented Reality (AR) enriches perception by overlaying virtual elements on
the physical world. Due to its growing popularity, cognitive attacks that alter
AR content to manipulate users' semantic perception have received increasing
attention. Existing detection methods often focus on visual changes, which are
restricted to pixel- or image-level processing and lack semantic reasoning
capabilities, or they rely on pre-trained vision-language models (VLMs), which
function as black-box approaches with limited interpretability. In this paper,
we present CADAR, a novel neurosymbolic approach for cognitive attack detection
in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a
symbolic perception-graph representation, incorporating prior knowledge,
salience weighting, and temporal correlations. The model then enables
particle-filter based statistical reasoning -- a sequential Monte Carlo method
-- to detect cognitive attacks. Thus, CADAR inherits the adaptability of
pre-trained VLM and the interpretability and reasoning rigor of particle
filtering. Experiments on an extended AR cognitive attack dataset show accuracy
improvements of up to 10.7% over strong baselines on challenging AR attack
scenarios, underscoring the promise of neurosymbolic methods for effective and
interpretable cognitive attack detection.

</details>


### [6] [RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System](https://arxiv.org/abs/2508.09186)
*Abdolazim Rezaei,Mehdi Sookhak,Mahboobeh Haghparast*

Main category: cs.CV

TL;DR: RL-MoE框架通过将敏感视觉数据转化为隐私保护的文本描述，解决了智能交通系统中隐私与数据效用的冲突，结合MoE和强化学习，显著提升隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中AI摄像头的普及导致隐私与数据需求之间的冲突，现有方法如模糊或加密效果不佳，需要新的解决方案。

Method: 提出RL-MoE框架，结合MoE架构进行多场景分解和强化学习代理，优化文本生成以实现语义准确性和隐私保护。

Result: 实验显示，RL-MoE将重放攻击成功率降至9.4%，同时生成比基线方法更丰富的文本内容。

Conclusion: RL-MoE为隐私敏感领域提供了实用且可扩展的解决方案，推动智慧城市和自动驾驶网络的安全性提升。

Abstract: The proliferation of AI-powered cameras in Intelligent Transportation Systems
(ITS) creates a severe conflict between the need for rich visual data and the
fundamental right to privacy. Existing privacy-preserving mechanisms, such as
blurring or encryption, are often insufficient, creating an undesirable
trade-off where either privacy is compromised against advanced reconstruction
attacks or data utility is critically degraded. To resolve this impasse, we
propose RL-MoE, a novel framework that transforms sensitive visual data into
privacy-preserving textual descriptions, eliminating the need for direct image
transmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture
for nuanced, multi-aspect scene decomposition with a Reinforcement Learning
(RL) agent that optimizes the generated text for a dual objective of semantic
accuracy and privacy preservation. Extensive experiments demonstrate that
RL-MoE provides superior privacy protection, reducing the success rate of
replay attacks to just 9.4\% on the CFP-FP dataset, while simultaneously
generating richer textual content than baseline methods. Our work provides a
practical and scalable solution for building trustworthy AI systems in
privacy-sensitive domains, paving the way for more secure smart city and
autonomous vehicle networks.

</details>


### [7] [Synthetic Data Generation for Emotional Depth Faces: Optimizing Conditional DCGANs via Genetic Algorithms in the Latent Space and Stabilizing Training with Knowledge Distillation](https://arxiv.org/abs/2508.09188)
*Seyed Muhammad Hossein Mousavi,S. Younes Mirinezhad*

Main category: cs.CV

TL;DR: 提出了一种基于GAN和知识蒸馏的深度面部生成框架，结合遗传算法优化潜变量，提升多样性和质量。特征提取和分类方法在情感识别中表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量、多样化的深度面部数据集，识别微妙情感表情面临挑战。

Method: 使用优化的GAN与知识蒸馏（EMA教师模型）稳定训练，遗传算法优化潜变量，结合多种特征提取方法。

Result: 在多样性和质量上优于GAN、VAE、GMM和KDE，分类准确率达94%-96%。

Conclusion: 该方法在情感计算中表现出色，超越了现有技术。

Abstract: Affective computing faces a major challenge: the lack of high-quality,
diverse depth facial datasets for recognizing subtle emotional expressions. We
propose a framework for synthetic depth face generation using an optimized GAN
with Knowledge Distillation (EMA teacher models) to stabilize training, improve
quality, and prevent mode collapse. We also apply Genetic Algorithms to evolve
GAN latent vectors based on image statistics, boosting diversity and visual
quality for target emotions. The approach outperforms GAN, VAE, GMM, and KDE in
both diversity and quality. For classification, we extract and concatenate LBP,
HOG, Sobel edge, and intensity histogram features, achieving 94% and 96%
accuracy with XGBoost. Evaluation using FID, IS, SSIM, and PSNR shows
consistent improvement over state-of-the-art methods.

</details>


### [8] [$Δ$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation](https://arxiv.org/abs/2508.09199)
*Jucheng Hu,Suorong Yang,Dongzhan Zhou*

Main category: cs.CV

TL;DR: 提出Δ-AttnMask框架，通过注意力引导的隐藏状态掩码评估多模态数据质量，仅需20%数据即可实现SOTA性能，训练速度提升5倍。


<details>
  <summary>Details</summary>
Motivation: 视觉指令微调(VIF)需要高质量多模态数据，但数据选择研究不足，且传统方法难以高效扩展。

Method: Δ-AttnMask利用注意力掩码隐藏状态差异(Δ)量化样本质量，无需额外标注或训练。

Result: 实验显示，Δ-AttnMask用20%数据达到SOTA，训练加速5倍，准确率超越基线+10.1%。

Conclusion: Δ-AttnMask以模型和数据无关的设计，广泛适用于多模态任务，显著提升数据效率和性能。

Abstract: Visual Instruction Finetuning (VIF) is pivotal for post-training
Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in
plain-text large language models, which mainly requires instruction datasets to
enable model instruction-following ability, VIF also requires multimodal data
to enable joint visual and textual understanding; therefore, it typically
requires more data. Consequently, VIF imposes stricter data selection
challenges: the method must scale efficiently to handle larger data demands
while ensuring the quality of both visual and textual content, as well as their
alignment. Despite its critical impact on performance, data selection for VIF
remains an understudied area. In this paper, we propose $\Delta$-AttnMask. This
data-efficient framework quantifies sample quality through attention-guided
masking of the model's hidden states, jointly evaluating image-text pairs
without requiring domain labels, auxiliary models, or extra training. By
computing loss differences ($\Delta$) between the original states and states
masked using high-attention regions, $\Delta$-AttnMask intrinsically assesses
sample quality. Experiments across multiple VLMs and datasets show that
$\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data,
accelerating training by 5x while surpassing full-dataset baselines by +10.1%
in overall accuracy. Its model-agnostic and data-agnostic design ensures broad
applicability across modalities and architectures.

</details>


### [9] [Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method](https://arxiv.org/abs/2508.09202)
*Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger*

Main category: cs.CV

TL;DR: 本文提出了一种个性化的特征翻译方法（PFT），用于无源数据域的适应（SFDA），以解决面部表情识别（FER）中的细微表情和高个体差异问题。该方法在潜在空间中进行操作，避免了图像生成的复杂性和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有深度FER模型在细微表情和个体差异上的表现不佳，且传统SFDA方法无法处理目标域数据仅为单一中性表情的情况。

Method: 提出PFT方法，首先在源域数据上预训练翻译器，然后在目标域中性数据上进行适应，避免了图像生成和源数据的使用。

Result: PFT在潜在空间中生成区分性嵌入，提高了分类性能，同时减少了计算负担。

Conclusion: PFT是一种高效的SFDA方法，适用于仅有中性目标数据的场景，避免了图像合成的复杂性。

Abstract: Facial expression recognition (FER) models are employed in many video-based
affective computing applications, such as human-computer interaction and
healthcare monitoring. However, deep FER models often struggle with subtle
expressions and high inter-subject variability, limiting their performance in
real-world applications. To improve their performance, source-free domain
adaptation (SFDA) methods have been proposed to personalize a pretrained source
model using only unlabeled target domain data, thereby avoiding data privacy,
storage, and transmission constraints. This paper addresses a challenging
scenario where source data is unavailable for adaptation, and only unlabeled
target data consisting solely of neutral expressions is available. SFDA methods
are not typically designed to adapt using target data from only a single class.
Further, using models to generate facial images with non-neutral expressions
can be unstable and computationally intensive. In this paper, personalized
feature translation (PFT) is proposed for SFDA. Unlike current image
translation methods for SFDA, our lightweight method operates in the latent
space. We first pre-train the translator on the source domain data to transform
the subject-specific style features from one source subject into another.
Expression information is preserved by optimizing a combination of expression
consistency and style-aware objectives. Then, the translator is adapted on
neutral target data, without using source data or image synthesis. By
translating in the latent space, PFT avoids the complexity and noise of face
expression generation, producing discriminative embeddings optimized for
classification. Using PFT eliminates the need for image synthesis, reduces
computational overhead (using a lightweight translator), and only adapts part
of the model, making the method efficient compared to image-based translation.

</details>


### [10] [GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning](https://arxiv.org/abs/2508.09207)
*Tai Vu,Robert Yang*

Main category: cs.CV

TL;DR: 研究比较了多种图像转换模型在动漫角色与草图间的效果，发现C-GAN最接近人类创作的高质量结果。


<details>
  <summary>Details</summary>
Motivation: 解决动漫产业中草图到彩色绘图的高成本瓶颈问题。

Method: 比较了神经风格迁移、C-GAN和CycleGAN等多种图像转换模型。

Result: C-GAN在质量和分辨率上表现最佳，接近人类创作水平。

Conclusion: C-GAN是动漫草图彩色化的有效解决方案。

Abstract: The process of generating fully colorized drawings from sketches is a large,
usually costly bottleneck in the manga and anime industry. In this study, we
examine multiple models for image-to-image translation between anime characters
and their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By
assessing them qualitatively and quantitatively, we find that C-GAN is the most
effective model that is able to produce high-quality and high-resolution images
close to those created by humans.

</details>


### [11] [MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models](https://arxiv.org/abs/2508.09210)
*Fan Zhang,Zebang Cheng,Chong Deng,Haoxuan Li,Zheng Lian,Qian Chen,Huadai Liu,Wen Wang,Yi-Fan Zhang,Renrui Zhang,Ziyu Guo,Zhihong Zhu,Hao Wu,Haixin Wang,Yefeng Zheng,Xiaojiang Peng,Xian Wu,Kun Wang,Xiangang Li,Jieping Ye,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 论文介绍了MME-Emotion基准，用于评估多模态大语言模型（MLLMs）的情感情感和推理能力，揭示了当前模型的不足。


<details>
  <summary>Details</summary>
Motivation: 当前情感计算的基准测试存在局限，尤其是MLLMs的泛化能力和情感触发因素推理能力尚未清楚。

Method: 提出MME-Emotion基准，包含6000多个视频片段和问题-答案对，涵盖八种情感任务，并采用混合指标和多代理系统框架进行评估。

Result: 评估20个先进MLLMs后，发现其情感情感表现不佳，最佳模型的情感识别和推理得分仅为39.3%和56.0%。

Conclusion: MME-Emotion为未来提升MLLMs的情感情感能力奠定了基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have catalyzed
transformative progress in affective computing, enabling models to exhibit
emergent emotional intelligence. Despite substantial methodological progress,
current emotional benchmarks remain limited, as it is still unknown: (a) the
generalization abilities of MLLMs across distinct scenarios, and (b) their
reasoning capabilities to identify the triggering factors behind emotional
states. To bridge these gaps, we present \textbf{MME-Emotion}, a systematic
benchmark that assesses both emotional understanding and reasoning capabilities
of MLLMs, enjoying \textit{scalable capacity}, \textit{diverse settings}, and
\textit{unified protocols}. As the largest emotional intelligence benchmark for
MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific
questioning-answering (QA) pairs, spanning broad scenarios to formulate eight
emotional tasks. It further incorporates a holistic evaluation suite with
hybrid metrics for emotion recognition and reasoning, analyzed through a
multi-agent system framework. Through a rigorous evaluation of 20 advanced
MLLMs, we uncover both their strengths and limitations, yielding several key
insights: \ding{182} Current MLLMs exhibit unsatisfactory emotional
intelligence, with the best-performing model achieving only $39.3\%$
recognition score and $56.0\%$ Chain-of-Thought (CoT) score on our benchmark.
\ding{183} Generalist models (\emph{e.g.}, Gemini-2.5-Pro) derive emotional
intelligence from generalized multimodal understanding capabilities, while
specialist models (\emph{e.g.}, R1-Omni) can achieve comparable performance
through domain-specific post-training adaptation. By introducing MME-Emotion,
we hope that it can serve as a foundation for advancing MLLMs' emotional
intelligence in the future.

</details>


### [12] [Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity](https://arxiv.org/abs/2508.09218)
*Zuoou Li,Weitong Zhang,Jingyuan Wang,Shuyuan Zhang,Wenjia Bai,Bernhard Kainz,Mengyun Qiao*

Main category: cs.CV

TL;DR: 提出四轴评估框架改进对抗提示的有效性评估，开发递归重写策略（BSD）提升攻击成功率和危害性。


<details>
  <summary>Details</summary>
Motivation: 现有研究高估对抗提示的成功率，需更精准评估框架来识别真正有效的攻击。

Method: 引入四轴评估框架（输入相关性、OOD强度、输出危害性、拒绝率），并开发BSD递归重写策略。

Result: BSD在13个MLLM中显著提升攻击成功率（67%）和危害性（21%），揭示安全系统弱点。

Conclusion: 平衡相关性和新颖性的对抗提示更有效，当前多模态安全系统存在未被充分认识的漏洞。

Abstract: Multimodal large language models (MLLMs) are widely used in vision-language
reasoning tasks. However, their vulnerability to adversarial prompts remains a
serious concern, as safety mechanisms often fail to prevent the generation of
harmful outputs. Although recent jailbreak strategies report high success
rates, many responses classified as "successful" are actually benign, vague, or
unrelated to the intended malicious goal. This mismatch suggests that current
evaluation standards may overestimate the effectiveness of such attacks. To
address this issue, we introduce a four-axis evaluation framework that
considers input on-topicness, input out-of-distribution (OOD) intensity, output
harmfulness, and output refusal rate. This framework identifies truly effective
jailbreaks. In a substantial empirical study, we reveal a structural trade-off:
highly on-topic prompts are frequently blocked by safety filters, whereas those
that are too OOD often evade detection but fail to produce harmful content.
However, prompts that balance relevance and novelty are more likely to evade
filters and trigger dangerous output. Building on this insight, we develop a
recursive rewriting strategy called Balanced Structural Decomposition (BSD).
The approach restructures malicious prompts into semantically aligned
sub-tasks, while introducing subtle OOD signals and visual cues that make the
inputs harder to detect. BSD was tested across 13 commercial and open-source
MLLMs, where it consistently led to higher attack success rates, more harmful
outputs, and fewer refusals. Compared to previous methods, it improves success
rates by $67\%$ and harmfulness by $21\%$, revealing a previously
underappreciated weakness in current multimodal safety systems.

</details>


### [13] [Towards Scalable Training for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.09220)
*Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong*

Main category: cs.CV

TL;DR: 论文提出了一种结合手写公式和大型LaTeX渲染公式的新方法，构建了一个包含8000万训练样本的数据集Tex80M，并开发了首个大规模训练的HMER模型TexTeller，取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 手工标注的稀缺性限制了手写数学表达式识别（HMER）的发展，需要解决数据不足的问题。

Method: 开发了可扩展的数据引擎，整合限量的手写公式和大量LaTeX渲染公式，构建了Tex80M数据集，并通过混合训练方法训练TexTeller模型。

Result: TexTeller模型在几乎所有基准测试中达到了SOTA性能。

Conclusion: 团队将公开发布模型、数据集和代码，推动HMER领域的进一步研究。

Abstract: Large foundation models have achieved significant performance gains through
scalable training on massive datasets. However, the field of
\textbf{H}andwritten \textbf{M}athematical \textbf{E}xpression
\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily
due to the arduous and costly process of manual annotation. To bridge this gap,
we propose a novel method integrating limited handwritten formulas with
large-scale LaTeX-rendered formulas by developing a scalable data engine to
generate complex and consistent LaTeX sequences. With this engine, we built the
largest formula dataset to date, termed \texttt{Tex80M}, comprising over 80
million high-quality training instances. Then we propose \texttt{TexTeller},
the first HMER model trained at scale, by mix-training \texttt{Tex80M} with a
relatively small HME dataset. The expansive training dataset and our refined
pipeline have equipped \texttt{TexTeller} with state-of-the-art (SOTA)
performance across nearly all benchmarks. To advance the field, we will openly
release our complete model, entire dataset, and full codebase, enabling further
research building upon our contributions.

</details>


### [14] [Gradient-Direction-Aware Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2508.09239)
*Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Jia-Chen Zhang,Hong-Jian Zhan*

Main category: cs.CV

TL;DR: GDAGS提出了一种梯度方向感知的自适应密度控制框架，通过梯度一致性比（GCR）和非线性动态权重机制，解决了3D高斯泼溅中的过重构和过密化问题，显著提升了渲染质量并减少了内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在复杂场景中存在过重构和过密化问题，导致渲染质量下降和内存浪费。GDAGS旨在通过梯度方向感知的密度控制解决这些问题。

Method: GDAGS引入梯度一致性比（GCR）和非线性动态权重机制，根据梯度方向自适应控制高斯函数的密度，优化分裂和克隆过程。

Result: GDAGS在多样化的真实场景基准测试中表现出色，渲染质量提升，内存消耗减少50%。

Conclusion: GDAGS通过梯度方向感知的密度控制，成功解决了3D高斯泼溅的关键问题，实现了高效紧凑的场景表示。

Abstract: The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced
novel view synthesis through explicit scene representation, enabling real-time
photorealistic rendering. However, existing approaches manifest two critical
limitations in complex scenarios: (1) Over-reconstruction occurs when
persistent large Gaussians cannot meet adaptive splitting thresholds during
density control. This is exacerbated by conflicting gradient directions that
prevent effective splitting of these Gaussians; (2) Over-densification of
Gaussians occurs in regions with aligned gradient aggregation, leading to
redundant component proliferation. This redundancy significantly increases
memory overhead due to unnecessary data retention. We present
Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware
adaptive density control framework to address these challenges. Our key
innovations: the gradient coherence ratio (GCR), computed through normalized
gradient vector norms, which explicitly discriminates Gaussians with concordant
versus conflicting gradient directions; and a nonlinear dynamic weighting
mechanism leverages the GCR to enable gradient-direction-aware density control.
Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting
operations to enhance geometric details while suppressing redundant
concordant-direction Gaussians. Conversely, in cloning processes, GDAGS
promotes concordant-direction Gaussian densification for structural completion
while preventing conflicting-direction Gaussian overpopulation. Comprehensive
evaluations across diverse real-world benchmarks demonstrate that GDAGS
achieves superior rendering quality while effectively mitigating
over-reconstruction, suppressing over-densification, and constructing compact
scene representations with 50\% reduced memory consumption through optimized
Gaussians utilization.

</details>


### [15] [FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents](https://arxiv.org/abs/2508.09241)
*Fengxian Ji,Jingpu Yang,Zirui Song,Yuanxi Wang,Zhexuan Cui,Yuke Li,Qian Jiang,Miao Fang,Xiuying Chen*

Main category: cs.CV

TL;DR: 提出了FineState-Bench，首个针对GUI代理细粒度控制的评估与诊断标准，填补了现有基准在细粒度能力评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理的评估框架过于关注粗粒度任务完成度，忽视了细粒度控制能力在现实应用中的重要性。

Method: 开发了多平台的FineState-Bench框架，包含2257个任务基准，并引入四阶段指标和视觉诊断助手(VDA)进行能力评估与解耦分析。

Result: 实验显示当前先进模型在细粒度交互准确率上仅为32.8%，而理想视觉定位能力可将Gemini-2.5-Flash的成功率提升14.9%。

Conclusion: 当前GUI代理的主要瓶颈是基础视觉定位能力，FineState-Bench为细粒度控制能力提供了首个量化评估与诊断工具。

Abstract: With the rapid advancement of generative artificial intelligence technology,
Graphical User Interface (GUI) agents have demonstrated tremendous potential
for autonomously managing daily tasks through natural language instructions.
However, current evaluation frameworks for GUI agents suffer from fundamental
flaws: existing benchmarks overly focus on coarse-grained task completion while
neglecting fine-grained control capabilities crucial for real-world
applications. To address this, we introduce FineState-Bench, the first
evaluation and diagnostic standard for fine-grained GUI proxy operations,
designed to quantify fine-grained control. This multi-platform (desktop, Web,
mobile) framework includes 2257 task benchmarks in four components and uses a
four-phase indicator for comprehensive perception-to-control assessment. To
analyze perception and positioning for refined operations, we developed the
plug-and-play Visual Diagnostic Assistant (VDA), enabling the first
quantitative decoupling analysis of these capabilities. Experimental results on
our benchmark show that the most advanced models achieve only 32.8%
fine-grained interaction accuracy. Using our VDA in controlled experiments,
quantifying the impact of visual capabilities, we showed that ideal visual
localization boosts Gemini-2.5-Flash's success rate by 14.9\%. Our diagnostic
framework confirms for the first time that the primary bottleneck for current
GUI proxies is basic visual positioning capability.All resources are fully
open-source. github: https://github.com/AnonymousThewarehouse/FineState-Bench
huggingface: https://huggingface.co/datasets/Willtime2006/Static-FineBench

</details>


### [16] [Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users](https://arxiv.org/abs/2508.09245)
*Jeffri Murrugarra-LLerena,Haoran Niu,K. Suzanne Barber,Hal Daumé III,Yang Trista Cao,Paola Cascante-Bonilla*

Main category: cs.CV

TL;DR: FiGPriv是一个细粒度隐私保护框架，通过选择性遮蔽高风险隐私信息来提升视觉助手系统的实用性。


<details>
  <summary>Details</summary>
Motivation: 针对视觉语言模型（VLMs）中盲人和低视力用户可能无意中捕获隐私信息的问题，提出了更精细的隐私保护方案。

Method: 结合细粒度分割和数据驱动的风险评分机制，选择性遮蔽高风险隐私信息。

Result: 在BIV-Priv-Seg数据集上，FiGPriv保留26%的图像内容，提升VLM实用性11%和内容识别45%。

Conclusion: FiGPriv在保护隐私的同时显著提升了系统的可用性和功能。

Abstract: As visual assistant systems powered by visual language models (VLMs) become
more prevalent, concerns over user privacy have grown, particularly for blind
and low vision users who may unknowingly capture personal private information
in their images. Existing privacy protection methods rely on coarse-grained
segmentation, which uniformly masks entire private objects, often at the cost
of usability. In this work, we propose FiGPriv, a fine-grained privacy
protection framework that selectively masks only high-risk private information
while preserving low-risk information. Our approach integrates fine-grained
segmentation with a data-driven risk scoring mechanism. We evaluate our
framework using the BIV-Priv-Seg dataset and show that FiG-Priv preserves +26%
of image content, enhancing the ability of VLMs to provide useful responses by
11% and identify the image content by 45%, while ensuring privacy protection.
Project Page: https://artcs1.github.io/VLMPrivacy/

</details>


### [17] [Harnessing Input-Adaptive Inference for Efficient VLN](https://arxiv.org/abs/2508.09262)
*Dongwoo Kang,Akhil Perincherry,Zachary Coalson,Aiden Gabriel,Stefan Lee,Sanghyun Hong*

Main category: cs.CV

TL;DR: 提出了一种新颖的输入自适应导航方法，通过三种算法分别提升空间、模型内和时间效率，显著降低了计算量，保持了性能。


<details>
  <summary>Details</summary>
Motivation: 针对视觉与语言导航（VLN）中大模型计算资源消耗高的问题，提出输入自适应方法以提高效率。

Method: 引入三种自适应算法：选择性处理全景视图、重要性自适应阈值法和视图缓存机制。

Result: 在七个VLN基准测试中，计算量降低超过2倍且性能未显著下降。

Conclusion: 提出的方法有效提升了VLN模型的效率，适用于资源受限的场景。

Abstract: An emerging paradigm in vision-and-language navigation (VLN) is the use of
history-aware multi-modal transformer models. Given a language instruction,
these models process observation and navigation history to predict the most
appropriate action for an agent. While they have significantly improved
performance, the scale of these models can be a bottleneck in practical
settings with limited computational resources. In this work, we propose a novel
input-adaptive navigation method to enhance VLN model efficiency. We first show
that existing input-adaptive mechanisms fail to reduce computations without
substantial performance degradation. To address this, we introduce three
adaptive algorithms, each deployed at a different level: (1) To improve spatial
efficiency, we selectively process panoramic views at each observation of an
agent. (2) To improve intra-model efficiency, we propose importance-based
adaptive thresholding for the early-exit methods. (3) To improve temporal
efficiency, we implement a caching mechanism that prevents reprocessing of
views previously seen by the agent. In evaluations on seven VLN benchmarks, we
demonstrate over a 2$\times$ reduction in computation across three
off-the-shelf agents in both standard and continuous environments. Our code is
publicly available at
https://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.

</details>


### [18] [SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning](https://arxiv.org/abs/2508.09325)
*Alexandre Brown,Glen Berseth*

Main category: cs.CV

TL;DR: SegDAC是一种基于分割的视觉强化学习方法，通过Segment Anything和YOLO-World实现对象中心分解和语义接地，在Maniskill3基准测试中表现出卓越的视觉泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习需要从高维输入和噪声奖励中学习感知和动作，现有的感知模型如何有效整合到RL中以提升泛化能力和样本效率仍不明晰。

Method: 提出SegDAC，结合Segment Anything和YOLO-World实现对象分解和语义接地，采用新型Transformer架构动态处理分段并通过在线RL学习关键分段。

Result: 在Maniskill3基准测试中，SegDAC在视觉泛化能力上显著优于之前方法（最困难环境下性能翻倍），并在样本效率上匹配或超越之前方法。

Conclusion: SegDAC通过对象中心分解和语义接地有效提升了视觉RL的泛化能力和效率，展示了无需人工标注的潜力。

Abstract: Visual reinforcement learning (RL) is challenging due to the need to learn
both perception and actions from high-dimensional inputs and noisy rewards.
Although large perception models exist, integrating them effectively into RL
for visual generalization and improved sample efficiency remains unclear. We
propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment
Anything (SAM) for object-centric decomposition and YOLO-World to ground
segments semantically via text prompts. It includes a novel transformer-based
architecture that supports a dynamic number of segments at each time step and
effectively learns which segments to focus on using online RL, without using
human labels. By evaluating SegDAC over a challenging visual generalization
benchmark using Maniskill3, which covers diverse manipulation tasks under
strong visual perturbations, we demonstrate that SegDAC achieves significantly
better visual generalization, doubling prior performance on the hardest setting
and matching or surpassing prior methods in sample efficiency across all
evaluated tasks.

</details>


### [19] [Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model](https://arxiv.org/abs/2508.09327)
*Yifan Jiang,Ahmad Shariftabrizi,Venkata SK. Manem*

Main category: cs.CV

TL;DR: 论文提出了一种改进的生成模型Lung-DDPM+，用于高效且精确地生成肺部CT图像，提高了采样效率和图像质量，适用于肺癌诊断等医疗任务。


<details>
  <summary>Details</summary>
Motivation: 现有的肺部CT图像生成模型效率低且解剖精度不足，限制了其临床应用。作者旨在解决这些问题，提出了一种更高效的模型。

Method: Lung-DDPM+是一种基于去噪扩散概率模型（DDPM）的方法，通过结节语义布局指导并利用肺动脉DPM-solver加速，专注于病变区域并平衡采样效率与质量。

Result: 实验结果显示，Lung-DDPM+在LIDC-IDRI数据集上实现了更低的计算成本、GPU内存消耗和更快的采样速度，同时保持了与现有最佳模型相当的图像质量。

Conclusion: Lung-DDPM+能够高效生成高质量的肺部CT图像，展示了其在肿瘤合成等医疗影像任务中的潜力。

Abstract: Generative artificial intelligence (AI) has been playing an important role in
various domains. Leveraging its high capability to generate high-fidelity and
diverse synthetic data, generative AI is widely applied in diagnostic tasks,
such as lung cancer diagnosis using computed tomography (CT). However, existing
generative models for lung cancer diagnosis suffer from low efficiency and
anatomical imprecision, which limit their clinical applicability. To address
these drawbacks, we propose Lung-DDPM+, an improved version of our previous
model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic
model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary
DPM-solver, enabling the method to focus on lesion areas while achieving a
better trade-off between sampling efficiency and quality. Evaluation results on
the public LIDC-IDRI dataset suggest that the proposed method achieves
8$\times$ fewer FLOPs (floating point operations per second), 6.8$\times$ lower
GPU memory consumption, and 14$\times$ faster sampling compared to Lung-DDPM.
Moreover, it maintains comparable sample quality to both Lung-DDPM and other
state-of-the-art (SOTA) generative models in two downstream segmentation tasks.
We also conducted a Visual Turing Test by an experienced radiologist, showing
the advanced quality and fidelity of synthetic samples generated by the
proposed method. These experimental results demonstrate that Lung-DDPM+ can
effectively generate high-quality thoracic CT images with lung nodules,
highlighting its potential for broader applications, such as general tumor
synthesis and lesion generation in medical imaging. The code and pretrained
models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.

</details>


### [20] [UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas](https://arxiv.org/abs/2508.09339)
*Aqsa Sultana,Nordin Abouzahra,Ahmed Rahu,Brian Shula,Brandon Combs,Derrick Forchetti,Theus Aspiras,Vijayan K. Asari*

Main category: cs.CV

TL;DR: 利用深度学习模型Ultralight Med-Vision Mamba改进结肠镜筛查中息肉分类和风险评估。


<details>
  <summary>Details</summary>
Motivation: 通过精确识别和分类息肉，降低结直肠癌风险，优化患者随访方案。

Method: 使用基于状态空间的Ultralight Med-Vision Mamba模型，分析全幻灯片图像。

Result: 模型在长短期依赖性和图像泛化方面表现优异，计算效率高，适合临床实时应用。

Conclusion: Ultralight Med-Vision Mamba是一个有潜力的工具，可提升结肠镜筛查的效率和准确性。

Abstract: Identification of precancerous polyps during routine colonoscopy screenings
is vital for their excision, lowering the risk of developing colorectal cancer.
Advanced deep learning algorithms enable precise adenoma classification and
stratification, improving risk assessment accuracy and enabling personalized
surveillance protocols that optimize patient outcomes. Ultralight Med-Vision
Mamba, a state-space based model (SSM), has excelled in modeling long- and
short-range dependencies and image generalization, critical factors for
analyzing whole slide images. Furthermore, Ultralight Med-Vision Mamba's
efficient architecture offers advantages in both computational speed and
scalability, making it a promising tool for real-time clinical deployment.

</details>


### [21] [Blink-to-code: real-time Morse code communication via eye blink detection and classification](https://arxiv.org/abs/2508.09344)
*Anushka Bhatt*

Main category: cs.CV

TL;DR: 提出一种实时系统，将自主眨眼转化为莫尔斯电码，帮助严重运动障碍者通信。


<details>
  <summary>Details</summary>
Motivation: 为严重运动障碍者提供低成本的辅助通信方案。

Method: 利用标准摄像头和计算机视觉技术检测眨眼并分类为短（点）或长（划），解码为字母数字。

Result: 实验显示解码准确率为62%，响应时间为18-20秒。

Conclusion: 该系统是一种可行的低成本辅助通信方法。

Abstract: This study proposes a real-time system that translates voluntary eye blinks
into Morse code, enabling communication for individuals with severe motor
impairments. Using a standard webcam and computer vision, the system detects
and classifies blinks as short (dot) or long (dash), then decodes them into
alphanumeric characters. Experiments with five participants show 62% decoding
accuracy and 18-20 seconds response times, demonstrating a viable, low-cost
assistive communication method.

</details>


### [22] [FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition](https://arxiv.org/abs/2508.09362)
*Md. Milon Islam,Md Rezwanul Haque,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: FusionEnsemble-Net是一种基于注意力的时空网络集成方法，通过融合视觉和运动数据提升手语识别准确率，在意大利手语数据集上达到99.44%的测试准确率。


<details>
  <summary>Details</summary>
Motivation: 解决医疗沟通中复杂多模态手势的精确识别问题。

Method: 使用四个不同的时空网络同步处理RGB视频和雷达数据，通过注意力融合模块动态融合特征，并通过集成分类器结合输出。

Result: 在MultiMeDaLIS数据集上实现了99.44%的测试准确率，优于现有方法。

Conclusion: 基于注意力融合的多样化时空网络集成方法为复杂多模态手势识别提供了鲁棒且准确的框架。

Abstract: Accurate recognition of sign language in healthcare communication poses a
significant challenge, requiring frameworks that can accurately interpret
complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net,
a novel attention-based ensemble of spatiotemporal networks that dynamically
fuses visual and motion data to enhance recognition accuracy. The proposed
approach processes RGB video and range Doppler map radar modalities
synchronously through four different spatiotemporal networks. For each network,
features from both modalities are continuously fused using an attention-based
fusion module before being fed into an ensemble of classifiers. Finally, the
outputs of these four different fused channels are combined in an ensemble
classification head, thereby enhancing the model's robustness. Experiments
demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches
with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for
Italian Sign Language. Our findings indicate that an ensemble of diverse
spatiotemporal networks, unified by attention-based fusion, yields a robust and
accurate framework for complex, multimodal isolated gesture recognition tasks.
The source code is available at:
https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.

</details>


### [23] [A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition](https://arxiv.org/abs/2508.09372)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: 本文提出了一种双架构框架，用于解决连续手语识别中的关键挑战，包括签名者独立性和未见句子结构的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 连续手语识别面临签名者间差异大和陌生句子结构泛化能力差的问题，传统方法效果不佳。

Method: 设计了基于姿态骨骼关键点的签名者无关Conformer模型和多尺度融合Transformer模型来处理这些挑战。

Result: 在Isharah-1000数据集上取得了新基准，SI任务的WER降低了13.53%，US任务的WER达到47.78%。

Conclusion: 针对特定任务设计的网络显著提升了性能，为后续研究设定了新基准。

Abstract: Continuous Sign Language Recognition (CSLR) faces multiple challenges,
including significant inter-signer variability and poor generalization to novel
sentence structures. Traditional solutions frequently fail to handle these
issues efficiently. For overcoming these constraints, we propose a
dual-architecture framework. For the Signer-Independent (SI) challenge, we
propose a Signer-Invariant Conformer that combines convolutions with multi-head
self-attention to learn robust, signer-agnostic representations from pose-based
skeletal keypoints. For the Unseen-Sentences (US) task, we designed a
Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that
captures both fine-grained posture dynamics, enabling the model's ability to
comprehend novel grammatical compositions. Experiments on the challenging
Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The
proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on
the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US
task, the transformer model scores a WER of 47.78%, surpassing previous work.
In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th
in the SI task, demonstrating the performance of these models. The findings
validate our key hypothesis: that developing task-specific networks designed
for the particular challenges of CSLR leads to considerable performance
improvements and establishes a new baseline for further research. The source
code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.

</details>


### [24] [What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?](https://arxiv.org/abs/2508.09381)
*Kumar Abhishek,Jeremy Kawahara,Ghassan Hamarneh*

Main category: cs.CV

TL;DR: IMA++是最大的多标注者皮肤病变分割数据集，研究了标注者、恶性程度、工具和技能等因素对分割结果的影响，发现恶性病变与标注一致性显著相关，并利用一致性作为特征提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中存在标注者内部和之间的变异性，特别是模糊边界的病变（如恶性肿瘤）更易产生分歧。研究这些因素对分割结果的影响，并利用标注一致性改进模型。

Method: 构建IMA++数据集，研究标注一致性（IAA）与恶性程度的关系，预测IAA值，并将其作为软特征用于多任务学习。

Result: 恶性病变与IAA显著相关（p<0.001）；IAA可直接从图像预测（MAE=0.108）；多任务学习使平衡准确率平均提升4.2%。

Conclusion: 标注一致性可作为临床特征的补充，帮助提高皮肤病变分割模型的性能，尤其在处理恶性病变时效果显著。

Abstract: Medical image segmentation exhibits intra- and inter-annotator variability
due to ambiguous object boundaries, annotator preferences, expertise, and
tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated
or infiltrative nodules, or irregular borders per the ABCD rule, are
particularly prone to disagreement and are often associated with malignancy. In
this work, we curate IMA++, the largest multi-annotator skin lesion
segmentation dataset, on which we conduct an in-depth study of variability due
to annotator, malignancy, tool, and skill factors. We find a statistically
significant (p<0.001) association between inter-annotator agreement (IAA),
measured using Dice, and the malignancy of skin lesions. We further show that
IAA can be accurately predicted directly from dermoscopic images, achieving a
mean absolute error of 0.108. Finally, we leverage this association by
utilizing IAA as a "soft" clinical feature within a multi-task learning
objective, yielding a 4.2% improvement in balanced accuracy averaged across
multiple model architectures and across IMA++ and four public dermoscopic
datasets. The code is available at https://github.com/sfu-mial/skin-IAV.

</details>


### [25] [X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents](https://arxiv.org/abs/2508.09383)
*Guoxian Song,Hongyi Xu,Xiaochen Zhao,You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Linjie Luo*

Main category: cs.CV

TL;DR: X-UniMotion是一种统一且表达丰富的隐式潜在表示方法，用于全人体运动，包括面部表情、身体姿势和手势，通过自监督的端到端框架实现高保真的跨身份运动转移。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决现有运动转移方法依赖显式骨骼姿势和启发式跨身份调整的局限性，提出一种更高效、更通用的隐式表示方式。

Method: 方法包括将多粒度运动从单图像编码为四个解耦的潜在标记（面部表情、身体姿势和双手各一个），并通过自监督的端到端框架联合学习运动编码器和潜在表示，辅以辅助解码器和数据增强技术。

Result: 实验结果显示，X-UniMotion在运动保真度和身份保持方面优于现有方法，能够生成高度表达的动画。

Conclusion: 结论是X-UniMotion是一种高效且通用的隐式潜在表示方法，适用于全人体运动的生成和转移。

Abstract: We present X-UniMotion, a unified and expressive implicit latent
representation for whole-body human motion, encompassing facial expressions,
body poses, and hand gestures. Unlike prior motion transfer methods that rely
on explicit skeletal poses and heuristic cross-identity adjustments, our
approach encodes multi-granular motion directly from a single image into a
compact set of four disentangled latent tokens -- one for facial expression,
one for body pose, and one for each hand. These motion latents are both highly
expressive and identity-agnostic, enabling high-fidelity, detailed
cross-identity motion transfer across subjects with diverse identities, poses,
and spatial configurations. To achieve this, we introduce a self-supervised,
end-to-end framework that jointly learns the motion encoder and latent
representation alongside a DiT-based video generative model, trained on
large-scale, diverse human motion datasets. Motion-identity disentanglement is
enforced via 2D spatial and color augmentations, as well as synthetic 3D
renderings of cross-identity subject pairs under shared poses. Furthermore, we
guide motion token learning with auxiliary decoders that promote fine-grained,
semantically aligned, and depth-aware motion embeddings. Extensive experiments
show that X-UniMotion outperforms state-of-the-art methods, producing highly
expressive animations with superior motion fidelity and identity preservation.

</details>


### [26] [DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection](https://arxiv.org/abs/2508.09392)
*Kang Ni,Minrui Zou,Yuxuan Li,Xiang Li,Kehua Guo,Ming-Ming Cheng,Yimian Dai*

Main category: cs.CV

TL;DR: DenoDet V2通过变换域特征解构和调制，以及振幅与相位信息的互补机制，显著提升了SAR目标检测性能，并降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: SAR目标检测中相干噪声的影响是一个主要挑战，传统方法通常通过空间域特征分析或增强进行隐式去噪，而DenoDet V2尝试从变换域角度解决问题。

Method: 提出DenoDet V2，采用变换域特征解构和调制的方法，通过精心设计的注意力架构和振幅-相位互调机制实现性能提升。

Result: 在多个SAR数据集上表现出最先进的性能，SARDet-100K数据集上比DenoDet V1提升0.8%，同时模型复杂度减半。

Conclusion: DenoDet V2通过变换域和互补机制为SAR目标检测提供了新的解决方案，性能显著提升。

Abstract: One of the primary challenges in Synthetic Aperture Radar (SAR) object
detection lies in the pervasive influence of coherent noise. As a common
practice, most existing methods, whether handcrafted approaches or deep
learning-based methods, employ the analysis or enhancement of object
spatial-domain characteristics to achieve implicit denoising. In this paper, we
propose DenoDet V2, which explores a completely novel and different perspective
to deconstruct and modulate the features in the transform domain via a
carefully designed attention architecture. Compared to DenoDet V1, DenoDet V2
is a major advancement that exploits the complementary nature of amplitude and
phase information through a band-wise mutual modulation mechanism, which
enables a reciprocal enhancement between phase and amplitude spectra. Extensive
experiments on various SAR datasets demonstrate the state-of-the-art
performance of DenoDet V2. Notably, DenoDet V2 achieves a significant 0.8\%
improvement on SARDet-100K dataset compared to DenoDet V1, while reducing the
model complexity by half. The code is available at
https://github.com/GrokCV/GrokSAR.

</details>


### [27] [Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety](https://arxiv.org/abs/2508.09397)
*Zhengli Zhang,Xinyu Luo,Yuchen Sun,Wenhua Ding,Dongyu Huang,Xinlei Chen*

Main category: cs.CV

TL;DR: SkyShield是一个事件驱动的端到端框架，用于检测无人机在复杂环境中的亚毫米级薄障碍物，采用轻量级U-Net架构和创新的Dice-Contour正则化损失，实验表明其检测精度高且延迟低。


<details>
  <summary>Details</summary>
Motivation: 传统传感器难以检测亚毫米级薄障碍物，如钢丝和风筝线，这对无人机在复杂环境中的操作构成威胁。

Method: 基于事件流的特征，采用轻量级U-Net架构和Dice-Contour正则化损失来实现精确检测。

Result: 实验结果显示，方法的平均F1得分为0.7088，延迟低至21.2毫秒，适合边缘和移动平台部署。

Conclusion: SkyShield框架能有效解决薄障碍物检测问题，具有高精度和低延迟的特点。

Abstract: Drones operating in complex environments face a significant threat from thin
obstacles, such as steel wires and kite strings at the submillimeter level,
which are notoriously difficult for conventional sensors like RGB cameras,
LiDAR, and depth cameras to detect. This paper introduces SkyShield, an
event-driven, end-to-end framework designed for the perception of submillimeter
scale obstacles. Drawing upon the unique features that thin obstacles present
in the event stream, our method employs a lightweight U-Net architecture and an
innovative Dice-Contour Regularization Loss to ensure precise detection.
Experimental results demonstrate that our event-based approach achieves mean F1
Score of 0.7088 with a low latency of 21.2 ms, making it ideal for deployment
on edge and mobile platforms.

</details>


### [28] [Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring](https://arxiv.org/abs/2508.09398)
*El Mustapha Mansouri*

Main category: cs.CV

TL;DR: 提出了一种低成本、本地化的比利时城市花园鸟类监测系统，使用运动触发的IP摄像头和本地服务器进行鸟类检测与分类。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自主监测系统记录城市花园中的鸟类多样性，同时保护隐私并避免云服务费用。

Method: 结合Detectron2进行鸟类定位，使用微调的EfficientNet-B3模型分类40种比利时鸟类，系统运行在普通硬件上。

Result: 分类器在验证集上达到99.5%准确率，实际应用中识别未知物种的top-1准确率为88%。

Conclusion: 系统证明在家中使用低成本硬件进行公民科学级鸟类多样性监测是可行的。

Abstract: This paper presents a low cost, on premise system for autonomous backyard
bird monitoring in Belgian urban gardens. A motion triggered IP camera uploads
short clips via FTP to a local server, where frames are sampled and birds are
localized with Detectron2; cropped regions are then classified by an
EfficientNet-B3 model fine tuned on a 40-species Belgian subset derived from a
larger Kaggle corpus. All processing runs on commodity hardware without a
discrete GPU, preserving privacy and avoiding cloud fees. The physical feeder
uses small entry ports (30 mm) to exclude pigeons and reduce nuisance triggers.
Detector-guided cropping improves classification accuracy over raw-frame
classification. The classifier attains high validation performance on the
curated subset (about 99.5 percent) and delivers practical field accuracy
(top-1 about 88 percent) on held-out species, demonstrating feasibility for
citizen-science-grade biodiversity logging at home.

</details>


### [29] [RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata](https://arxiv.org/abs/2508.09415)
*John S. O'Meara,Jared Hwang,Zeyu Wang,Michael Saugstad,Jon E. Froehlich*

Main category: cs.CV

TL;DR: 论文提出了一个名为RampNet的两阶段流水线，用于扩展路缘坡道检测数据集并提升模型性能。第一阶段通过自动转换政府提供的位置数据生成大规模标注数据集，第二阶段训练高效检测模型。实验表明，该方法显著优于现有工作。


<details>
  <summary>Details</summary>
Motivation: 路缘坡道对城市无障碍环境至关重要，但现有数据稀缺且质量不足。此前尝试通过众包或手动标注改善数据，但效果有限。本文旨在解决这一问题。

Method: 采用两阶段方法：1) 将政府数据自动转换为街景图像的像素坐标，生成21万+标注样本；2) 基于改进的ConvNeXt V2训练检测模型。

Result: 生成数据集精度达94.0% (准确率) 和92.5% (召回率)；检测模型AP为0.9236，远超之前研究。

Conclusion: 本研究首次提供了大规模高质量的坡道数据集、基准和模型，显著提升了检测性能。

Abstract: Curb ramps are critical for urban accessibility, but robustly detecting them
in images remains an open problem due to the lack of large-scale, high-quality
datasets. While prior work has attempted to improve data availability with
crowdsourced or manually labeled data, these efforts often fall short in either
quality or scale. In this paper, we introduce and evaluate a two-stage pipeline
called RampNet to scale curb ramp detection datasets and improve model
performance. In Stage 1, we generate a dataset of more than 210,000 annotated
Google Street View (GSV) panoramas by auto-translating government-provided curb
ramp location data to pixel coordinates in panoramic images. In Stage 2, we
train a curb ramp detection model (modified ConvNeXt V2) from the generated
dataset, achieving state-of-the-art performance. To evaluate both stages of our
pipeline, we compare to manually labeled panoramas. Our generated dataset
achieves 94.0% precision and 92.5% recall, and our detection model reaches
0.9236 AP -- far exceeding prior work. Our work contributes the first
large-scale, high-quality curb ramp detection dataset, benchmark, and model.

</details>


### [30] [Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://arxiv.org/abs/2508.09423)
*Badi Li,Ren-jie Lu,Yu Zhou,Jingke Meng,Wei-shi Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种名为GOAL的生成式流框架，用于物体目标导航任务，通过结合LLM增强的语义地图和流模型，实现了更好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在物体目标导航任务中依赖确定性模型，忽视了室内布局的不确定性，限制了泛化能力。

Method: 提出GOAL框架，利用大语言模型（LLMs）推断空间先验，将这些先验编码为二维高斯场并注入目标地图，通过生成式流模型完成语义地图。

Result: 在MP3D和Gibson数据集上达到了state-of-the-art性能，并在HM3D上展现了强泛化能力。

Conclusion: GOAL通过结合LLM和流模型，显著提升了物体目标导航任务的性能，尤其在泛化能力上表现优异。

Abstract: The Object Goal Navigation (ObjectNav) task challenges agents to locate a
specified object in an unseen environment by imagining unobserved regions of
the scene. Prior approaches rely on deterministic and discriminative models to
complete semantic maps, overlooking the inherent uncertainty in indoor layouts
and limiting their ability to generalize to unseen environments. In this work,
we propose GOAL, a generative flow-based framework that models the semantic
distribution of indoor environments by bridging observed regions with
LLM-enriched full-scene semantic maps. During training, spatial priors inferred
from large language models (LLMs) are encoded as two-dimensional Gaussian
fields and injected into target maps, distilling rich contextual knowledge into
the flow model and enabling more generalizable completions. Extensive
experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D
and Gibson, and shows strong generalization in transfer settings to HM3D. Codes
and pretrained models are available at https://github.com/Badi-Li/GOAL.

</details>


### [31] [What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset](https://arxiv.org/abs/2508.09428)
*Yuxiao Wang,Yu Lei,Wolin Liang,Weiying Xue,Zhenao Wei,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: 论文提出了一种新的视觉任务，同时预测高层动作语义和细粒度身体接触区域，并介绍了数据集PaIR和框架PaIR-Net，实验显示其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能同时建模动作语义及其在场景中的空间上下文，因此需要一种新方法来捕捉这种双重性。

Method: 提出PaIR-Net框架，包含CPAM、PGCS和IIM三个模块，分别负责身体部位识别、接触区域分割和全局关系整合。

Result: PaIR-Net显著优于基线方法，消融实验验证了各模块的有效性。

Conclusion: PaIR-Net能有效结合动作语义和空间上下文，为复杂视觉任务提供新思路。

Abstract: People control their bodies to establish contact with the environment. To
comprehensively understand actions across diverse visual contexts, it is
essential to simultaneously consider \textbf{what} action is occurring and
\textbf{where} it is happening. Current methodologies, however, often
inadequately capture this duality, typically failing to jointly model both
action semantics and their spatial contextualization within scenes. To bridge
this gap, we introduce a novel vision task that simultaneously predicts
high-level action semantics and fine-grained body-part contact regions. Our
proposed framework, PaIR-Net, comprises three key components: the Contact Prior
Aware Module (CPAM) for identifying contact-relevant body parts, the
Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and
the Interaction Inference Module (IIM) responsible for integrating global
interaction relationships. To facilitate this task, we present PaIR (Part-aware
Interaction Representation), a comprehensive dataset containing 13,979 images
that encompass 654 actions, 80 object categories, and 17 body parts.
Experimental evaluation demonstrates that PaIR-Net significantly outperforms
baseline approaches, while ablation studies confirm the efficacy of each
architectural component. The code and dataset will be released upon
publication.

</details>


### [32] [MPT: Motion Prompt Tuning for Micro-Expression Recognition](https://arxiv.org/abs/2508.09446)
*Jiateng Liu,Hengcan Shi,Feng Chen,Zhiwen Shao,Yaonan Wang,Jianfei Cai,Wenming Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为Motion Prompt Tuning (MPT)的新方法，用于调整大型预训练模型（LMs）以进行微表情识别（MER），通过运动放大和高斯标记化提取细微动作作为提示，并在LMs中插入组适配器，显著提升了MER的性能。


<details>
  <summary>Details</summary>
Motivation: 微表情识别（MER）在医疗诊断、测谎等领域具有广泛应用，但由于需要心理学专家的标注，数据集稀少，限制了模型学习。现有的LMs无法捕捉到微表情中短暂且细微的面部动作。

Method: 提出Motion Prompt Tuning (MPT)，包括运动放大和高斯标记化以提取细微动作作为提示，并设计组适配器插入LMs中，增强模型对微表情的区分能力。

Result: 在三个广泛使用的MER数据集上的实验表明，MPT方法一致优于当前最先进的方法。

Conclusion: MPT通过精细调整LMs并提取细微动作特征，有效提升了微表情识别的性能。

Abstract: Micro-expression recognition (MER) is crucial in the affective computing
field due to its wide application in medical diagnosis, lie detection, and
criminal investigation. Despite its significance, obtaining micro-expression
(ME) annotations is challenging due to the expertise required from
psychological professionals. Consequently, ME datasets often suffer from a
scarcity of training samples, severely constraining the learning of MER models.
While current large pre-training models (LMs) offer general and discriminative
representations, their direct application to MER is hindered by an inability to
capture transitory and subtle facial movements-essential elements for effective
MER. This paper introduces Motion Prompt Tuning (MPT) as a novel approach to
adapting LMs for MER, representing a pioneering method for subtle motion prompt
tuning. Particularly, we introduce motion prompt generation, including motion
magnification and Gaussian tokenization, to extract subtle motions as prompts
for LMs. Additionally, a group adapter is carefully designed and inserted into
the LM to enhance it in the target MER domain, facilitating a more nuanced
distinction of ME representation. Furthermore, extensive experiments conducted
on three widely used MER datasets demonstrate that our proposed MPT
consistently surpasses state-of-the-art approaches and verifies its
effectiveness.

</details>


### [33] [RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration](https://arxiv.org/abs/2508.09449)
*Jiaqi Yan,Shuning Xu,Xiangyu Chen,Dell Zhang,Jie Tang,Gangshan Wu,Jie Liu*

Main category: cs.CV

TL;DR: 提出了Retrieval-Augmented Super Resolution（RASR）新范式，通过自动检索高分辨率参考图像解决现有RefSR依赖手动配对的局限性，并在公开数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RefSR方法依赖手动配对的参考图像，限制了实际应用；旨在通过自动检索参考图像提升实用性。

Method: 提出RASR框架，结合语义检索器与扩散生成模型，自动从参考数据库中检索并增强低分辨率图像。

Result: 在RASR-Flickr30数据集上，RASRNet比SISR基线提升0.38 dB PSNR和-0.0131 LPIPS，生成更真实的纹理。

Conclusion: 检索增强是缩小RefSR研究与实际应用差距的有前景方向。

Abstract: Reference-based Super Resolution (RefSR) improves upon Single Image Super
Resolution (SISR) by leveraging high-quality reference images to enhance
texture fidelity and visual realism. However, a critical limitation of existing
RefSR approaches is their reliance on manually curated target-reference image
pairs, which severely constrains their practicality in real-world scenarios. To
overcome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new
and practical RefSR paradigm that automatically retrieves semantically relevant
high-resolution images from a reference database given only a low-quality
input. This enables scalable and flexible RefSR in realistic use cases, such as
enhancing mobile photos taken in environments like zoos or museums, where
category-specific reference data (e.g., animals, artworks) can be readily
collected or pre-curated. To facilitate research in this direction, we
construct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike
prior datasets with fixed target-reference pairs, RASR-Flickr30 provides
per-category reference databases to support open-world retrieval. We further
propose RASRNet, a strong baseline that combines a semantic reference retriever
with a diffusion-based RefSR generator. It retrieves relevant references based
on semantic similarity and employs a diffusion-based generator enhanced with
semantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet
consistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131
LPIPS, while generating more realistic textures. These findings highlight
retrieval augmentation as a promising direction to bridge the gap between
academic RefSR research and real-world applicability.

</details>


### [34] [HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss](https://arxiv.org/abs/2508.09453)
*Abdul Matin,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: HyperKD是一种新型知识蒸馏框架，通过从简单的教师模型向学生模型反向传递知识，解决了基础模型在超光谱遥感中的直接应用问题。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在超光谱遥感中因光谱差异和观测稀缺性而难以直接应用的问题。

Method: 采用特征基础的策略，包括光谱范围通道对齐、空间特征引导掩码和改进的损失函数，从Prithvi基础模型向EnMAP超光谱图像学生模型传递知识。

Result: HyperKD显著提高了MAEs中的表示学习能力，增强了重建保真度和下游任务的稳健性，如土地覆盖分类和作物类型识别。

Conclusion: HyperKD展示了知识蒸馏框架在超光谱遥感分析中的潜力，通过弥合光谱域差距，实现了基础模型的有效应用。

Abstract: The proliferation of foundation models, pretrained on large-scale unlabeled
datasets, has emerged as an effective approach in creating adaptable and
reusable architectures that can be leveraged for various downstream tasks using
satellite observations. However, their direct application to hyperspectral
remote sensing remains challenging due to inherent spectral disparities and the
scarcity of available observations. In this work, we present HyperKD, a novel
knowledge distillation framework that enables transferring learned
representations from a teacher model into a student model for effective
development of a foundation model on hyperspectral images. Unlike typical
knowledge distillation frameworks, which use a complex teacher to guide a
simpler student, HyperKD enables an inverse form of knowledge transfer across
different types of spectral data, guided by a simpler teacher model. Building
upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi
foundational model into a student tailored for EnMAP hyperspectral imagery.
HyperKD addresses the inverse domain adaptation problem with spectral gaps by
introducing a feature-based strategy that includes spectral range-based channel
alignment, spatial feature-guided masking, and an enhanced loss function
tailored for hyperspectral images. HyperKD bridges the substantial spectral
domain gap, enabling the effective use of pretrained foundation models for
geospatial applications. Extensive experiments show that HyperKD significantly
improves representation learning in MAEs, leading to enhanced reconstruction
fidelity and more robust performance on downstream tasks such as land cover
classification, crop type identification, and soil organic carbon prediction,
underpinning the potential of knowledge distillation frameworks in remote
sensing analytics with hyperspectral imagery.

</details>


### [35] [Animate-X++: Universal Character Image Animation with Dynamic Backgrounds](https://arxiv.org/abs/2508.09454)
*Shuai Tan,Biao Gong,Zhuoxin Liu,Yan Wang,Xi Chen,Yifan Feng,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Animate-X++ 是一个基于 DiT 的通用动画框架，用于各种角色类型（包括拟人角色），并改进了运动表示和背景动态效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于人类角色且在静态背景下生成视频，限制了在游戏和娱乐行业中拟人角色的应用和视频的真实感。

Method: 提出 Pose Indicator 结合隐式和显式方式捕获运动模式，并采用多任务训练策略联合优化动画和文本驱动背景动态任务。

Result: 实验表明 Animate-X++ 在拟人角色动画和背景动态生成上表现优越，并通过 A2Bench 基准验证了其广泛适用性。

Conclusion: Animate-X++ 解决了现有方法的局限性，为通用角色动画和视频真实感提供了有效解决方案。

Abstract: Character image animation, which generates high-quality videos from a
reference image and target pose sequence, has seen significant progress in
recent years. However, most existing methods only apply to human figures, which
usually do not generalize well on anthropomorphic characters commonly used in
industries like gaming and entertainment. Furthermore, previous methods could
only generate videos with static backgrounds, which limits the realism of the
videos. For the first challenge, our in-depth analysis suggests to attribute
this limitation to their insufficient modeling of motion, which is unable to
comprehend the movement pattern of the driving video, thus imposing a pose
sequence rigidly onto the target character. To this end, this paper proposes
Animate-X++, a universal animation framework based on DiT for various character
types, including anthropomorphic characters. To enhance motion representation,
we introduce the Pose Indicator, which captures comprehensive motion pattern
from the driving video through both implicit and explicit manner. The former
leverages CLIP visual features of a driving video to extract its gist of
motion, like the overall movement pattern and temporal relations among motions,
while the latter strengthens the generalization of DiT by simulating possible
inputs in advance that may arise during inference. For the second challenge, we
introduce a multi-task training strategy that jointly trains the animation and
TI2V tasks. Combined with the proposed partial parameter training, this
approach achieves not only character animation but also text-driven background
dynamics, making the videos more realistic. Moreover, we introduce a new
Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of
Animate-X++ on universal and widely applicable animation images. Extensive
experiments demonstrate the superiority and effectiveness of Animate-X++.

</details>


### [36] [IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding](https://arxiv.org/abs/2508.09456)
*Junxian Li,Beining Xu,Di Zhang*

Main category: cs.CV

TL;DR: 提出了一种针对视觉语言模型的新型输入感知后门攻击方法IAG，通过自适应触发器生成器操纵模型的定位行为，在不影响干净样本准确性的情况下实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在视觉定位任务中的安全性问题，特别是后门攻击的潜在威胁。

Method: 使用基于文本条件U-Net的自适应触发生成器，将攻击目标的语义信息嵌入图像，并通过重建损失确保隐蔽性。

Result: 在InternVL-2.5-8B上ASR@0.5超过65%，且在Ferret-7B和LlaVA-1.5-7B上表现出较高的攻击潜力。

Conclusion: IAG方法展示了后门攻击的鲁棒性和可转移性，为视觉语言模型的安全研究提供了新的挑战。

Abstract: Vision-language models (VLMs) have shown significant advancements in tasks
such as visual grounding, where they localize specific objects in images based
on natural language queries and images. However, security issues in visual
grounding tasks for VLMs remain underexplored, especially in the context of
backdoor attacks. In this paper, we introduce a novel input-aware backdoor
attack method, IAG, designed to manipulate the grounding behavior of VLMs. This
attack forces the model to ground a specific target object in the input image,
regardless of the user's query. We propose an adaptive trigger generator that
embeds the semantic information of the attack target's description into the
original image using a text-conditional U-Net, thereby overcoming the
open-vocabulary attack challenge. To ensure the attack's stealthiness, we
utilize a reconstruction loss to minimize visual discrepancies between poisoned
and clean images. Additionally, we introduce a unified method for generating
attack data. IAG is evaluated theoretically and empirically, demonstrating its
feasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches
over 65\% on various testing sets. IAG also shows promising potential on
manipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on
clean samples. Extensive specific experiments, such as ablation study and
potential defense, also indicate the robustness and transferability of our
attack.

</details>


### [37] [RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization](https://arxiv.org/abs/2508.09459)
*Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia*

Main category: cs.CV

TL;DR: RelayFormer是一种统一且模块化的架构，用于图像和视频中的视觉篡改定位，通过全局-局部中继注意力机制实现了高效且分辨率无关的处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态泛化和处理高分辨率或长时间输入时效率不足，因此提出了RelayFormer来解决这些问题。

Method: 采用灵活的局部单元和全局-局部中继注意力机制（GLoRA），并与现有关注力模型（如ViT和SegFormer）无缝集成，通过轻量级调整模块实现兼容性。此外，设计了一个基于查询的轻量级掩码解码器，支持线性复杂度的单次推理。

Result: 在多个基准测试中，RelayFormer实现了最先进的定位性能，为可扩展且模态无关的视觉篡改定位设定了新基准。

Conclusion: RelayFormer通过其模块化设计和高效处理能力在跨模态和高分辨率输入任务中展现出显著优势，为视觉篡改定位领域提供了新的解决方案。

Abstract: Visual manipulation localization (VML) -- across both images and videos -- is
a crucial task in digital forensics that involves identifying tampered regions
in visual content. However, existing methods often lack cross-modal
generalization and struggle to handle high-resolution or long-duration inputs
efficiently.
  We propose RelayFormer, a unified and modular architecture for visual
manipulation localization across images and videos. By leveraging flexible
local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables
scalable, resolution-agnostic processing with strong generalization. Our
framework integrates seamlessly with existing Transformer-based backbones, such
as ViT and SegFormer, via lightweight adaptation modules that require only
minimal architectural changes, ensuring compatibility without disrupting
pretrained representations.
  Furthermore, we design a lightweight, query-based mask decoder that supports
one-shot inference across video sequences with linear complexity. Extensive
experiments across multiple benchmarks demonstrate that our approach achieves
state-of-the-art localization performance, setting a new baseline for scalable
and modality-agnostic VML. Code is available at:
https://github.com/WenOOI/RelayFormer.

</details>


### [38] [Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy](https://arxiv.org/abs/2508.09461)
*Hao Yu,Rupayan Mallick,Margrit Betke,Sarah Adel Bargal*

Main category: cs.CV

TL;DR: GEN-AFFECT是一个新颖的框架，通过多模态扩散变换器和身份-表情表示生成个性化、表达丰富且身份一致性强的2D虚拟形象。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细粒度表情和保持身份一致性上表现不足，需要一种能生成多样化表情且不损失身份特征的新方法。

Method: 使用多模态扩散变换器，结合提取的身份-表情表示，并通过一致注意力机制在推理阶段共享信息。

Result: 在表情准确性、身份保持和表情间的身份一致性上，GEN-AFFECT优于现有方法。

Conclusion: GEN-AFFECT为个性化虚拟形象生成提供了高效且一致的解决方案。

Abstract: Different forms of customized 2D avatars are widely used in gaming
applications, virtual communication, education, and content creation. However,
existing approaches often fail to capture fine-grained facial expressions and
struggle to preserve identity across different expressions. We propose
GEN-AFFECT, a novel framework for personalized avatar generation that generates
expressive and identity-consistent avatars with a diverse set of facial
expressions. Our framework proposes conditioning a multimodal diffusion
transformer on an extracted identity-expression representation. This enables
identity preservation and representation of a wide range of facial expressions.
GEN-AFFECT additionally employs consistent attention at inference for
information sharing across the set of generated expressions, enabling the
generation process to maintain identity consistency over the array of generated
fine-grained expressions. GEN-AFFECT demonstrates superior performance compared
to previous state-of-the-art methods on the basis of the accuracy of the
generated expressions, the preservation of the identity and the consistency of
the target identity across an array of fine-grained facial expressions.

</details>


### [39] [Event-driven Robust Fitting on Neuromorphic Hardware](https://arxiv.org/abs/2508.09466)
*Tam Ngoc-Bang Nguyen,Anh-Dzung Doan,Zhipeng Cai,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 提出了一种基于神经形态计算的新型能量高效鲁棒拟合方法，显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒拟合方法能耗高，而能量效率在AI应用中日益重要。

Method: 设计了基于Intel Loihi 2的脉冲神经网络，并提出事件驱动模型估计算法。

Result: 相比标准CPU，能耗降低至15%，精度相当。

Conclusion: 神经形态计算为高效鲁棒拟合提供了可行解决方案。

Abstract: Robust fitting of geometric models is a fundamental task in many computer
vision pipelines. Numerous innovations have been produced on the topic, from
improving the efficiency and accuracy of random sampling heuristics to
generating novel theoretical insights that underpin new approaches with
mathematical guarantees. However, one aspect of robust fitting that has
received little attention is energy efficiency. This performance metric has
become critical as high energy consumption is a growing concern for AI
adoption. In this paper, we explore energy-efficient robust fitting via the
neuromorphic computing paradigm. Specifically, we designed a novel spiking
neural network for robust fitting on real neuromorphic hardware, the Intel
Loihi 2. Enabling this are novel event-driven formulations of model estimation
that allow robust fitting to be implemented in the unique architecture of Loihi
2, and algorithmic strategies to alleviate the current limited precision and
instruction set of the hardware. Results show that our neuromorphic robust
fitting consumes only a fraction (15%) of the energy required to run the
established robust fitting algorithm on a standard CPU to equivalent accuracy.

</details>


### [40] [CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios](https://arxiv.org/abs/2508.09470)
*Jialei Xu,Zizhuang Wei,Weikang You,Linyun Li,Weijian Sun*

Main category: cs.CV

TL;DR: CitySeg是一种基于文本模态的城市规模点云语义分割基础模型，通过多模态和分层分类策略解决了数据分布不均和标签不一致问题，并实现了零样本推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型因数据规模有限和数据集间领域差距导致的泛化能力不足问题。

Method: 1. 定制数据预处理规则；2. 提出局部-全局交叉注意力网络；3. 引入分层分类策略和图形编码器；4. 采用两阶段训练策略和铰链损失。

Result: 在九个封闭数据集上实现SOTA性能，并首次实现零样本泛化能力。

Conclusion: CitySeg在城市场景点云分割中表现出色，通过多模态融合和分层策略显著提升了泛化能力。

Abstract: Semantic segmentation of city-scale point clouds is a critical technology for
Unmanned Aerial Vehicle (UAV) perception systems, enabling the classification
of 3D points without relying on any visual information to achieve comprehensive
3D understanding. However, existing models are frequently constrained by the
limited scale of 3D data and the domain gap between datasets, which lead to
reduced generalization capability. To address these challenges, we propose
CitySeg, a foundation model for city-scale point cloud semantic segmentation
that incorporates text modality to achieve open vocabulary segmentation and
zero-shot inference. Specifically, in order to mitigate the issue of
non-uniform data distribution across multiple domains, we customize the data
preprocessing rules, and propose a local-global cross-attention network to
enhance the perception capabilities of point networks in UAV scenarios. To
resolve semantic label discrepancies across datasets, we introduce a
hierarchical classification strategy. A hierarchical graph established
according to the data annotation rules consolidates the data labels, and the
graph encoder is used to model the hierarchical relationships between
categories. In addition, we propose a two-stage training strategy and employ
hinge loss to increase the feature separability of subcategories. Experimental
results demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA)
performance on nine closed-set benchmarks, significantly outperforming existing
approaches. Moreover, for the first time, CitySeg enables zero-shot
generalization in city-scale point cloud scenarios without relying on visual
information.

</details>


### [41] [Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection](https://arxiv.org/abs/2508.09475)
*Shibo Yao,Renshuai Tao,Xiaolong Zheng,Chao Liang,Chunjie Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种无需训练的少样本深度伪造检测方法（FTNet），通过利用少量真实和伪造样本进行比较分类，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 针对深度伪造检测中模型对未知样本泛化能力差的问题，研究者提出将问题转化为少样本任务，利用少量样本提升检测效果。

Method: 提出了Few-shot Training-free Network (FTNet)，仅使用一个伪造样本和真实样本进行比较分类，无需训练或参数更新。

Result: 在29种生成模型生成的图像上测试，FTNet平均性能提升8.7%，达到新的SoTA。

Conclusion: 通过利用失败样本，FTNet为真实世界中的少样本深度伪造检测提供了新思路。

Abstract: Recent deepfake detection studies often treat unseen sample detection as a
``zero-shot" task, training on images generated by known models but
generalizing to unknown ones. A key real-world challenge arises when a model
performs poorly on unknown samples, yet these samples remain available for
analysis. This highlights that it should be approached as a ``few-shot" task,
where effectively utilizing a small number of samples can lead to significant
improvement. Unlike typical few-shot tasks focused on semantic understanding,
deepfake detection prioritizes image realism, which closely mirrors real-world
distributions. In this work, we propose the Few-shot Training-free Network
(FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet
differs from traditional methods that rely on large-scale known data for
training. Instead, FTNet uses only one fake samplefrom an evaluation set,
mimicking the scenario where new samples emerge in the real world and can be
gathered for use, without any training or parameter updates. During evaluation,
each test sample is compared to the known fake and real samples, and it is
classified based on the category of the nearest sample. We conduct a
comprehensive analysis of AI-generated images from 29 different generative
models and achieve a new SoTA performance, with an average improvement of 8.7\%
compared to existing methods. This work introduces a fresh perspective on
real-world deepfake detection: when the model struggles to generalize on a
few-shot sample, leveraging the failed samples leads to better performance.

</details>


### [42] [From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts](https://arxiv.org/abs/2508.09476)
*Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 视频生成模型在大角度面部时难以保留身份特征，本研究提出混合面部专家（MoFE）和数据处理流程，并构建LFA数据集，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成模型在大角度面部时身份特征保留不足的问题。

Method: 引入混合面部专家（MoFE）动态整合三种专家特征，并设计数据处理流程构建LFA数据集。

Result: 在LFA数据集上，方法在面部相似度、FID和CLIP对齐上优于现有方法。

Conclusion: MoFE和LFA数据集有效解决了大角度面部时的身份保留问题。

Abstract: Current video generation models struggle with identity preservation under
large facial angles, primarily facing two challenges: the difficulty in
exploring an effective mechanism to integrate identity features into DiT
structure, and the lack of targeted coverage of large facial angles in existing
open-source video datasets. To address these, we present two key innovations.
First, we introduce a Mixture of Facial Experts (MoFE) that dynamically
combines complementary cues from three specialized experts, each designed to
capture distinct but mutually reinforcing aspects of facial attributes. The
identity expert captures cross-pose identity-sensitive features, the semantic
expert extracts high-level visual semantxics, and the detail expert preserves
pixel-level features (e.g., skin texture, color gradients). Furthermore, to
mitigate dataset limitations, we have tailored a data processing pipeline
centered on two key aspects: Face Constraints and Identity Consistency. Face
Constraints ensure facial angle diversity and a high proportion of facial
regions, while Identity Consistency preserves coherent person-specific features
across temporal sequences, collectively addressing the scarcity of large facial
angles and identity-stable training data in existing datasets. Leveraging this
pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from
existing open-source human video datasets, comprising 460K video clips with
annotated facial angles. Experimental results on the LFA benchmark demonstrate
that our method, empowered by the LFA dataset, significantly outperforms prior
SOTA methods in face similarity, face FID, and CLIP semantic alignment. The
code and dataset will be made publicly available at
https://github.com/rain152/LFA-Video-Generation.

</details>


### [43] [CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection](https://arxiv.org/abs/2508.09477)
*Zhipeng Yuan,Kai Wang,Weize Quan,Dong-Ming Yan,Tieru Wu*

Main category: cs.CV

TL;DR: 提出了一种通用的AI生成图像检测器，通过异常检测视角，无需访问AIIs并利用无监督学习，在多种生成模型的AIIs上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成模型的发展，AI生成图像（AIIs）的视觉质量接近真实图像，引发了安全隐患。传统检测方法在新生成模型上表现有限。

Method: 使用预训练的CLIP编码器作为特征提取器，设计无监督的流式模型，利用代理图像（如经过频谱修改的自然图像）进行训练。

Result: 在多种生成模型的AIIs上验证了方法的有效性。

Conclusion: 该检测器无需访问AIIs，通过无监督学习实现了对新生成模型的通用检测能力。

Abstract: With the rapid advancement of AI generative models, the visual quality of
AI-generated images (AIIs) has become increasingly close to natural images,
which inevitably raises security concerns. Most AII detectors often employ the
conventional image classification pipeline with natural images and AIIs
(generated by a generative model), which can result in limited detection
performance for AIIs from unseen generative models. To solve this, we proposed
a universal AI-generated image detector from the perspective of anomaly
detection. Our discriminator does not need to access any AIIs and learn a
generalizable representation with unsupervised learning. Specifically, we use
the pre-trained CLIP encoder as the feature extractor and design a normalizing
flow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by
applying a spectral modification operation on natural images, are used for
training. Our models are trained by minimizing the likelihood of proxy images,
optionally combined with maximizing the likelihood of natural images. Extensive
experiments demonstrate the effectiveness of our method on AIIs produced by
various image generators.

</details>


### [44] [GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs](https://arxiv.org/abs/2508.09478)
*Moinak Bhattacharya,Gagandeep Singh,Shubham Jain,Prateek Prasanna*

Main category: cs.CV

TL;DR: GazeLT是一种结合视觉注意力的方法，用于改善长尾疾病分类，通过捕捉放射科医师的眼动模式来提升深度学习框架的性能。


<details>
  <summary>Details</summary>
Motivation: 放射科医师的眼动模式包含了疾病相关信息，将这些动态视觉注意力整合到深度学习框架中可以提升自动化图像解读的准确性，尤其是针对长尾类疾病。

Method: GazeLT利用视觉搜索过程的时序特性，通过整合与分离机制，捕捉放射科医师的主要和次要注意力区域，以优化长尾疾病分类。

Result: 在NIH-CXR-LT和MIMIC-CXR-LT数据集上，GazeLT平均准确率分别比最佳长尾损失方法和基于视觉注意力的基线方法高出4.1%和21.7%。

Conclusion: GazeLT通过有效利用视觉注意力信息，显著提升了长尾疾病分类的性能，为自动化图像解读提供了新思路。

Abstract: In this work, we present GazeLT, a human visual attention
integration-disintegration approach for long-tailed disease classification. A
radiologist's eye gaze has distinct patterns that capture both fine-grained and
coarser level disease related information. While interpreting an image, a
radiologist's attention varies throughout the duration; it is critical to
incorporate this into a deep learning framework to improve automated image
interpretation. Another important aspect of visual attention is that apart from
looking at major/obvious disease patterns, experts also look at
minor/incidental findings (few of these constituting long-tailed classes)
during the course of image interpretation. GazeLT harnesses the temporal aspect
of the visual search process, via an integration and disintegration mechanism,
to improve long-tailed disease classification. We show the efficacy of GazeLT
on two publicly available datasets for long-tailed disease classification,
namely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets.
GazeLT outperforms the best long-tailed loss by 4.1% and the visual
attention-based baseline by 21.7% in average accuracy metrics for these
datasets. Our code is available at https://github.com/lordmoinak1/gazelt.

</details>


### [45] [SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images](https://arxiv.org/abs/2508.09479)
*Xuejun Huang,Xinyi Liu,Yi Wan,Zhi Zheng,Bin Zhang,Mingtao Xiong,Yingying Pei,Yongjun Zhang*

Main category: cs.CV

TL;DR: SkySplat是一种自监督框架，通过将RPC模型与3DGS结合，显著提升了稀疏卫星图像的3D重建效果，速度和准确性均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在稀疏卫星图像重建中存在与RPC模型不兼容及泛化能力不足的问题，尤其是多时相卫星图像的几何约束弱和辐射不一致性挑战。

Method: 提出SkySplat框架，整合RPC模型，引入Cross-Self Consistency Module（CSCM）抑制瞬变物体干扰，通过多视角一致性聚合优化重建。

Result: SkySplat比EOGS快86倍且精度更高，在DFC19数据集上MAE从13.18米降至1.80米，在MVS3D基准测试中表现出强泛化性。

Conclusion: SkySplat通过自监督和辐射鲁棒高度监督，无需地面实况高度图，显著提升了稀疏卫星图像的3D重建性能。

Abstract: Three-dimensional scene reconstruction from sparse-view satellite images is a
long-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its
variants have recently attracted attention for its high efficiency, existing
methods remain unsuitable for satellite images due to incompatibility with
rational polynomial coefficient (RPC) models and limited generalization
capability. Recent advances in generalizable 3DGS approaches show potential,
but they perform poorly on multi-temporal sparse satellite images due to
limited geometric constraints, transient objects, and radiometric
inconsistencies. To address these limitations, we propose SkySplat, a novel
self-supervised framework that integrates the RPC model into the generalizable
3DGS pipeline, enabling more effective use of sparse geometric cues for
improved reconstruction. SkySplat relies only on RGB images and
radiometric-robust relative height supervision, thereby eliminating the need
for ground-truth height maps. Key components include a Cross-Self Consistency
Module (CSCM), which mitigates transient object interference via
consistency-based masking, and a multi-view consistency aggregation strategy
that refines reconstruction results. Compared to per-scene optimization
methods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy.
It also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to
1.80 m on the DFC19 dataset significantly, and demonstrates strong
cross-dataset generalization on the MVS3D benchmark.

</details>


### [46] [SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection](https://arxiv.org/abs/2508.09487)
*Ju Yeon Kang,Jaehong Park,Semin Kim,Ji Won Yoon,Nam Soo Kim*

Main category: cs.CV

TL;DR: 提出了一种基于语义感知重建误差（SARE）的方法，用于检测扩散生成的假图，具有强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法在面对未见过的生成模型时性能下降，因为它们依赖于特定模型的伪影。假图与标题的相似性比真实图像更高，这一现象为检测提供了新思路。

Method: 通过测量图像与其标题引导重建结果之间的语义差异，提出SARE表示。假图与标题高度一致，重建时语义变化小；而真实图像因标题无法完全捕捉复杂内容，重建时语义变化显著。

Result: SARE方法在GenImage和CommunityForensics等基准测试中表现出色，优于现有基线。

Conclusion: SARE是一种有效的检测特征，能够跨多样生成模型实现稳健检测。

Abstract: Recently, diffusion-generated image detection has gained increasing
attention, as the rapid advancement of diffusion models has raised serious
concerns about their potential misuse. While existing detection methods have
achieved promising results, their performance often degrades significantly when
facing fake images from unseen, out-of-distribution (OOD) generative models,
since they primarily rely on model-specific artifacts. To address this
limitation, we explore a fundamental property commonly observed in fake images.
Motivated by the observation that fake images tend to exhibit higher similarity
to their captions than real images, we propose a novel representation, namely
Semantic-Aware Reconstruction Error (SARE), that measures the semantic
difference between an image and its caption-guided reconstruction. The
hypothesis behind SARE is that real images, whose captions often fail to fully
capture their complex visual content, may undergo noticeable semantic shifts
during the caption-guided reconstruction process. In contrast, fake images,
which closely align with their captions, show minimal semantic changes. By
quantifying these semantic shifts, SARE can be utilized as a discriminative
feature for robust detection across diverse generative models. We empirically
demonstrate that the proposed method exhibits strong generalization,
outperforming existing baselines on benchmarks including GenImage and
CommunityForensics.

</details>


### [47] [CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking](https://arxiv.org/abs/2508.09499)
*Liyan Jia,Chuan-Xian Ren,Hong Yan*

Main category: cs.CV

TL;DR: CWFBind是一种基于局部曲率特征的加权、快速且准确的分子对接方法，通过整合几何信息提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在分子对接中忽略了关键几何信息，导致不准确的结合构象预测。

Method: CWFBind引入局部曲率描述符增强几何表示，嵌入度感知加权机制，并采用配体感知动态半径策略解决类不平衡问题。

Result: CWFBind在多个对接基准测试中表现优异，平衡了准确性与效率。

Conclusion: CWFBind通过几何信息整合和改进的加权机制，显著提升了分子对接的预测性能。

Abstract: Accurately predicting the binding conformation of small-molecule ligands to
protein targets is a critical step in rational drug design. Although recent
deep learning-based docking surpasses traditional methods in speed and
accuracy, many approaches rely on graph representations and language
model-inspired encoders while neglecting critical geometric information,
resulting in inaccurate pocket localization and unrealistic binding
conformations. In this study, we introduce CWFBind, a weighted, fast, and
accurate docking method based on local curvature features. Specifically, we
integrate local curvature descriptors during the feature extraction phase to
enrich the geometric representation of both proteins and ligands, complementing
existing chemical, sequence, and structural features. Furthermore, we embed
degree-aware weighting mechanisms into the message passing process, enhancing
the model's ability to capture spatial structural distinctions and interaction
strengths. To address the class imbalance challenge in pocket prediction,
CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced
loss function, facilitating more precise identification of binding regions and
key residues. Comprehensive experimental evaluations demonstrate that CWFBind
achieves competitive performance across multiple docking benchmarks, offering a
balanced trade-off between accuracy and efficiency.

</details>


### [48] [Generation of Indian Sign Language Letters, Numbers, and Words](https://arxiv.org/abs/2508.09522)
*Ajeet Kumar Yadav,Nishant Kumar,Rathna G N*

Main category: cs.CV

TL;DR: 该论文提出一种结合ProGAN和SAGAN的GAN变体，用于生成高分辨率且特征丰富的印度手语图像，优于传统ProGAN，同时发布了一个大型数据集。


<details>
  <summary>Details</summary>
Motivation: 手语是与听力障碍者沟通的重要媒介，但手语生成技术仍需探索。研究旨在通过改进注意力机制，生成高质量的手语图像，解决分辨率与细节的平衡问题。

Method: 开发了一种结合Progressive Growing GAN (ProGAN)和Self-Attention GAN (SAGAN)的GAN变体，用于生成特征丰富、高分辨率和类条件的手语图像。

Result: 改进的注意力模型在Inception Score (IS)和Fréchet Inception Distance (FID)上分别提升了3.2和30.12，同时发布了一个包含印度手语字母、数字和129个单词的大型数据集。

Conclusion: 该研究成功生成高质量印度手语图像，并通过发布的公开数据集为相关研究提供了资源支持。

Abstract: Sign language, which contains hand movements, facial expressions and bodily
gestures, is a significant medium for communicating with hard-of-hearing
people. A well-trained sign language community communicates easily, but those
who don't know sign language face significant challenges. Recognition and
generation are basic communication methods between hearing and hard-of-hearing
individuals. Despite progress in recognition, sign language generation still
needs to be explored. The Progressive Growing of Generative Adversarial Network
(ProGAN) excels at producing high-quality images, while the Self-Attention
Generative Adversarial Network (SAGAN) generates feature-rich images at medium
resolutions. Balancing resolution and detail is crucial for sign language image
generation. We are developing a Generative Adversarial Network (GAN) variant
that combines both models to generate feature-rich, high-resolution, and
class-conditional sign language images. Our modified Attention-based model
generates high-quality images of Indian Sign Language letters, numbers, and
words, outperforming the traditional ProGAN in Inception Score (IS) and
Fr\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,
respectively. Additionally, we are publishing a large dataset incorporating
high-quality images of Indian Sign Language alphabets, numbers, and 129 words.

</details>


### [49] [SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking](https://arxiv.org/abs/2508.09524)
*Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao*

Main category: cs.CV

TL;DR: 论文首次系统研究了单目标跟踪中的相似物体干扰（SOI），提出通过外部认知指导（如自然语言）解决SOI问题，并构建了SOIBench基准测试，发现现有视觉语言跟踪方法效果不佳，最终提出基于大规模视觉语言模型的新方法，取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 相似物体干扰（SOI）是单目标跟踪（SOT）中一个长期被忽视的关键瓶颈，论文旨在量化SOI的影响并提出解决方案。

Method: 通过在线干扰掩码实验量化SOI影响，构建SOIBench基准测试，并提出基于大规模视觉语言模型（VLM）的新方法。

Result: 消除干扰源显著提升跟踪性能（AUC增益达4.35），新方法在语义认知指导下AUC增益达0.93，远超现有方法。

Conclusion: SOIBench为语义认知跟踪研究提供了标准化平台，基于VLM的新方法显著提升性能，为跟踪领域带来新见解。

Abstract: In this paper, we present the first systematic investigation and
quantification of Similar Object Interference (SOI), a long-overlooked yet
critical bottleneck in Single Object Tracking (SOT). Through controlled Online
Interference Masking (OIM) experiments, we quantitatively demonstrate that
eliminating interference sources leads to substantial performance improvements
(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a
primary constraint for robust tracking and highlighting the feasibility of
external cognitive guidance. Building upon these insights, we adopt natural
language as a practical form of external guidance, and construct SOIBench-the
first semantic cognitive guidance benchmark specifically targeting SOI
challenges. It automatically mines SOI frames through multi-tracker collective
judgment and introduces a multi-level annotation protocol to generate precise
semantic guidance texts. Systematic evaluation on SOIBench reveals a striking
finding: existing vision-language tracking (VLT) methods fail to effectively
exploit semantic cognitive guidance, achieving only marginal improvements or
even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we
propose a novel paradigm employing large-scale vision-language models (VLM) as
external cognitive engines that can be seamlessly integrated into arbitrary RGB
trackers. This approach demonstrates substantial improvements under semantic
cognitive guidance (AUC gains up to 0.93), representing a significant
advancement over existing VLT methods. We hope SOIBench will serve as a
standardized evaluation platform to advance semantic cognitive tracking
research and contribute new insights to the tracking research community.

</details>


### [50] [Learning Spatial Decay for Vision Transformers](https://arxiv.org/abs/2508.09525)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: SDT引入了一种新的上下文感知门控机制（CAG），通过动态调整空间衰减来优化ViT在空间结构任务中的性能。


<details>
  <summary>Details</summary>
Motivation: ViT的自注意力机制缺乏显式空间归纳偏置，导致空间结构任务表现不佳。现有方法基于固定距离度量，无法适应多样视觉场景。

Method: SDT结合曼哈顿距离空间先验与学习的内容表示，通过CAG机制动态生成数据相关的空间衰减。

Result: 在ImageNet-1K分类和生成任务中，SDT表现优于基线模型。

Conclusion: SDT为ViT的空间注意力增强提供了新范式。

Abstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their
self-attention mechanism lacks explicit spatial inductive biases, leading to
suboptimal performance on spatially-structured tasks. Existing approaches
introduce data-independent spatial decay based on fixed distance metrics,
applying uniform attention weighting regardless of image content and limiting
adaptability to diverse visual scenarios. Inspired by recent advances in large
language models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX)
significantly outperform static alternatives, we present the first successful
adaptation of data-dependent spatial decay to 2D vision transformers. We
introduce \textbf{Spatial Decay Transformer (SDT)}, featuring a novel
Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent
decay for patch interactions. Our approach learns to modulate spatial attention
based on both content relevance and spatial proximity. We address the
fundamental challenge of 1D-to-2D adaptation through a unified spatial-content
fusion framework that integrates manhattan distance-based spatial priors with
learned content representations. Extensive experiments on ImageNet-1K
classification and generation tasks demonstrate consistent improvements over
strong baselines. Our work establishes data-dependent spatial decay as a new
paradigm for enhancing spatial attention in vision transformers.

</details>


### [51] [Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing](https://arxiv.org/abs/2508.09528)
*Gang Qu,Ping Wang,Siming Zheng,Xin Yuan*

Main category: cs.CV

TL;DR: 该论文提出了一种新型的不对称Kronecker压缩感知模型（AKCS）和测量感知交叉注意力机制（MACA），结合到展开网络中（MEUNet），显著提升了图像压缩感知任务的重建精度和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在感知阶段的测量不相干性和重建阶段的隐式测量表示上存在不足，限制了整体性能。论文旨在解决这两个问题。

Method: 提出AKCS模型以提高测量不相干性，并通过MACA机制学习隐式测量表示，最终结合到展开网络中形成MEUNet。

Result: 实验证明MEUNet在重建精度和推理速度上达到最新水平。

Conclusion: 通过改进测量不相干性和学习测量表示，MEUNet在图像压缩感知任务中表现出色。

Abstract: Deep networks have achieved remarkable success in image compressed sensing
(CS) task, namely reconstructing a high-fidelity image from its compressed
measurement. However, existing works are deficient inincoherent compressed
measurement at sensing phase and implicit measurement representations at
reconstruction phase, limiting the overall performance. In this work, we answer
two questions: 1) how to improve the measurement incoherence for decreasing the
ill-posedness; 2) how to learn informative representations from measurements.
To this end, we propose a novel asymmetric Kronecker CS (AKCS) model and
theoretically present its better incoherence than previous Kronecker CS with
minimal complexity increase. Moreover, we reveal that the unfolding networks'
superiority over non-unfolding ones result from sufficient gradient descents,
called explicit measurement representations. We propose a measurement-aware
cross attention (MACA) mechanism to learn implicit measurement representations.
We integrate AKCS and MACA into widely-used unfolding architecture to get a
measurement-enhanced unfolding network (MEUNet). Extensive experiences
demonstrate that our MEUNet achieves state-of-the-art performance in
reconstruction accuracy and inference speed.

</details>


### [52] [COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection](https://arxiv.org/abs/2508.09533)
*Peiran Peng,Tingfa Xu,Liqiang Song,Mengqi Zhu,Yuqiang Fang,Jianan Li*

Main category: cs.CV

TL;DR: 论文提出COXNet框架，通过多层融合和动态对齐解决RGBT微小物体检测问题，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 无人机场景下RGBT图像中微小物体检测面临空间错位、低光照等问题，现有方法难以有效利用多模态信息。

Method: COXNet通过跨层融合模块、动态对齐和尺度细化模块，以及优化的标签分配策略提升检测效果。

Result: 在RGBTDronePerson数据集上，COXNet比现有方法提升了3.32%的mAP50。

Conclusion: COXNet在复杂环境中表现出色，为RGBT微小物体检测提供了有效解决方案。

Abstract: Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is
a critical challenge in computer vision, particularly in surveillance, search
and rescue, and autonomous navigation. Drone-based scenarios exacerbate these
challenges due to spatial misalignment, low-light conditions, occlusion, and
cluttered backgrounds. Current methods struggle to leverage the complementary
information between visible and thermal modalities effectively. We propose
COXNet, a novel framework for RGBT tiny object detection, addressing these
issues through three core innovations: i) the Cross-Layer Fusion Module, fusing
high-level visible and low-level thermal features for enhanced semantic and
spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module,
correcting cross-modal spatial misalignments and preserving multi-scale
features; and iii) an optimized label assignment strategy using the GeoShape
Similarity Measure for better localization. COXNet achieves a 3.32\% mAP$_{50}$
improvement on the RGBTDronePerson dataset over state-of-the-art methods,
demonstrating its effectiveness for robust detection in complex environments.

</details>


### [53] [Iterative Volume Fusion for Asymmetric Stereo Matching](https://arxiv.org/abs/2508.09543)
*Yuanting Gao,Linghao Shen*

Main category: cs.CV

TL;DR: 针对双目视觉中不对称性问题，提出了一种两阶段迭代体积融合网络（IVF-AStereo），通过综合两种成本体积方法解决匹配问题，效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统立体匹配算法假设双目视觉对称，但实际中多相机系统（如长焦-广角组合）会引入不对称性，影响成本体积计算。

Method: 研究了两种成本体积构建方法的匹配成本分布，提出两阶段网络：先用聚合拼接体积优化相关体积，再融合两体积提升细节。

Result: 在不对称场景下表现优异，对分辨率与颜色退化具有鲁棒性，广泛实验验证了有效性。

Conclusion: 综合两种成本体积方法能有效解决不对称立体匹配问题，为多相机系统提供了新思路。

Abstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming
symmetric visual properties between binocular visions. However, the rise of
asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this
assumption and complicates stereo matching. Visual asymmetry disrupts stereo
matching by affecting the crucial cost volume computation. To address this, we
explore the matching cost distribution of two established cost volume
construction methods in asymmetric stereo. We find that each cost volume
experiences distinct information distortion, indicating that both should be
comprehensively utilized to solve the issue. Based on this, we propose the
two-phase Iterative Volume Fusion network for Asymmetric Stereo matching
(IVF-AStereo). Initially, the aggregated concatenation volume refines the
correlation volume. Subsequently, both volumes are fused to enhance fine
details. Our method excels in asymmetric scenarios and shows robust performance
against significant visual asymmetry. Extensive comparative experiments on
benchmark datasets, along with ablation studies, confirm the effectiveness of
our approach in asymmetric stereo with resolution and color degradation.

</details>


### [54] [GoViG: Goal-Conditioned Visual Navigation Instruction Generation](https://arxiv.org/abs/2508.09547)
*Fengyi Wu,Yifei Dong,Zhi-Qi Cheng,Yilong Dai,Guangyu Chen,Hang Wang,Qi Dai,Alexander G. Hauptmann*

Main category: cs.CV

TL;DR: GoVIG是一个新任务，仅利用第一视角视觉数据自动生成导航指令，无需结构化输入，通过视觉预测和指令生成两个子任务实现，并在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统导航指令生成依赖于结构化输入（如语义标注或环境地图），限制了其在未知和非结构化环境中的适用性。GoVIG旨在仅通过原始视觉数据实现精确和上下文连贯的指令生成。

Method: 1. 将任务分解为视觉预测（预测中间视觉状态）和指令生成（基于视觉合成连贯指令）两个子任务。2. 使用自回归多模态大语言模型，结合单次和交替推理策略模拟人类导航认知过程。

Result: 实验结果表明，GoVIG在BLEU-4和CIDEr分数上显著优于现有方法，并表现出强大的跨领域泛化能力。

Conclusion: GoVIG通过仅依赖第一视角视觉数据，实现了高适应性和性能提升，适用于未知和非结构化环境。

Abstract: We introduce Goal-Conditioned Visual Navigation Instruction Generation
(GoViG), a new task that aims to autonomously generate precise and contextually
coherent navigation instructions solely from egocentric visual observations of
initial and goal states. Unlike conventional approaches that rely on structured
inputs such as semantic annotations or environmental maps, GoViG exclusively
leverages raw egocentric visual data, substantially improving its adaptability
to unseen and unstructured environments. Our method addresses this task by
decomposing it into two interconnected subtasks: (1) visual forecasting, which
predicts intermediate visual states bridging the initial and goal views; and
(2) instruction generation, which synthesizes linguistically coherent
instructions grounded in both observed and anticipated visuals. These subtasks
are integrated within an autoregressive multimodal large language model trained
with tailored objectives to ensure spatial accuracy and linguistic clarity.
Furthermore, we introduce two complementary multimodal reasoning strategies,
one-pass and interleaved reasoning, to mimic incremental human cognitive
processes during navigation. To evaluate our method, we propose the R2R-Goal
dataset, combining diverse synthetic and real-world trajectories. Empirical
results demonstrate significant improvements over state-of-the-art methods,
achieving superior BLEU-4 and CIDEr scores along with robust cross-domain
generalization.

</details>


### [55] [Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification](https://arxiv.org/abs/2508.09550)
*Haowen Wang,Guowei Zhang,Xiang Zhang,Zeyuan Chen,Haiyang Xu,Dou Hoon Kwark,Zhuowen Tu*

Main category: cs.CV

TL;DR: 论文探讨了在图像分类任务中使用生成模型增强训练数据（闭集生成数据增强）的效果，并通过实验得出了合成数据与真实数据增强的定量等价关系。


<details>
  <summary>Details</summary>
Motivation: 研究目标是探索生成模型生成的闭集合成数据是否能有效提升图像分类任务的性能，并与真实数据和开集生成数据进行对比。

Method: 通过实验分析真实图像与生成模型生成的闭集合成图像的异同，并量化合成数据增强所需的规模。

Result: 实验表明，合成数据增强可以接近真实数据的分类效果，但需要更多合成数据。效果受训练集规模和合成数据量的影响。

Conclusion: 生成数据增强在图像分类中可行，但需根据具体情况量化合成数据的规模。

Abstract: In this paper, we address a key scientific problem in machine learning: Given
a training set for an image classification task, can we train a generative
model on this dataset to enhance the classification performance? (i.e.,
closed-set generative data augmentation). We start by exploring the
distinctions and similarities between real images and closed-set synthetic
images generated by advanced generative models. Through extensive experiments,
we offer systematic insights into the effective use of closed-set synthetic
data for augmentation. Notably, we empirically determine the equivalent scale
of synthetic images needed for augmentation. In addition, we also show
quantitative equivalence between the real data augmentation and open-set
generative augmentation (generative models trained using data beyond the given
training set). While it aligns with the common intuition that real images are
generally preferred, our empirical formulation also offers a guideline to
quantify the increased scale of synthetic data augmentation required to achieve
comparable image classification performance. Our results on natural and medical
image datasets further illustrate how this effect varies with the baseline
training set size and the amount of synthetic data incorporated.

</details>


### [56] [Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning](https://arxiv.org/abs/2508.09555)
*Ahmet Öztel,İsmet Karaca*

Main category: cs.CV

TL;DR: 该研究提出了一种基于二维虹膜图像拓扑不变量的生物识别方法，通过数字同调学计算虹膜纹理特征，并在分类任务中表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种紧凑、可解释且准确的虹膜识别方法，以替代深度学习，尤其是在需要高解释性或数据有限的情况下。

Method: 将归一化的虹膜图像划分为子区域，计算每个区域的Betti0、Betti1及其比率作为特征矩阵，结合逻辑回归等分类器进行训练，并与CNN进行对比。

Result: 逻辑回归的准确率达到97.78 ± 0.82%，优于CNN和其他基于特征的方法，拓扑特征表现出高准确性和低方差。

Conclusion: 该方法首次利用数字同调学的拓扑不变量进行虹膜识别，具有高效、可解释性强等优势，适用于生物识别、医学影像等领域。

Abstract: Objective - This study presents a biometric identification method based on
topological invariants from 2D iris images, representing iris texture via
formally defined digital homology and evaluating classification performance.
  Methods - Each normalized iris image (48x482 pixels) is divided into grids
(e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their
ratio using a recent algorithm for homology groups in 2D digital images. The
resulting invariants form a feature matrix used with logistic regression, KNN,
and SVM (with PCA and 100 randomized repetitions). A convolutional neural
network (CNN) is trained on raw images for comparison.
  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy,
outperforming CNN (96.44 +/- 1.32%) and other feature-based models. The
topological features showed high accuracy with low variance.
  Conclusion - This is the first use of topological invariants from formal
digital homology for iris recognition. The method offers a compact,
interpretable, and accurate alternative to deep learning, useful when
explainability or limited data is important. Beyond iris recognition, it can
apply to other biometrics, medical imaging, materials science, remote sensing,
and interpretable AI. It runs efficiently on CPU-only systems and produces
robust, explainable features valuable for security-critical domains.

</details>


### [57] [WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization](https://arxiv.org/abs/2508.09560)
*Jiahao Wen,Hang Yu,Zhedong Zheng*

Main category: cs.CV

TL;DR: WeatherPrompt通过多模态学习范式，融合图像嵌入与文本上下文，建立天气不变的表示，显著提升了无人机在复杂天气条件下的地理定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在天气扰动下表现不佳，主要因依赖有限的天气类别和对场景-天气特征的分离不理想。

Method: 1) 无训练的天气推理机制，利用现有大模型生成多天气文本描述；2) 动态门控机制驱动的多模态框架，通过跨模态目标优化。

Result: 在多样化天气条件下，WeatherPrompt显著提升了召回率，夜间提高13.37%，雾雪条件下提高18.69%。

Conclusion: WeatherPrompt通过多模态融合和动态门控机制，有效解决了天气变化对无人机地理定位的负面影响。

Abstract: Visual geo-localization for drones faces critical degradation under weather
perturbations, \eg, rain and fog, where existing methods struggle with two
inherent limitations: 1) Heavy reliance on limited weather categories that
constrain generalization, and 2) Suboptimal disentanglement of entangled
scene-weather features through pseudo weather categories. We present
WeatherPrompt, a multi-modality learning paradigm that establishes
weather-invariant representations through fusing the image embedding with the
text context. Our framework introduces two key contributions: First, a
Training-free Weather Reasoning mechanism that employs off-the-shelf large
multi-modality models to synthesize multi-weather textual descriptions through
human-like reasoning. It improves the scalability to unseen or complex weather,
and could reflect different weather strength. Second, to better disentangle the
scene and weather feature, we propose a multi-modality framework with the
dynamic gating mechanism driven by the text embedding to adaptively reweight
and fuse visual features across modalities. The framework is further optimized
by the cross-modal objectives, including image-text contrastive learning and
image-text matching, which maps the same scene with different weather
conditions closer in the respresentation space. Extensive experiments validate
that, under diverse weather conditions, our method achieves competitive recall
rates compared to state-of-the-art drone geo-localization methods. Notably, it
improves Recall@1 by +13.37\% under night conditions and by 18.69\% under fog
and snow conditions.

</details>


### [58] [WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description](https://arxiv.org/abs/2508.09565)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于小波的曝光校正方法（WEC-DG），通过退化描述符和小波变换的特性，解决了现有方法在复杂光照条件下的曝光校正问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有多曝光校正方法在处理单曝光图像时，因光照条件和环境多样性导致类内变异性问题，难以准确校正曝光异常。

Method: 在曝光一致性对齐模块（ECAM）中引入退化描述符，确保曝光一致性；利用小波变换的光-细节解耦特性设计曝光恢复与细节重建模块（EDRM），先处理低频曝光增强，后利用高频信息重建空间域细节。

Result: 在多个公开数据集上的实验表明，该方法显著优于现有算法，性能提升明显。

Conclusion: WEC-DG通过退化指导和串行处理策略，解决了曝光校正中的挑战，验证了其有效性和实用性。

Abstract: Multi-exposure correction technology is essential for restoring images
affected by insufficient or excessive lighting, enhancing the visual experience
by improving brightness, contrast, and detail richness. However, current
multi-exposure correction methods often encounter challenges in addressing
intra-class variability caused by diverse lighting conditions, shooting
environments, and weather factors, particularly when processing images captured
at a single exposure level. To enhance the adaptability of these models under
complex imaging conditions, this paper proposes a Wavelet-based Exposure
Correction method with Degradation Guidance (WEC-DG). Specifically, we
introduce a degradation descriptor within the Exposure Consistency Alignment
Module (ECAM) at both ends of the processing pipeline to ensure exposure
consistency and achieve final alignment. This mechanism effectively addresses
miscorrected exposure anomalies caused by existing methods' failure to
recognize 'blurred' exposure degradation. Additionally, we investigate the
light-detail decoupling properties of the wavelet transform to design the
Exposure Restoration and Detail Reconstruction Module (EDRM), which processes
low-frequency information related to exposure enhancement before utilizing
high-frequency information as a prior guide for reconstructing spatial domain
details. This serial processing strategy guarantees precise light correction
and enhances detail recovery. Extensive experiments conducted on multiple
public datasets demonstrate that the proposed method outperforms existing
algorithms, achieving significant performance improvements and validating its
effectiveness and practical applicability.

</details>


### [59] [A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation](https://arxiv.org/abs/2508.09566)
*Haibo Jin,Haoxuan Che,Sunan He,Hao Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为诊断链（CoD）的框架，旨在解决现有放射学报告生成（RRG）在临床效果和可解释性方面的不足。通过生成QA对和利用大语言模型，CoD实现了更准确且可解释的报告生成，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有RRG方法在临床效果（尤其是病变属性描述）和生成文本的可解释性上表现不佳，难以为放射科医生所信任。

Method: 提出诊断链（CoD）框架，通过生成QA对提取关键发现，并利用大语言模型进行准确生成；设计了诊断和病变定位模块以增强可解释性，还提出了一种全监督学习策略。

Result: CoD在两个RRG基准测试中表现优于专家和通用模型，并展示了通过准确匹配QA诊断和图像实现的可解释性。

Conclusion: CoD框架通过增强临床准确性和可解释性，为放射科医生提供了更高效和可信的报告生成工具。

Abstract: Despite the progress of radiology report generation (RRG), existing works
face two challenges: 1) The performances in clinical efficacy are
unsatisfactory, especially for lesion attributes description; 2) the generated
text lacks explainability, making it difficult for radiologists to trust the
results. To address the challenges, we focus on a trustworthy RRG model, which
not only generates accurate descriptions of abnormalities, but also provides
basis of its predictions. To this end, we propose a framework named chain of
diagnosis (CoD), which maintains a chain of diagnostic process for clinically
accurate and explainable RRG. It first generates question-answer (QA) pairs via
diagnostic conversation to extract key findings, then prompts a large language
model with QA diagnoses for accurate generation. To enhance explainability, a
diagnosis grounding module is designed to match QA diagnoses and generated
sentences, where the diagnoses act as a reference. Moreover, a lesion grounding
module is designed to locate abnormalities in the image, further improving the
working efficiency of radiologists. To facilitate label-efficient training, we
propose an omni-supervised learning strategy with clinical consistency to
leverage various types of annotations from different datasets. Our efforts lead
to 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a
evaluation tool for assessing the accuracy of reports in describing lesion
location and severity; 3) extensive experiments to demonstrate the
effectiveness of CoD, where it outperforms both specialist and generalist
models consistently on two RRG benchmarks and shows promising explainability by
accurately grounding generated sentences to QA diagnoses and images.

</details>


### [60] [Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion](https://arxiv.org/abs/2508.09575)
*Jiwon Kim,Pureum Kim,SeonHwa Kim,Soobin Park,Eunju Cha,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的双重递归反馈（DRF）系统，用于改进可控文本到图像扩散模型，解决其在保留空间结构和捕捉细粒度条件（如物体姿态和场景布局）方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的可控文本到图像扩散模型（如Ctrl-X和FreeControl）在空间和外观控制方面表现优秀，但难以准确保留空间结构或捕获物体姿态和场景布局等细粒度条件，研究者希望通过DRF系统改进这些问题。

Method: 提出双重递归反馈（DRF）系统，包含外观反馈和生成反馈，通过递归优化中间潜在表示以更好地反映外观信息和用户意图。

Result: 实验结果表明，DRF能够生成高质量、语义一致且结构一致的图像，甚至能实现跨类别的结构-外观融合（如将人类动作转移到老虎形态）。

Conclusion: DRF系统通过双重更新机制在可控文本到图像模型中有效整合结构和外观属性，显著提升了生成效果。

Abstract: Recent advancements in controllable text-to-image (T2I) diffusion models,
such as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance
control without requiring auxiliary module training. However, these models
often struggle to accurately preserve spatial structures and fail to capture
fine-grained conditions related to object poses and scene layouts. To address
these challenges, we propose a training-free Dual Recursive Feedback (DRF)
system that properly reflects control conditions in controllable T2I models.
The proposed DRF consists of appearance feedback and generation feedback that
recursively refines the intermediate latents to better reflect the given
appearance information and the user's intent. This dual-update mechanism guides
latent representations toward reliable manifolds, effectively integrating
structural and appearance attributes. Our approach enables fine-grained
generation even between class-invariant structure-appearance fusion, such as
transferring human motion onto a tiger's form. Extensive experiments
demonstrate the efficacy of our method in producing high-quality, semantically
coherent, and structurally consistent image generations. Our source code is
available at https://github.com/jwonkm/DRF.

</details>


### [61] [SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs](https://arxiv.org/abs/2508.09584)
*Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: SHALE是一个可扩展的幻觉评估基准，针对大型视觉语言模型（LVLM）中的幻觉问题进行细粒度分析，提出自动数据构建和层次化幻觉诱导框架。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在评估幻觉问题时缺乏细粒度分析和数据依赖手动构建或公共数据集的问题。

Method: 提出自动数据构建管道以生成可扩展、可控且多样化的评估数据，并设计层次化幻觉诱导框架模拟噪声场景。

Result: 构建了包含30K+图像-指令对的SHALE基准，实验显示主流LVLM存在显著的事实性幻觉和对语义扰动的高敏感性。

Conclusion: SHALE为LVLM中的幻觉问题提供了细粒度和可扩展的评估工具，揭示了模型在事实性和噪声场景下的不足。

Abstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer
from hallucinations, i.e., generating content inconsistent with input or
established world knowledge, which correspond to faithfulness and factuality
hallucinations, respectively. Prior studies primarily evaluate faithfulness
hallucination at a coarse level (e.g., object-level) and lack fine-grained
analysis. Additionally, existing benchmarks rely on costly manual curation or
reused public datasets, raising concerns about scalability and data leakage. To
address these limitations, we propose an automated data construction pipeline
that produces scalable, controllable, and diverse evaluation data. We also
design a hierarchical hallucination induction framework with input
perturbations to simulate realistic noisy scenarios. Integrating these designs,
we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to
assess both faithfulness and factuality hallucinations via a fine-grained
hallucination categorization scheme. SHALE comprises over 30K image-instruction
pairs spanning 12 representative visual perception aspects for faithfulness and
6 knowledge domains for factuality, considering both clean and noisy scenarios.
Extensive experiments on over 20 mainstream LVLMs reveal significant factuality
hallucinations and high sensitivity to semantic perturbations.

</details>


### [62] [Offline Auto Labeling: BAAS](https://arxiv.org/abs/2508.09585)
*Stefan Haag,Bharanidhar Duraisamy,Felix Govaers,Wolfgang Koch,Martin Fritzsche,Juergen Dickmann*

Main category: cs.CV

TL;DR: BAAS是一个用于自动驾驶雷达检测的扩展目标跟踪和融合标注框架，通过贝叶斯方法提供精确的目标轨迹和形状估计，支持多级监督下的标注和性能评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中需要精确的雷达检测标注和跟踪性能评估，BAAS旨在通过融合方法和闭环改进解决这一问题。

Method: 基于贝叶斯的跟踪、平滑和融合方法，结合多级监督和手动标注数据进行独立或联合模块分析。

Result: 在真实城市场景中验证了框架的跟踪性能和标注误差，适用于不同动态目标和类别。

Conclusion: BAAS提供了一种高效的雷达检测标注和跟踪解决方案，支持闭环改进和多场景应用。

Abstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and
fusion-based label annotation framework for radar detections in autonomous
driving. Our framework utilizes Bayesian-based tracking, smoothing and
eventually fusion methods to provide veritable and precise object trajectories
along with shape estimation to provide annotation labels on the detection level
under various supervision levels. Simultaneously, the framework provides
evaluation of tracking performance and label annotation. If manually labeled
data is available, each processing module can be analyzed independently or
combined with other modules to enable closed-loop continuous improvements. The
framework performance is evaluated in a challenging urban real-world scenario
in terms of tracking performance and the label annotation errors. We
demonstrate the functionality of the proposed approach for varying dynamic
objects and class types

</details>


### [63] [Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma](https://arxiv.org/abs/2508.09593)
*Haotian Tang,Jianwei Chen,Xinrui Tang,Yunjia Wu,Zhengyang Miao,Chao Li*

Main category: cs.CV

TL;DR: 本文提出Hi-SMGNN，一种基于结构和形态连接组的层次化框架，用于改进IDH突变预测，解决了现有方法忽略大脑多层次组织的问题。


<details>
  <summary>Details</summary>
Motivation: IDH突变状态是神经胶质瘤预后的重要生物标志物，但现有预测方法受限于功能MRI的低可用性和噪声。结构和形态连接组提供了非侵入性替代方案，但缺乏对大脑多层次组织的考虑。

Method: 提出Hi-SMGNN框架，包括多模态交互模块（Siamese网络和跨模态注意力）、多尺度特征融合机制和个性化模块划分策略。

Result: 在UCSF-PDGM数据集上，Hi-SMGNN在IDH突变预测中表现出优于基线方法和前沿模型的性能，具有更高的鲁棒性和有效性。

Conclusion: Hi-SMGNN通过整合结构和形态连接组的多层次信息，显著提升了IDH突变预测的准确性和可解释性。

Abstract: Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for
glioma prognosis. However, current prediction methods are limited by the low
availability and noise of functional MRI. Structural and morphological
connectomes offer a non-invasive alternative, yet existing approaches often
ignore the brain's hierarchical organisation and multiscale interactions. To
address this, we propose Hi-SMGNN, a hierarchical framework that integrates
structural and morphological connectomes from regional to modular levels. It
features a multimodal interaction module with a Siamese network and cross-modal
attention, a multiscale feature fusion mechanism for reducing redundancy, and a
personalised modular partitioning strategy to enhance individual specificity
and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that
Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved
robustness and effectiveness in IDH mutation prediction.

</details>


### [64] [SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing](https://arxiv.org/abs/2508.09597)
*Heyi Sun,Cong Wang,Tian-Xing Xu,Jingwei Huang,Di Kang,Chunchao Guo,Song-Hai Zhang*

Main category: cs.CV

TL;DR: 提出了SVG-Head，一种结合3D高斯和FLAME网格的混合表示方法，用于高保真、可编辑的头像建模，支持实时外观编辑。


<details>
  <summary>Details</summary>
Motivation: 解决头像建模中几何与全局外观纠缠的难题，支持实时外观编辑。

Method: 结合表面和体积高斯，利用FLAME网格进行UV映射，并通过分层优化提升重建质量和编辑灵活性。

Result: 在NeRSemble数据集上实现高保真渲染，并首次支持高斯头像的显式纹理图像和实时编辑。

Conclusion: SVG-Head在高保真重建和实时编辑方面表现出色，为头像建模提供了新思路。

Abstract: Creating high-fidelity and editable head avatars is a pivotal challenge in
computer vision and graphics, boosting many AR/VR applications. While recent
advancements have achieved photorealistic renderings and plausible animation,
head editing, especially real-time appearance editing, remains challenging due
to the implicit representation and entangled modeling of the geometry and
global appearance. To address this, we propose Surface-Volumetric Gaussian Head
Avatar (SVG-Head), a novel hybrid representation that explicitly models the
geometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled
texture images to capture the global appearance. Technically, it contains two
types of Gaussians, in which surface Gaussians explicitly model the appearance
of head avatars using learnable texture images, facilitating real-time texture
editing, while volumetric Gaussians enhance the reconstruction quality of
non-Lambertian regions (e.g., lips and hair). To model the correspondence
between 3D world and texture space, we provide a mesh-aware Gaussian UV mapping
method, which leverages UV coordinates given by the FLAME mesh to obtain sharp
texture images and real-time rendering speed. A hierarchical optimization
strategy is further designed to pursue the optimal performance in both
reconstruction quality and editing flexibility. Experiments on the NeRSemble
dataset show that SVG-Head not only generates high-fidelity rendering results,
but also is the first method to obtain explicit texture images for Gaussian
head avatars and support real-time appearance editing.

</details>


### [65] [Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality](https://arxiv.org/abs/2508.09598)
*Jie Shao,Ke Zhu,Minghao Fu,Guo-hua Wang,Jianxin Wu*

Main category: cs.CV

TL;DR: 该论文提出了一种名为FaME的方法，通过图像质量评估模型识别低质量生成图像，并利用其采样轨迹作为负引导，以提升图像生成的感知质量，同时保持FID分数不变。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在类别到图像生成方面取得了显著进展，但现有模型在某些类别下仍会生成扭曲或低质量图像。FID指标仅评估全局分布对齐，而忽略了单个样本的感知质量。

Method: 提出FaME方法，利用图像质量评估模型识别低质量生成图像，存储其采样轨迹，并将这些失败模式作为负引导，避免未来采样进入低质量区域。

Result: 在ImageNet上的实验表明，FaME在不影响FID的情况下，显著提升了视觉质量。

Conclusion: FaME是一种无需训练且推理高效的方法，能够提升扩散模型生成的感知质量，并有望扩展到文本到图像生成领域。

Abstract: Diffusion models have achieved remarkable progress in class-to-image
generation. However, we observe that despite impressive FID scores,
state-of-the-art models often generate distorted or low-quality images,
especially in certain classes. This gap arises because FID evaluates global
distribution alignment, while ignoring the perceptual quality of individual
samples. We further examine the role of CFG, a common technique used to enhance
generation quality. While effective in improving metrics and suppressing
outliers, CFG can introduce distribution shift and visual artifacts due to its
misalignment with both training objectives and user expectations. In this work,
we propose FaME, a training-free and inference-efficient method for improving
perceptual quality. FaME uses an image quality assessment model to identify
low-quality generations and stores their sampling trajectories. These failure
modes are then used as negative guidance to steer future sampling away from
poor-quality regions. Experiments on ImageNet demonstrate that FaME brings
consistent improvements in visual quality without compromising FID. FaME also
shows the potential to be extended to improve text-to-image generation.

</details>


### [66] [BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation](https://arxiv.org/abs/2508.09599)
*Beomjun Kim,Suhan Woo,Sejong Heo,Euntai Kim*

Main category: cs.CV

TL;DR: BridgeTA是一种成本效益高的蒸馏框架，通过教师助理网络缩小LiDAR-Camera融合模型与纯相机模型之间的表示差距，同时保持学生模型的架构和推理成本不变。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法主要通过模仿教师模型的架构来扩大学生模型，导致推理成本增加。本文旨在提出一种更高效的蒸馏方法。

Method: 引入轻量级教师助理网络，结合教师和学生的BEV表示，创建一个共享的潜在空间作为中间表示，并使用Young不等式推导蒸馏损失。

Result: 在nuScenes数据集上，比纯相机基线提高了4.2%的mIoU，比其他先进KD方法的提升高出45%。

Conclusion: BridgeTA通过教师助理网络显著提升了纯相机模型的性能，同时保持了推理成本的低廉。

Abstract: Bird's-Eye-View (BEV) map segmentation is one of the most important and
challenging tasks in autonomous driving. Camera-only approaches have drawn
attention as cost-effective alternatives to LiDAR, but they still fall behind
LiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been
explored to narrow this gap, but existing methods mainly enlarge the student
model by mimicking the teacher's architecture, leading to higher inference
cost. To address this issue, we introduce BridgeTA, a cost-effective
distillation framework to bridge the representation gap between LC fusion and
Camera-only models through a Teacher Assistant (TA) network while keeping the
student's architecture and inference cost unchanged. A lightweight TA network
combines the BEV representations of the teacher and student, creating a shared
latent space that serves as an intermediate representation. To ground the
framework theoretically, we derive a distillation loss using Young's
Inequality, which decomposes the direct teacher-student distillation path into
teacher-TA and TA-student dual paths, stabilizing optimization and
strengthening knowledge transfer. Extensive experiments on the challenging
nuScenes dataset demonstrate the effectiveness of our method, achieving an
improvement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than
the improvement of other state-of-the-art KD methods.

</details>


### [67] [MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography](https://arxiv.org/abs/2508.09616)
*Daniel Barco,Marc Stadelmann,Martin Oswald,Ivo Herzig,Lukas Lichtensteiger,Pascal Paysan,Igor Peterlik,Michal Walczak,Bjoern Menze,Frank-Peter Schilling*

Main category: cs.CV

TL;DR: MInDI-3D是一种基于3D条件扩散的模型，用于稀疏视图CBCT伪影去除，显著降低辐射暴露，并通过生成大量伪CBCT数据集进行训练，证明其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 减少医学成像中的辐射暴露，提升稀疏视图CBCT的图像质量。

Method: 从2D InDI扩展到3D体积方法，通过迭代去噪从稀疏输入直接优化CBCT体积，并利用伪CBCT数据集训练模型。

Result: 在CT-RATE测试集上PSNR增益达12.96 dB，辐射暴露减少8倍，性能与3D U-Net相当，并支持新几何的CBCT扫描仪。

Conclusion: MInDI-3D在临床评估中表现优秀，适用于患者定位并保留肿瘤边界。

Abstract: We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first
3D conditional diffusion-based model for real-world sparse-view Cone Beam
Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation
exposure. A key contribution is extending the "InDI" concept from 2D to a full
3D volumetric approach for medical images, implementing an iterative denoising
process that refines the CBCT volume directly from sparse-view input. A further
contribution is the generation of a large pseudo-CBCT dataset (16,182) from
chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We
performed a comprehensive evaluation, including quantitative metrics,
scalability analysis, generalisation tests, and a clinical assessment by 11
clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10)
dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE
pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in
imaging radiation exposure. We demonstrate its scalability by showing that
performance improves with more training data. Importantly, MInDI-3D matches the
performance of a 3D U-Net on real-world scans from 16 cancer patients across
distortion and task-based metrics. It also generalises to new CBCT scanner
geometries. Clinicians rated our model as sufficient for patient positioning
across all anatomical sites and found it preserved lung tumour boundaries well.

</details>


### [68] [Plane Detection and Ranking via Model Information Optimization](https://arxiv.org/abs/2508.09625)
*Daoxin Zhong,Jun Li,Meng Yee Michael Chuah*

Main category: cs.CV

TL;DR: 该论文提出了一个基于模型信息优化的通用框架，用于解决深度图像中平面检测的假阳性问题，并通过实验验证了其相较于传统RANSAC方法的优势。


<details>
  <summary>Details</summary>
Motivation: 传统RANSAC方法因其阈值的模糊性容易产生假阳性平面检测，尤其在复杂的真实场景中问题更为突出。作者试图通过信息优化来客观确定真实平面数量以避免此类问题。

Method: 论文将深度读数视为离散随机变量，通过随机子采样生成不同候选平面约束的模型，并结合深度传感器的物理和噪声模型计算信息量，选择信息量最小的模型作为最优解。

Result: 实验表明，该方法在合成数据中能更准确地估计平面参数，优于Open3D的RANSAC平面分割算法。通过神经网络分割加速后，进一步提升了在真实数据中的性能。

Conclusion: 所提框架通过信息优化机制有效减少了假阳性平面检测，同时能对平面质量进行排名，为复杂场景下的平面检测提供了更可靠的解决方案。

Abstract: Plane detection from depth images is a crucial subtask with broad robotic
applications, often accomplished by iterative methods such as Random Sample
Consensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic
guarantees, the ambiguity of its inlier threshold criterion makes it
susceptible to false positive plane detections. This issue is particularly
prevalent in complex real-world scenes, where the true number of planes is
unknown and multiple planes coexist. In this paper, we aim to address this
limitation by proposing a generalised framework for plane detection based on
model information optimization. Building on previous works, we treat the
observed depth readings as discrete random variables, with their probability
distributions constrained by the ground truth planes. Various models containing
different candidate plane constraints are then generated through repeated
random sub-sampling to explain our observations. By incorporating the physics
and noise model of the depth sensor, we can calculate the information for each
model, and the model with the least information is accepted as the most likely
ground truth. This information optimization process serves as an objective
mechanism for determining the true number of planes and preventing false
positive detections. Additionally, the quality of each detected plane can be
ranked by summing the information reduction of inlier points for each plane. We
validate these properties through experiments with synthetic data and find that
our algorithm estimates plane parameters more accurately compared to the
default Open3D RANSAC plane segmentation. Furthermore, we accelerate our
algorithm by partitioning the depth map using neural network segmentation,
which enhances its ability to generate more realistic plane parameters in
real-world data.

</details>


### [69] [Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation](https://arxiv.org/abs/2508.09626)
*Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SAD-Splat的新方法，通过高斯点丢弃模块和高置信度伪标签生成，解决了3D航空场景语义分割中的语义歧义问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在3D航空场景语义分割中无法有效处理尺度变化和结构遮挡导致的语义歧义，限制了分割精度和一致性。

Method: SAD-Splat引入了基于Hard Concrete分布的高斯点丢弃模块和高置信度伪标签生成流程，优化分割性能和表示紧凑性。

Result: 实验表明，SAD-Splat在分割精度和表示紧凑性方面达到优秀平衡，为3D航空场景理解提供了高效可扩展的解决方案。

Conclusion: SAD-Splat通过创新的模块设计和新数据集3D-AS，显著提升了3D航空场景语义分割的性能。

Abstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),
traditional methods struggle to address semantic ambiguity caused by scale
variations and structural occlusions in aerial images. This limits their
segmentation accuracy and consistency. To tackle these challenges, we propose a
novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian
point drop module, which integrates semantic confidence estimation with a
learnable sparsity mechanism based on the Hard Concrete distribution. This
module effectively eliminates redundant and semantically ambiguous Gaussian
points, enhancing both segmentation performance and representation compactness.
Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation
pipeline. It leverages 2D foundation models to enhance supervision when
ground-truth labels are limited, thereby further improving segmentation
accuracy. To advance research in this domain, we introduce a challenging
benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse
real-world aerial scenes with sparse annotations. Experimental results
demonstrate that SAD-Splat achieves an excellent balance between segmentation
accuracy and representation compactness. It offers an efficient and scalable
solution for 3D aerial scene understanding.

</details>


### [70] [Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors](https://arxiv.org/abs/2508.09629)
*Giorgos Karvounas,Nikolaos Kyriazis,Iason Oikonomidis,Georgios Pavlakos,Antonis A. Argyros*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的纹理模块，利用纹理对齐作为监督信号，提升单目3D手部重建的准确性和真实感。


<details>
  <summary>Details</summary>
Motivation: 传统方法中纹理仅用于提升视觉真实感，而忽视其作为密集空间线索对姿势和形状估计的潜在价值。

Method: 提出一个自包含的纹理模块，将像素观测嵌入UV纹理空间，并设计密集对齐损失函数，可轻松嵌入现有重建流程。

Result: 在HaMeR架构上测试，证明了纹理引导监督能显著提升重建的准确性和真实感。

Conclusion: 纹理对齐是一种有效的监督信号，能为手部重建任务带来实质性改进。

Abstract: We revisit the role of texture in monocular 3D hand reconstruction, not as an
afterthought for photorealism, but as a dense, spatially grounded cue that can
actively support pose and shape estimation. Our observation is simple: even in
high-performing models, the overlay between predicted hand geometry and image
appearance is often imperfect, suggesting that texture alignment may be an
underused supervisory signal. We propose a lightweight texture module that
embeds per-pixel observations into UV texture space and enables a novel dense
alignment loss between predicted and observed hand appearances. Our approach
assumes access to a differentiable rendering pipeline and a model that maps
images to 3D hand meshes with known topology, allowing us to back-project a
textured hand onto the image and perform pixel-based alignment. The module is
self-contained and easily pluggable into existing reconstruction pipelines. To
isolate and highlight the value of texture-guided supervision, we augment
HaMeR, a high-performing yet unadorned transformer architecture for 3D hand
pose estimation. The resulting system improves both accuracy and realism,
demonstrating the value of appearance-guided alignment in hand reconstruction.

</details>


### [71] [Preacher: Paper-to-Video Agentic System](https://arxiv.org/abs/2508.09632)
*Jingwei Liu,Ling Yang,Hao Luo,Fan Wang Hongyan Li,Mengdi Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种将科研论文转换为结构化视频摘要的系统Preacher，通过分解、总结和重组论文内容，再生成高质量视频，解决了现有视频生成模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型受限于上下文窗口、视频时长、风格多样性和领域知识表达不足，因此需要开发一个能够灵活处理这些问题的新系统。

Method: Preacher采用自上而下的方法分解、总结和重组论文内容，再通过自下而上的视频生成方式合成多样化的视频片段，并结合渐进式思维链（P-CoT）实现跨模态对齐。

Result: 在五个研究领域中，Preacher生成了高质量的视频摘要，表现出超越当前视频生成模型的专业能力。

Conclusion: Preacher成功地解决了现有视频生成模型的局限性，为论文到视频的转换提供了一种有效的解决方案。

Abstract: The paper-to-video task converts a research paper into a structured video
abstract, distilling key concepts, methods, and conclusions into an accessible,
well-organized format. While state-of-the-art video generation models
demonstrate potential, they are constrained by limited context windows, rigid
video duration constraints, limited stylistic diversity, and an inability to
represent domain-specific knowledge. To address these limitations, we introduce
Preacher, the first paper-to-video agentic system. Preacher employs a top-down
approach to decompose, summarize, and reformulate the paper, followed by
bottom-up video generation, synthesizing diverse video segments into a coherent
abstract. To align cross-modal representations, we define key scenes and
introduce a Progressive Chain of Thought (P-CoT) for granular, iterative
planning. Preacher successfully generates high-quality video abstracts across
five research fields, demonstrating expertise beyond current video generation
models. Code will be released at: https://github.com/GenVerse/Paper2Video

</details>


### [72] [Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification](https://arxiv.org/abs/2508.09644)
*Shengjun Zhu,Siyu Liu,Runqing Xiong,Liping Zheng,Duo Ma,Rongshang Chen,Jiaxin Cai*

Main category: cs.CV

TL;DR: 提出了一种新型多对比融合模块（MCFM），用于增强超声图像中胎儿躯干平面的识别精度，通过多对比注意力机制提升了模型的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 超声图像的低对比度和纹理细节不清晰限制了胎儿躯干平面的准确识别，影响临床诊断的可靠性。

Method: 设计MCFM模块，专注于神经网络的低层处理原始超声数据，通过多对比注意力加权增强特征建模，同时保持低参数开销。

Result: 在胎儿躯干平面超声数据集上验证，MCFM显著提高了识别性能，且模型复杂度增加极小。

Conclusion: MCFM为胎儿躯干平面识别提供了一种有效方法，通过多对比融合增强特征表示，支持更准确和一致的临床诊断。

Abstract: Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural
development and detecting abnormalities, contributing to reduced perinatal
complications and improved neonatal survival. Accurate identification of
standard fetal torso planes is essential for reliable assessment and
personalized prenatal care. However, limitations such as low contrast and
unclear texture details in ultrasound imaging pose significant challenges for
fine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast
Fusion Module (MCFM) to enhance the model's ability to extract detailed
information from ultrasound images. MCFM operates exclusively on the lower
layers of the neural network, directly processing raw ultrasound data. By
assigning attention weights to image representations under different contrast
conditions, the module enhances feature modeling while explicitly maintaining
minimal parameter overhead. Results: The proposed MCFM was evaluated on a
curated dataset of fetal torso plane ultrasound images. Experimental results
demonstrate that MCFM substantially improves recognition performance, with a
minimal increase in model complexity. The integration of multi-contrast
attention enables the model to better capture subtle anatomical structures,
contributing to higher classification accuracy and clinical reliability.
Conclusions: Our method provides an effective solution for improving fetal
torso plane recognition in ultrasound imaging. By enhancing feature
representation through multi-contrast fusion, the proposed approach supports
clinicians in achieving more accurate and consistent diagnoses, demonstrating
strong potential for clinical adoption in prenatal screening. The codes are
available at https://github.com/sysll/MCFM.

</details>


### [73] [Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model](https://arxiv.org/abs/2508.09645)
*Zhongyuan Wu,Chuan-Xian Ren,Yu Wang,Xiaohua Ban,Jianning Xiao,Xiaohui Duan*

Main category: cs.CV

TL;DR: PG-SAM通过专家诊断文本指导SAM，结合专家领域知识进行跨序列腮腺病变分割，提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 腮腺病变分割因病变大小和边界复杂性而具有挑战性，且现有方法依赖精确提示或忽略专家知识。

Method: 提出PG-SAM，包含诊断报告引导的提示生成模块和跨序列注意力模块，结合多模态信息进行分割。

Result: 在三个临床中心验证中，PG-SAM表现最佳，证实其临床适用性和诊断文本对分割的增强效果。

Conclusion: PG-SAM通过融合专家知识解决了现有方法的不足，为实际临床应用提供了高效工具。

Abstract: Parotid gland lesion segmentation is essential for the treatment of parotid
gland diseases. However, due to the variable size and complex lesion
boundaries, accurate parotid gland lesion segmentation remains challenging.
Recently, the Segment Anything Model (SAM) fine-tuning has shown remarkable
performance in the field of medical image segmentation. Nevertheless, SAM's
interaction segmentation model relies heavily on precise lesion prompts
(points, boxes, masks, etc.), which are very difficult to obtain in real-world
applications. Besides, current medical image segmentation methods are
automatically generated, ignoring the domain knowledge of medical experts when
performing segmentation. To address these limitations, we propose the parotid
gland segment anything model (PG-SAM), an expert diagnosis text-guided SAM
incorporating expert domain knowledge for cross-sequence parotid gland lesion
segmentation. Specifically, we first propose an expert diagnosis report guided
prompt generation module that can automatically generate prompt information
containing the prior domain knowledge to guide the subsequent lesion
segmentation process. Then, we introduce a cross-sequence attention module,
which integrates the complementary information of different modalities to
enhance the segmentation effect. Finally, the multi-sequence image features and
generated prompts are feed into the decoder to get segmentation result.
Experimental results demonstrate that PG-SAM achieves state-of-the-art
performance in parotid gland lesion segmentation across three independent
clinical centers, validating its clinical applicability and the effectiveness
of diagnostic text for enhancing image segmentation in real-world clinical
settings.

</details>


### [74] [The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge](https://arxiv.org/abs/2508.09649)
*Reuben Dorent,Laura Rigolo,Colin P. Galvin,Junyu Chen,Mattias P. Heinrich,Aaron Carass,Olivier Colliot,Demian Wassermann,Alexandra Golby,Tina Kapur,William Wells*

Main category: cs.CV

TL;DR: ReMIND2Reg 2025挑战赛提供了一个公开基准，用于解决脑肿瘤手术中术前MRI与术后超声图像对齐的难题。


<details>
  <summary>Details</summary>
Motivation: 解决由于脑移位导致的术中导航系统准确性下降问题，提升手术安全性。

Method: 通过多模态图像（MRI和iUS）配准，估计脑移位变形，建立标准化评估框架。

Result: 提供99个训练案例和15个测试案例，评估指标包括TRE、TRE30和运行时间。

Conclusion: ReMIND2Reg旨在推动开发稳健、可泛化且适用于临床的多模态配准算法。

Abstract: Accurate intraoperative image guidance is critical for achieving maximal safe
resection in brain tumor surgery, yet neuronavigation systems based on
preoperative MRI lose accuracy during the procedure due to brain shift.
Aligning post-resection intraoperative ultrasound (iUS) with preoperative MRI
can restore spatial accuracy by estimating brain shift deformations, but it
remains a challenging problem given the large anatomical and topological
changes and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge
provides the largest public benchmark for this task, built upon the ReMIND
dataset. It offers 99 training cases, 5 validation cases, and 10 private test
cases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes.
Data are provided without annotations for training, while validation and test
performance are evaluated on manually annotated anatomical landmarks. Metrics
include target registration error (TRE), robustness to worst-case landmark
misalignment (TRE30), and runtime. By establishing a standardized evaluation
framework for this clinically critical and technically complex problem,
ReMIND2Reg aims to accelerate the development of robust, generalizable, and
clinically deployable multimodal registration algorithms for image-guided
neurosurgery.

</details>


### [75] [TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos](https://arxiv.org/abs/2508.09650)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazely,Sunil Aryal*

Main category: cs.CV

TL;DR: 提出TOTNet网络，利用3D卷积和遮挡增强技术提升体育视频中球的遮挡跟踪性能，显著降低误差并提高准确率。


<details>
  <summary>Details</summary>
Motivation: 体育视频分析中球的遮挡跟踪问题影响事件检测和裁判，需解决。

Method: 使用3D卷积、可见性加权损失和遮挡增强的Temporal Occlusion Tracking Network (TOTNet)。

Result: 在多个数据集上RMSE从37.30降至7.19，完全遮挡帧准确率从0.63提升至0.80。

Conclusion: TOTNet在高速体育场景中表现优异，适用于离线分析。

Abstract: Robust ball tracking under occlusion remains a key challenge in sports video
analysis, affecting tasks like event detection and officiating. We present
TOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions,
visibility-weighted loss, and occlusion augmentation to improve performance
under partial and full occlusions. Developed in collaboration with Paralympics
Australia, TOTNet is designed for real-world sports analytics. We introduce
TTA, a new occlusion-rich table tennis dataset collected from
professional-level Paralympic matches, comprising 9,159 samples with 1,996
occlusion cases. Evaluated on four datasets across tennis, badminton, and table
tennis, TOTNet significantly outperforms prior state-of-the-art methods,
reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded
frames from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for
offline sports analytics in fast-paced scenarios. Code and data
access:\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.

</details>


### [76] [Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging](https://arxiv.org/abs/2508.09655)
*Lianfang Wang,Kuilin Qin,Xueying Liu,Huibin Chang,Yong Wang,Yuping Duan*

Main category: cs.CV

TL;DR: 本文提出了一种参数化逆向问题框架，用于3D成像重建中的大规模线性问题，结合噪声估计模块和参数化神经算子，实现快速端到端图像重建。


<details>
  <summary>Details</summary>
Motivation: 解决非视线（NLOS）成像中因间接光信号弱且易受噪声干扰而导致的重建准确性难题。

Method: 采用噪声估计模块评估瞬态数据噪声，开发参数化神经算子近似逆映射，并通过算法展开学习动态适应不同噪声水平的数据。

Result: 在模拟和真实数据集上的实验表明，该方法显著提高了重建精度和鲁棒性，适用于复杂场景。

Conclusion: 该框架为NLOS成像提供了高效且稳健的解决方案，尤其在快速扫描和稀疏照明数据中表现优异。

Abstract: Computational imaging, especially non-line-of-sight (NLOS) imaging, the
extraction of information from obscured or hidden scenes is achieved through
the utilization of indirect light signals resulting from multiple reflections
or scattering. The inherently weak nature of these signals, coupled with their
susceptibility to noise, necessitates the integration of physical processes to
ensure accurate reconstruction. This paper presents a parameterized inverse
problem framework tailored for large-scale linear problems in 3D imaging
reconstruction. Initially, a noise estimation module is employed to adaptively
assess the noise levels present in transient data. Subsequently, a
parameterized neural operator is developed to approximate the inverse mapping,
facilitating end-to-end rapid image reconstruction. Our 3D image reconstruction
framework, grounded in operator learning, is constructed through deep algorithm
unfolding, which not only provides commendable model interpretability but also
enables dynamic adaptation to varying noise levels in the acquired data,
thereby ensuring consistently robust and accurate reconstruction outcomes.
Furthermore, we introduce a novel method for the fusion of global and local
spatiotemporal data features. By integrating structural and detailed
information, this method significantly enhances both accuracy and robustness.
Comprehensive numerical experiments conducted on both simulated and real
datasets substantiate the efficacy of the proposed method. It demonstrates
remarkable performance with fast scanning data and sparse illumination point
data, offering a viable solution for NLOS imaging in complex scenarios.

</details>


### [77] [NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation](https://arxiv.org/abs/2508.09661)
*Eduarda Caldeira,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: 该论文提出了一种名为NegFaceDiff的新采样方法，通过在身份条件扩散过程中引入负条件，显著提升了生成人脸数据的身份一致性和可分性，从而改善了人脸识别系统的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有身份条件扩散模型在生成人脸数据时缺乏明确的采样机制导致身份重叠的问题，作者提出了NegFaceDiff方法，旨在通过负条件增强身份分离。

Method: 论文提出了NegFaceDiff，一种在身份条件扩散过程中引入负条件的采样方法，通过显式引导模型远离不需要的特征来增强身份可分性。

Result: 实验表明，NegFaceDiff将身份可分性（FDR）从2.427提升到5.687，并在多个人脸识别基准测试中优于未使用负条件生成的数据训练的模型。

Conclusion: NegFaceDiff通过引入负条件，有效改善了生成数据的身份一致性和可分性，为人脸识别系统的训练提供了更高质量的合成数据。

Abstract: The use of synthetic data as an alternative to authentic datasets in face
recognition (FR) development has gained significant attention, addressing
privacy, ethical, and practical concerns associated with collecting and using
authentic data. Recent state-of-the-art approaches have proposed
identity-conditioned diffusion models to generate identity-consistent face
images, facilitating their use in training FR models. However, these methods
often lack explicit sampling mechanisms to enforce inter-class separability,
leading to identity overlap in the generated data and, consequently, suboptimal
FR performance. In this work, we introduce NegFaceDiff, a novel sampling method
that incorporates negative conditions into the identity-conditioned diffusion
process. NegFaceDiff enhances identity separation by leveraging negative
conditions that explicitly guide the model away from unwanted features while
preserving intra-class consistency. Extensive experiments demonstrate that
NegFaceDiff significantly improves the identity consistency and separability of
data generated by identity-conditioned diffusion models. Specifically, identity
separability, measured by the Fisher Discriminant Ratio (FDR), increases from
2.427 to 5.687. These improvements are reflected in FR systems trained on the
NegFaceDiff dataset, which outperform models trained on data generated without
negative conditions across multiple benchmarks.

</details>


### [78] [GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors](https://arxiv.org/abs/2508.09667)
*Xingyilang Yin,Qi Zhang,Jiahao Chang,Ying Feng,Qingnan Fan,Xi Yang,Chi-Man Pun,Huaqi Zhang,Xiaodong Cun*

Main category: cs.CV

TL;DR: 提出了GSFixer框架，通过参考引导的视频修复模型改进稀疏视点下3D高斯喷绘重建的质量，结合2D语义和3D几何特征，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视点下3D高斯喷绘重建因信息不足导致的伪影问题，现有生成先验方法难以保持与输入观测的一致性。

Method: 基于DiT的视频扩散模型，结合2D语义和3D几何特征，参考稀疏视点修复伪影。

Result: GSFixer在3DGS伪影修复和稀疏视点重建中优于现有方法，并提出了新基准DL3DV-Res。

Conclusion: GSFixer有效提升了稀疏视点下3DGS重建的质量和一致性，为相关领域提供了新工具和评测标准。

Abstract: Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views
is an ill-posed problem due to insufficient information, often resulting in
noticeable artifacts. While recent approaches have sought to leverage
generative priors to complete information for under-constrained regions, they
struggle to generate content that remains consistent with input observations.
To address this challenge, we propose GSFixer, a novel framework designed to
improve the quality of 3DGS representations reconstructed from sparse inputs.
The core of our approach is the reference-guided video restoration model, built
upon a DiT-based video diffusion model trained on paired artifact 3DGS renders
and clean frames with additional reference-based conditions. Considering the
input sparse views as references, our model integrates both 2D semantic
features and 3D geometric features of reference views extracted from the visual
geometry foundation model, enhancing the semantic coherence and 3D consistency
when fixing artifact novel views. Furthermore, considering the lack of suitable
benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which
contains artifact frames rendered using low-quality 3DGS. Extensive experiments
demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS
artifact restoration and sparse-view 3D reconstruction. Project page:
https://github.com/GVCLab/GSFixer.

</details>


### [79] [Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision](https://arxiv.org/abs/2508.09681)
*Gerardo Loza,Junlei Hu,Dominic Jones,Sharib Ali,Pietro Valdastri*

Main category: cs.CV

TL;DR: 本文提出了一种基于NeRF的新型测试时优化（TTO）方法，用于长期3D点跟踪，通过可逆神经辐射场（InvNeRF）架构实现2D和3D跟踪，并在手术场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的点跟踪方法在一致性运动或3D跟踪方面存在不足，本文旨在通过优化函数和新型架构解决这些问题。

Method: 采用InvNeRF架构，结合渲染方法的优势，提出了双向可变形规范映射、高效采样算法和多尺度HexPlanes，用于快速推理。

Result: 在STIR和SCARE数据集上验证，2D跟踪精度提升50%，3D跟踪首次超越前馈方法，并兼具可变形NeRF重建的优势。

Conclusion: 本文方法在点跟踪领域表现突出，尤其在3D跟踪中填补了TTO方法的空白，展示了NeRF架构的潜力。

Abstract: We proposed a novel test-time optimisation (TTO) approach framed by a
NeRF-based architecture for long-term 3D point tracking. Most current methods
in point tracking struggle to obtain consistent motion or are limited to 2D
motion. TTO approaches frame the solution for long-term tracking as optimising
a function that aggregates correspondences from other specialised
state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose
parametrising such a function with our new invertible Neural Radiance Field
(InvNeRF) architecture to perform both 2D and 3D tracking in surgical
scenarios. Our approach allows us to exploit the advantages of a
rendering-based approach by supervising the reprojection of pixel
correspondences. It adapts strategies from recent rendering-based methods to
obtain a bidirectional deformable-canonical mapping, to efficiently handle a
defined workspace, and to guide the rays' density. It also presents our
multi-scale HexPlanes for fast inference and a new algorithm for efficient
pixel sampling and convergence criteria. We present results in the STIR and
SCARE datasets, for evaluating point tracking and testing the integration of
kinematic data in our pipeline, respectively. In 2D point tracking, our
approach surpasses the precision and accuracy of the TTO state-of-the-art
methods by nearly 50% on average precision, while competing with other
approaches. In 3D point tracking, this is the first TTO approach, surpassing
feed-forward methods while incorporating the benefits of a deformable
NeRF-based reconstruction.

</details>


### [80] [PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training](https://arxiv.org/abs/2508.09691)
*Yin Xie,Zhichao Chen,Xiaoze Yu,Yongle Zhao,Xiang An,Kaicheng Yang,Zimin Ran,Jia Guo,Ziyong Feng,Jiankang Deng*

Main category: cs.CV

TL;DR: 提出了一种名为PaCo-FR的无监督框架，通过掩码图像建模和像素-块对齐技术解决了现有面部表示预训练方法在特征提取、空间结构利用和数据效率方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有面部表示预训练方法在捕捉细微语义、利用空间结构特征和处理有限标注数据时表现不佳。

Method: PaCo-FR结合结构化掩码策略、基于块的代码书和空间一致性约束，提升了面部特征的判别力和几何关系保持。

Result: 仅需200万无标注图像进行预训练，PaCo-FR在多种面部分析任务中达到了最先进的性能，尤其在处理姿态、遮挡和光照变化时表现出色。

Conclusion: 该工作推动了面部表示学习的发展，提供了一种高效且可扩展的解决方案，减少了对昂贵标注数据的依赖。

Abstract: Facial representation pre-training is crucial for tasks like facial
recognition, expression analysis, and virtual reality. However, existing
methods face three key challenges: (1) failing to capture distinct facial
features and fine-grained semantics, (2) ignoring the spatial structure
inherent to facial anatomy, and (3) inefficiently utilizing limited labeled
data. To overcome these, we introduce PaCo-FR, an unsupervised framework that
combines masked image modeling with patch-pixel alignment. Our approach
integrates three innovative components: (1) a structured masking strategy that
preserves spatial coherence by aligning with semantically meaningful facial
regions, (2) a novel patch-based codebook that enhances feature discrimination
with multiple candidate tokens, and (3) spatial consistency constraints that
preserve geometric relationships between facial components. PaCo-FR achieves
state-of-the-art performance across several facial analysis tasks with just 2
million unlabeled images for pre-training. Our method demonstrates significant
improvements, particularly in scenarios with varying poses, occlusions, and
lighting conditions. We believe this work advances facial representation
learning and offers a scalable, efficient solution that reduces reliance on
expensive annotated datasets, driving more effective facial analysis systems.

</details>


### [81] [Slot Attention-based Feature Filtering for Few-Shot Learning](https://arxiv.org/abs/2508.09699)
*Javier Rodenas,Eduardo Aguilar,Petia Radeva*

Main category: cs.CV

TL;DR: SAFF利用槽注意力机制过滤无关特征，提升小样本学习性能。


<details>
  <summary>Details</summary>
Motivation: 小样本学习中，无关特征（如背景）容易导致混淆和误分类，影响性能。

Method: 提出SAFF方法，结合槽注意力和补丁嵌入，通过相似性矩阵过滤无关特征。

Result: 实验表明SAFF优于其他注意力机制，在多个数据集上超越现有方法。

Conclusion: SAFF能有效捕捉判别性特征，减少无关信息，提升分类性能。

Abstract: Irrelevant features can significantly degrade few-shot learn ing performance.
This problem is used to match queries and support images based on meaningful
similarities despite the limited data. However, in this process, non-relevant
fea tures such as background elements can easily lead to confu sion and
misclassification. To address this issue, we pro pose Slot Attention-based
Feature Filtering for Few-Shot Learning (SAFF) that leverages slot attention
mechanisms to discriminate and filter weak features, thereby improving few-shot
classification performance. The key innovation of SAFF lies in its integration
of slot attention with patch em beddings, unifying class-aware slots into a
single attention mechanism to filter irrelevant features effectively. We intro
duce a similarity matrix that computes across support and query images to
quantify the relevance of filtered embed dings for classification. Through
experiments, we demon strate that Slot Attention performs better than other
atten tion mechanisms, capturing discriminative features while reducing
irrelevant information. We validate our approach through extensive experiments
on few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma
geNet, outperforming several state-of-the-art methods.

</details>


### [82] [MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers](https://arxiv.org/abs/2508.09709)
*Qianru Qiu,Jiafeng Mao,Kento Masui,Xueting Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散变换器（DiT）的模型MangaDiT，通过内部注意力机制实现参考引导的线稿上色，解决了现有方法在区域级颜色一致性上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在参考引导的线稿上色中表现不佳，尤其是在参考图和目标图姿态或动作差异较大时。本文旨在通过内部注意力机制隐式发现语义对应关系，提升区域级颜色一致性。

Method: 提出MangaDiT模型，采用扩散变换器（DiT），引入分层注意力机制和动态注意力权重策略，通过额外的上下文感知路径增强模型的感受野和颜色对齐能力。

Result: 在两个基准数据集上的实验表明，MangaDiT在定性和定量评估中均优于现有方法。

Conclusion: MangaDiT通过改进的注意力机制有效提升了参考引导线稿上色的性能和区域级颜色一致性。

Abstract: Recent advances in diffusion models have significantly improved the
performance of reference-guided line art colorization. However, existing
methods still struggle with region-level color consistency, especially when the
reference and target images differ in character pose or motion. Instead of
relying on external matching annotations between the reference and target, we
propose to discover semantic correspondences implicitly through internal
attention mechanisms. In this paper, we present MangaDiT, a powerful model for
reference-guided line art colorization based on Diffusion Transformers (DiT).
Our model takes both line art and reference images as conditional inputs and
introduces a hierarchical attention mechanism with a dynamic attention
weighting strategy. This mechanism augments the vanilla attention with an
additional context-aware path that leverages pooled spatial features,
effectively expanding the model's receptive field and enhancing region-level
color alignment. Experiments on two benchmark datasets demonstrate that our
method significantly outperforms state-of-the-art approaches, achieving
superior performance in both qualitative and quantitative evaluations.

</details>


### [83] [NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation](https://arxiv.org/abs/2508.09715)
*Devvrat Joshi,Islem Rekik*

Main category: cs.CV

TL;DR: NEURAL框架通过语义引导的压缩方法，显著减少医学图像数据量并保持诊断性能。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限的临床环境中多模态医学影像数据的存储与传输难题。

Method: 利用生成式视觉-语言模型的交叉注意力分数对X光图像进行结构修剪，转化为图形表示。

Result: 在MIMIC-CXR和CheXpert Plus数据集上，数据量减少93.4-97.7%，诊断AUC为0.88-0.95。

Conclusion: NEURAL在数据压缩与临床效用间取得平衡，适用于高效工作流程和远程放射学。

Abstract: The rapid growth of multimodal medical imaging data presents significant
storage and transmission challenges, particularly in resource-constrained
clinical settings. We propose NEURAL, a novel framework that addresses this by
using semantics-guided data compression. Our approach repurposes
cross-attention scores between the image and its radiological report from a
fine-tuned generative vision-language model to structurally prune chest X-rays,
preserving only diagnostically critical regions. This process transforms the
image into a highly compressed, graph representation. This unified graph-based
representation fuses the pruned visual graph with a knowledge graph derived
from the clinical report, creating a universal data structure that simplifies
downstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for
pneumonia detection, NEURAL achieves a 93.4-97.7\% reduction in image data size
while maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming
other baseline models that use uncompressed data. By creating a persistent,
task-agnostic data asset, NEURAL resolves the trade-off between data size and
clinical utility, enabling efficient workflows and teleradiology without
sacrificing performance. Our NEURAL code is available at
https://github.com/basiralab/NEURAL.

</details>


### [84] [Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction](https://arxiv.org/abs/2508.09717)
*Shekhnaz Idrissova,Islem Rekik*

Main category: cs.CV

TL;DR: 该论文提出了一种基于sheaf的新框架，用于结构感知且一致地融合MRI和组织病理学数据，改进了现有的多模态方法，并在缺失数据情况下表现出鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为解决胶质母细胞瘤分子亚型分类需要侵入性组织提取的局限性，以及现有多模态方法在保留跨模态共享结构信息方面的不足。

Method: 提出了一种sheaf-based框架，用于结构感知和一致性地融合MRI与组织病理学数据，并处理缺失或不完整模态数据的问题。

Result: 模型优于基线方法，在缺失或不完整数据情况下表现稳健，有助于开发虚拟活检工具以加速诊断。

Conclusion: 该框架为多模态数据融合提供了新的解决方案，有望推动胶质母细胞瘤的快速诊断技术发展。

Abstract: Glioblastoma is a highly invasive brain tumor with rapid progression rates.
Recent studies have shown that glioblastoma molecular subtype classification
serves as a significant biomarker for effective targeted therapy selection.
However, this classification currently requires invasive tissue extraction for
comprehensive histopathological analysis. Existing multimodal approaches
combining MRI and histopathology images are limited and lack robust mechanisms
for preserving shared structural information across modalities. In particular,
graph-based models often fail to retain discriminative features within
heterogeneous graphs, and structural reconstruction mechanisms for handling
missing or incomplete modality data are largely underexplored. To address these
limitations, we propose a novel sheaf-based framework for structure-aware and
consistent fusion of MRI and histopathology data. Our model outperforms
baseline methods and demonstrates robustness in incomplete or missing data
scenarios, contributing to the development of virtual biopsy tools for rapid
diagnostics. Our source code is available at
https://github.com/basiralab/MMSN/.

</details>


### [85] [Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System](https://arxiv.org/abs/2508.09732)
*Romeo Valentin,Sydney M. Katz,Artur B. Carneiro,Don Walker,Mykel J. Kochenderfer*

Main category: cs.CV

TL;DR: 提出了一种基于视觉的飞机姿态估计管道，解决了航空应用中数据驱动系统的鲁棒性和安全性挑战，通过三种创新方法实现高精度和不确定性校准。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的计算机视觉技术虽在民航自主导航中取得进展，但其在安全关键航空应用中的鲁棒性和安全性仍需验证。本文旨在开发一种可认证的系统。

Method: 采用基于空间Soft Argmax算子的高效神经网络架构，设计校准预测不确定性的损失函数，并引入残差自主完整性监测（RAIM）进行故障检测。

Result: 模型在跑道图像数据集上表现优于基线架构，提供亚像素精度的校准不确定性估计，可用于下游故障检测。

Conclusion: 提出的方法为实现可认证的航空安全关键系统迈出重要一步，兼具高精度和实用性。

Abstract: Recent advances in data-driven computer vision have enabled robust autonomous
navigation capabilities for civil aviation, including automated landing and
runway detection. However, ensuring that these systems meet the robustness and
safety requirements for aviation applications remains a major challenge. In
this work, we present a practical vision-based pipeline for aircraft pose
estimation from runway images that represents a step toward the ability to
certify these systems for use in safety-critical aviation applications. Our
approach features three key innovations: (i) an efficient, flexible neural
architecture based on a spatial Soft Argmax operator for probabilistic keypoint
regression, supporting diverse vision backbones with real-time inference; (ii)
a principled loss function producing calibrated predictive uncertainties, which
are evaluated via sharpness and calibration metrics; and (iii) an adaptation of
Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling
runtime detection and rejection of faulty model outputs. We implement and
evaluate our pose estimation pipeline on a dataset of runway images. We show
that our model outperforms baseline architectures in terms of accuracy while
also producing well-calibrated uncertainty estimates with sub-pixel precision
that can be used downstream for fault detection.

</details>


### [86] [Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://arxiv.org/abs/2508.09736)
*Lin Long,Yichen He,Wentao Ye,Yiyuan Pan,Yuan Lin,Hang Li,Junbo Zhao,Wei Li*

Main category: cs.CV

TL;DR: 介绍了M3-Agent，这是一种具有长期记忆的新型多模态代理框架，能够处理和更新视觉和听觉输入，具备语义和情景记忆能力，并在新的长视频问答基准M3-Bench上表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在推动多模态代理实现更接近人类的长期记忆能力，并探索其实际应用设计。

Method: 采用强化学习训练M3-Agent，通过多轮迭代推理和记忆检索完成任务；开发了M3-Bench作为评估基准。

Result: M3-Agent在多个基准测试中表现优于基线模型，准确率提升6.7%至7.7%。

Conclusion: M3-Agent通过长期记忆和多模态理解能力，为多模态代理的实际应用提供了新方向。

Abstract: We introduce M3-Agent, a novel multimodal agent framework equipped with
long-term memory. Like humans, M3-Agent can process real-time visual and
auditory inputs to build and update its long-term memory. Beyond episodic
memory, it also develops semantic memory, enabling it to accumulate world
knowledge over time. Its memory is organized in an entity-centric, multimodal
format, allowing deeper and more consistent understanding of the environment.
Given an instruction, M3-Agent autonomously performs multi-turn, iterative
reasoning and retrieves relevant information from memory to accomplish the
task. To evaluate memory effectiveness and memory-based reasoning in multimodal
agents, we develop M3-Bench, a new long-video question answering benchmark.
M3-Bench comprises 100 newly recorded real-world videos captured from a robot's
perspective (M3-Bench-robot) and 929 web-sourced videos across diverse
scenarios (M3-Bench-web). We annotate question-answer pairs designed to test
key capabilities essential for agent applications, such as human understanding,
general knowledge extraction, and cross-modal reasoning. Experimental results
show that M3-Agent, trained via reinforcement learning, outperforms the
strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,
achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web
and VideoMME-long, respectively. Our work advances the multimodal agents toward
more human-like long-term memory and provides insights into their practical
design. Model, code and data are available at
https://github.com/bytedance-seed/m3-agent

</details>


### [87] [Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection](https://arxiv.org/abs/2508.09746)
*Zhiqiu Zhang,Dongqi Fan,Mingjie Wang,Qiang Tang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: 论文提出了一种新的图像协调方法（R2R），通过区域到区域的变换和自适应滤波技术，解决了现有方法在细节保留和协调能力上的局限，同时构建了更真实的数据集（RPHarmony）。


<details>
  <summary>Details</summary>
Motivation: 现有基于潜在扩散模型的图像协调方法在细节保留和协调能力上有局限，且合成数据集缺乏多样性。

Method: 提出区域到区域变换，结合Clear-VAE和Harmony控制器（MACA），并开发随机泊松混合构造新数据集RPHarmony。

Result: 实验表明，新方法在定量指标和视觉协调性上均优于现有方法，且RPHarmony数据集成效显著。

Conclusion: 该方法显著提升了图像协调效果，且公开的代码和数据集促进了研究进一步发展。

Abstract: The goal of image harmonization is to adjust the foreground in a composite
image to achieve visual consistency with the background. Recently, latent
diffusion model (LDM) are applied for harmonization, achieving remarkable
results. However, LDM-based harmonization faces challenges in detail
preservation and limited harmonization ability. Additionally, current synthetic
datasets rely on color transfer, which lacks local variations and fails to
capture complex real-world lighting conditions. To enhance harmonization
capabilities, we propose the Region-to-Region transformation. By injecting
information from appropriate regions into the foreground, this approach
preserves original details while achieving image harmonization or, conversely,
generating new composite data. From this perspective, We propose a novel model
R2R. Specifically, we design Clear-VAE to preserve high-frequency details in
the foreground using Adaptive Filter while eliminating disharmonious elements.
To further enhance harmonization, we introduce the Harmony Controller with
Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the
foreground based on the channel importance of both foreground and background
regions. To address the limitation of existing datasets, we propose Random
Poisson Blending, which transfers color and lighting information from a
suitable region to the foreground, thereby generating more diverse and
challenging synthetic images. Using this method, we construct a new synthetic
dataset, RPHarmony. Experiments demonstrate the superiority of our method over
other methods in both quantitative metrics and visual harmony. Moreover, our
dataset helps the model generate more realistic images in real examples. Our
code, dataset, and model weights have all been released for open access.

</details>


### [88] [MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models](https://arxiv.org/abs/2508.09779)
*Dianyi Wang,Siyuan Wang,Zejun Li,Yikun Wang,Yitong Li,Duyu Tang,Xiaoyu Shen,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CV

TL;DR: 论文提出了一种新的稀疏专家混合架构MoIIE，用于提升大型视觉语言模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的密集大型视觉语言模型计算成本高，稀疏专家混合架构（MoE）虽提高参数效率，但在多模态任务中同时建模模态特定特征和跨模态关联仍具挑战性。

Method: 引入MoIIE架构，通过模态引导的路由机制将令牌分配到模态内专家和共享的跨模态专家池，并结合两阶段训练策略。

Result: 实验表明，MoIIE模型在激活参数较少的情况下，性能匹配甚至超越现有开源MoE多模态模型。

Conclusion: MoIIE架构在效率、性能和通用性上表现优异，为多模态任务提供了一种有效解决方案。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across multi-modal tasks by scaling model size and training data. However,
these dense LVLMs incur significant computational costs and motivate the
exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve
parameter efficiency, effectively applying MoE to simultaneously model
modality-specific features and cross-modal associations in LVLMs remains
challenging. In this work, we propose to incorporate Mixture of Intra- and
Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is
guided by its modality, directing tokens to their respective intra-modality
experts as well as a shared pool of inter-modality experts, enabling the model
to jointly learn rich intra-modal features and cross-modal interactions. We
further introduce an effective and straightforward two-stage training strategy,
which facilitates the direct activation of both MoE and multi-modal
capabilities. Extensive experiments across different data scales and LLM
backbone demonstrate the effectiveness, efficiency and generality of our
approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters
match or even surpass the performance of existing advanced open-source MoE-LLMs
based multi-modal models that involve more activated parameters. The code is
available at https://github.com/AlenjandroWang/MoIIE.

</details>


### [89] [Combinative Matching for Geometric Shape Assembly](https://arxiv.org/abs/2508.09780)
*Nahyuk Lee,Juhong Min,Junhong Lee,Chunghyun Park,Minsu Cho*

Main category: cs.CV

TL;DR: 本文提出了一种名为"组合匹配"的新方法，用于几何形状装配中的互锁部件组合。它通过显式建模"相同表面形状"和"相反体积占据"来解决传统形状匹配的局限性，显著提升了装配的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统几何装配方法通常依赖于通过寻找相同表面来对齐部件，但在处理互锁形状时存在局限性。本文旨在通过显式建模互锁形状的两个特性，提高装配的准确性和鲁棒性。

Method: 提出组合匹配方法，学习在表面上相同但体积占据相反的区域建立对应关系，并通过等变神经网络估计形状方向以对齐区域旋转。

Result: 在几何装配基准测试中，该方法显著减少了局部匹配的模糊性，并优于现有技术。

Conclusion: 组合匹配方法通过显式建模互锁形状的双重特性，为几何形状装配提供了更鲁棒和高效的解决方案。

Abstract: This paper introduces a new shape-matching methodology, combinative matching,
to combine interlocking parts for geometric shape assembly. Previous methods
for geometric assembly typically rely on aligning parts by finding identical
surfaces between the parts as in conventional shape matching and registration.
In contrast, we explicitly model two distinct properties of interlocking
shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method
thus learns to establish correspondences across regions where their surface
shapes appear identical but their volumes occupy the inverted space to each
other. To facilitate this process, we also learn to align regions in rotation
by estimating their shape orientations via equivariant neural networks. The
proposed approach significantly reduces local ambiguities in matching and
allows a robust combination of parts in assembly. Experimental results on
geometric assembly benchmarks demonstrate the efficacy of our method,
consistently outperforming the state of the art. Project page:
https://nahyuklee.github.io/cmnet.

</details>


### [90] [DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.09785)
*Linpu He,Yanan Li,Bingze Li,Elvis Han Cui,Donghui Wang*

Main category: cs.CV

TL;DR: DSS-Prompt是一种简单有效的方法，通过微调预训练视觉Transformer的提示（prompts），将其转化为强大的少样本类增量学习（FSCIL）分类器，结合静态和动态提示提升性能。


<details>
  <summary>Details</summary>
Motivation: 大规模预训练模型在少样本类增量学习任务中尚未充分探索，该任务旨在从有限的样本中持续学习新概念而不遗忘旧知识。

Method: 提出DSS-Prompt，通过静态提示弥合预训练与下游任务的领域差距，动态提示捕获实例感知语义，并结合多模态预训练模型生成输入感知的动态提示。

Result: 在四个基准测试中验证，DSS-Prompt性能优于现有方法，有效缓解灾难性遗忘问题。

Conclusion: DSS-Prompt通过简单的原型分类器在增量任务中表现出色，无需额外训练，展示了其高效性和实用性。

Abstract: Learning from large-scale pre-trained models with strong generalization
ability has shown remarkable success in a wide range of downstream tasks
recently, but it is still underexplored in the challenging few-shot
class-incremental learning (FSCIL) task. It aims to continually learn new
concepts from limited training samples without forgetting the old ones at the
same time. In this paper, we introduce DSS-Prompt, a simple yet effective
approach that transforms the pre-trained Vision Transformer with minimal
modifications in the way of prompts into a strong FSCIL classifier. Concretely,
we synergistically utilize two complementary types of prompts in each
Transformer block: static prompts to bridge the domain gap between the
pre-training and downstream datasets, thus enabling better adaption; and
dynamic prompts to capture instance-aware semantics, thus enabling easy
transfer from base to novel classes. Specially, to generate dynamic prompts, we
leverage a pre-trained multi-modal model to extract input-related diverse
semantics, thereby generating complementary input-aware prompts, and then
adaptively adjust their importance across different layers. In this way, on top
of the prompted visual embeddings, a simple prototype classifier can beat
state-of-the-arts without further training on the incremental tasks. We conduct
extensive experiments on four benchmarks to validate the effectiveness of our
DSS-Prompt and show that it consistently achieves better performance than
existing approaches on all datasets and can alleviate the catastrophic
forgetting issue as well.

</details>


### [91] [MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking](https://arxiv.org/abs/2508.09796)
*Yingjie Wang,Zhixing Wang,Le Zheng,Tianxiao Liu,Roujing Li,Xueyao Hu*

Main category: cs.CV

TL;DR: 论文提出了一种名为MeMoSORT的实时多目标跟踪方法，通过改进Kalman滤波器和引入自适应IoU匹配，解决了复杂运动和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 传统跟踪方法因Kalman滤波器的运动模型不匹配和固定IoU匹配在遮挡下表现不佳，导致跟踪错误和目标丢失，需要改进。

Method: MeMoSORT提出了基于记忆辅助的Kalman滤波器（MeKF）和自适应IoU匹配（Mo-IoU），提升运动预测和遮挡处理能力。

Result: 在DanceTrack和SportsMOT数据集上，MeMoSORT分别取得了67.9%和82.1%的HOTA分数，达到领先水平。

Conclusion: MeMoSORT通过创新的运动模型和匹配策略，显著提升了复杂场景下的多目标跟踪性能。

Abstract: Multi-object tracking (MOT) in human-dominant scenarios, which involves
continuously tracking multiple people within video sequences, remains a
significant challenge in computer vision due to targets' complex motion and
severe occlusions. Conventional tracking-by-detection methods are fundamentally
limited by their reliance on Kalman filter (KF) and rigid Intersection over
Union (IoU)-based association. The motion model in KF often mismatches
real-world object dynamics, causing filtering errors, while rigid association
struggles under occlusions, leading to identity switches or target loss. To
address these issues, we propose MeMoSORT, a simple, online, and real-time MOT
tracker with two key innovations. First, the Memory-assisted Kalman filter
(MeKF) uses memory-augmented neural networks to compensate for mismatches
between assumed and actual object motion. Second, the Motion-adaptive IoU
(Mo-IoU) adaptively expands the matching space and incorporates height
similarity to reduce the influence of detection errors and association
failures, while remaining lightweight. Experiments on DanceTrack and SportsMOT
show that MeMoSORT achieves state-of-the-art performance, with HOTA scores of
67.9\% and 82.1\%, respectively.

</details>


### [92] [MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention](https://arxiv.org/abs/2508.09802)
*Xin Du,Maoyuan Xu,Zhi Ying*

Main category: cs.CV

TL;DR: 论文提出了一种名为MUJICA的方法，通过跨图注意力改进预训练的SISR模型，解决了PBR材质超分辨率中的跨图不一致性和模态特定特征建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有的单图像超分辨率（SISR）方法在处理PBR材质时存在跨图不一致性、模态特征建模不足等问题，限制了其应用。

Method: 提出了MUJICA方法，它是一种灵活的适配器，通过跨图注意力机制融合特征，结合预训练的SISR模型（如SwinIR）提升PBR材质的超分辨率性能。

Result: 在实验中，MUJICA显著提升了PSNR、SSIM和LPIPS分数，同时保持了跨图一致性，并在有限资源下实现了高效训练。

Conclusion: MUJICA是一种高效且性能优越的方法，适用于PBR材质的超分辨率任务，并在多个SISR模型中验证了其有效性。

Abstract: Physically Based Rendering (PBR) materials are typically characterized by
multiple 2D texture maps such as basecolor, normal, metallic, and roughness
which encode spatially-varying bi-directional reflectance distribution function
(SVBRDF) parameters to model surface reflectance properties and microfacet
interactions. Upscaling SVBRDF material is valuable for modern 3D graphics
applications. However, existing Single Image Super-Resolution (SISR) methods
struggle with cross-map inconsistency, inadequate modeling of modality-specific
features, and limited generalization due to data distribution shifts. In this
work, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention
(MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based
SISR models for PBR material super-resolution. MUJICA is seamlessly attached
after the pre-trained and frozen SISR backbone. It leverages cross-map
attention to fuse features while preserving remarkable reconstruction ability
of the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and
HMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map
consistency. Experiments demonstrate that MUJICA enables efficient training
even with limited resources and delivers state-of-the-art performance on PBR
material datasets.

</details>


### [93] [Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology](https://arxiv.org/abs/2508.09805)
*Jonathan Williams Ramirez,Dina Zemlyanker,Lucas Deden-Binder,Rogeny Herisse,Erendira Garcia Pallares,Karthik Gopinath,Harshvardhan Gazula,Christopher Mount,Liana N. Kozanno,Michael S. Marshall,Theresa R. Connors,Matthew P. Frosch,Mark Montine,Derek H. Oakley,Christine L. Mac Donald,C. Dirk Keene,Bradley T. Hyman,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 提出了一种基于U-Net的深度学习方法，用于自动化分割脑组织照片中的组织，显著减少了手动干预需求。


<details>
  <summary>Details</summary>
Motivation: 脑组织照片的分割通常需要昂贵的手动操作，自动化这一过程可提高效率并降低成本。

Method: 使用U-Net架构，结合手动标注的图像和合成的MRI扫描数据训练模型。

Result: 模型在未见的测试数据上表现出色，Dice分数中位数超过0.98，接近人工标注的精度。

Conclusion: 该方法为脑组织分割提供了高效、准确的自动化工具，已公开可用。

Abstract: Advances in image registration and machine learning have recently enabled
volumetric analysis of \emph{postmortem} brain tissue from conventional
photographs of coronal slabs, which are routinely collected in brain banks and
neuropathology laboratories worldwide. One caveat of this methodology is the
requirement of segmentation of the tissue from photographs, which currently
requires costly manual intervention. In this article, we present a deep
learning model to automate this process. The automatic segmentation tool relies
on a U-Net architecture that was trained with a combination of
\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,
from specimens with varying diagnoses, photographed at two different sites; and
\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding
masks generated from MRI scans for improved generalizability to unseen
photographic setups. Automated model predictions on a subset of photographs not
seen in training were analyzed to estimate performance compared to manual
labels -- including both inter- and intra-rater variability. Our model achieved
a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\%
Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.
Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.

</details>


### [94] [TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos](https://arxiv.org/abs/2508.09811)
*Jinxi Li,Ziyang Song,Bo Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为TRACE的新框架，通过将3D场景中的每个点建模为具有空间大小和方向的刚性粒子，直接从动态多视角视频中学习场景的几何、外观和物理信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过物理信息损失或简单物理模型作为约束，往往无法学习复杂的运动物理，或需要额外的标签（如对象类型或掩码）。

Method: TRACE框架将每个3D点视为刚性粒子，直接学习其平移、旋转动态系统，并显式估计物理参数以控制粒子随时间运动。

Result: 在三个现有动态数据集和一个新合成的数据集上实验表明，该方法在未来帧外推任务中表现优于基线。

Conclusion: 该方法无需人工标签即可学习复杂动态3D场景的物理信息，并能通过聚类物理参数轻松分割多个对象或部分。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and physical
information just from dynamic multi-view videos in the absence of any human
labels. By leveraging physics-informed losses as soft constraints or
integrating simple physics models into neural nets, existing works often fail
to learn complex motion physics, or doing so requires additional labels such as
object types or masks. We propose a new framework named TRACE to model the
motion physics of complex dynamic 3D scenes. The key novelty of our method is
that, by formulating each 3D point as a rigid particle with size and
orientation in space, we directly learn a translation rotation dynamics system
for each particle, explicitly estimating a complete set of physical parameters
to govern the particle's motion over time. Extensive experiments on three
existing dynamic datasets and one newly created challenging synthetic datasets
demonstrate the extraordinary performance of our method over baselines in the
task of future frame extrapolation. A nice property of our framework is that
multiple objects or parts can be easily segmented just by clustering the
learned physical parameters.

</details>


### [95] [Poaching Hotspot Identification Using Satellite Imagery](https://arxiv.org/abs/2508.09812)
*Aryan Pandhi,Shrey Baid,Sanjali Jha*

Main category: cs.CV

TL;DR: 非洲象偷猎问题日益严重，计算机视觉模型通过地理标志识别偷猎热点区域，成为解决方案。


<details>
  <summary>Details</summary>
Motivation: 非洲象因象牙偷猎濒临灭绝，现有反偷猎措施效率不足，需新技术动态定位偷猎热点。

Method: 结合卫星图像与计算机视觉模型，自动化分析地理环境特征以预测偷猎热点，减少人力巡逻。

Result: 模型可动态追踪偷猎热点变化，高效分配资源，避免干扰生态或航空限制。

Conclusion: 计算机视觉模型为反偷猎提供高效、非侵入式解决方案，有望遏制非洲象偷猎趋势。

Abstract: Elephant Poaching in African countries has been a decade-old problem. So much
so that African Forest Elephants are now listed as an endangered species, and
African Savannah Elephants as critically endangered by the IUCN (International
Union for Conservation of Nature). [1] Elephants are hunted primarily for their
ivory tusks which caused many elephants to be born tuskless as a genetic
modification for survival. [2] Data gathered by recent studies shows that
though poaching methods remain the same, the poaching grounds are rather
dynamic. Poachers have shifted to areas with less ranger patrols and several
other factors like watering holes, seasons, altitude etc. cause constant shifts
in poaching hotspot locations. [3] After a period of low poaching from
2000-2014, poaching numbers in African countries are now on the rise again --
WWF (World Wildlife Foundation) says there are 20,000 elephants poached
annually [4]. In African countries, anti-poaching efforts are concentrated near
towns, while a majority of poaching occurs in the deserted regions. All of
these factors result in the need for a Computer Vision Model to identify
poaching hotspots through locating the geographic indicators of favorable
poaching regions. A CV model eliminates the need to manually track poachers and
account for the environmental factors to deploy resources and its combination
with satellite imagery allows us to survey large areas without disturbing local
species or cross border aviation restrictions.

</details>


### [96] [Evolution of Low-Level and Texture Human-CLIP Alignment](https://arxiv.org/abs/2508.09814)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra*

Main category: cs.CV

TL;DR: CLIP模型早期训练阶段更符合人类低级图像质量评估，但随着训练深入，其对噪声敏感性和纹理偏好增加，逐渐转向抽象形状表示，影响了低级感知对齐。


<details>
  <summary>Details</summary>
Motivation: 研究多模态模型（如CLIP）在训练过程中与人类低级图像质量评估相关性的变化，探究其原因。

Method: 通过分析形状-纹理偏置对齐和噪声下的分类准确率下降两个关键因素，研究CLIP的学习机制。

Result: CLIP早期学习低级视觉特征，增强与人类感知的对齐，但增加噪声敏感性和纹理偏置；后期转向抽象形状表示，提高噪声鲁棒性但削弱了对齐。

Conclusion: 研究发现了一种学习机制，为优化视觉-语言模型中感知对齐与鲁棒性的权衡提供了新思路。

Abstract: During the training of multi-modal models like CLIP, we observed an
intriguing phenomenon: the correlation with low-level human image quality
assessments peaks in the early epochs before gradually declining. This study
investigates this observation and seeks to understand its causes through two
key factors: shape-texture bias alignment and classification accuracy drop
under noise. Our findings suggest that CLIP initially learn low-level visual
features, enhancing its alignment with low-level human perception but also
increasing its sensitivity to noise and its texture bias. As training
progresses, the model shifts toward more abstract shape-based representations,
improving noise robustness but reducing alignment with low-level human
perception. These results suggest that these factors shared an underlying
learning mechanism and provide new insights into optimizing the trade-off
between perceptual alignment and robustness in vision-language models.

</details>


### [97] [ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video](https://arxiv.org/abs/2508.09818)
*Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Abir Ahmed,Liew Tze Hui*

Main category: cs.CV

TL;DR: 该研究探讨了如何利用大语言模型（LLMs）结合运动与视频数据理解人类行为，提出了名为ViMoNet的框架，通过联合训练策略整合两种数据优势，并引入新数据集VIMOS和评估基准ViMoNet-Bench。实验显示ViMoNet在行为理解任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅关注单一数据类型（运动或视频），无法完全捕捉人类行为的细微动作与含义，因此需要一种能结合两种数据的方法以更全面地理解行为。

Method: 提出ViMoNet框架，采用联合训练策略，结合精确的运动-文本数据和通用的视频-文本数据，同时引入新数据集VIMOS和评估基准ViMoNet-Bench。

Result: ViMoNet在行为理解任务中表现优于现有方法，特别是在动作理解、行为解释和生成字幕方面。

Conclusion: 结合运动与视频数据的联合训练策略有助于更全面地理解人类行为，ViMoNet框架和配套数据集为未来研究提供了有价值的工具。

Abstract: This study investigates how large language models (LLMs) can be used to
understand human behavior using motion and video data. We think that mixing
both types is essential to completely capture the nuanced movements and
meanings of human actions, in contrast to recent models that simply concentrate
on motion data or films. To address this, we provide ViMoNet, a straightforward
yet effective framework for comprehending, characterizing, and deducing human
action. ViMoNet employs a joint training strategy that leverages the advantages
of two data types: detailed motion-text data, which is more exact, and generic
video-text data, which is more comprehensive but less detailed. This aids in
the model's acquisition of rich data regarding time and space in human
behavior. Additionally, we provide a brand new dataset named VIMOS that
contains a variety of films, motion sequences, instructions, and subtitles. We
developed ViMoNet-Bench, a standardized benchmark with carefully labeled
samples, to evaluate how well models understand human behavior. Our tests show
that ViMoNet outperforms existing methods in caption generation, motion
understanding, and behavior interpretation.

</details>


### [98] [Physical Autoregressive Model for Robotic Manipulation without Action Pretraining](https://arxiv.org/abs/2508.09822)
*Zijian Song,Sihan Qin,Tianshui Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: 本文提出了物理自回归模型（PAR），结合视频生成模型和物理动力学，实现了机器人操作的高效学习和视频预测。


<details>
  <summary>Details</summary>
Motivation: 通过利用预训练视频模型中的世界知识，解决机器人操作中数据稀缺的问题。

Method: 结合帧和动作的物理令牌、DiT去令牌器、因果掩码和逆向运动学等技术。

Result: 在ManiSkill基准测试中，PushCube任务成功率100%，其他任务表现与基线相当。

Conclusion: 通过视频预训练传递世界知识，为机器人操作提供了新方向。

Abstract: The scarcity of manipulation data has motivated the use of pretrained large
models from other modalities in robotics. In this work, we build upon
autoregressive video generation models to propose a Physical Autoregressive
Model (PAR), where physical tokens combine frames and actions to represent the
joint evolution of the robot and its environment. PAR leverages the world
knowledge embedded in video pretraining to understand physical dynamics without
requiring action pretraining, enabling accurate video prediction and consistent
action trajectories. It also adopts a DiT-based de-tokenizer to model frames
and actions as continuous tokens, mitigating quantization errors and
facilitating mutual enhancement. Furthermore, we incorporate a causal mask with
inverse kinematics, parallel training, and the KV-cache mechanism to further
improve performance and efficiency. Experiments on the ManiSkill benchmark show
that PAR achieves a 100\% success rate on the PushCube task, matches the
performance of action-pretrained baselines on other tasks, and accurately
predicts future videos with tightly aligned action trajectories. These findings
underscore a promising direction for robotic manipulation by transferring world
knowledge from autoregressive video pretraining.

</details>


### [99] [KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.09823)
*Valentin Boussot,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: KonfAI是一个为医学影像任务设计的模块化、可扩展的深度学习框架，通过YAML配置文件定义工作流程，提升可重复性和开发效率。


<details>
  <summary>Details</summary>
Motivation: 医学影像任务需要高效、可重复且透明的深度学习框架，以简化开发和实验跟踪。

Method: 采用结构化YAML配置文件定义训练、推理和评估流程，支持高级策略如补丁学习、模型集成和多模型训练。

Result: 成功应用于分割、配准和图像合成任务，并在国际比赛中取得优异成绩。

Conclusion: KonfAI通过模块化和可扩展性满足了医学影像任务的需求，开源且实用。

Abstract: KonfAI is a modular, extensible, and fully configurable deep learning
framework specifically designed for medical imaging tasks. It enables users to
define complete training, inference, and evaluation workflows through
structured YAML configuration files, without modifying the underlying code.
This declarative approach enhances reproducibility, transparency, and
experimental traceability while reducing development time. Beyond the
capabilities of standard pipelines, KonfAI provides native abstractions for
advanced strategies including patch-based learning, test-time augmentation,
model ensembling, and direct access to intermediate feature representations for
deep supervision. It also supports complex multi-model training setups such as
generative adversarial architectures. Thanks to its modular and extensible
architecture, KonfAI can easily accommodate custom models, loss functions, and
data processing components. The framework has been successfully applied to
segmentation, registration, and image synthesis tasks, and has contributed to
top-ranking results in several international medical imaging challenges. KonfAI
is open source and available at
\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.

</details>


### [100] [Reverse Convolution and Its Applications to Image Restoration](https://arxiv.org/abs/2508.09824)
*Xuhong Huang,Shiqi Liu,Kai Zhang,Ying Tai,Jian Yang,Hui Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的深度反向卷积算子，用于有效反转深度卷积，通过构建并解决正则化最小二乘优化问题。


<details>
  <summary>Details</summary>
Motivation: 由于转置卷积并非真正意义上的卷积逆运算，目前神经网络中缺乏标准的反向卷积算子，本文旨在填补这一空白。

Method: 提出了深度反向卷积算子，并研究了其核初始化、填充策略等关键实现细节，进一步将其与层归一化、1×1卷积和GELU激活结合，构建了类似Transformer的结构。

Result: 在图像恢复任务（去噪、超分辨率、去模糊）中训练了ConverseNet的三个变体，实验证明了反向卷积算子作为基础模块的有效性。

Conclusion: 本文为深度模型设计中开发新算子提供了新思路，未来有望推动更多相关应用。

Abstract: Convolution and transposed convolution are fundamental operators widely used
in neural networks. However, transposed convolution (a.k.a. deconvolution) does
not serve as a true inverse of convolution due to inherent differences in their
mathematical formulations. To date, no reverse convolution operator has been
established as a standard component in neural architectures. In this paper, we
propose a novel depthwise reverse convolution operator as an initial attempt to
effectively reverse depthwise convolution by formulating and solving a
regularized least-squares optimization problem. We thoroughly investigate its
kernel initialization, padding strategies, and other critical aspects to ensure
its effective implementation. Building upon this operator, we further construct
a reverse convolution block by combining it with layer normalization,
1$\times$1 convolution, and GELU activation, forming a Transformer-like
structure. The proposed operator and block can directly replace conventional
convolution and transposed convolution layers in existing architectures,
leading to the development of ConverseNet. Corresponding to typical image
restoration models such as DnCNN, SRResNet and USRNet, we train three variants
of ConverseNet for Gaussian denoising, super-resolution and deblurring,
respectively. Extensive experiments demonstrate the effectiveness of the
proposed reverse convolution operator as a basic building module. We hope this
work could pave the way for developing new operators in deep model design and
applications.

</details>


### [101] [RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians](https://arxiv.org/abs/2508.09830)
*Shenxing Wei,Jinxi Li,Yafei Yang,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: 提出了一种名为RayletDF的新方法，通过射线距离场从点云或3D高斯中实现高效且泛化性强的3D表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于坐标的方法在渲染显式表面时计算量大，因此需要一种更高效且泛化的解决方案。

Method: 采用射线距离场技术，通过射线特征提取器、距离场预测器和多射线混合器三个模块，直接预测表面点。

Result: 在多个公共数据集上表现出色，特别是在泛化能力上，能够在未见数据集上单次前向传播完成重建。

Conclusion: RayletDF是一种高效且泛化性强的3D表面重建方法，适用于点云或3D高斯输入。

Abstract: In this paper, we present a generalizable method for 3D surface
reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from
RGB images. Unlike existing coordinate-based methods which are often
computationally intensive when rendering explicit surfaces, our proposed
method, named RayletDF, introduces a new technique called raylet distance
field, which aims to directly predict surface points from query rays. Our
pipeline consists of three key modules: a raylet feature extractor, a raylet
distance field predictor, and a multi-raylet blender. These components work
together to extract fine-grained local geometric features, predict raylet
distances, and aggregate multiple predictions to reconstruct precise surface
points. We extensively evaluate our method on multiple public real-world
datasets, demonstrating superior performance in surface reconstruction from
point clouds or 3D Gaussians. Most notably, our method achieves exceptional
generalization ability, successfully recovering 3D surfaces in a single-forward
pass across unseen datasets in testing.

</details>


### [102] [Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment](https://arxiv.org/abs/2508.09843)
*Hao Yang,Xu Zhang,Jiaqi Ma,Linwei Zhu,Yun Zhang,Huan Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于图神经网络的OIQA框架，通过建模视口间结构关系来提升对空间非均匀失真的感知能力，实验证明其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前OIQA方法因无法有效捕捉局部非均匀失真和空间质量变化，亟需改进。

Method: 采用斐波那契球采样生成结构化的视口图节点，结合多阶段特征提取网络、图注意力网络和图变换器来建模局部与长程失真关系。

Result: 在两个大规模OIQA数据库上表现显著优于现有方法，验证了其有效性和泛化能力。

Conclusion: 该方法通过结构化建模与多尺度特征融合，成功解决了空间非均匀失真的评估问题。

Abstract: Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to
evaluate locally non-uniform distortions due to inadequate modeling of spatial
variations in quality and ineffective feature representation capturing both
local details and global context. To address this, we propose a graph neural
network-based OIQA framework that explicitly models structural relationships
between viewports to enhance perception of spatial distortion non-uniformity.
Our approach employs Fibonacci sphere sampling to generate viewports with
well-structured topology, representing each as a graph node. Multi-stage
feature extraction networks then derive high-dimensional node representation.
To holistically capture spatial dependencies, we integrate a Graph Attention
Network (GAT) modeling fine-grained local distortion variations among adjacent
viewports, and a graph transformer capturing long-range quality interactions
across distant regions. Extensive experiments on two large-scale OIQA databases
with complex spatial distortions demonstrate that our method significantly
outperforms existing approaches, confirming its effectiveness and strong
generalization capability.

</details>


### [103] [Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance](https://arxiv.org/abs/2508.09847)
*Dhruvraj Singh Rawat,Enggen Sherpa,Rishikesan Kirupanantha,Tin Hoang*

Main category: cs.CV

TL;DR: 论文提出了一个小规模的CelebAMask-HQ数据集上的人脸生成扩散模型基准，比较了无条件生成和条件生成，并引入InfoNCE损失和SegFormer编码器提升语义对齐和可控性。


<details>
  <summary>Details</summary>
Motivation: 研究目标是评估扩散模型在小规模数据集上的人脸生成效果，尤其是通过改进条件生成的语义对齐和可控性。

Method: 使用UNet和DiT架构进行无条件生成实验，同时基于LoRA微调预训练Stable Diffusion模型；在多条件生成中，引入InfoNCE损失和SegFormer编码器。

Result: 实验结果表明，对比嵌入学习和高级分割编码器在有限数据环境下显著提升了可控人脸生成的效果。

Conclusion: 通过引入InfoNCE损失和SegFormer编码器，论文在语义对齐和可控性方面取得了显著改进，为小规模数据集上的可控人脸生成提供了有效方法。

Abstract: We present a benchmark of diffusion models for human face generation on a
small-scale CelebAMask-HQ dataset, evaluating both unconditional and
conditional pipelines. Our study compares UNet and DiT architectures for
unconditional generation and explores LoRA-based fine-tuning of pretrained
Stable Diffusion models as a separate experiment. Building on the
multi-conditioning approach of Giambi and Lisanti, which uses both attribute
vectors and segmentation masks, our main contribution is the integration of an
InfoNCE loss for attribute embedding and the adoption of a SegFormer-based
segmentation encoder. These enhancements improve the semantic alignment and
controllability of attribute-guided synthesis. Our results highlight the
effectiveness of contrastive embedding learning and advanced segmentation
encoding for controlled face generation in limited data settings.

</details>


### [104] [ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images](https://arxiv.org/abs/2508.09849)
*Jan Phillipp Albrecht,Jose R. A. Godinho,Christina Hübers,Deborah Schmidt*

Main category: cs.CV

TL;DR: ARI3D是一款软件工具，旨在通过交互式分析三维X射线CT图像，帮助用户更准确地分类和量化微结构。


<details>
  <summary>Details</summary>
Motivation: X射线CT在材料微结构分析中存在成像伪影（如束硬化和部分体积效应）的挑战，需要用户做出复杂决策。

Method: ARI3D通过设计协议步骤，辅助用户识别相、考虑部分体积效应，并提高量化准确性。

Result: 该工具提高了相识别能力、量化精度，并能应用于不同科学领域。

Conclusion: ARI3D为三维X射线CT图像的定量分析提供了高效且标准化的解决方案。

Abstract: X-ray computed tomography (CT) is the main 3D technique for imaging the
internal microstructures of materials. Quantitative analysis of the
microstructures is usually achieved by applying a sequence of steps that are
implemented to the entire 3D image. This is challenged by various imaging
artifacts inherent from the technique, e.g., beam hardening and partial volume.
Consequently, the analysis requires users to make a number of decisions to
segment and classify the microstructures based on the voxel gray-values. In
this context, a software tool, here called ARI3D, is proposed to interactively
analyze regions in three-dimensional X-ray CT images, assisting users through
the various steps of a protocol designed to classify and quantify objects
within regions of a three-dimensional image. ARI3D aims to 1) Improve phase
identification; 2) Account for partial volume effect; 3) Increase the detection
limit and accuracy of object quantification; and 4) Harmonize quantitative 3D
analysis that can be implemented in different fields of science.

</details>


### [105] [Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment](https://arxiv.org/abs/2508.09850)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Valero Laparra,Jesus Malo*

Main category: cs.CV

TL;DR: 论文研究了视觉Transformer（ViT）与人类感知的对齐性，发现模型越大对齐性越低，数据增强和正则化会进一步降低对齐性。


<details>
  <summary>Details</summary>
Motivation: 探索ViT在图像识别任务中与人类感知的对齐性，分析模型大小、数据集大小、数据增强和正则化的影响。

Method: 在TID2013数据集上系统分析ViT的感知对齐性，考察模型大小、数据集多样性、训练次数等因素。

Result: 大模型对齐性更低；数据增强和正则化会进一步降低对齐性，尤其在重复训练周期中。

Conclusion: 模型复杂性、训练策略与人类感知对齐性之间存在权衡，对需要类人视觉理解的应用有重要启示。

Abstract: Vision Transformers (ViTs) achieve remarkable performance in image
recognition tasks, yet their alignment with human perception remains largely
unexplored. This study systematically analyzes how model size, dataset size,
data augmentation and regularization impact ViT perceptual alignment with human
judgments on the TID2013 dataset. Our findings confirm that larger models
exhibit lower perceptual alignment, consistent with previous works. Increasing
dataset diversity has a minimal impact, but exposing models to the same images
more times reduces alignment. Stronger data augmentation and regularization
further decrease alignment, especially in models exposed to repeated training
cycles. These results highlight a trade-off between model complexity, training
strategies, and alignment with human perception, raising important
considerations for applications requiring human-like visual understanding.

</details>


### [106] [OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better](https://arxiv.org/abs/2508.09857)
*Yupeng Zhou,Zhen Li,Ziheng Ouyang,Yuming Chen,Ruoyi Du,Daquan Zhou,Bin Fu,Yihao Liu,Peng Gao,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: 提出了一种名为OneVAE的方法，通过结合连续和离散视频VAE的优势，显著提升了视频编码的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 视频编码为离散标记可以方便多模态LLM的整合，但传统离散视频VAE存在训练不稳定、时间长和重建质量差的问题。

Method: 利用连续VAE的先验知识改进离散VAE，设计了多标记量化机制和强化首帧重建，并提出联合优化方案。

Result: OneVAE训练速度显著提升，重建质量优于传统方法，并在连续和离散表示上均达到高性能。

Conclusion: OneVAE成功统一了连续和离散视频表示，为多模态LLM提供了更高效的编码方案。

Abstract: Encoding videos into discrete tokens could align with text tokens to
facilitate concise and unified multi-modal LLMs, yet introducing significant
spatiotemporal compression compared to continuous video representation.
Previous discrete video VAEs experienced unstable training, long training time,
and degraded reconstruction quality. Given the easier training and superior
performance of continuous VAEs, an intuitive idea is to enhance discrete video
VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between
discrete and continuous representations, we found that FSQ could effectively
preserve pre-trained continuous VAE priors compared to other quantization
methods. By leveraging continuous VAE priors, it converges several times faster
than training from scratch and achieves superior performance at convergence.
Meanwhile, two structural improvements are proposed. First, inspired by how
continuous VAEs enhance reconstruction via enlarged latent dimensions, we
introduce a multi-token quantization mechanism, which achieves nearly a 1 dB
improvement in PSNR without compromising the token compression ratio. Second,
to tackle reconstruction challenges in high-compression video VAEs, we
strengthen first-frame reconstruction, enabling the causal VAE to leverage this
information in subsequent frames and markedly improving the performance of 4 x
16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous
optimization scheme that unifies the two paradigms and, for the first time,
achieves competitive performance on both continuous and discrete
representations within a single network. We name our method OneVAE to reflect
this connection.

</details>


### [107] [HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics](https://arxiv.org/abs/2508.09858)
*Weiqi Li,Zehao Zhang,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: 提出了HumanGenesis框架，通过四个协作代理解决合成人类动态中的几何不一致和运动泛化问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前合成人类动态的方法面临几何不一致和运动泛化限制等问题，HumanGenesis旨在解决这些挑战。

Method: 使用包含Reconstructor、Critique Agent、Pose Guider和Video Harmonizer的协作代理框架，结合3D高斯溅射和变形分解等技术。

Result: 在文本引导合成、视频重演和新姿态泛化等任务中实现最先进性能，显著提升表现力、几何保真度和场景整合。

Conclusion: HumanGenesis有效解决了合成人类动态的核心问题，为相关领域提供了高效解决方案。

Abstract: \textbf{Synthetic human dynamics} aims to generate photorealistic videos of
human subjects performing expressive, intention-driven motions. However,
current approaches face two core challenges: (1) \emph{geometric inconsistency}
and \emph{coarse reconstruction}, due to limited 3D modeling and detail
preservation; and (2) \emph{motion generalization limitations} and \emph{scene
inharmonization}, stemming from weak generative capabilities. To address these,
we present \textbf{HumanGenesis}, a framework that integrates geometric and
generative modeling through four collaborative agents: (1)
\textbf{Reconstructor} builds 3D-consistent human-scene representations from
monocular video using 3D Gaussian Splatting and deformation decomposition. (2)
\textbf{Critique Agent} enhances reconstruction fidelity by identifying and
refining poor regions via multi-round MLLM-based reflection. (3) \textbf{Pose
Guider} enables motion generalization by generating expressive pose sequences
using time-aware parametric encoders. (4) \textbf{Video Harmonizer} synthesizes
photorealistic, coherent video via a hybrid rendering pipeline with diffusion,
refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis
achieves state-of-the-art performance on tasks including text-guided synthesis,
video reenactment, and novel-pose generalization, significantly improving
expressiveness, geometric fidelity, and scene integration.

</details>


### [108] [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)
*Trevine Oorloff,Vishwanath Sindagi,Wele Gedara Chaminda Bandara,Ali Shafahi,Amin Ghiasi,Charan Prakash,Reza Ardekani*

Main category: cs.CV

TL;DR: 论文探讨了如何利用现成的Stable Diffusion模型进行视觉上下文学习（V-ICL），无需额外训练即可适应多种视觉任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉上下文学习方法需要专门训练或额外数据，限制了通用性。作者希望通过改进Stable Diffusion模型，简化过程并提升性能。

Method: 通过在Stable Diffusion的自注意力层中重新计算注意力，显式结合查询和示例提示的上下文信息。

Result: 改进后的模型在六项任务中表现优异，例如在Pascal-5i数据集上的前景分割任务中，mIoU分别比Visual Prompting和IMProv提高了8.9%和3.2%。

Conclusion: 利用现成Stable Diffusion模型进行V-ICL是可行的，且通过集成多个提示可以进一步提升性能。

Abstract: Large language models (LLM) in natural language processing (NLP) have
demonstrated great potential for in-context learning (ICL) -- the ability to
leverage a few sets of example prompts to adapt to various tasks without having
to explicitly update the model weights. ICL has recently been explored for
computer vision tasks with promising early outcomes. These approaches involve
specialized training and/or additional data that complicate the process and
limit its generalizability. In this work, we show that off-the-shelf Stable
Diffusion models can be repurposed for visual in-context learning (V-ICL).
Specifically, we formulate an in-place attention re-computation within the
self-attention layers of the Stable Diffusion architecture that explicitly
incorporates context between the query and example prompts. Without any
additional fine-tuning, we show that this repurposed Stable Diffusion model is
able to adapt to six different tasks: foreground segmentation, single object
detection, semantic segmentation, keypoint detection, edge detection, and
colorization. For example, the proposed approach improves the mean intersection
over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by
8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,
respectively. Additionally, we show that the proposed method is able to
effectively leverage multiple prompts through ensembling to infer the task
better and further improve the performance.

</details>


### [109] [COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets](https://arxiv.org/abs/2508.09886)
*Lingyu Chen,Yawen Zeng,Yue Wang,Peng Wan,Guo-chen Ning,Hongen Liao,Daoqiang Zhang,Fang Chen*

Main category: cs.CV

TL;DR: 论文提出了一个名为COME的通用框架，用于解决超声波图像分析中多异构数据集训练的问题，通过结合共享专家和源特定专家的互补特征，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 由于超声波图像数据的局限性（如声影和斑点噪声），传统单数据集训练在新数据分布下表现不佳，需要构建一个通用框架来处理多异构数据集。

Method: 提出COME框架，通过双结构-语义共享专家构建通用表示空间，并与源特定专家协作提取区分性特征。

Result: 在三种评估模式下（单数据集、器官内和器官间集成数据集），COME性能优于现有方法，实现了显著的mAP提升。

Conclusion: COME通过结合共享专家和源特定专家，有效解决了多异构数据集训练的挑战，具有更好的泛化能力。

Abstract: Conventional single-dataset training often fails with new data distributions,
especially in ultrasound (US) image analysis due to limited data, acoustic
shadows, and speckle noise. Therefore, constructing a universal framework for
multi-heterogeneous US datasets is imperative. However, a key challenge arises:
how to effectively mitigate inter-dataset interference while preserving
dataset-specific discriminative features for robust downstream task? Previous
approaches utilize either a single source-specific decoder or a domain
adaptation strategy, but these methods experienced a decline in performance
when applied to other domains. Considering this, we propose a Universal
Collaborative Mixture of Heterogeneous Source-Specific Experts (COME).
Specifically, COME establishes dual structure-semantic shared experts that
create a universal representation space and then collaborate with
source-specific experts to extract discriminative features through providing
complementary features. This design enables robust generalization by leveraging
cross-datasets experience distributions and providing universal US priors for
small-batch or unseen data scenarios. Extensive experiments under three
evaluation modes (single-dataset, intra-organ, and inter-organ integration
datasets) demonstrate COME's superiority, achieving significant mean AP
improvements over state-of-the-art methods. Our project is available at:
https://universalcome.github.io/UniversalCOME/.

</details>


### [110] [Story2Board: A Training-Free Approach for Expressive Storyboard Generation](https://arxiv.org/abs/2508.09983)
*David Dinkevich,Matan Levy,Omri Avrahami,Dvir Samuel,Dani Lischinski*

Main category: cs.CV

TL;DR: Story2Board是一个无需训练的框架，用于从自然语言生成富有表现力的故事板。现有方法过于关注主体身份，而忽略了空间构图、背景演变和叙述节奏等关键视觉叙事元素。通过轻量级一致性框架和两项组件，实现了无需架构调整或微调的多样性一致故事板生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成故事板时忽视了视觉叙事的多维需求，如空间构图和背景演变。Story2Board旨在填补这一空白，提供更动态且一致的视觉叙事工具。

Method: 框架包含两项组件：潜在面板锚定（保持角色一致性）和互相关注值混合（软性融合视觉特征）。结合现成语言模型，将自由故事转换为面板级提示。

Result: 在Rich Storyboard Benchmark上的定性和定量评估表明，Story2Board生成的故事板在一致性、多样性和叙事性上优于现有基线。

Conclusion: Story2Board通过轻量级框架和新技术，实现了更高质量的故事板生成，在视觉叙事中表现出色，为未来研究提供了新方向。

Abstract: We present Story2Board, a training-free framework for expressive storyboard
generation from natural language. Existing methods narrowly focus on subject
identity, overlooking key aspects of visual storytelling such as spatial
composition, background evolution, and narrative pacing. To address this, we
introduce a lightweight consistency framework composed of two components:
Latent Panel Anchoring, which preserves a shared character reference across
panels, and Reciprocal Attention Value Mixing, which softly blends visual
features between token pairs with strong reciprocal attention. Together, these
mechanisms enhance coherence without architectural changes or fine-tuning,
enabling state-of-the-art diffusion models to generate visually diverse yet
consistent storyboards. To structure generation, we use an off-the-shelf
language model to convert free-form stories into grounded panel-level prompts.
To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain
narratives designed to assess layout diversity and background-grounded
storytelling, in addition to consistency. We also introduce a new Scene
Diversity metric that quantifies spatial and pose variation across storyboards.
Our qualitative and quantitative results, as well as a user study, show that
Story2Board produces more dynamic, coherent, and narratively engaging
storyboards than existing baselines.

</details>


### [111] [E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras](https://arxiv.org/abs/2508.09912)
*Chaoran Feng,Zhenyu Tang,Wangbo Yu,Yatian Pang,Yian Zhao,Jianbin Zhao,Li Yuan,Yonghong Tian*

Main category: cs.CV

TL;DR: 本文提出了一种基于事件相机的动态高斯泼溅方法E-4DGS，用于快速运动相机下的多视角事件流新视角合成，解决了传统RGB相机在高速运动和低光场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在高速运动和低光场景中表现不佳，事件相机因其高性能特点为这些场景提供了新的解决方案。

Method: 提出了基于事件的初始化方案、事件自适应切片泼溅技术、强度重要性剪枝和自适应对比度阈值优化。

Result: E-4DGS在合成数据上优于仅使用事件或事件-RGB融合的基线方法。

Conclusion: E-4DGS为多视角事件流重建提供了一种新方法，推动了快速场景捕获的探索。

Abstract: Novel view synthesis and 4D reconstruction techniques predominantly rely on
RGB cameras, thereby inheriting inherent limitations such as the dependence on
adequate lighting, susceptibility to motion blur, and a limited dynamic range.
Event cameras, offering advantages of low power, high temporal resolution and
high dynamic range, have brought a new perspective to addressing the scene
reconstruction challenges in high-speed motion and low-light scenes. To this
end, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting
approach, for novel view synthesis from multi-view event streams with
fast-moving cameras. Specifically, we introduce an event-based initialization
scheme to ensure stable training and propose event-adaptive slicing splatting
for time-aware reconstruction. Additionally, we employ intensity importance
pruning to eliminate floating artifacts and enhance 3D consistency, while
incorporating an adaptive contrast threshold for more precise optimization. We
design a synthetic multi-view camera setup with six moving event cameras
surrounding the object in a 360-degree configuration and provide a benchmark
multi-view event stream dataset that captures challenging motion scenarios. Our
approach outperforms both event-only and event-RGB fusion baselines and paves
the way for the exploration of multi-view event-based reconstruction as a novel
approach for rapid scene capture.

</details>


### [112] [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://arxiv.org/abs/2508.09913)
*Yachao Liang,Min Yu,Gang Li,Jianguo Jiang,Boquan Li,Feng Yu,Ning Zhang,Xiang Meng,Weiqing Huang*

Main category: cs.CV

TL;DR: 提出一种利用音频视觉语音表示学习的方法，通过自监督掩码预测任务学习真实视频的语音表征，直接迁移至伪造检测任务，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 音频信号能精确反映面部运动，有助于解决视频伪造检测的泛化和鲁棒性问题。

Method: 通过自监督掩码预测任务学习真实视频的音频视觉语音表示，直接迁移至伪造检测任务。

Result: 在跨数据集泛化和鲁棒性上优于现有方法，无需训练中使用伪造视频。

Conclusion: 音频视觉语音表示学习方法有效提升了伪造检测的泛化和鲁棒性。

Abstract: Detection of face forgery videos remains a formidable challenge in the field
of digital forensics, especially the generalization to unseen datasets and
common perturbations. In this paper, we tackle this issue by leveraging the
synergy between audio and visual speech elements, embarking on a novel approach
through audio-visual speech representation learning. Our work is motivated by
the finding that audio signals, enriched with speech content, can provide
precise information effectively reflecting facial movements. To this end, we
first learn precise audio-visual speech representations on real videos via a
self-supervised masked prediction task, which encodes both local and global
semantic information simultaneously. Then, the derived model is directly
transferred to the forgery detection task. Extensive experiments demonstrate
that our method outperforms the state-of-the-art methods in terms of
cross-dataset generalization and robustness, without the participation of any
fake video in model training. Code is available at
https://github.com/Eleven4AI/SpeechForensics.

</details>


### [113] [Towards Comprehensive Cellular Characterisation of H&E slides](https://arxiv.org/abs/2508.09926)
*Benjamin Adjadj,Pierre-Antoine Bannier,Guillaume Horent,Sebastien Mandela,Aurore Lyon,Kathryn Schutte,Ulysse Marteau,Valentin Gaury,Laura Dumont,Thomas Mathieu,Reda Belbahri,Benoît Schmauch,Eric Durand,Katharina Von Loga,Lucie Gillet*

Main category: cs.CV

TL;DR: HistoPLUS是一种先进的细胞分析模型，针对肿瘤微环境中的细胞检测、分割和分类问题，解决了现有方法在罕见细胞类型和跨领域泛化上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的细胞分析方法在罕见细胞类型和跨领域泛化上表现不佳，限制了肿瘤微环境研究的深入。

Method: 提出HistoPLUS模型，基于一个新颖的泛癌数据集（108,722个核，13种细胞类型）进行训练。

Result: 在外部验证中，HistoPLUS在检测质量和分类F1分数上分别优于现有最佳模型5.2%和23.7%，参数减少了5倍，并能研究7种罕见细胞类型。

Conclusion: HistoPLUS显著提升了细胞分析的性能，支持更广泛的肿瘤微环境生物标志物研究，并公开了模型权重和推理代码。

Abstract: Cell detection, segmentation and classification are essential for analyzing
tumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing
methods suffer from poor performance on understudied cell types (rare or not
present in public datasets) and limited cross-domain generalization. To address
these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell
analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei
covering 13 cell types. In external validation across 4 independent cohorts,
HistoPLUS outperforms current state-of-the-art models in detection quality by
5.2% and overall F1 classification score by 23.7%, while using 5x fewer
parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types
and brings significant improvements on 8 of 13 cell types. Moreover, we show
that HistoPLUS robustly transfers to two oncology indications unseen during
training. To support broader TME biomarker research, we release the model
weights and inference code at https://github.com/owkin/histoplus/.

</details>


### [114] [Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?](https://arxiv.org/abs/2508.09936)
*Vittorio Pippi,Konstantina Nikolaidou,Silvia Cascianelli,George Retsinas,Giorgos Sfikas,Rita Cucchiara,Marcus Liwicki*

Main category: cs.CV

TL;DR: 论文研究了手写文本生成（HTG）模型在低资源手写文本识别（HTR）中的应用，比较了三种先进模型的效果。


<details>
  <summary>Details</summary>
Motivation: 解决历史手稿数字化中HTR系统因训练数据分布不同而面临的挑战。

Method: 系统比较了三种HTG模型（生成对抗、扩散和自回归范式），分析合成数据对HTR微调的影响。

Result: 提供了选择最有效HTG模型的量化指南，并指出了HTG方法的当前能力。

Conclusion: 为HTG在低资源HTR中的应用指明了改进方向。

Abstract: The digitization of historical manuscripts presents significant challenges
for Handwritten Text Recognition (HTR) systems, particularly when dealing with
small, author-specific collections that diverge from the training data
distributions. Handwritten Text Generation (HTG) techniques, which generate
synthetic data tailored to specific handwriting styles, offer a promising
solution to address these challenges. However, the effectiveness of various HTG
models in enhancing HTR performance, especially in low-resource transcription
settings, has not been thoroughly evaluated. In this work, we systematically
compare three state-of-the-art styled HTG models (representing the generative
adversarial, diffusion, and autoregressive paradigms for HTG) to assess their
impact on HTR fine-tuning. We analyze how visual and linguistic characteristics
of synthetic data influence fine-tuning outcomes and provide quantitative
guidelines for selecting the most effective HTG model. The results of our
analysis provide insights into the current capabilities of HTG methods and
highlight key areas for further improvement in their application to
low-resource HTR.

</details>


### [115] [AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models](https://arxiv.org/abs/2508.09943)
*Tomás de la Sotta,José M. Saavedra,Héctor Henríquez,Violeta Chang,Aline Xavier*

Main category: cs.CV

TL;DR: AST-n 框架通过从中间噪声水平启动反向扩散并整合高阶 ODE 求解器，显著加快了 LDCT 去噪的推理速度，同时在 25 步内达到与标准基线相当的图像质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决低剂量 CT（LDCT）成像中因降噪需求导致的推理时间长的问题，研究提出了加速推理框架 AST-n，旨在在保证图像质量的同时显著减少推理时间。

Method: AST-n 框架通过从中间噪声水平启动反向扩散，并整合高阶 ODE 求解器来减少采样步骤，同时在条件化模型中使用高阶求解器进一步优化。

Result: 实验表明，AST-n 在 25 步内实现了 PSNR 高于 38 dB 和 SSIM 高于 0.95，推理时间从 16 秒降至不到 1 秒每切片。无条件采样质量显著下降，而 DDIM 逆虽然提升了 PSNR，但耗时加倍。

Conclusion: AST-n 结合高阶求解器能够在极短时间内完成 LDCT 重建，且不显著损失图像质量，为临床工作流程中的扩散模型应用提供了可行性。

Abstract: Low-dose CT (LDCT) protocols reduce radiation exposure but increase image
noise, compromising diagnostic confidence. Diffusion-based generative models
have shown promise for LDCT denoising by learning image priors and performing
iterative refinement. In this work, we introduce AST-n, an accelerated
inference framework that initiates reverse diffusion from intermediate noise
levels, and integrate high-order ODE solvers within conditioned models to
further reduce sampling steps. We evaluate two acceleration paradigms--AST-n
sampling and standard scheduling with high-order solvers -- on the Low Dose CT
Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %
of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak
signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)
above 0.95, closely matching standard baselines while cutting inference time
from ~16 seg to under 1 seg per slice. Unconditional sampling suffers
substantial quality loss, underscoring the necessity of conditioning. We also
assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling
inference time, limiting its clinical practicality. Our results demonstrate
that AST-n with high-order samplers enables rapid LDCT reconstruction without
significant loss of image fidelity, advancing the feasibility of
diffusion-based methods in clinical workflows.

</details>


### [116] [LIA-X: Interpretable Latent Portrait Animator](https://arxiv.org/abs/2508.09959)
*Yaohui Wang,Di Yang,Xinyuan Chen,Francois Bremond,Yu Qiao,Antitza Dantcheva*

Main category: cs.CV

TL;DR: LIA-X是一种新颖的可解释肖像动画工具，通过稀疏运动词典实现面部动态的精细控制，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 目标是开发一种可解释的面部动态转移方法，支持精细控制和实际应用。

Method: 采用基于自编码器的线性运动编码导航，结合稀疏运动词典分解面部动态。

Result: 在自我重演和交叉重演任务中表现优异，支持用户引导的精细编辑。

Conclusion: LIA-X为肖像动画提供了可解释且高效的解决方案，具有广泛的应用潜力。

Abstract: We introduce LIA-X, a novel interpretable portrait animator designed to
transfer facial dynamics from a driving video to a source portrait with
fine-grained control. LIA-X is an autoencoder that models motion transfer as a
linear navigation of motion codes in latent space. Crucially, it incorporates a
novel Sparse Motion Dictionary that enables the model to disentangle facial
dynamics into interpretable factors. Deviating from previous 'warp-render'
approaches, the interpretability of the Sparse Motion Dictionary allows LIA-X
to support a highly controllable 'edit-warp-render' strategy, enabling precise
manipulation of fine-grained facial semantics in the source portrait. This
helps to narrow initial differences with the driving video in terms of pose and
expression. Moreover, we demonstrate the scalability of LIA-X by successfully
training a large-scale model with approximately 1 billion parameters on
extensive datasets. Experimental results show that our proposed method
outperforms previous approaches in both self-reenactment and cross-reenactment
tasks across several benchmarks. Additionally, the interpretable and
controllable nature of LIA-X supports practical applications such as
fine-grained, user-guided image and video editing, as well as 3D-aware portrait
video manipulation.

</details>


### [117] [January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis](https://arxiv.org/abs/2508.09966)
*Amir Hosseinian,Ashkan Dehghani Zahedani,Umer Mansoor,Noosheen Hashemi,Mark Woodward*

Main category: cs.CV

TL;DR: 论文提出了January Food Benchmark（JFB）数据集、全面的评测框架及专用模型，显著提升了自动营养分析的性能。


<details>
  <summary>Details</summary>
Motivation: 解决AI在营养分析中缺乏标准化评测方法和高质量数据集的问题。

Method: 引入JFB数据集（1000张图像）、评测框架（包含新提出的综合评分）及专用模型january/food-vision-v1。

Result: 专用模型综合评分为86.2，比通用模型高12.1分。

Conclusion: 为研究领域提供了新数据集和评测框架，推动自动营养分析的发展。

Abstract: Progress in AI for automated nutritional analysis is critically hampered by
the lack of standardized evaluation methodologies and high-quality, real-world
benchmark datasets. To address this, we introduce three primary contributions.
First, we present the January Food Benchmark (JFB), a publicly available
collection of 1,000 food images with human-validated annotations. Second, we
detail a comprehensive benchmarking framework, including robust metrics and a
novel, application-oriented overall score designed to assess model performance
holistically. Third, we provide baseline results from both general-purpose
Vision-Language Models (VLMs) and our own specialized model,
january/food-vision-v1. Our evaluation demonstrates that the specialized model
achieves an Overall Score of 86.2, a 12.1-point improvement over the
best-performing general-purpose configuration. This work offers the research
community a valuable new evaluation dataset and a rigorous framework to guide
and benchmark future developments in automated nutritional analysis.

</details>


### [118] [MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification](https://arxiv.org/abs/2508.09967)
*Tianqi Xiang,Yi Li,Qixiang Zhang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 本文提出了一种元优化分类器（MOC），通过结合元学习和多样化的分类器库，显著提升了在数据稀缺条件下的全切片图像（WSI）分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言基础模型（VLFM）在全切片图像分类中仍逊色于传统多实例学习（MIL）方法，且数据稀缺问题限制了现有少样本学习方法的性能。

Method: MOC包含一个元学习器和一个分类器库，前者优化分类器配置，后者提供多样化的候选分类器。

Result: 在多个少样本基准测试中，MOC表现优于现有技术，尤其在TCGA-NSCLC基准上将AUC提高了10.4%，在1-shot条件下提升达26.25%。

Conclusion: MOC为临床部署中的诊断数据稀缺问题提供了重要解决方案。

Abstract: Recent advances in histopathology vision-language foundation models (VLFMs)
have shown promise in addressing data scarcity for whole slide image (WSI)
classification via zero-shot adaptation. However, these methods remain
outperformed by conventional multiple instance learning (MIL) approaches
trained on large datasets, motivating recent efforts to enhance VLFM-based WSI
classification through fewshot learning paradigms. While existing few-shot
methods improve diagnostic accuracy with limited annotations, their reliance on
conventional classifier designs introduces critical vulnerabilities to data
scarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC)
comprising two core components: (1) a meta-learner that automatically optimizes
a classifier configuration from a mixture of candidate classifiers and (2) a
classifier bank housing diverse candidate classifiers to enable a holistic
pathological interpretation. Extensive experiments demonstrate that MOC
outperforms prior arts in multiple few-shot benchmarks. Notably, on the
TCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art
few-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions,
offering a critical advancement for clinical deployments where diagnostic
training data is severely limited. Code is available at
https://github.com/xmed-lab/MOC.

</details>


### [119] [PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image](https://arxiv.org/abs/2508.09973)
*Geonhee Sim,Gyeongsik Moon*

Main category: cs.CV

TL;DR: PERSONA结合3D和扩散模型方法，从单张图像生成具备姿态驱动变形的3D个性化人体化身，通过平衡采样和几何加权优化确保高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 现有3D方法需要大量姿态丰富视频，而扩散方法难以保持身份一致。PERSONA旨在结合两者优势。

Method: 利用扩散模型从输入图像生成姿态丰富视频，并基于其优化3D化身。引入平衡采样和几何加权优化以提升渲染质量。

Result: 实现从单张图像生成具备多样化姿态的3D个性化化身，身份保持和渲染质量均得到提升。

Conclusion: PERSONA为低成本、高效生成高质量3D人体化身提供了可行方案。

Abstract: Two major approaches exist for creating animatable human avatars. The first,
a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a
single person, achieving personalization through a disentangled identity
representation. However, modeling pose-driven deformations, such as non-rigid
cloth deformations, requires numerous pose-rich videos, which are costly and
impractical to capture in daily life. The second, a diffusion-based approach,
learns pose-driven deformations from large-scale in-the-wild videos but
struggles with identity preservation and pose-dependent identity entanglement.
We present PERSONA, a framework that combines the strengths of both approaches
to obtain a personalized 3D human avatar with pose-driven deformations from a
single image. PERSONA leverages a diffusion-based approach to generate
pose-rich videos from the input image and optimizes a 3D avatar based on them.
To ensure high authenticity and sharp renderings across diverse poses, we
introduce balanced sampling and geometry-weighted optimization. Balanced
sampling oversamples the input image to mitigate identity shifts in
diffusion-generated training videos. Geometry-weighted optimization prioritizes
geometry constraints over image loss, preserving rendering quality in diverse
poses.

</details>


### [120] [A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation](https://arxiv.org/abs/2508.09977)
*Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding*

Main category: cs.CV

TL;DR: 3D高斯分布（3DGS）作为NeRF的替代方案，提供了高质量实时渲染，并支持多种下游应用。本文综述了3DGS在语义理解、分割、编辑和生成等方面的应用进展。


<details>
  <summary>Details</summary>
Motivation: 探索3DGS在几何和语义理解方面的潜力，并为相关研究提供资源支持。

Method: 分类总结了3DGS应用的代表性方法、监督策略和学习范式。

Result: 3DGS在分割、编辑、生成等任务中表现优异，且有多样化的数据集和评估协议。

Conclusion: 3DGS展示了强大的应用潜力，未来研究可通过公开资源进一步推动发展。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative
to Neural Radiance Fields (NeRF) for 3D scene representation, offering
high-fidelity photorealistic rendering with real-time performance. Beyond novel
view synthesis, the explicit and compact nature of 3DGS enables a wide range of
downstream applications that require geometric and semantic understanding. This
survey provides a comprehensive overview of recent progress in 3DGS
applications. It first introduces 2D foundation models that support semantic
understanding and control in 3DGS applications, followed by a review of
NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS
applications into segmentation, editing, generation, and other functional
tasks. For each, we summarize representative methods, supervision strategies,
and learning paradigms, highlighting shared design principles and emerging
trends. Commonly used datasets and evaluation protocols are also summarized,
along with comparative analyses of recent methods across public benchmarks. To
support ongoing research and development, a continually updated repository of
papers, code, and resources is maintained at
https://github.com/heshuting555/Awesome-3DGS-Applications.

</details>


### [121] [LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit](https://arxiv.org/abs/2508.09981)
*Chengtao Lv,Bilang Zhang,Yang Yong,Ruihao Gong,Yushi Huang,Shiqiao Gu,Jiajun Wu,Yumeng Shi,Jinyang Guo,Wenya Wang*

Main category: cs.CV

TL;DR: LLMC+是一个全面的VLM压缩基准测试工具包，支持20多种算法，揭示了空间和时间冗余需要不同策略，以及组合压缩方法的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前VLM压缩方法存在模块不可比、评估局限和孤立使用技术的问题，需系统性解决方案。

Method: 提出LLMC+工具包，支持多种算法，并研究token级和模型级压缩的组合效果。

Result: 发现空间与时间冗余需不同策略，token减少方法在多任务中表现差，组合压缩可实现高效压缩。

Conclusion: LLMC+为VLM压缩提供了公平评估平台，并启发未来高效VLM研究。

Abstract: Large Vision-Language Models (VLMs) exhibit impressive multi-modal
capabilities but suffer from prohibitive computational and memory demands, due
to their long visual token sequences and massive parameter sizes. To address
these issues, recent works have proposed training-free compression methods.
However, existing efforts often suffer from three major limitations: (1)
Current approaches do not decompose techniques into comparable modules,
hindering fair evaluation across spatial and temporal redundancy. (2)
Evaluation confined to simple single-turn tasks, failing to reflect performance
in realistic scenarios. (3) Isolated use of individual compression techniques,
without exploring their joint potential. To overcome these gaps, we introduce
LLMC+, a comprehensive VLM compression benchmark with a versatile,
plug-and-play toolkit. LLMC+ supports over 20 algorithms across five
representative VLM families and enables systematic study of token-level and
model-level compression. Our benchmark reveals that: (1) Spatial and temporal
redundancies demand distinct technical strategies. (2) Token reduction methods
degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3)
Combining token and model compression achieves extreme compression with minimal
performance loss. We believe LLMC+ will facilitate fair evaluation and inspire
future research in efficient VLM. Our code is available at
https://github.com/ModelTC/LightCompress.

</details>


### [122] [Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation](https://arxiv.org/abs/2508.09987)
*Junyan Ye,Dongzhi Jiang,Zihao Wang,Leqi Zhu,Zhenghao Hu,Zilong Huang,Jun He,Zhiyuan Yan,Jinghua Yu,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 论文探讨了GPT-4o生成的合成图像数据的两大优势，提出Echo-4o-Image数据集，并通过新评测基准展示其性能提升和迁移性。


<details>
  <summary>Details</summary>
Motivation: 开源模型在图像生成领域落后于GPT-4o，且真实世界图像数据存在噪声和对齐问题，合成数据能弥补这些不足。

Method: 从GPT-4o提取图像数据构建Echo-4o-Image数据集，并用于微调基线模型Bagel；同时提出新评测基准GenEval++和Imagine-Bench。

Result: Echo-4o在标准评测中表现优异，且合成数据对其他基础模型也带来性能提升。

Conclusion: 合成数据能补充真实数据的盲点，提升模型性能，且具有广泛迁移性。

Abstract: Recently, GPT-4o has garnered significant attention for its strong
performance in image generation, yet open-source models still lag behind.
Several studies have explored distilling image data from GPT-4o to enhance
open-source models, achieving notable progress. However, a key question
remains: given that real-world image datasets already constitute a natural
source of high-quality data, why should we use GPT-4o-generated synthetic data?
In this work, we identify two key advantages of synthetic images. First, they
can complement rare scenarios in real-world datasets, such as surreal fantasy
or multi-reference image generation, which frequently occur in user queries.
Second, they provide clean and controllable supervision. Real-world data often
contains complex background noise and inherent misalignment between text
descriptions and image content, whereas synthetic images offer pure backgrounds
and long-tailed supervision signals, facilitating more accurate text-to-image
alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale
synthetic dataset generated by GPT-4o, harnessing the power of synthetic image
data to address blind spots in real-world coverage. Using this dataset, we
fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.
In addition, we propose two new evaluation benchmarks for a more accurate and
challenging assessment of image generation capabilities: GenEval++, which
increases instruction complexity to mitigate score saturation, and
Imagine-Bench, which focuses on evaluating both the understanding and
generation of imaginative content. Echo-4o demonstrates strong performance
across standard benchmarks. Moreover, applying Echo-4o-Image to other
foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains
across multiple metrics, highlighting the datasets strong transferability.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [123] [PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research](https://arxiv.org/abs/2508.09232)
*Nick Oh,Giorgos D. Vrakas,Siân J. M. Brooke,Sasha Morinière,Toju Duke*

Main category: cs.MM

TL;DR: PETLP（隐私设计提取、转换、加载和展示）框架帮助AI研究人员在社交媒体数据研究中整合GDPR、版权法和平台条款的合规要求。


<details>
  <summary>Details</summary>
Motivation: 现有框架未能整合不同法规领域，导致研究人员缺乏统一指导，社交媒体数据的法律合规性成为挑战。

Method: 引入PETLP框架，将数据保护影响评估（DPIA）作为动态文档嵌入ETL流程，通过系统分析Reddit数据探讨不同机构的提取权利差异。

Result: 发现研究机构可引用DSM第3条绕过平台限制，而商业实体受服务条款约束，GDPR义务普遍适用；真实匿名化不可行，数据集创建与模型分发存在法律空白。

Conclusion: PETLP通过结构化合规决策和简化数据管理计划，弥合法律要求与研究实践的差距，帮助研究人员应对法规复杂性。

Abstract: Social media data presents AI researchers with overlapping obligations under
the GDPR, copyright law, and platform terms -- yet existing frameworks fail to
integrate these regulatory domains, leaving researchers without unified
guidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and
Present), a compliance framework that embeds legal safeguards directly into
extended ETL pipelines. Central to PETLP is treating Data Protection Impact
Assessments as living documents that evolve from pre-registration through
dissemination. Through systematic Reddit analysis, we demonstrate how
extraction rights fundamentally differ between qualifying research
organisations (who can invoke DSM Article 3 to override platform restrictions)
and commercial entities (bound by terms of service), whilst GDPR obligations
apply universally. We reveal why true anonymisation remains unachievable for
social media data and expose the legal gap between permitted dataset creation
and uncertain model distribution. By structuring compliance decisions into
practical workflows and simplifying institutional data management plans, PETLP
enables researchers to navigate regulatory complexity with confidence, bridging
the gap between legal requirements and research practice.

</details>


### [124] [AI Blob! LLM-Driven Recontextualization of Italian Television Archives](https://arxiv.org/abs/2508.09535)
*Roberto Balestri*

Main category: cs.MM

TL;DR: AI Blob! 是一个实验性系统，利用语义编目和大型语言模型（LLM）探索电视档案素材的检索与再语境化，通过自动语音识别、语义嵌入等技术生成叙事蒙太奇。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索语义技术在档案研究中的潜力，提供自动化叙事构建和文化分析的新方法。

Method: 系统结合自动语音识别（ASR）、语义嵌入和检索增强生成（RAG），将电视片段转录、分段并嵌入向量数据库，根据用户主题提示生成相关查询并重组片段。

Result: AI Blob! 成功生成了具有讽刺性并置和主题连贯性的叙事序列，展示了动态检索优于静态元数据模式的优势。

Conclusion: 项目为媒体史学与AI驱动的档案研究提供了新思路，并公开数据集以支持跨学科实验。

Abstract: This paper introduces AI Blob!, an experimental system designed to explore
the potential of semantic cataloging and Large Language Models (LLMs) for the
retrieval and recontextualization of archival television footage. Drawing
methodological inspiration from Italian television programs such as Blob (RAI
Tre, 1989-), AI Blob! integrates automatic speech recognition (ASR), semantic
embeddings, and retrieval-augmented generation (RAG) to organize and
reinterpret archival content. The system processes a curated dataset of 1,547
Italian television videos by transcribing audio, segmenting it into
sentence-level units, and embedding these segments into a vector database for
semantic querying. Upon user input of a thematic prompt, the LLM generates a
range of linguistically and conceptually related queries, guiding the retrieval
and recombination of audiovisual fragments. These fragments are algorithmically
selected and structured into narrative sequences producing montages that
emulate editorial practices of ironic juxtaposition and thematic coherence. By
foregrounding dynamic, content-aware retrieval over static metadata schemas, AI
Blob! demonstrates how semantic technologies can facilitate new approaches to
archival engagement, enabling novel forms of automated narrative construction
and cultural analysis. The project contributes to ongoing debates in media
historiography and AI-driven archival research, offering both a conceptual
framework and a publicly available dataset to support further interdisciplinary
experimentation.

</details>


### [125] [In-place Double Stimulus Methodology for Subjective Assessment of High Quality Images](https://arxiv.org/abs/2508.09777)
*Shima Mohammadi,Mohsen Jenadeleh,Michela Testolina,Jon Sneyers,Touradj Ebrahimi,Dietmar Saupe,João Ascenso*

Main category: cs.MM

TL;DR: 该论文提出了一种新颖的双刺激主观评估方法（IDSQS），用于高质量图像的评估，解决了现有协议在检测细微感知差异上的局限性。通过大规模众包研究生成数据集，并利用Beta分布建模质量分数。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像质量评估协议在检测高或视觉无损质量级别下细微差异的不足。

Method: 采用原位双刺激质量量表（IDSQS），让受试者在同一空间位置交替观看参考图像和失真图像，便于更直观地检测质量差异。

Result: IDSQS方法在实现高相关性方面表现出色，生成了全面的公共数据集。

Conclusion: IDSQS方法能有效提升主观评估的准确性，相关数据集和工具已公开。

Abstract: This paper introduces a novel double stimulus subjective assessment
methodology for the evaluation of high quality images to address the
limitations of existing protocols in detecting subtle perceptual differences.
The In-place Double Stimulus Quality Scale (IDSQS) allows subjects to
alternately view a reference and a distorted image at the same spatial
location, facilitating a more intuitive detection of differences in quality,
especially at high to visually lossless quality levels. A large-scale
crowdsourcing study employing this methodology was conducted, generating a
comprehensive public dataset to evaluate perceived image quality across several
compression algorithms and distortion levels. An additional contribution is the
modeling of quality scores using a Beta distribution, allowing for the
assessment of variability and subject consistency. Our findings demonstrate the
effectiveness of the IDSQS methodology in achieving high correlation with more
precise subjective evaluation benchmarks. The dataset, subjective data, and
graphical user interface developed for this study are publicly available at
https://github.com/shimamohammadi/IDSQS

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [126] [Efficient Real-Time Aircraft ETA Prediction via Feature Tokenization Transformer](https://arxiv.org/abs/2508.09144)
*Liping Huang,Yicheng Zhang,Yifang Yin,Sheng Zhang,Yi Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的航班预计到达时间（ETA）实时预测方法，通过特征标记化和多头部自注意力机制提升效率和准确性，并在新加坡樟宜机场的实验中验证优于传统XGBoost模型。


<details>
  <summary>Details</summary>
Motivation: 在航空管理中，实时准确预测航班ETA对于跑道排序至关重要。现有方法需权衡效率与精度，而本研究旨在通过Transformer模型兼顾两者。

Method: 利用特征标记化将原始输入映射到潜在空间，并采用Transformer的多头部自注意力机制捕获关键特征，避免复杂特征工程。模型支持高频（1Hz）并行计算。

Result: 实验表明，该方法比XGBoost提升7%的精度，计算时间仅需39%，且在40架飞机同时预测时耗时仅51.7微秒。

Conclusion: 提出的Transformer模型适合实时航班ETA预测，在高精度与高效性上表现优异，适用于实时到达管理系统。

Abstract: Estimated time of arrival (ETA) for airborne aircraft in real-time is crucial
for arrival management in aviation, particularly for runway sequencing. Given
the rapidly changing airspace context, the ETA prediction efficiency is as
important as its accuracy in a real-time arrival aircraft management system. In
this study, we utilize a feature tokenization-based Transformer model to
efficiently predict aircraft ETA. Feature tokenization projects raw inputs to
latent spaces, while the multi-head self-attention mechanism in the Transformer
captures important aspects of the projections, alleviating the need for complex
feature engineering. Moreover, the Transformer's parallel computation
capability allows it to handle ETA requests at a high frequency, i.e., 1HZ,
which is essential for a real-time arrival management system. The model inputs
include raw data, such as aircraft latitude, longitude, ground speed, theta
degree for the airport, day and hour from track data, the weather context, and
aircraft wake turbulence category. With a data sampling rate of 1HZ, the ETA
prediction is updated every second. We apply the proposed aircraft ETA
prediction approach to Singapore Changi Airport (ICAO Code: WSSS) using
one-month Automatic Dependent Surveillance-Broadcast (ADS-B) data from October
1 to October 31, 2022. In the experimental evaluation, the ETA modeling covers
all aircraft within a range of 10NM to 300NM from WSSS. The results show that
our proposed method method outperforms the commonly used boosting tree based
model, improving accuracy by 7\% compared to XGBoost, while requiring only 39\%
of its computing time. Experimental results also indicate that, with 40
aircraft in the airspace at a given timestamp, the ETA inference time is only
51.7 microseconds, making it promising for real-time arrival management
systems.

</details>


### [127] [MoLAN: A Unified Modality-Aware Noise Dynamic Editing Framework for Multimodal Sentiment Analysis](https://arxiv.org/abs/2508.09145)
*Xingle Xu,Yongkang Liu,Dexian Cai,Shi Feng,Xiaocui Yang,Daling Wang,Yifei Zhang*

Main category: cs.LG

TL;DR: MoLAN 框架通过模态感知的动态噪声编辑，实现对多模态情感分析中噪声的细粒度抑制，保留关键信息。


<details>
  <summary>Details</summary>
Motivation: 解决多模态情感分析中视觉和听觉信息可能带来的无关或误导性噪声的问题。

Method: 提出 MoLAN 框架，将每个模态的特征划分为多个块，并根据噪声水平和语义相关性动态分配去噪强度。

Result: MoLAN+ 在五种模型和四个数据集上表现优异，达到最先进水平。

Conclusion: MoLAN 是一种灵活且有效的框架，可广泛应用于多模态模型中的噪声处理。

Abstract: Multimodal Sentiment Analysis aims to integrate information from various
modalities, such as audio, visual, and text, to make complementary predictions.
However, it often struggles with irrelevant or misleading visual and auditory
information. Most existing approaches typically treat the entire modality
information (e.g., a whole image, audio segment, or text paragraph) as an
independent unit for feature enhancement or denoising. They often suppress the
redundant and noise information at the risk of losing critical information. To
address this challenge, we propose MoLAN, a unified ModaLity-aware noise
dynAmic editiNg framework. Specifically, MoLAN performs modality-aware blocking
by dividing the features of each modality into multiple blocks. Each block is
then dynamically assigned a distinct denoising strength based on its noise
level and semantic relevance, enabling fine-grained noise suppression while
preserving essential multimodal information. Notably, MoLAN is a unified and
flexible framework that can be seamlessly integrated into a wide range of
multimodal models. Building upon this framework, we further introduce MoLAN+, a
new multimodal sentiment analysis approach. Experiments across five models and
four datasets demonstrate the broad effectiveness of the MoLAN framework.
Extensive evaluations show that MoLAN+ achieves the state-of-the-art
performance. The code is publicly available at
https://github.com/betterfly123/MoLAN-Framework.

</details>


### [128] [To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA](https://arxiv.org/abs/2508.09146)
*Shugang Hao,Hongbo Li,Lingjie Duan*

Main category: cs.LG

TL;DR: 论文提出了一种基于LLM transformer的上下文学习（ICL）理论，用于优化WiFi 7中的信道访问性能，避免了传统方法在动态环境下因节点密度估计不准确导致的吞吐量损失。


<details>
  <summary>Details</summary>
Motivation: 传统的二进制指数退避方案在动态信道环境下性能较差，而现有基于模型的方法（如非持久和p持久CSMA）因依赖于固定的节点密度估计导致吞吐量损失。因此，需要一种更灵活的方法来优化信道访问。

Method: 设计了基于transformer的ICL优化器，通过预收集碰撞阈值数据样本和查询碰撞案例构建提示输入，以预测最优竞争窗口阈值（CWT）。并开发了一种高效算法，保证在有限训练步骤内预测接近最优。

Result: 理论分析和实验（基于NS-3）表明，该方法在未知节点密度下能够快速收敛，且吞吐量接近最优，优于现有基于模型和深度强化学习的方法。

Conclusion: 提出的基于transformer的ICL方法在动态信道环境下展现出优异的性能，解决了传统方法的局限性，为信道访问优化提供了新思路。

Abstract: The binary exponential backoff scheme is widely used in WiFi 7 and still
incurs poor throughput performance under dynamic channel environments. Recent
model-based approaches (e.g., non-persistent and $p$-persistent CSMA) simply
optimize backoff strategies under a known and fixed node density, still leading
to a large throughput loss due to inaccurate node density estimation. This
paper is the first to propose LLM transformer-based in-context learning (ICL)
theory for optimizing channel access. We design a transformer-based ICL
optimizer to pre-collect collision-threshold data examples and a query
collision case. They are constructed as a prompt as the input for the
transformer to learn the pattern, which then generates a predicted contention
window threshold (CWT). To train the transformer for effective ICL, we develop
an efficient algorithm and guarantee a near-optimal CWT prediction within
limited training steps. As it may be hard to gather perfect data examples for
ICL in practice, we further extend to allow erroneous data input in the prompt.
We prove that our optimizer maintains minimal prediction and throughput
deviations from the optimal values. Experimental results on NS-3 further
demonstrate our approach's fast convergence and near-optimal throughput over
existing model-based and DRL-based approaches under unknown node densities.

</details>


### [129] [Motif 2.6B Technical Report](https://arxiv.org/abs/2508.09148)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Eunhwan Park,Hyunbyung Park,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Jihwan Kim,Minjae Kim,Taehwan Kim,Youngrok Kim,Haesol Lee,Jeesoo Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Daewon Suh,Dongjoo Weon*

Main category: cs.LG

TL;DR: 介绍Motif-2.6B，一个2.6B参数的基础模型，通过创新架构设计提升LLM性能，同时实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在性能与计算效率之间难以平衡，Motif-2.6B旨在填补这一空白，推动先进LLM技术的普及。

Method: 采用差分注意力（Differential Attention）和PolyNorm激活函数等创新技术，优化长上下文理解与减少幻觉。

Result: Motif-2.6B在多种基准测试中表现优异，性能优于同类模型，展示了其高效与可扩展性。

Conclusion: Motif-2.6B为高效、强大且可扩展的基础LLM提供了新方向，为未来研究与应用打下坚实基础。

Abstract: Recent advancements in Large Language Models (LLMs) have revolutionized
artificial intelligence, yet developing an effective foundational LLM that
balances high performance with computational efficiency remains challenging,
especially for emerging research groups. To address this gap, we introduce
Motif-2.6B, a 2.6-billion-parameter foundation model designed to democratize
advanced LLM capabilities. Motif-2.6B incorporates several innovative
architectural enhancements, including Differential Attention and PolyNorm
activation functions, which improve long-context comprehension, reduce
hallucination, and enhance in-context learning capabilities. We rigorously
tested multiple novel architectural components through extensive
experimentation to determine the optimal architecture for Motif-2.6B.
Comprehensive evaluations demonstrate that Motif-2.6B consistently meets or
exceeds the performance of similarly sized state-of-the-art models across
diverse benchmarks, showcasing its effectiveness, scalability, and real-world
applicability. Through detailed experiments and tailored techniques, Motif-2.6B
significantly advances the landscape of efficient, scalable, and powerful
foundational LLMs, offering valuable insights and a robust foundation for
future research and deployment.

</details>


### [130] [JustDense: Just using Dense instead of Sequence Mixer for Time Series analysis](https://arxiv.org/abs/2508.09153)
*TaekHyun Park,Yongjae Lee,Daesan Park,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: 论文质疑复杂序列混合器（如注意力机制）在时间序列分析中的必要性，并提出JustDense，通过将序列混合器替换为密集层进行实证研究。结果表明，简单架构可达到甚至优于复杂架构的性能。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，简单架构在时间序列分析中表现优异，复杂序列混合器的优势可能源于其他因素。论文旨在验证序列混合器是否必要。

Method: 提出JustDense框架，将序列混合器替换为密集层，并在29个基准测试中使用7种先进模型进行实验。

Result: 实验显示密集层表现与序列混合器相当或更优，挑战了“更复杂架构更优”的假设。

Conclusion: 时间序列分析中复杂序列混合器非必要，简单架构可提供高效解决方案。

Abstract: Sequence and channel mixers, the core mechanism in sequence models, have
become the de facto standard in time series analysis (TSA). However, recent
studies have questioned the necessity of complex sequence mixers, such as
attention mechanisms, demonstrating that simpler architectures can achieve
comparable or even superior performance. This suggests that the benefits
attributed to complex sequencemixers might instead emerge from other
architectural or optimization factors. Based on this observation, we pose a
central question: Are common sequence mixers necessary for time-series
analysis? Therefore, we propose JustDense, an empirical study that
systematically replaces sequence mixers in various well-established TSA models
with dense layers. Grounded in the MatrixMixer framework, JustDense treats any
sequence mixer as a mixing matrix and replaces it with a dense layer. This
substitution isolates the mixing operation, enabling a clear theoretical
foundation for understanding its role. Therefore, we conducted extensive
experiments on 29 benchmarks covering five representative TSA tasks using seven
state-of-the-art TSA models to address our research question. The results show
that replacing sequence mixers with dense layers yields comparable or even
superior performance. In the cases where dedicated sequence mixers still offer
benefits, JustDense challenges the assumption that "deeper and more complex
architectures are inherently better" in TSA.

</details>


### [131] [Peer Effect Estimation in the Presence of Simultaneous Feedback and Unobserved Confounders](https://arxiv.org/abs/2508.09154)
*Xiaojing Du,Jiuyong Li,Lin Liu,Debo Cheng,Thuc. Le*

Main category: cs.LG

TL;DR: DIG2RSI是一种新的深度学习框架，通过结合I-G变换和2SRI技术，解决了社交网络中peer效应估计中同时存在的反馈循环和未观测混杂问题。


<details>
  <summary>Details</summary>
Motivation: 由于peer间的相互反馈和未观测混杂因素，现有方法无法准确估计peer效应，DIG2RSI旨在解决这一问题。

Method: 使用I-G变换消除反馈偏差，利用2SRI技术构建工具变量，并通过两阶段神经网络和对抗性去偏处理混杂。

Result: 理论证明和实验验证表明，DIG2RSI优于现有方法，能更准确地估计peer效应。

Conclusion: DIG2RSI为复杂网络中的peer效应估计提供了有效解决方案，具有理论和实践意义。

Abstract: Estimating peer causal effects within complex real-world networks such as
social networks is challenging, primarily due to simultaneous feedback between
peers and unobserved confounders. Existing methods either address unobserved
confounders while ignoring the simultaneous feedback, or account for feedback
but under restrictive linear assumptions, thus failing to obtain accurate peer
effect estimation. In this paper, we propose DIG2RSI, a novel Deep learning
framework which leverages I-G transformation (matrix operation) and 2SRI (an
instrumental variable or IV technique) to address both simultaneous feedback
and unobserved confounding, while accommodating complex, nonlinear and
high-dimensional relationships. DIG2RSI first applies the I-G transformation to
disentangle mutual peer influences and eliminate the bias due to the
simultaneous feedback. To deal with unobserved confounding, we first construct
valid IVs from network data. In stage 1 of 2RSI, we train a neural network on
these IVs to predict peer exposure, and extract residuals as proxies for the
unobserved confounders. In the stage 2, we fit a separate neural network
augmented by an adversarial discriminator that incorporates these residuals as
a control function and enforces the learned representation to contain no
residual confounding signal. The expressive power of deep learning models in
capturing complex non-linear relationships and adversarial debiasing enhances
the effectiveness of DIG2RSI in eliminating bias from both feedback loops and
hidden confounders. We prove consistency of our estimator under standard
regularity conditions, ensuring asymptotic recovery of the true peer effect.
Empirical results on two semi-synthetic benchmarks and a real-world dataset
demonstrate that DIG2RSI outperforms existing approaches.

</details>


### [132] [A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models](https://arxiv.org/abs/2508.09155)
*Wenkai Wang,Hongcan Guo,Zheqi Lv,Shengyu Zhang*

Main category: cs.LG

TL;DR: 论文提出AdaPO框架，通过自适应调整训练目标和动态奖励机制，解决多任务训练中的奖励黑客问题，显著提升模型的推理和自我评估能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决大型多模态模型在自我评估中因固定奖励机制导致的奖励黑客和模型崩溃问题，以实现自我改进。

Method: 方法包括引入自适应奖励模型(ARM)和奖励感知动态KL正则化机制，实时调整训练目标。

Result: 在8个基准测试和多种模型上的实验表明，AdaPO显著提升了直接推理和自我评估能力。

Conclusion: AdaPO框架有效解决了奖励黑客问题，无需人工干预即可自适应调整学习重点，具有广泛的应用前景。

Abstract: Self-evaluation, a model's ability to assess the correctness of its own
output, is crucial for Large Multimodal Models (LMMs) to achieve
self-improvement in multi-turn conversations, yet largely absent in foundation
models. Recent work has employed reinforcement learning (RL) to enhance
self-evaluation; however, its fixed reward mechanism suffers from reward
hacking when optimizing multiple training objectives, leading to model
collapse. In this paper we propose AdaPO, an online reinforcement learning
framework capable of adaptively adjusting training objective in real time
according to the current training state for each task. Specifically, to
mitigate reward hacking , AdaPO introduces an Adaptive Reward Model (ARM) and a
Reward Aware Dynamic KL Regularization mechanism. ARM assesses the task's
training state from the distribution of model generated multi-turn
trajectories' performance. Reward Aware Dynamic KL replaces a fixed penalty
with dynamic coefficients which is modulated by the reward gap between
different multi-turn situations. Notably, our method automatically and smoothly
adjusts its learning focus based on sub-tasks' training progress without manual
intervention. Extensive experiments over 8 benchmarks and various models show
that our method significantly enhances both direct reasoning and
self-evaluation capability. We will release our code to contribute to the
community.

</details>


### [133] [Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems](https://arxiv.org/abs/2508.09156)
*Jan Tauberschmidt,Sophie Fellenz,Sebastian J. Vollmer,Andrew B. Duncan*

Main category: cs.LG

TL;DR: 该论文提出了一种框架，用于调整流匹配生成模型以强制物理约束并解决科学系统中的逆问题。通过可微调的后训练程序，最小化偏微分方程（PDE）的弱形式残差，确保物理一致性和边界条件，同时不破坏学习的分布。此外，还提出了联合优化策略，用于推断未知物理输入。


<details>
  <summary>Details</summary>
Motivation: 科学系统中的逆问题通常涉及推断未知物理输入（如源项、材料参数或边界数据）。传统的生成模型难以同时满足物理约束和生成准确的结果。论文旨在通过结合生成建模和科学推理，提供一种既数据驱动又物理一致的方法。

Method: 框架基于流匹配生成模型，通过可微调的后训练程序优化弱形式的PDE残差。为实现逆问题的求解，引入可学习的潜在参数预测器，并提出联合优化策略。

Result: 在经典的PDE基准测试中，模型显著提高了对PDE约束的满足程度，并能够准确恢复潜在系数。方法在生成物理有效场解和估计隐藏参数方面表现出色。

Conclusion: 该方法成功地将生成建模与科学推理结合起来，为仿真增强的发现和物理系统的数据高效建模开辟了新途径。

Abstract: We present a framework for fine-tuning flow-matching generative models to
enforce physical constraints and solve inverse problems in scientific systems.
Starting from a model trained on low-fidelity or observational data, we apply a
differentiable post-training procedure that minimizes weak-form residuals of
governing partial differential equations (PDEs), promoting physical consistency
and adherence to boundary conditions without distorting the underlying learned
distribution. To infer unknown physical inputs, such as source terms, material
parameters, or boundary data, we augment the generative process with a
learnable latent parameter predictor and propose a joint optimization strategy.
The resulting model produces physically valid field solutions alongside
plausible estimates of hidden parameters, effectively addressing ill-posed
inverse problems in a data-driven yet physicsaware manner. We validate our
method on canonical PDE benchmarks, demonstrating improved satisfaction of PDE
constraints and accurate recovery of latent coefficients. Our approach bridges
generative modelling and scientific inference, opening new avenues for
simulation-augmented discovery and data-efficient modelling of physical
systems.

</details>


### [134] [EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.09158)
*Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng*

Main category: cs.LG

TL;DR: EvaDrive是一种新型多目标强化学习框架，通过对抗优化实现轨迹生成与评估的闭环协同进化，解决现有框架的标量化偏差问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要类似人类的迭代决策能力，而现有方法将轨迹生成与评估隔离或仅用标量奖励，无法有效权衡多目标偏好。

Method: 采用多轮对抗游戏框架，生成器结合自回归意图建模和扩散模型，评估器保留多样偏好结构并通过帕累托前沿选择机制迭代优化。

Result: 在NAVSIM和Bench2Drive基准测试中表现最优，分别以94.9 PDMS和64.96 Driving Score超越其他方法。

Conclusion: EvaDrive提供了一种无需标量化的闭环对抗优化框架，实现多样驾驶风格和迭代决策能力的提升。

Abstract: Autonomous driving faces significant challenges in achieving human-like
iterative decision-making, which continuously generates, evaluates, and refines
trajectory proposals. Current generation-evaluation frameworks isolate
trajectory generation from quality assessment, preventing iterative refinement
essential for planning, while reinforcement learning methods collapse
multi-dimensional preferences into scalar rewards, obscuring critical
trade-offs and yielding scalarization bias.To overcome these issues, we present
EvaDrive, a novel multi-objective reinforcement learning framework that
establishes genuine closed-loop co-evolution between trajectory generation and
evaluation via adversarial optimization. EvaDrive frames trajectory planning as
a multi-round adversarial game. In this game, a hierarchical generator
continuously proposes candidate paths by combining autoregressive intent
modeling for temporal causality with diffusion-based refinement for spatial
flexibility. These proposals are then rigorously assessed by a trainable
multi-objective critic that explicitly preserves diverse preference structures
without collapsing them into a single scalarization bias.This adversarial
interplay, guided by a Pareto frontier selection mechanism, enables iterative
multi-round refinement, effectively escaping local optima while preserving
trajectory diversity.Extensive experiments on NAVSIM and Bench2Drive benchmarks
demonstrate SOTA performance, achieving 94.9 PDMS on NAVSIM v1 (surpassing
DiffusionDrive by 6.8, DriveSuprim by 5.0, and TrajHF by 0.9) and 64.96 Driving
Score on Bench2Drive. EvaDrive generates diverse driving styles via dynamic
weighting without external preference data, introducing a closed-loop
adversarial framework for human-like iterative decision-making, offering a
novel scalarization-free trajectory optimization approach.

</details>


### [135] [Presenting DiaData for Research on Type 1 Diabetes](https://arxiv.org/abs/2508.09160)
*Beyza Cinar,Maria Maleshkova*

Main category: cs.LG

TL;DR: 本文整合了15个数据集，构建了一个包含2510名受试者、1.49亿次血糖测量的大型数据库，用于1型糖尿病研究。同时分析了数据质量挑战和血糖与心率之间的相关性。


<details>
  <summary>Details</summary>
Motivation: 1型糖尿病（T1D）是一种导致胰岛素缺乏的自身免疫性疾病，患者依赖外部胰岛素注射。低血糖是常见且危险的副作用。机器学习可以预测血糖水平并提供早期警报，但缺乏大型数据集限制了研究。

Method: 整合15个数据集，构建包含2510名受试者的数据库，记录每5分钟的血糖测量数据。提取两个子数据库（人口统计学和心率数据），并评估数据质量与不平衡问题。

Result: 整合数据库包含1.49亿次测量，其中4%为低血糖范围。研究发现血糖水平与心率在低血糖前15至55分钟存在相关性。

Conclusion: 该数据库为糖尿病研究提供了丰富资源，同时数据不平衡和缺失值是主要挑战。血糖与心率的相关性为未来研究提供了方向。

Abstract: Type 1 diabetes (T1D) is an autoimmune disorder that leads to the destruction
of insulin-producing cells, resulting in insulin deficiency, as to why the
affected individuals depend on external insulin injections. However, insulin
can decrease blood glucose levels and can cause hypoglycemia. Hypoglycemia is a
severe event of low blood glucose levels ($\le$70 mg/dL) with dangerous side
effects of dizziness, coma, or death. Data analysis can significantly enhance
diabetes care by identifying personal patterns and trends leading to adverse
events. Especially, machine learning (ML) models can predict glucose levels and
provide early alarms. However, diabetes and hypoglycemia research is limited by
the unavailability of large datasets. Thus, this work systematically integrates
15 datasets to provide a large database of 2510 subjects with glucose
measurements recorded every 5 minutes. In total, 149 million measurements are
included, of which 4% represent values in the hypoglycemic range. Moreover, two
sub-databases are extracted. Sub-database I includes demographics, and
sub-database II includes heart rate data. The integrated dataset provides an
equal distribution of sex and different age levels. As a further contribution,
data quality is assessed, revealing that data imbalance and missing values
present a significant challenge. Moreover, a correlation study on glucose
levels and heart rate data is conducted, showing a relation between 15 and 55
minutes before hypoglycemia.

</details>


### [136] [Physics-Guided Memory Network for Building Energy Modeling](https://arxiv.org/abs/2508.09161)
*Muhammad Umair Danish,Kashif Ali,Kamran Siddiqui,Katarina Grolinger*

Main category: cs.LG

TL;DR: 本文提出了一种物理引导记忆网络（PgMN），结合深度学习与基于物理的模型，解决了现有方法在历史数据不足或缺失时的局限性。


<details>
  <summary>Details</summary>
Motivation: 建筑能源消耗预测对资源管理和可持续性至关重要，但现有深度学习和物理模型各有不足，尤其在历史数据缺失的新建筑中。

Method: PgMN通过并行投影层、记忆单元和记忆经验模块，整合深度学习和物理模型的预测，优化预测结果。

Result: 理论验证了PgMN组件的数学有效性，实验证明了其在多种场景（如新建筑、数据缺失）下的准确性和适用性。

Conclusion: PgMN为动态建筑环境中的能源预测提供了一种有效解决方案，扩展了模型在历史数据不足或缺失场景下的适用性。

Abstract: Accurate energy consumption forecasting is essential for efficient resource
management and sustainability in the building sector. Deep learning models are
highly successful but struggle with limited historical data and become unusable
when historical data are unavailable, such as in newly constructed buildings.
On the other hand, physics-based models, such as EnergyPlus, simulate energy
consumption without relying on historical data but require extensive building
parameter specifications and considerable time to model a building. This paper
introduces a Physics-Guided Memory Network (PgMN), a neural network that
integrates predictions from deep learning and physics-based models to address
their limitations. PgMN comprises a Parallel Projection Layers to process
incomplete inputs, a Memory Unit to account for persistent biases, and a Memory
Experience Module to optimally extend forecasts beyond their input range and
produce output. Theoretical evaluation shows that components of PgMN are
mathematically valid for performing their respective tasks. The PgMN was
evaluated on short-term energy forecasting at an hourly resolution, critical
for operational decision-making in smart grid and smart building systems.
Experimental validation shows accuracy and applicability of PgMN in diverse
scenarios such as newly constructed buildings, missing data, sparse historical
data, and dynamic infrastructure changes. This paper provides a promising
solution for energy consumption forecasting in dynamic building environments,
enhancing model applicability in scenarios where historical data are limited or
unavailable or when physics-based models are inadequate.

</details>


### [137] [An Unsupervised Deep XAI Framework for Localization of Concurrent Replay Attacks in Nuclear Reactor Signals](https://arxiv.org/abs/2508.09162)
*Konstantinos Vasili,Zachery T. Dahm,William Richards,Stylianos Chatzidakis*

Main category: cs.LG

TL;DR: 本文提出了一种基于自编码器和定制化windowSHAP算法的无监督可解释AI框架，用于实时检测和表征核反应堆中的重放攻击，效果显著。


<details>
  <summary>Details</summary>
Motivation: 新一代核反应堆依赖数字化系统，数据完整性对安全至关重要，而现有方法未能充分识别异常根源且依赖合成数据。

Method: 结合自编码器和定制化windowSHAP算法，提出无监督可解释AI框架，实时检测并表征重放攻击。

Result: 在PUR-1核反应堆的实测数据中，框架对高达六个信号的重放攻击实现了95%以上的检测和识别准确率。

Conclusion: 该框架为核能系统的安全运行提供了一种有效的、基于真实数据的异常检测与解释方法。

Abstract: Next generation advanced nuclear reactors are expected to be smaller both in
size and power output, relying extensively on fully digital instrumentation and
control systems. These reactors will generate a large flow of information in
the form of multivariate time series data, conveying simultaneously various non
linear cyber physical, process, control, sensor, and operational states.
Ensuring data integrity against deception attacks is becoming increasingly
important for networked communication and a requirement for safe and reliable
operation. Current efforts to address replay attacks, almost universally focus
on watermarking or supervised anomaly detection approaches without further
identifying and characterizing the root cause of the anomaly. In addition,
these approaches rely mostly on synthetic data with uncorrelated Gaussian
process and measurement noise and full state feedback or are limited to
univariate signals, signal stationarity, linear quadratic regulators, or other
linear-time invariant state-space which may fail to capture any unmodeled
system dynamics. In the realm of regulated nuclear cyber-physical systems,
additional work is needed on characterization of replay attacks and
explainability of predictions using real data. Here, we propose an unsupervised
explainable AI framework based on a combination of autoencoder and customized
windowSHAP algorithm to fully characterize real-time replay attacks, i.e.,
detection, source identification, timing and type, of increasing complexity
during a dynamic time evolving reactor process. The proposed XAI framework was
benchmarked on several real world datasets from Purdue's nuclear reactor PUR-1
with up to six signals concurrently being replayed. In all cases, the XAI
framework was able to detect and identify the source and number of signals
being replayed and the duration of the falsification with 95 percent or better
accuracy.

</details>


### [138] [Energy-Efficient Stochastic Computing (SC) Neural Networks for Internet of Things Devices With Layer-Wise Adjustable Sequence Length (ASL)](https://arxiv.org/abs/2508.09163)
*Ziheng Wang,Pedro Reviriego,Farzad Niknia,Zhen Gao,Javier Conde,Shanshan Liu,Fabrizio Lombardi*

Main category: cs.LG

TL;DR: 本文提出了一种名为可调序列长度（ASL）的新方案，将混合精度概念应用于随机计算神经网络（SC NNs），通过理论模型和实验验证，显著降低了能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 随机计算（SC）在资源受限场景（如物联网）中表现出低功耗优势，但层间混合精度实现的优化尚未充分探索。

Method: 引入了基于算子范数的理论模型，分析截断噪声的累积传播，并提出两种截断策略（粗粒度和细粒度）。

Result: 在32nm工艺下实现的SC MLP实验中，ASL方案能将能耗和延迟降低60%以上，且精度损失可忽略。

Conclusion: ASL方案在物联网应用中具有可行性，并突显了混合精度截断在SC设计中的独特优势。

Abstract: Stochastic computing (SC) has emerged as an efficient low-power alternative
for deploying neural networks (NNs) in resource-limited scenarios, such as the
Internet of Things (IoT). By encoding values as serial bitstreams, SC
significantly reduces energy dissipation compared to conventional
floating-point (FP) designs; however, further improvement of layer-wise
mixed-precision implementation for SC remains unexplored. This article
introduces Adjustable Sequence Length (ASL), a novel scheme that applies
mixed-precision concepts specifically to SC NNs. By introducing an
operator-norm-based theoretical model, this article shows that truncation noise
can cumulatively propagate through the layers by the estimated amplification
factors. An extended sensitivity analysis is presented, using random forest
(RF) regression to evaluate multilayer truncation effects and validate the
alignment of theoretical predictions with practical network behaviors. To
accommodate different application scenarios, this article proposes two
truncation strategies (coarse-grained and fine-grained), which apply diverse
sequence length configurations at each layer. Evaluations on a pipelined SC MLP
synthesized at 32nm demonstrate that ASL can reduce energy and latency
overheads by up to over 60% with negligible accuracy loss. It confirms the
feasibility of the ASL scheme for IoT applications and highlights the distinct
advantages of mixed-precision truncation in SC designs.

</details>


### [139] [Generating Feasible and Diverse Synthetic Populations Using Diffusion Models](https://arxiv.org/abs/2508.09164)
*Min Tang,Peng Lu,Qing Feng*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型的新方法，用于合成人口数据，解决了高维属性下的稀疏性和生成不可行组合的问题，优于VAE和GAN。


<details>
  <summary>Details</summary>
Motivation: 解决人口合成中高维属性导致的稀疏性问题，以及生成不可行组合的挑战。

Method: 使用扩散模型估计人口的联合分布，恢复缺失的采样零并最小化结构零的生成。

Result: 与VAE和GAN相比，新方法在可行性和多样性之间取得了更好的平衡。

Conclusion: 基于扩散模型的方法在人口合成任务中表现优异，为ABM提供了更真实的输入。

Abstract: Population synthesis is a critical task that involves generating synthetic
yet realistic representations of populations. It is a fundamental problem in
agent-based modeling (ABM), which has become the standard to analyze
intelligent transportation systems. The synthetic population serves as the
primary input for ABM transportation simulation, with traveling agents
represented by population members. However, when the number of attributes
describing agents becomes large, survey data often cannot densely support the
joint distribution of the attributes in the population due to the curse of
dimensionality. This sparsity makes it difficult to accurately model and
produce the population. Interestingly, deep generative models trained from
available sample data can potentially synthesize possible attribute
combinations that present in the actual population but do not exist in the
sample data(called sampling zeros). Nevertheless, this comes at the cost of
falsely generating the infeasible attribute combinations that do not exist in
the population (called structural zeros). In this study, a novel diffusion
model-based population synthesis method is proposed to estimate the underlying
joint distribution of a population. This approach enables the recovery of
numerous missing sampling zeros while keeping the generated structural zeros
minimal. Our method is compared with other recently proposed approaches such as
Variational Autoencoders (VAE) and Generative Adversarial Network (GAN)
approaches, which have shown success in high dimensional tabular population
synthesis. We assess the performance of the synthesized outputs using a range
of metrics, including marginal distribution similarity, feasibility, and
diversity. The results demonstrate that our proposed method outperforms
previous approaches in achieving a better balance between the feasibility and
diversity of the synthesized population.

</details>


### [140] [Masked Training for Robust Arrhythmia Detection from Digitalized Multiple Layout ECG Images](https://arxiv.org/abs/2508.09165)
*Shanwei Zhang,Deyun Zhang,Yirao Tao,Kexin Wang,Shijia Geng,Jun Li,Qinghao Zhao,Xingpeng Liu,Yuxi Zhou,Shenda Hong*

Main category: cs.LG

TL;DR: 论文提出了一种名为PatchECG的框架，用于处理不同医院心电图布局差异导致的信号异步和部分缺失问题，通过学习自适应可变块缺失表示，实现对不同布局心电图中心律失常的关键识别。


<details>
  <summary>Details</summary>
Motivation: 由于不同医院使用的心电图（ECG）布局不同，数字化信号存在异步导联时间和部分缺失问题，这对现有模型提出了严峻挑战。研究旨在解决这一问题，提升心电图分析的鲁棒性。

Method: 研究引入了PatchECG框架，基于掩码训练策略学习自适应可变块缺失表示，自动聚焦具有导联间协作依赖关系的关键块。

Result: 在PTB-XL数据集和生成的21388个异步心电图图像上测试，平均AUROC为0.835，且在布局变化时保持稳定。外部验证中，房颤诊断的AUROC为0.778，12x1布局下达到0.893，优于经典方法和当前最优预训练模型ECGFounder。

Conclusion: PatchECG框架在处理不同布局心电图时表现出强鲁棒性和高准确性，显著提升了心律失常诊断的性能。

Abstract: Electrocardiogram (ECG) as an important tool for diagnosing cardiovascular
diseases such as arrhythmia. Due to the differences in ECG layouts used by
different hospitals, the digitized signals exhibit asynchronous lead time and
partial blackout loss, which poses a serious challenge to existing models. To
address this challenge, the study introduced PatchECG, a framework for adaptive
variable block count missing representation learning based on a masking
training strategy, which automatically focuses on key patches with
collaborative dependencies between leads, thereby achieving key recognition of
arrhythmia in ECGs with different layouts. Experiments were conducted on the
PTB-XL dataset and 21388 asynchronous ECG images generated using ECG image kit
tool, using the 23 Subclasses as labels. The proposed method demonstrated
strong robustness under different layouts, with average Area Under the Receiver
Operating Characteristic Curve (AUROC) of 0.835 and remained stable (unchanged
with layout changes). In external validation based on 400 real ECG images data
from Chaoyang Hospital, the AUROC for atrial fibrillation diagnosis reached
0.778; On 12 x 1 layout ECGs, AUROC reaches 0.893. This result is superior to
various classic interpolation and baseline methods, and compared to the current
optimal large-scale pre-training model ECGFounder, it has improved by 0.111 and
0.19.

</details>


### [141] [SVGen: Interpretable Vector Graphics Generation with Large Language Models](https://arxiv.org/abs/2508.09168)
*Feiyu Wang,Zhiyuan Zhao,Yuandong Liu,Da Zhang,Junyu Gao,Hao Sun,Xuelong Li*

Main category: cs.LG

TL;DR: 论文提出了SVG-1M数据集和SVGen模型，用于从自然语言生成高质量的SVG代码，显著提升了语义准确性和效率。


<details>
  <summary>Details</summary>
Motivation: SVG在前端开发和设计中广泛应用，但将创意转换为精确矢量图耗时较长，缺乏高效的解决方案。

Method: 通过SVG-1M数据集，采用数据增强和标注对齐技术，结合链式思维标注，提出SVGen模型，利用课程学习和强化学习优化生成过程。

Result: SVGen在语义准确性和结构完整性上优于通用大模型和传统渲染方法，同时效率更高。

Conclusion: SVG-1M和SVGen为文本到SVG的生成提供了高效解决方案，显著提升了设计自动化水平。

Abstract: Scalable Vector Graphics (SVG) is widely used in front-end development and
UI/UX design due to its scalability, editability, and rendering efficiency.
However, turning creative ideas into precise vector graphics remains a
time-consuming challenge. To address this, we introduce SVG-1M, a large-scale
dataset of high-quality SVGs paired with natural language descriptions. Through
advanced data augmentation and annotation, we create well-aligned Text to SVG
training pairs, including a subset with Chain of Thought annotations for
enhanced semantic guidance. Based on this dataset, we propose SVGen, an
end-to-end model that generates SVG code from natural language inputs. Our
approach ensures semantic accuracy and structural completeness, supported by
curriculum learning and reinforcement learning optimization. Experiments show
that SVGen outperforms general large models and traditional rendering methods
in both effectiveness and efficiency. Code, model, and dataset are available on
GitHub.

</details>


### [142] [Multimodal RAG Enhanced Visual Description](https://arxiv.org/abs/2508.09170)
*Amit Kumar Jaiswal,Haiming Liu,Ingo Frommholz*

Main category: cs.LG

TL;DR: 提出了一种轻量级、无需训练的方法，利用检索增强生成（RAG）解决多模态模型中的模态差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）存在模态差距问题，即文本与视觉表征在共享嵌入空间中的不匹配，而微调成本高且不实用。

Method: 采用基于RAG的线性映射方法，高效计算跨模态映射，并在推理时应用该映射从训练集中检索最接近的文本描述，结合指令生成新的文本描述。

Result: 在两个多模态基准数据集上的实验结果显示显著改进。

Conclusion: 该方法以轻量级、无需训练的方式有效解决了模态差距问题，具有实用性和高效性。

Abstract: Textual descriptions for multimodal inputs entail recurrent refinement of
queries to produce relevant output images. Despite efforts to address
challenges such as scaling model size and data volume, the cost associated with
pre-training and fine-tuning remains substantial. However, pre-trained large
multimodal models (LMMs) encounter a modality gap, characterised by a
misalignment between textual and visual representations within a common
embedding space. Although fine-tuning can potentially mitigate this gap, it is
typically expensive and impractical due to the requirement for extensive
domain-driven data. To overcome this challenge, we propose a lightweight
training-free approach utilising Retrieval-Augmented Generation (RAG) to extend
across the modality using a linear mapping, which can be computed efficiently.
During inference, this mapping is applied to images embedded by an LMM enabling
retrieval of closest textual descriptions from the training set. These textual
descriptions, in conjunction with an instruction, cater as an input prompt for
the language model to generate new textual descriptions. In addition, we
introduce an iterative technique for distilling the mapping by generating
synthetic descriptions via the language model facilitating optimisation for
standard utilised image description measures. Experimental results on two
benchmark multimodal datasets demonstrate significant improvements.

</details>


### [143] [FedMP: Tackling Medical Feature Heterogeneity in Federated Learning from a Manifold Perspective](https://arxiv.org/abs/2508.09174)
*Zhekai Zhou,Shudong Liu,Zhaokun Zhou,Yang Liu,Qiang Yang,Yuesheng Zhu,Guibo Luo*

Main category: cs.LG

TL;DR: FedMP是一种新方法，通过特征流形补全和类别原型对齐来解决非IID数据下联邦学习的性能问题，尤其在医学影像领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实中的联邦学习常因非独立同分布（non-IID）数据导致模型收敛和性能问题，尤其在医学影像领域更为突出。

Method: FedMP采用随机特征流形补全和类别原型对齐技术，优化客户端的特征空间和决策边界。

Result: 在多个医学影像和自然图像数据集上，FedMP表现优于现有联邦学习算法。

Conclusion: FedMP有效解决了非IID数据下的联邦学习问题，同时分析了流形维度、通信效率和隐私影响。

Abstract: Federated learning (FL) is a decentralized machine learning paradigm in which
multiple clients collaboratively train a shared model without sharing their
local private data. However, real-world applications of FL frequently encounter
challenges arising from the non-identically and independently distributed
(non-IID) local datasets across participating clients, which is particularly
pronounced in the field of medical imaging, where shifts in image feature
distributions significantly hinder the global model's convergence and
performance. To address this challenge, we propose FedMP, a novel method
designed to enhance FL under non-IID scenarios. FedMP employs stochastic
feature manifold completion to enrich the training space of individual client
classifiers, and leverages class-prototypes to guide the alignment of feature
manifolds across clients within semantically consistent subspaces, facilitating
the construction of more distinct decision boundaries. We validate the
effectiveness of FedMP on multiple medical imaging datasets, including those
with real-world multi-center distributions, as well as on a multi-domain
natural image dataset. The experimental results demonstrate that FedMP
outperforms existing FL algorithms. Additionally, we analyze the impact of
manifold dimensionality, communication efficiency, and privacy implications of
feature exposure in our method.

</details>


### [144] [DQT: Dynamic Quantization Training via Dequantization-Free Nested Integer Arithmetic](https://arxiv.org/abs/2508.09176)
*Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Francesca Palermo,Diana Trojaniello,Manuel Roveri*

Main category: cs.LG

TL;DR: 本文提出了一种名为动态量化训练（DQT）的新框架，通过嵌套整数表示和自定义整数算术，实现了高效的动态混合精度量化，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署深度神经网络时，传统静态量化无法适配输入复杂度变化，而动态量化方法由于需要解量化和重新量化操作，导致性能损失。

Method: DQT框架采用嵌套整数表示方法，通过位移操作实现比特宽度切换，避免了昂贵的浮点操作。

Result: 在ImageNet上，4位动态ResNet50达到77.00%的top-1准确率，优于现有静态和动态方法，且计算成本显著降低。

Conclusion: DQT为高效、自适应的AI提供了一个新的解决方案。

Abstract: The deployment of deep neural networks on resource-constrained devices relies
on quantization. While static, uniform quantization applies a fixed bit-width
to all inputs, it fails to adapt to their varying complexity. Dynamic,
instance-based mixed-precision quantization promises a superior
accuracy-efficiency trade-off by allocating higher precision only when needed.
However, a critical bottleneck remains: existing methods require a costly
dequantize-to-float and requantize-to-integer cycle to change precision,
breaking the integer-only hardware paradigm and compromising performance gains.
This paper introduces Dynamic Quantization Training (DQT), a novel framework
that removes this bottleneck. At the core of DQT is a nested integer
representation where lower-precision values are bit-wise embedded within
higher-precision ones. This design, coupled with custom integer-only
arithmetic, allows for on-the-fly bit-width switching through a near-zero-cost
bit-shift operation. This makes DQT the first quantization framework to enable
both dequantization-free static mixed-precision of the backbone network, and
truly efficient dynamic, instance-based quantization through a lightweight
controller that decides at runtime how to quantize each layer. We demonstrate
DQT state-of-the-art performance on ResNet18 on CIFAR-10 and ResNet50 on
ImageNet. On ImageNet, our 4-bit dynamic ResNet50 achieves 77.00% top-1
accuracy, an improvement over leading static (LSQ, 76.70%) and dynamic (DQNET,
76.94%) methods at a comparable BitOPs budget. Crucially, DQT achieves this
with a bit-width transition cost of only 28.3M simple bit-shift operations, a
drastic improvement over the 56.6M costly Multiply-Accumulate (MAC)
floating-point operations required by previous dynamic approaches - unlocking a
new frontier in efficient, adaptive AI.

</details>


### [145] [scAGC: Learning Adaptive Cell Graphs with Contrastive Guidance for Single-Cell Clustering](https://arxiv.org/abs/2508.09180)
*Huifa Li,Jie Fu,Xinlin Zhuang,Haolin Yang,Xinpeng Ling,Tong Cheng,Haochen xue,Imran Razzak,Zhili Chen*

Main category: cs.LG

TL;DR: scAGC是一种单细胞聚类方法，通过学习自适应细胞图和对比指导来解决传统方法的局限性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 单细胞RNA测序数据的高维性和稀疏性使传统聚类方法面临挑战，现有方法依赖静态图结构，无法处理噪声和长尾分布问题。

Method: scAGC采用拓扑自适应图自动编码器和可微Gumbel-Softmax采样策略动态优化图结构，结合ZINB损失和对比学习目标。

Result: 在9个真实数据集上，scAGC在NMI和ARI指标上均表现最优。

Conclusion: scAGC通过自适应图学习和对比指导有效解决了单细胞聚类问题，性能优于现有方法。

Abstract: Accurate cell type annotation is a crucial step in analyzing single-cell RNA
sequencing (scRNA-seq) data, which provides valuable insights into cellular
heterogeneity. However, due to the high dimensionality and prevalence of zero
elements in scRNA-seq data, traditional clustering methods face significant
statistical and computational challenges. While some advanced methods use graph
neural networks to model cell-cell relationships, they often depend on static
graph structures that are sensitive to noise and fail to capture the
long-tailed distribution inherent in single-cell populations.To address these
limitations, we propose scAGC, a single-cell clustering method that learns
adaptive cell graphs with contrastive guidance. Our approach optimizes feature
representations and cell graphs simultaneously in an end-to-end manner.
Specifically, we introduce a topology-adaptive graph autoencoder that leverages
a differentiable Gumbel-Softmax sampling strategy to dynamically refine the
graph structure during training. This adaptive mechanism mitigates the problem
of a long-tailed degree distribution by promoting a more balanced neighborhood
structure. To model the discrete, over-dispersed, and zero-inflated nature of
scRNA-seq data, we integrate a Zero-Inflated Negative Binomial (ZINB) loss for
robust feature reconstruction. Furthermore, a contrastive learning objective is
incorporated to regularize the graph learning process and prevent abrupt
changes in the graph topology, ensuring stability and enhancing convergence.
Comprehensive experiments on 9 real scRNA-seq datasets demonstrate that scAGC
consistently outperforms other state-of-the-art methods, yielding the best NMI
and ARI scores on 9 and 7 datasets, respectively.Our code is available at
Anonymous Github.

</details>


### [146] [Long-Term Client Selection for Federated Learning with Non-IID Data: A Truthful Auction Approach](https://arxiv.org/abs/2508.09181)
*Jinghong Tan,Zhian Liu,Kun Guo,Mingxiong Zhao*

Main category: cs.LG

TL;DR: 论文提出了一种基于真实拍卖的长期客户选择联邦学习方案（LCSFLA），以解决联邦学习中非独立同分布数据和资源浪费问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中的非独立同分布数据和资源浪费问题影响了模型收敛和准确性，特别是在车联网环境中，客户选择和激励机制的不完善加剧了这些挑战。

Method: 提出LCSFLA方案，结合长期数据质量评估和拍卖机制，激励客户参与并确保信息真实性。

Result: 实验证明LCSFLA能有效缓解非独立同分布数据导致的性能下降。

Conclusion: LCSFLA方案在车联网场景中表现出色，通过改进客户选择和激励机制提升了联邦学习的性能。

Abstract: Federated learning (FL) provides a decentralized framework that enables
universal model training through collaborative efforts on mobile nodes, such as
smart vehicles in the Internet of Vehicles (IoV). Each smart vehicle acts as a
mobile client, contributing to the process without uploading local data. This
method leverages non-independent and identically distributed (non-IID) training
data from different vehicles, influenced by various driving patterns and
environmental conditions, which can significantly impact model convergence and
accuracy. Although client selection can be a feasible solution for non-IID
issues, it faces challenges related to selection metrics. Traditional metrics
evaluate client data quality independently per round and require client
selection after all clients complete local training, leading to resource
wastage from unused training results. In the IoV context, where vehicles have
limited connectivity and computational resources, information asymmetry in
client selection risks clients submitting false information, potentially making
the selection ineffective. To tackle these challenges, we propose a novel
Long-term Client-Selection Federated Learning based on Truthful Auction
(LCSFLA). This scheme maximizes social welfare with consideration of long-term
data quality using a new assessment mechanism and energy costs, and the advised
auction mechanism with a deposit requirement incentivizes client participation
and ensures information truthfulness. We theoretically prove the incentive
compatibility and individual rationality of the advised incentive mechanism.
Experimental results on various datasets, including those from IoV scenarios,
demonstrate its effectiveness in mitigating performance degradation caused by
non-IID data.

</details>


### [147] [Breath as a biomarker: A survey of contact and contactless applications and approaches in respiratory monitoring](https://arxiv.org/abs/2508.09187)
*Almustapha A. Wakili,Babajide J. Asaju,Woosub Jung*

Main category: cs.LG

TL;DR: 论文综述了呼吸分析的接触式和非接触式方法，重点探讨了机器学习和深度学习技术在呼吸监测中的应用，并讨论了当前挑战与未来趋势。


<details>
  <summary>Details</summary>
Motivation: 呼吸分析是健康监测的重要工具，但传统接触式方法在舒适性和实用性上存在问题，因此需要研究更高效的非接触式方法。

Method: 通过分析Wi-Fi信道状态信息和声学传感等非接触式方法，结合数据预处理、特征提取和分类技术，应用机器学习和深度学习模型。

Result: 展示了非接触式呼吸监测的准确性及其在呼吸率检测、疾病诊断等多场景中的应用潜力。

Conclusion: 呼吸分析的未来发展需关注数据隐私、多用户干扰等挑战，并结合可解释AI、联邦学习等新兴技术，以实现更广泛的医疗应用。

Abstract: Breath analysis has emerged as a critical tool in health monitoring, offering
insights into respiratory function, disease detection, and continuous health
assessment. While traditional contact-based methods are reliable, they often
pose challenges in comfort and practicality, particularly for long-term
monitoring. This survey comprehensively examines contact-based and contactless
approaches, emphasizing recent advances in machine learning and deep learning
techniques applied to breath analysis. Contactless methods, including Wi-Fi
Channel State Information and acoustic sensing, are analyzed for their ability
to provide accurate, noninvasive respiratory monitoring. We explore a broad
range of applications, from single-user respiratory rate detection to
multi-user scenarios, user identification, and respiratory disease detection.
Furthermore, this survey details essential data preprocessing, feature
extraction, and classification techniques, offering comparative insights into
machine learning/deep learning models suited to each approach. Key challenges
like dataset scarcity, multi-user interference, and data privacy are also
discussed, along with emerging trends like Explainable AI, federated learning,
transfer learning, and hybrid modeling. By synthesizing current methodologies
and identifying open research directions, this survey offers a comprehensive
framework to guide future innovations in breath analysis, bridging advanced
technological capabilities with practical healthcare applications.

</details>


### [148] [Fine-Grained Safety Neurons with Training-Free Continual Projection to Reduce LLM Fine Tuning Risks](https://arxiv.org/abs/2508.09190)
*Bing Han,Feifei Zhao,Dongcheng Zhao,Guobin Shen,Ping Wu,Yu Shi,Yi Zeng*

Main category: cs.LG

TL;DR: FGSN方法通过细粒度安全神经元与训练无关的持续投影，有效降低LLM微调的安全风险，平衡安全性与实用性。


<details>
  <summary>Details</summary>
Motivation: 解决微调过程中因领域知识注入导致的安全风险与原对齐机制受损问题，现有防御策略缺乏对安全层与细粒度神经元的全面考量。

Method: 提出FGSN方法，整合多尺度交互，定位细粒度安全神经元并通过投影提升安全性，同时最小化对下游任务神经元干扰。

Result: 实验表明，FGSN显著降低有害性分数与攻击成功率，参数修改极少且保持模型实用性，具备持续防御能力。

Conclusion: FGSN为LLM微调提供了高效安全解决方案，通过细粒度神经元优化实现持续防御与泛化能力。

Abstract: Fine-tuning as service injects domain-specific knowledge into large language
models (LLMs), while challenging the original alignment mechanisms and
introducing safety risks. A series of defense strategies have been proposed for
the alignment, fine-tuning, and post-fine-tuning phases, where most
post-fine-tuning defenses rely on coarse-grained safety layer mapping. These
methods lack a comprehensive consideration of both safety layers and
fine-grained neurons, limiting their ability to efficiently balance safety and
utility. To address this, we propose the Fine-Grained Safety Neurons (FGSN)
with Training-Free Continual Projection method to reduce the fine-tuning safety
risks. FGSN inherently integrates the multi-scale interactions between safety
layers and neurons, localizing sparser and more precise fine-grained safety
neurons while minimizing interference with downstream task neurons. We then
project the safety neuron parameters onto safety directions, improving model
safety while aligning more closely with human preferences. Extensive
experiments across multiple fine-tuned LLM models demonstrate that our method
significantly reduce harmfulness scores and attack success rates with minimal
parameter modifications, while preserving the model's utility. Furthermore, by
introducing a task-specific, multi-dimensional heterogeneous safety neuron
cluster optimization mechanism, we achieve continual defense and generalization
capability against unforeseen emerging safety concerns.

</details>


### [149] [From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization](https://arxiv.org/abs/2508.09191)
*Xiaoyu Tao,Shilong Zhang,Mingyue Cheng,Daoyu Wang,Tingyue Pan,Bokai Pan,Changqing Zhang,Shijin Wang*

Main category: cs.LG

TL;DR: 该论文提出TokenCast框架，利用语言模型将时间序列和上下文特征统一表示，提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在多个关键领域很重要，但现有方法难以整合历史数值序列和上下文特征（如非结构化文本数据）。

Method: TokenCast通过离散标记化将连续数值序列转换为时间标记，并使用预训练的大型语言模型（LLM）将时间标记和上下文标记嵌入共享表示空间，最后通过监督微调预测未来时间标记。

Result: 在多个真实数据集上的实验验证了TokenCast的有效性和泛化能力。

Conclusion: TokenCast通过统一表示时间序列和上下文特征，显著提升了预测性能，展示了广泛的应用潜力。

Abstract: Time series forecasting plays a vital role in supporting decision-making
across a wide range of critical applications, including energy, healthcare, and
finance. Despite recent advances, forecasting accuracy remains limited due to
the challenge of integrating historical numerical sequences with contextual
features, which often comprise unstructured textual data. To address this
challenge, we propose TokenCast, an LLM-driven framework that leverages
language-based symbolic representations as a unified intermediary for
context-aware time series forecasting. Specifically, TokenCast employs a
discrete tokenizer to transform continuous numerical sequences into temporal
tokens, enabling structural alignment with language-based inputs. To bridge the
semantic gap between modalities, both temporal and contextual tokens are
embedded into a shared representation space via a pre-trained large language
model (LLM), further optimized with autoregressive generative objectives.
Building upon this unified semantic space, the aligned LLM is subsequently
fine-tuned in a supervised manner to predict future temporal tokens, which are
then decoded back into the original numerical space. Extensive experiments on
diverse real-world datasets enriched with contextual features demonstrate the
effectiveness and generalizability of TokenCast.

</details>


### [150] [Diffusion LLMs Can Do Faster-Than-AR Inference via Discrete Diffusion Forcing](https://arxiv.org/abs/2508.09192)
*Xu Wang,Chenkai Xu,Yijie Jin,Jiachun Jin,Hao Zhang,Zhijie Deng*

Main category: cs.LG

TL;DR: 该论文提出了一种名为离散扩散强制（D2F）的策略，通过将扩散大语言模型（dLLMs）改造为自回归-扩散混合范式，显著提升了推理速度，超越了类似大小的自回归LLMs。


<details>
  <summary>Details</summary>
Motivation: 解决现有开源dLLMs在推理速度上无法超越类似大小的自回归LLMs的问题，提出一种有效策略以提升dLLMs的效率。

Method: 采用D2F策略，实现块级自回归生成和跨块并行解码，并通过非对称蒸馏过程和流水线并行解码算法优化效率与效果。

Result: D2F dLLMs在推理速度上比LLaMA3和Qwen2.5快2.5倍以上，比vanilla dLLMs快50倍以上，同时保持输出质量。

Conclusion: D2F是一种简单有效的策略，能够显著提升dLLMs的推理效率，同时保持生成质量，为文本生成提供了新的可能性。

Abstract: Diffusion Large Language Models (dLLMs) have emerged as a promising
alternative to autoregressive (AR) LLMs for text generation, with the potential
to decode multiple tokens in a single iteration. However, none of the existing
open-source dLLMs have achieved superior inference speed over AR LLMs of
similar size. This paper breaks this barrier based on a simple and effective
strategy named discrete diffusion forcing (D2F). D2F equips dLLMs with two key
capabilities: (1) block-wise autoregressive generation to enable KV cache
utilization; (2) prediction of following tokens without requiring completion of
prior blocks for inter-block parallel decoding. In this way, the vanilla dLLMs
are refurbished into an AR-diffusion hybrid paradigm for efficient inference.
D2F can be implemented with an asymmetric distillation process based on
pre-trained dLLMs. We further propose a pipelined parallel decoding algorithm,
which enables a trade-off between efficiency and efficacy. Empirically, D2F
dLLMs achieve more than $\mathbf{2.5\times}$ inference speed than LLaMA3 and
Qwen2.5 on GSM8K. Compared to vanilla dLLMs like LLaDA and Dream, the
acceleration can be more than $\mathbf{50\times}$ while maintaining comparable
output quality. The code is available at
https://github.com/zhijie-group/Discrete-Diffusion-Forcing.

</details>


### [151] [Multi-Objective Instruction-Aware Representation Learning in Procedural Content Generation RL](https://arxiv.org/abs/2508.09193)
*Sung-Hyun Kim,In-Chang Baek,Seo-Young Lee,Geum-Hwan Hwang,Kyung-Joong Kim*

Main category: cs.LG

TL;DR: MIPCGRL是一种多目标表示学习方法，通过引入句子嵌入作为条件，提高了基于复杂指令的内容生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用文本输入的丰富表达能力方面存在不足，尤其是在复杂多目标指令下，可控性受限。

Method: 结合多标签分类和多头回归网络，训练多目标嵌入空间。

Result: 实验表明，该方法在复杂指令下将可控性提高了13.8%。

Conclusion: MIPCGRL能够处理复杂指令，使内容生成更具表现力和灵活性。

Abstract: Recent advancements in generative modeling emphasize the importance of
natural language as a highly expressive and accessible modality for controlling
content generation. However, existing instructed reinforcement learning for
procedural content generation (IPCGRL) method often struggle to leverage the
expressive richness of textual input, especially under complex, multi-objective
instructions, leading to limited controllability. To address this problem, we
propose \textit{MIPCGRL}, a multi-objective representation learning method for
instructed content generators, which incorporates sentence embeddings as
conditions. MIPCGRL effectively trains a multi-objective embedding space by
incorporating multi-label classification and multi-head regression networks.
Experimental results show that the proposed method achieves up to a 13.8\%
improvement in controllability with multi-objective instructions. The ability
to process complex instructions enables more expressive and flexible content
generation.

</details>


### [152] [Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments](https://arxiv.org/abs/2508.09194)
*Yipeng Du,Zihao Wang,Ahmad Farhan,Claudio Angione,Harry Yang,Fielding Johnston,James P. Buban,Patrick Colangelo,Yue Zhao,Yuzhe Yang*

Main category: cs.LG

TL;DR: 论文提出了一种基于元学习的框架，用于在分散系统中自动选择最优推理加速方案，以提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大规模模型部署成本高昂，分散系统成为趋势，但如何选择高效的推理加速方案是关键挑战。

Method: 引入元学习框架，利用历史性能数据自动选择适合任务的加速策略。

Result: 该框架较传统方法在效率和性能上表现更优。

Conclusion: 该研究为分散式AI系统提供了更经济、高效的解决方案。

Abstract: The deployment of large-scale models, such as large language models (LLMs),
incurs substantial costs due to their computational demands. To mitigate these
costs and address challenges related to scalability and data security, there is
a growing shift towards decentralized systems for model deployment, where
choosing efficient inference acceleration schemes become crucial to manage
computational resources effectively and enhance system responsiveness. In this
work, we address the challenge of selecting optimal acceleration methods in
decentralized systems by introducing a meta-learning-based framework. This
framework automates the selection process by learning from historical
performance data of various acceleration techniques across different tasks.
Unlike traditional methods that rely on random selection or expert intuition,
our approach systematically identifies the best acceleration strategies based
on the specific characteristics of each task. We demonstrate that our
meta-learning framework not only streamlines the decision-making process but
also consistently outperforms conventional methods in terms of efficiency and
performance. Our results highlight the potential of inference acceleration in
decentralized AI systems, offering a path towards more democratic and
economically feasible artificial intelligence solutions.

</details>


### [153] [ADT4Coupons: An Innovative Framework for Sequential Coupon Distribution in E-commerce](https://arxiv.org/abs/2508.09198)
*Li Kong,Bingzhe Wang,Zhou Chen,Suhan Hu,Yuchao Ma,Qi Qi,Suoyuan Song,Bicheng Jin*

Main category: cs.LG

TL;DR: 论文提出了一种名为ADT4Coupons的新型营销框架，通过整合通用场景、历史数据序列建模和迭代更新，优化在线优惠券分发策略以提升长期收入。


<details>
  <summary>Details</summary>
Motivation: 现有优惠券分发策略未能充分利用平台与用户之间的复杂序列交互，导致性能瓶颈。

Method: 提出ADT4Coupons框架，结合通用场景、历史数据序列建模和迭代更新，直接设计长期收入提升的优惠券分发策略。

Result: 在真实工业数据集、公开数据集和合成数据集上的实验验证了框架的优越性。

Conclusion: ADT4Coupons为优惠券分发提供了高效、灵活的解决方案，显著提升了长期收入。

Abstract: Coupon distribution is a critical marketing strategy used by online platforms
to boost revenue and enhance user engagement. Regrettably, existing coupon
distribution strategies fall far short of effectively leveraging the complex
sequential interactions between platforms and users. This critical oversight,
despite the abundance of e-commerce log data, has precipitated a performance
plateau. In this paper, we focus on the scene that the platforms make
sequential coupon distribution decision multiple times for various users, with
each user interacting with the platform repeatedly. Based on this marketing
scenario, we propose a novel marketing framework, named Aligned Decision
Transformer for Coupons (ADT4Coupons), to directly devise coupon distribution
policy for long-term revenue boosting. ADT4Coupons enables optimized online
decision-making in a variety of real-world marketing scenarios. It achieves
this by seamlessly integrating three key characteristics, general scenarios,
sequential modeling with more comprehensive historical data, and efficient
iterative updates within a unified framework. Furthermore, empirical results on
real-world industrial dataset, alongside public and synthetic datasets
demonstrate the superiority of our framework.

</details>


### [154] [Building Safer Sites: A Large-Scale Multi-Level Dataset for Construction Safety Research](https://arxiv.org/abs/2508.09203)
*Zhenhui Ou,Dawei Li,Zhen Tan,Wenlin Li,Huan Liu,Siyuan Song*

Main category: cs.LG

TL;DR: 本文介绍了CSDataset，一个全面的多层次建筑安全数据集，用于解决现有数据不足的问题，并通过机器学习和大语言模型提供分析支持。


<details>
  <summary>Details</summary>
Motivation: 现有建筑安全数据集规模小且多样性不足，限制了深入分析的可行性。

Method: 引入CSDataset，整合结构化属性和非结构化叙述，并进行初步基准测试和跨层次分析。

Result: 例如，投诉驱动的检查与后续事故可能性降低17.3%相关。

Conclusion: CSDataset为建筑安全研究提供了新的数据支持，推动了未来研究的进展。

Abstract: Construction safety research is a critical field in civil engineering, aiming
to mitigate risks and prevent injuries through the analysis of site conditions
and human factors. However, the limited volume and lack of diversity in
existing construction safety datasets pose significant challenges to conducting
in-depth analyses. To address this research gap, this paper introduces the
Construction Safety Dataset (CSDataset), a well-organized comprehensive
multi-level dataset that encompasses incidents, inspections, and violations
recorded sourced from the Occupational Safety and Health Administration (OSHA).
This dataset uniquely integrates structured attributes with unstructured
narratives, facilitating a wide range of approaches driven by machine learning
and large language models. We also conduct a preliminary approach benchmarking
and various cross-level analyses using our dataset, offering insights to inform
and enhance future efforts in construction safety. For example, we found that
complaint-driven inspections were associated with a 17.3% reduction in the
likelihood of subsequent incidents. Our dataset and code are released at
https://github.com/zhenhuiou/Construction-Safety-Dataset-CSDataset.

</details>


### [155] [MoQE: Improve Quantization Model performance via Mixture of Quantization Experts](https://arxiv.org/abs/2508.09204)
*Jinhao Zhang,Yunquan Zhang,Boyang Zhang,Zeyu Liu,Daning Cheng*

Main category: cs.LG

TL;DR: MoQE是一种基于MoE架构的量化推理框架，通过联合多个量化专家模型动态选择最优量化方案，缓解单一量化模型的性能下降问题，同时保持较低的推理延迟。


<details>
  <summary>Details</summary>
Motivation: 量化方法在提升模型效率和降低部署成本方面至关重要，但量化过程会带来精度下降的问题。作者旨在通过MoQE框架缓解这一问题。

Method: MoQE结合了一个全精度模型的多个量化变体作为专门的"量化专家"，并根据输入数据的特征动态路由到最合适的专家。设计了轻量级的、结构感知的路由器模型。

Result: 在ResNet、LLaMA和Qwen模型族以及多种基准数据集上的实验表明，MoQE的性能接近SOTA量化模型，且未显著增加推理延迟。

Conclusion: MoQE通过动态选择量化专家模型，有效缓解了量化带来的性能下降问题，同时保持了高效的推理速度，为量化方法的实际应用提供了新思路。

Abstract: Quantization method plays a crucial role in improving model efficiency and
reducing deployment costs, enabling the widespread application of deep learning
models on resource-constrained devices. However, the quantization process
inevitably introduces accuracy degradation. In this paper, we propose Mixture
of Quantization Experts( abbr. MoQE), a quantization inference framework based
on the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the
performance of quantization models. MoQE combines multiple quantization
variants of one full-precision model as specialized "quantization experts" and
dynamically routes input data to the most suitable expert based on its
characteristics. MoQE alleviates the performance degradation commonly seen in
single quantization models through specialization quantization expert models.
We design lightweight, structure-aware router models tailored for both CV and
NLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families
across benchmark datasets including ImageNet, WikiText, C4, and OpenWebText
demonstrate that MoQE achieves performance comparable to SOTA quantization
model, without incurring significant increases in inference latency.

</details>


### [156] [The First Differentiable Transfer-Based Algorithm for Discrete MicroLED Repair](https://arxiv.org/abs/2508.09206)
*Ning-Yuan Lue*

Main category: cs.LG

TL;DR: 提出一种基于可微分转移模块的修复算法，优化微LED修复过程，减少转移步骤50%，在2000x2000阵列中规划时间低于2分钟。


<details>
  <summary>Details</summary>
Motivation: 解决微LED制造中XY平台运动最小化和优化目标多变的问题，提升修复效率和灵活性。

Method: 使用可微分转移模块建模离散转移，实现梯度优化训练，避免了手工特征提取，训练速度更快。

Result: 相比局部邻近搜索和强化学习方法，实现更优修复性能和灵活目标设计，转移步骤减少50%。

Conclusion: 为AR/VR和下一代显示制造提供实用且适应性强的微LED修复加速方案。

Abstract: Laser-enabled selective transfer, a key process in high-throughput microLED
fabrication, requires computational models that can plan shift sequences to
minimize motion of XY stages and adapt to varying optimization objectives
across the substrate. We propose the first repair algorithm based on a
differentiable transfer module designed to model discrete shifts of transfer
platforms, while remaining trainable via gradient-based optimization. Compared
to local proximity searching algorithms, our approach achieves superior repair
performance and enables more flexible objective designs, such as minimizing the
number of steps. Unlike reinforcement learning (RL)-based approaches, our
method eliminates the need for handcrafted feature extractors and trains
significantly faster, allowing scalability to large arrays. Experiments show a
50% reduction in transfer steps and sub-2-minute planning time on 2000x2000
arrays. This method provides a practical and adaptable solution for
accelerating microLED repair in AR/VR and next-generation display fabrication.

</details>


### [157] [Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation](https://arxiv.org/abs/2508.09223)
*Sameer Ambekar,Daniel M. Lang,Julia A. Schnabel*

Main category: cs.LG

TL;DR: Hi-Vec是一种分层自适应网络，通过动态选择层和权重合并机制，解决了测试时适应中的复杂分布偏移问题，提高了鲁棒性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单维线性分类层，难以应对复杂多样的分布偏移，因此需要一种更灵活的自适应机制。

Method: Hi-Vec利用分层结构动态选择最优适应层，并通过权重合并和线性层协议机制防止噪声批次导致的错误优化。

Result: 实验表明，Hi-Vec在多种挑战性场景下显著提升了现有方法的性能，增强了鲁棒性并处理了不确定性。

Conclusion: Hi-Vec通过分层动态适应机制，为测试时适应提供了更灵活、更有效的解决方案。

Abstract: Test-time adaptation allows pretrained models to adjust to incoming data
streams, addressing distribution shifts between source and target domains.
However, standard methods rely on single-dimensional linear classification
layers, which often fail to handle diverse and complex shifts. We propose
Hierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages
multiple layers of increasing size for dynamic test-time adaptation. By
decomposing the encoder's representation space into such hierarchically
organized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to
adapt to shifts of varying complexity. Our contributions are threefold: First,
we propose dynamic layer selection for automatic identification of the optimal
layer for adaptation to each test batch. Second, we propose a mechanism that
merges weights from the dynamic layer to other layers, ensuring all layers
receive target information. Third, we propose linear layer agreement that acts
as a gating function, preventing erroneous fine-tuning by adaptation on noisy
batches. We rigorously evaluate the performance of Hi-Vec in challenging
scenarios and on multiple target datasets, proving its strong capability to
advance state-of-the-art methods. Our results show that Hi-Vec improves
robustness, addresses uncertainty, and handles limited batch sizes and
increased outlier rates.

</details>


### [158] [GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction](https://arxiv.org/abs/2508.09227)
*Fan Ding,Hwa Hui Tew,Junn Yong Loo,Susilawati,LiTong Liu,Fang Yu Leong,Xuewen Luo,Kar Keong Chin,Jia Jun Gan*

Main category: cs.LG

TL;DR: GSMT是一种混合模型，结合图注意力网络和RNN，用于公交车轨迹预测，在数据有限的城市环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在数据有限的地区，仅依赖GPS数据预测公交车轨迹具有挑战性，但仍是智能交通系统的关键需求。

Method: GSMT整合GAT和RNN，并通过任务校正器聚类历史轨迹以优化预测，采用两阶段方法融合动态与静态信息。

Result: 在吉隆坡的真实数据集上，GSMT在短长期轨迹预测任务中均显著优于现有方法。

Conclusion: GSMT通过混合模型和任务校正器，有效提升了复杂城市环境下的公交车轨迹预测性能。

Abstract: Accurate trajectory prediction for buses is crucial in intelligent
transportation systems, particularly within urban environments. In developing
regions where access to multimodal data is limited, relying solely on onboard
GPS data remains indispensable despite inherent challenges. To address this
problem, we propose GSMT, a hybrid model that integrates a Graph Attention
Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and
incorporates a task corrector capable of extracting complex behavioral patterns
from large-scale trajectory data. The task corrector clusters historical
trajectories to identify distinct motion patterns and fine-tunes the
predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus
information and static station information through embedded hybrid networks to
perform trajectory prediction, and applies the task corrector for secondary
refinement after the initial predictions are generated. This two-stage approach
enables multi-node trajectory prediction among buses operating in dense urban
traffic environments under complex conditions. Experiments conducted on a
real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method
significantly outperforms existing approaches, achieving superior performance
in both short-term and long-term trajectory prediction tasks.

</details>


### [159] [Blockchain Network Analysis using Quantum Inspired Graph Neural Networks & Ensemble Models](https://arxiv.org/abs/2508.09237)
*Luigi D'Amico,Daniel De Rosso,Ninad Dixit,Raul Salles de Padua,Samuel Palmer,Samuel Mugel,Román Orús,Holger Eble,Ali Abedi*

Main category: cs.LG

TL;DR: 本文提出了一种结合量子启发图神经网络（QI-GNN）和集成模型（如QBoost或随机森林分类器）的新方法，用于区块链网络中的反洗钱（AML）工作。通过引入一个新颖的Canonical Polyadic（CP）分解层，该方法显著提升了对复杂数据结构的处理能力。实验结果显示，该方法在检测欺诈交易时达到了74.8%的F2分数，表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 金融科技领域中，区块链网络中的非法交易检测是一个关键挑战，需要创新且稳健的解决方案。本文旨在通过量子启发技术和新型CP分解层提升复杂网络分析的性能。

Method: 本文提出了一种结合量子启发图神经网络（QI-GNN）和集成模型（QBoost或随机森林分类器）的方法，并引入了CP分解层以增强模型处理复杂数据结构的能力。

Result: 该方法在检测欺诈交易时达到了74.8%的F2分数，表现优于传统机器学习方法。

Conclusion: 研究结果表明，量子启发算法在金融安全领域的复杂网络分析中具有潜力，可能超越传统方法。建议进一步探索和推广量子启发技术在金融领域的应用以有效打击欺诈。

Abstract: In the rapidly evolving domain of financial technology, the detection of
illicit transactions within blockchain networks remains a critical challenge,
necessitating robust and innovative solutions. This work proposes a novel
approach by combining Quantum Inspired Graph Neural Networks (QI-GNN) with
flexibility of choice of an Ensemble Model using QBoost or a classic model such
as Random Forrest Classifier. This system is tailored specifically for
blockchain network analysis in anti-money laundering (AML) efforts. Our
methodology to design this system incorporates a novel component, a Canonical
Polyadic (CP) decomposition layer within the graph neural network framework,
enhancing its capability to process and analyze complex data structures
efficiently. Our technical approach has undergone rigorous evaluation against
classical machine learning implementations, achieving an F2 score of 74.8% in
detecting fraudulent transactions. These results highlight the potential of
quantum-inspired techniques, supplemented by the structural advancements of the
CP layer, to not only match but potentially exceed traditional methods in
complex network analysis for financial security. The findings advocate for a
broader adoption and further exploration of quantum-inspired algorithms within
the financial sector to effectively combat fraud.

</details>


### [160] [LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data](https://arxiv.org/abs/2508.09263)
*Peng Wang,Dongsheng Wang,He Zhao,Hangting Ye,Dandan Guo,Yi Chang*

Main category: cs.LG

TL;DR: 论文提出了一种基于LLM的原型估计框架，用于零样本和小样本的表格数据学习，通过无示例提示生成特征值，无需训练或微调。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLMs）在表格数据建模中潜力巨大，但在小样本和零样本场景中有效利用仍具挑战性。

Method: 通过无示例提示查询LLM生成特征值，构建零样本原型，并可融合小样本数据进一步优化，无需训练或微调。

Result: 实验证明该框架在零样本和小样本表格学习中表现有效。

Conclusion: 提出的方法突破了基于示例提示的限制，提供了一个可扩展且鲁棒的框架。

Abstract: Recent breakthroughs in large language models (LLMs) have opened the door to
in-depth investigation of their potential in tabular data modeling. However,
effectively utilizing advanced LLMs in few-shot and even zero-shot scenarios is
still challenging. To this end, we propose a novel LLM-based prototype
estimation framework for tabular learning. Our key idea is to query the LLM to
generate feature values based example-free prompt, which solely relies on task
and feature descriptions. With the feature values generated by LLM, we can
build a zero-shot prototype in a training-free manner, which can be further
enhanced by fusing few-shot samples, avoiding training a classifier or
finetuning the LLMs. Thanks to the example-free prompt and prototype
estimation, ours bypasses the constraints brought by the example-based prompt,
providing a scalable and robust framework. Extensive experiments demonstrate
the effectiveness of ours in zero and few-shot tabular learning.

</details>


### [161] [Detection of Odor Presence via Deep Neural Networks](https://arxiv.org/abs/2508.09264)
*Matin Hassanloo,Ali Zareh,Mehmet Kemal Özdemir*

Main category: cs.LG

TL;DR: 本研究提出了一种基于局部场电位（LFPs）的深度学习模型，用于高效单次气味检测，支持了两个假设并显著优于先前基准。


<details>
  <summary>Details</summary>
Motivation: 气味检测在食品安全、环境监测和医疗诊断等领域至关重要，但现有传感器难以处理复杂混合物，且非侵入式记录缺乏可靠的单次检测能力。

Method: 使用了两种互补的一维卷积网络（ResCNN和AttentionCNN）解码嗅球多通道LFPs中的气味信号，测试了七只清醒小鼠的2,349次试验。

Result: 最终模型平均准确率达86.6%，F1分数为81.0%，AUC为0.9247，显著优于先前基准。t-SNE可视化显示模型捕捉了生物学重要特征。

Conclusion: 研究表明从细胞外LFPs中实现单次气味检测的可行性，并展示了深度学习模型在加深对嗅觉表征理解的潜力。

Abstract: Odor detection underpins food safety, environmental monitoring, medical
diagnostics, and many more fields. The current artificial sensors developed for
odor detection struggle with complex mixtures while non-invasive recordings
lack reliable single-trial fidelity. To develop a general system for odor
detection, in this study we present a preliminary work where we aim to test two
hypotheses: (i) that spectral features of local field potentials (LFPs) are
sufficient for robust single-trial odor detection and (ii) that signals from
the olfactory bulb alone are adequate. To test two hypotheses, we propose an
ensemble of complementary one-dimensional convolutional networks (ResCNN and
AttentionCNN) that decodes the presence of odor from multichannel olfactory
bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble
model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score
of 81.0%, and an AUC of 0.9247, substantially outperforming previous
benchmarks. In addition, the t-SNE visualization confirms that our framework
captures biologically significant signatures. These findings establish the
feasibility of robust single-trial detection of the presence of odor from
extracellular LFPs, as well as demonstrate the potential of deep learning
models to provide a deeper understanding of olfactory representations.

</details>


### [162] [Over-Squashing in GNNs and Causal Inference of Rewiring Strategies](https://arxiv.org/abs/2508.09265)
*Danial Saber,Amirali Salehi-Abari*

Main category: cs.LG

TL;DR: 该论文提出了一个基于拓扑的方法评估图神经网络中的过度压缩问题，并通过实验证明重连技术能有效缓解这一问题，但效果因数据集和方法而异。


<details>
  <summary>Details</summary>
Motivation: 研究GNN中消息传递导致的远程信息过度压缩问题，解决缺乏直接评估指标的问题，提出实用的诊断工具。

Method: 利用节点间相互敏感性的衰减率评估过度压缩，扩展为四种图级统计量，结合因果设计量化重连策略的效果。

Result: 实验表明大多数图分类数据集存在过度压缩，重连可有效缓解；节点分类数据集中问题较小，重连可能适得其反。

Conclusion: 重连技术对解决过度压缩问题有效，但需谨慎使用，特别是在问题轻微时可能带来负面影响。

Abstract: Graph neural networks (GNNs) have exhibited state-of-the-art performance
across wide-range of domains such as recommender systems, material design, and
drug repurposing. Yet message-passing GNNs suffer from over-squashing --
exponential compression of long-range information from distant nodes -- which
limits expressivity. Rewiring techniques can ease this bottleneck; but their
practical impacts are unclear due to the lack of a direct empirical
over-squashing metric. We propose a rigorous, topology-focused method for
assessing over-squashing between node pairs using the decay rate of their
mutual sensitivity. We then extend these pairwise assessments to four
graph-level statistics (prevalence, intensity, variability, extremity).
Coupling these metrics with a within-graph causal design, we quantify how
rewiring strategies affect over-squashing on diverse graph- and
node-classification benchmarks. Our extensive empirical analyses show that most
graph classification datasets suffer from over-squashing (but to various
extents), and rewiring effectively mitigates it -- though the degree of
mitigation, and its translation into performance gains, varies by dataset and
method. We also found that over-squashing is less notable in node
classification datasets, where rewiring often increases over-squashing, and
performance variations are uncorrelated with over-squashing changes. These
findings suggest that rewiring is most beneficial when over-squashing is both
substantial and corrected with restraint -- while overly aggressive rewiring,
or rewiring applied to minimally over-squashed graphs, is unlikely to help and
may even harm performance. Our plug-and-play diagnostic tool lets practitioners
decide -- before any training -- whether rewiring is likely to pay off.

</details>


### [163] [Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.09275)
*Amine Andam,Jamal Bentahar,Mustapha Hedabou*

Main category: cs.LG

TL;DR: 论文研究多智能体强化学习在现实对抗条件下的新漏洞，提出一种简单高效的攻击算法。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体强化学习在现实场景中的安全性漏洞，弥补现有研究对训练时攻击或不切实际假设的依赖。

Method: 假设攻击者仅能收集并扰动部署智能体的观测数据，提出高效生成对抗扰动的算法。

Result: 在3个基准和22种环境中的实验验证了算法的有效性，且样本效率显著优于现有方法。

Conclusion: 提出的算法在多智能体强化学习安全领域具有实际应用价值。

Abstract: Collaborative multi-agent reinforcement learning (c-MARL) has rapidly
evolved, offering state-of-the-art algorithms for real-world applications,
including sensitive domains. However, a key challenge to its widespread
adoption is the lack of a thorough investigation into its vulnerabilities to
adversarial attacks. Existing work predominantly focuses on training-time
attacks or unrealistic scenarios, such as access to policy weights or the
ability to train surrogate policies. In this paper, we investigate new
vulnerabilities under more realistic and constrained conditions, assuming an
adversary can only collect and perturb the observations of deployed agents. We
also consider scenarios where the adversary has no access at all. We propose
simple yet highly effective algorithms for generating adversarial perturbations
designed to misalign how victim agents perceive their environment. Our approach
is empirically validated on three benchmarks and 22 environments, demonstrating
its effectiveness across diverse algorithms and environments. Furthermore, we
show that our algorithm is sample-efficient, requiring only 1,000 samples
compared to the millions needed by previous methods.

</details>


### [164] [Pattern-based Knowledge Component Extraction from Student Code Using Representation Learning](https://arxiv.org/abs/2508.09281)
*Muntasir Hoq,Griffin Pitts,Andrew Lan,Peter Brusilovsky,Bita Akram*

Main category: cs.LG

TL;DR: 论文提出了一种基于模式的自动知识成分发现框架，通过变分自编码器和可解释的注意力模型提取学生代码中的关键模式，改善了计算机科学教育中的个性化学习建模。


<details>
  <summary>Details</summary>
Motivation: 在计算机科学教育中，准确的个性化学习需要有效建模学生的知识掌握情况，但传统方法因代码多样性和概念复杂性面临挑战。

Method: 提出一种基于模式的知识成分提取框架，结合变分自编码器和注意力模型，从学生代码中生成和聚类代表性模式。

Result: 实验结果表明，学习曲线分析和深度知识追踪（DKT）验证了该方法的有效性，其预测性能优于传统知识追踪方法。

Conclusion: 该框架为计算机科学教育提供了自动化、可扩展且可解释的知识建模方法，有助于提升学生学习的精细化指导。

Abstract: Effective personalized learning in computer science education depends on
accurately modeling what students know and what they need to learn. While
Knowledge Components (KCs) provide a foundation for such modeling, automated KC
extraction from student code is inherently challenging due to insufficient
explainability of discovered KCs and the open-endedness of programming problems
with significant structural variability across student solutions and complex
interactions among programming concepts. In this work, we propose a novel,
explainable framework for automated KC discovery through pattern-based KCs:
recurring structural patterns within student code that capture the specific
programming patterns and language constructs that students must master. Toward
this, we train a Variational Autoencoder to generate important representative
patterns from student code guided by an explainable, attention-based code
representation model that identifies important correct and incorrect pattern
implementations from student code. These patterns are then clustered to form
pattern-based KCs. We evaluate our KCs using two well-established methods
informed by Cognitive Science: learning curve analysis and Deep Knowledge
Tracing (DKT). Experimental results demonstrate meaningful learning
trajectories and significant improvements in DKT predictive performance over
traditional KT methods. This work advances knowledge modeling in CS education
by providing an automated, scalable, and explainable framework for identifying
granular code patterns and algorithmic constructs, essential for student
learning.

</details>


### [165] [Distilling Reinforcement Learning into Single-Batch Datasets](https://arxiv.org/abs/2508.09283)
*Connor Wilhelm,Dan Ventura*

Main category: cs.LG

TL;DR: 这篇论文研究了如何将大型数据集压缩成小型合成数据集，通过一梯度步进实现高效学习，并展示了其在强化学习任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索数据集蒸馏技术在不同任务中的通用性，尤其是将强化学习环境压缩为一批量监督学习数据集，以验证其跨学习模态的能力。

Method: 提出了一种近端策略优化的新扩展用于元学习，并在多个任务（如MuJoCo环境和Atari游戏）中进行了应用。

Result: 成功将复杂强化学习环境压缩为一步监督学习数据集，并验证了其在不同学习架构中的通用性。

Conclusion: 数据集蒸馏技术不仅能高效压缩任务，还能实现不同学习模态间的转换，展示了广泛的应用潜力。

Abstract: Dataset distillation compresses a large dataset into a small synthetic
dataset such that learning on the synthetic dataset approximates learning on
the original. Training on the distilled dataset can be performed in as little
as one step of gradient descent. We demonstrate that distillation is
generalizable to different tasks by distilling reinforcement learning
environments into one-batch supervised learning datasets. This demonstrates not
only distillation's ability to compress a reinforcement learning task but also
its ability to transform one learning modality (reinforcement learning) into
another (supervised learning). We present a novel extension of proximal policy
optimization for meta-learning and use it in distillation of a
multi-dimensional extension of the classic cart-pole problem, all MuJoCo
environments, and several Atari games. We demonstrate distillation's ability to
compress complex RL environments into one-step supervised learning, explore RL
distillation's generalizability across learner architectures, and demonstrate
distilling an environment into the smallest-possible synthetic dataset.

</details>


### [166] [Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation](https://arxiv.org/abs/2508.09299)
*Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi*

Main category: cs.LG

TL;DR: 论文提出了一种结合联邦学习和区块链技术的去中心化天气预报框架，旨在解决现有系统的安全漏洞、扩展性不足和单点故障问题。


<details>
  <summary>Details</summary>
Motivation: 当前集中式天气预报系统存在安全隐患、扩展性差和易受单点故障影响的问题，因此需要一种更安全、更可靠的解决方案。

Method: 结合联邦学习（保护本地数据隐私，减少数据传输开销）和区块链技术（确保模型更新的透明性和可靠性），并引入基于信誉的投票机制和IPFS存储以增强系统安全性。

Result: 实验结果表明，该框架提高了预报准确性，同时增强了系统的韧性和扩展性。

Conclusion: 这一去中心化框架是现实世界中安全关键环境中部署的可行候选方案。

Abstract: Weather forecasting plays a vital role in disaster preparedness, agriculture,
and resource management, yet current centralized forecasting systems are
increasingly strained by security vulnerabilities, limited scalability, and
susceptibility to single points of failure. To address these challenges, we
propose a decentralized weather forecasting framework that integrates Federated
Learning (FL) with blockchain technology. FL enables collaborative model
training without exposing sensitive local data; this approach enhances privacy
and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures
transparent and dependable verification of model updates. To further enhance
the system's security, we introduce a reputation-based voting mechanism that
assesses the trustworthiness of submitted models while utilizing the
Interplanetary File System (IPFS) for efficient off-chain storage. Experimental
results demonstrate that our approach not only improves forecasting accuracy
but also enhances system resilience and scalability, making it a viable
candidate for deployment in real-world, security-critical environments.

</details>


### [167] [Exact Verification of Graph Neural Networks with Incremental Constraint Solving](https://arxiv.org/abs/2508.09320)
*Minghao Liu,Chia-Hsuan Lu,Marta Kwiatkowska*

Main category: cs.LG

TL;DR: 本文提出了一种名为GNNev的精确验证方法，用于计算图神经网络的对抗鲁棒性保证，支持多种聚合函数，并通过实验证明了其有效性和优越性能。


<details>
  <summary>Details</summary>
Motivation: 图神经网络在高风险应用中容易受到对抗攻击，现有技术对常用聚合函数的支持不足，因此需要开发更全面的验证方法。

Method: 采用约束求解和边界收紧技术，迭代解决一系列松弛约束满足问题，并利用求解器的增量求解能力提高效率。

Result: 在多个数据集上的实验表明，GNNev在支持多种聚合函数的同时，性能优于现有工具。

Conclusion: GNNev提供了一种高效的精确验证方法，填补了现有技术在聚合函数支持上的空白。

Abstract: Graph neural networks (GNNs) are increasingly employed in high-stakes
applications, such as fraud detection or healthcare, but are susceptible to
adversarial attacks. A number of techniques have been proposed to provide
adversarial robustness guarantees, but support for commonly used aggregation
functions in message-passing GNNs is still lacking. In this paper, we develop
an exact (sound and complete) verification method for GNNs to compute
guarantees against attribute and structural perturbations that involve edge
addition or deletion, subject to budget constraints. Focusing on node
classification tasks, our method employs constraint solving with bound
tightening, and iteratively solves a sequence of relaxed constraint
satisfaction problems while relying on incremental solving capabilities of
solvers to improve efficiency. We implement GNNev, a versatile solver for
message-passing neural networks, which supports three aggregation functions,
sum, max and mean, with the latter two considered here for the first time.
Extensive experimental evaluation of GNNev on two standard benchmarks (Cora and
CiteSeer) and two real-world fraud datasets (Amazon and Yelp) demonstrates its
usability and effectiveness, as well as superior performance compared to
existing {exact verification} tools on sum-aggregated node classification
tasks.

</details>


### [168] [Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization](https://arxiv.org/abs/2508.09330)
*Gideon Vos,Liza van Eijk,Zoltan Sarnyai,Mostafa Rahimi Azghadi*

Main category: cs.LG

TL;DR: 该论文提出了一种基于重要性的突触修剪方法，模拟生物大脑的修剪过程，通过逐渐移除低重要性连接来提高神经网络效率，无需单独的修剪和微调阶段。在多个时间序列预测模型中表现优异，尤其在金融预测中显著降低误差。


<details>
  <summary>Details</summary>
Motivation: 受生物大脑突触修剪的启发，提出一种更符合生物学的修剪方法，以替代传统的随机失活（dropout）正则化技术，提高神经网络的效率和性能。

Method: 基于权重的绝对重要性逐步修剪低重要性连接，采用立方调度增加全局稀疏度，并在训练过程中直接应用修剪掩码，保持梯度流动。

Result: 在多个时间序列预测模型中表现最佳，显著降低了预测误差（如金融预测中MAE降低多达20%），并通过统计测试确认了其优越性。

Conclusion: 该方法通过动态修剪机制改进了正则化技术，易于集成到不同架构中，尤其是在金融时间序列预测中表现出巨大潜力。

Abstract: Synaptic pruning in biological brains removes weak connections to improve
efficiency. In contrast, dropout regularization in artificial neural networks
randomly deactivates neurons without considering activity-dependent pruning. We
propose a magnitude-based synaptic pruning method that better reflects biology
by progressively removing low-importance connections during training.
Integrated directly into the training loop as a dropout replacement, our
approach computes weight importance from absolute magnitudes across layers and
applies a cubic schedule to gradually increase global sparsity. At fixed
intervals, pruning masks permanently remove low-importance weights while
maintaining gradient flow for active ones, eliminating the need for separate
pruning and fine-tuning phases. Experiments on multiple time series forecasting
models including RNN, LSTM, and Patch Time Series Transformer across four
datasets show consistent gains. Our method ranked best overall, with
statistically significant improvements confirmed by Friedman tests (p < 0.01).
In financial forecasting, it reduced Mean Absolute Error by up to 20% over
models with no or standard dropout, and up to 52% in select transformer models.
This dynamic pruning mechanism advances regularization by coupling weight
elimination with progressive sparsification, offering easy integration into
diverse architectures. Its strong performance, especially in financial time
series forecasting, highlights its potential as a practical alternative to
conventional dropout techniques.

</details>


### [169] [RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs](https://arxiv.org/abs/2508.09334)
*Zhongtian Sun,Anoushka Harit*

Main category: cs.LG

TL;DR: 提出RicciFlowRec，一种基于几何的推荐框架，通过Ricci曲率和流分析动态金融图中的根因，提升稳健性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过几何方法量化金融图中的局部压力并追踪冲击传播，以支持金融决策。

Method: 利用Ricci曲率和流建模股票、宏观经济指标和新闻的交互，通过曲率梯度揭示因果子结构。

Result: 初步结果表明，在S&P 500数据和FinBERT情感分析下，框架在合成扰动下表现更稳健和可解释。

Conclusion: RicciFlowRec是首个在金融决策中应用几何流推理的推荐系统，未来计划拓展至组合优化和回报预测。

Abstract: We propose RicciFlowRec, a geometric recommendation framework that performs
root cause attribution via Ricci curvature and flow on dynamic financial
graphs. By modelling evolving interactions among stocks, macroeconomic
indicators, and news, we quantify local stress using discrete Ricci curvature
and trace shock propagation via Ricci flow. Curvature gradients reveal causal
substructures, informing a structural risk-aware ranking function. Preliminary
results on S\&P~500 data with FinBERT-based sentiment show improved robustness
and interpretability under synthetic perturbations. This ongoing work supports
curvature-based attribution and early-stage risk-aware ranking, with plans for
portfolio optimization and return forecasting. To our knowledge, RicciFlowRec
is the first recommender to apply geometric flow-based reasoning in financial
decision support.

</details>


### [170] [Resurrecting the Salmon: Rethinking Mechanistic Interpretability with Domain-Specific Sparse Autoencoders](https://arxiv.org/abs/2508.09363)
*Charles O'Neill,Mudith Jayasekara,Max Kirkby*

Main category: cs.LG

TL;DR: 论文研究通过限制稀疏自编码器（SAEs）的训练范围为特定领域（如医学文本），提高了特征分解的重建保真度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的SAEs在广泛数据分布上训练时，往往只能捕获高频通用模式，导致重建误差中的线性“暗物质”和特征碎片化问题，影响可解释性。

Method: 研究通过将SAEs训练限制在医学文本领域，使用JumpReLU SAEs在Gemma-2模型的第20层激活上进行训练，并与广泛领域SAEs进行对比。

Result: 领域限制的SAEs解释了更多方差（高达20%）、实现了更高的损失恢复，并减少了线性残差误差。学习到的特征与临床相关概念一致。

Conclusion: 领域限制缓解了广泛领域SAEs的关键限制，为更完整和可解释的潜在分解提供了可能，并质疑了通用SAEs的“基础模型”扩展。

Abstract: Sparse autoencoders (SAEs) decompose large language model (LLM) activations
into latent features that reveal mechanistic structure. Conventional SAEs train
on broad data distributions, forcing a fixed latent budget to capture only
high-frequency, generic patterns. This often results in significant linear
``dark matter'' in reconstruction error and produces latents that fragment or
absorb each other, complicating interpretation. We show that restricting SAE
training to a well-defined domain (medical text) reallocates capacity to
domain-specific features, improving both reconstruction fidelity and
interpretability. Training JumpReLU SAEs on layer-20 activations of Gemma-2
models using 195k clinical QA examples, we find that domain-confined SAEs
explain up to 20\% more variance, achieve higher loss recovery, and reduce
linear residual error compared to broad-domain SAEs. Automated and human
evaluations confirm that learned features align with clinically meaningful
concepts (e.g., ``taste sensations'' or ``infectious mononucleosis''), rather
than frequent but uninformative tokens. These domain-specific SAEs capture
relevant linear structure, leaving a smaller, more purely nonlinear residual.
We conclude that domain-confinement mitigates key limitations of broad-domain
SAEs, enabling more complete and interpretable latent decompositions, and
suggesting the field may need to question ``foundation-model'' scaling for
general-purpose SAEs.

</details>


### [171] [Understanding Dementia Speech Alignment with Diffusion-Based Image Generation](https://arxiv.org/abs/2508.09385)
*Mansi,Anastasios Lepipas,Dominika Woszczyk,Yiying Guan,Soteris Demetriou*

Main category: cs.LG

TL;DR: 该论文研究了文本到图像模型是否能将痴呆相关语音信息与生成图像对齐，并在ADReSS数据集中实现了75%的准确率。


<details>
  <summary>Details</summary>
Motivation: 探讨文本到图像模型是否能对齐痴呆相关语音信息与生成图像，并解释这种对齐性。

Method: 通过生成图像分析痴呆检测的可行性，并利用可解释性方法识别关键语言特征。

Result: 在ADReSS数据集中，仅通过生成图像实现75%的痴呆检测准确率。

Conclusion: 文本到图像模型可以用于痴呆检测，且通过可解释性方法揭示了关键语言特征。

Abstract: Text-to-image models generate highly realistic images based on natural
language descriptions and millions of users use them to create and share images
online. While it is expected that such models can align input text and
generated image in the same latent space little has been done to understand
whether this alignment is possible between pathological speech and generated
images. In this work, we examine the ability of such models to align
dementia-related speech information with the generated images and develop
methods to explain this alignment. Surprisingly, we found that dementia
detection is possible from generated images alone achieving 75% accuracy on the
ADReSS dataset. We then leverage explainability methods to show which parts of
the language contribute to the detection.

</details>


### [172] [Integrating Feature Attention and Temporal Modeling for Collaborative Financial Risk Assessment](https://arxiv.org/abs/2508.09399)
*Yue Yao,Zhen Xu,Youzhu Liu,Kunyuan Ma,Yuxiu Lin,Mohan Jiang*

Main category: cs.LG

TL;DR: 论文提出了一种基于联邦学习的风险评估框架，用于跨机构金融风险分析，通过特征注意力和时态建模结构实现联合建模，同时保护数据隐私。实验证明该方法优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决跨机构金融风险分析中的数据隐私和协作建模挑战。

Method: 采用联邦学习结合特征注意力机制和时态建模结构，分布式优化策略，局部模型训练后通过差分隐私和噪声注入保护参数上传。

Result: 实验表明，该方法在通效率、模型精度、系统风险检测和跨市场泛化方面优于传统方法。

Conclusion: 该方法为敏感金融环境提供了一种安全高效的智能风险分析方案，增强了风险识别的范围和效率，同时保护了数据主权。

Abstract: This paper addresses the challenges of data privacy and collaborative
modeling in cross-institution financial risk analysis. It proposes a risk
assessment framework based on federated learning. Without sharing raw data, the
method enables joint modeling and risk identification across multiple
institutions. This is achieved by incorporating a feature attention mechanism
and temporal modeling structure. Specifically, the model adopts a distributed
optimization strategy. Each financial institution trains a local sub-model. The
model parameters are protected using differential privacy and noise injection
before being uploaded. A central server then aggregates these parameters to
generate a global model. This global model is used for systemic risk
identification. To validate the effectiveness of the proposed method, multiple
experiments are conducted. These evaluate communication efficiency, model
accuracy, systemic risk detection, and cross-market generalization. The results
show that the proposed model outperforms both traditional centralized methods
and existing federated learning variants across all evaluation metrics. It
demonstrates strong modeling capabilities and practical value in sensitive
financial environments. The method enhances the scope and efficiency of risk
identification while preserving data sovereignty. It offers a secure and
efficient solution for intelligent financial risk analysis.

</details>


### [173] [Graph Neural Network and Transformer Integration for Unsupervised System Anomaly Discovery](https://arxiv.org/abs/2508.09401)
*Yun Zi,Ming Gong,Zhihao Xue,Yujun Zou,Nia Qi,Yingnan Deng*

Main category: cs.LG

TL;DR: 提出了一种无监督异常检测方法，用于分布式后端服务系统，通过动态图和Transformer结合捕捉结构与行为特征，实验结果优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决分布式服务系统中的复杂结构依赖、行为多样性和无标签数据等实际挑战。

Method: 构建动态图提取结构特征，使用Transformer建模时序行为，通过联合嵌入机制融合特征并计算异常分数。

Result: 在真实云监控数据上表现优于现有模型，具有更强的表达能力和稳定性。

Conclusion: 该方法在无监督情况下能有效捕捉异常传播路径和动态行为序列，适合实际部署。

Abstract: This study proposes an unsupervised anomaly detection method for distributed
backend service systems, addressing practical challenges such as complex
structural dependencies, diverse behavioral evolution, and the absence of
labeled data. The method constructs a dynamic graph based on service invocation
relationships and applies graph convolution to extract high-order structural
representations from multi-hop topologies. A Transformer is used to model the
temporal behavior of each node, capturing long-term dependencies and local
fluctuations. During the feature fusion stage, a learnable joint embedding
mechanism integrates structural and behavioral representations into a unified
anomaly vector. A nonlinear mapping is then applied to compute anomaly scores,
enabling an end-to-end detection process without supervision. Experiments on
real-world cloud monitoring data include sensitivity analyses across different
graph depths, sequence lengths, and data perturbations. Results show that the
proposed method outperforms existing models on several key metrics,
demonstrating stronger expressiveness and stability in capturing anomaly
propagation paths and modeling dynamic behavior sequences, with high potential
for practical deployment.

</details>


### [174] [Domain-Generalization to Improve Learning in Meta-Learning Algorithms](https://arxiv.org/abs/2508.09418)
*Usman Anjum,Chris Stockman,Cat Luong,Justin Zhan*

Main category: cs.LG

TL;DR: DGS-MAML是一种新的元学习算法，结合梯度匹配和锐度感知最小化，提升模型适应性和鲁棒性，在小样本学习任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决小样本学习中模型泛化能力不足的问题。

Method: 结合梯度匹配和锐度感知最小化，采用双层优化框架，并通过PAC-Bayes理论分析收敛性。

Result: 在基准数据集上，DGS-MAML在准确率和泛化能力上优于现有方法。

Conclusion: DGS-MAML在小样本学习和快速适应任务中表现出色，源代码已公开。

Abstract: This paper introduces Domain Generalization Sharpness-Aware Minimization
Model-Agnostic Meta-Learning (DGS-MAML), a novel meta-learning algorithm
designed to generalize across tasks with limited training data. DGS-MAML
combines gradient matching with sharpness-aware minimization in a bi-level
optimization framework to enhance model adaptability and robustness. We support
our method with theoretical analysis using PAC-Bayes and convergence
guarantees. Experimental results on benchmark datasets show that DGS-MAML
outperforms existing approaches in terms of accuracy and generalization. The
proposed method is particularly useful for scenarios requiring few-shot
learning and quick adaptation, and the source code is publicly available at
GitHub.

</details>


### [175] [Implicit Hypergraph Neural Networks: A Stable Framework for Higher-Order Relational Learning with Provable Guarantees](https://arxiv.org/abs/2508.09427)
*Xiaoyu Li,Guangyu Tang,Jiaojiao Jiang*

Main category: cs.LG

TL;DR: 论文提出了一种隐式超图神经网络（IHGNN），通过非线性固定点方程计算表示，解决了传统超图神经网络依赖固定层数的问题，实现了更稳定和高效的长程依赖捕获。实验表明IHGNN在准确性和鲁棒性上均优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现实中的交互通常是群体性的（如多作者论文），传统超图神经网络依赖固定层数，限制了长程依赖捕获和训练稳定性。

Method: 提出隐式超图神经网络（IHGNN），通过非线性固定点方程计算表示，无需堆叠多层；开发了收敛性可证明的训练方案，并分析了模型表达能力和过平滑条件。

Result: 在引用数据集上的实验显示，IHGNN在准确性和鲁棒性上均优于基线方法，且对初始化和超参数变化具有鲁棒性。

Conclusion: IHGNN为高阶关系学习提供了高效且稳定的解决方案，具有强泛化能力和实用价值。

Abstract: Many real-world interactions are group-based rather than pairwise such as
papers with multiple co-authors and users jointly engaging with items.
Hypergraph neural networks have shown great promise at modeling higher-order
relations, but their reliance on a fixed number of explicit message-passing
layers limits long-range dependency capture and can destabilize training as
depth grows. In this work, we introduce Implicit Hypergraph Neural Networks
(IHGNN), which bring the implicit equilibrium formulation to hypergraphs:
instead of stacking layers, IHGNN computes representations as the solution to a
nonlinear fixed-point equation, enabling stable and efficient global
propagation across hyperedges without deep architectures. We develop a
well-posed training scheme with provable convergence, analyze the oversmoothing
conditions and expressivity of the model, and derive a transductive
generalization bound on hypergraphs. We further present an implicit-gradient
training procedure coupled with a projection-based stabilization strategy.
Extensive experiments on citation benchmarks show that IHGNN consistently
outperforms strong traditional graph/hypergraph neural network baselines in
both accuracy and robustness. Empirically, IHGNN is resilient to random
initialization and hyperparameter variation, highlighting its strong
generalization and practical value for higher-order relational learning.

</details>


### [176] [NEXICA: Discovering Road Traffic Causality (Extended arXiv Version)](https://arxiv.org/abs/2508.09447)
*Siddharth Srikanth,John Krumm,Jonathan Qin*

Main category: cs.LG

TL;DR: 该论文提出了一种名为NEXICA的算法，用于识别高速公路系统中引发拥堵的因果关系，其通过分析时间序列中的事件并使用概率模型和分类器，显著提升了准确性和计算速度。


<details>
  <summary>Details</summary>
Motivation: 道路拥堵是一个长期问题，通过集中资源解决拥堵根源可能更高效。

Method: 1. 专注于时间序列中事件的有无；2. 开发基于最大似然估计的概率模型；3. 训练二元分类器识别因果对。

Result: 在洛杉矶地区的数据测试中，NEXICA在准确性和计算速度上优于现有基线方法。

Conclusion: NEXICA为交通拥堵的因果发现提供了一种高效且新颖的解决方案。

Abstract: Road traffic congestion is a persistent problem. Focusing resources on the
causes of congestion is a potentially efficient strategy for reducing
slowdowns. We present NEXICA, an algorithm to discover which parts of the
highway system tend to cause slowdowns on other parts of the highway. We use
time series of road speeds as inputs to our causal discovery algorithm. Finding
other algorithms inadequate, we develop a new approach that is novel in three
ways. First, it concentrates on just the presence or absence of events in the
time series, where an event indicates the temporal beginning of a traffic
slowdown. Second, we develop a probabilistic model using maximum likelihood
estimation to compute the probabilities of spontaneous and caused slowdowns
between two locations on the highway. Third, we train a binary classifier to
identify pairs of cause/effect locations trained on pairs of road locations
where we are reasonably certain a priori of their causal connections, both
positive and negative. We test our approach on six months of road speed data
from 195 different highway speed sensors in the Los Angeles area, showing that
our approach is superior to state-of-the-art baselines in both accuracy and
computation speed.

</details>


### [177] [A Unified Contrastive-Generative Framework for Time Series Classification](https://arxiv.org/abs/2508.09451)
*Ziyu Liu,Azadeh Alavi,Minyi Li,Xiang Zhang*

Main category: cs.LG

TL;DR: 提出了一种名为CoGenT的统一框架，结合对比学习与生成方法，优化自监督学习在多元时间序列中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在多元时间序列中主要分为对比学习和生成方法，两者优势互补但尚未结合。

Method: 通过联合对比-生成优化框架（CoGenT），克服了对比学习对类内相似性的敏感性和生成方法对大数据集的依赖。

Result: 在六个数据集上测试，F1分数比SimCLR提高了59.2%，比MAE提高了14.27%。

Conclusion: 混合目标保留了判别能力并提升了生成鲁棒性，为时间序列领域的混合自监督学习奠定基础。

Abstract: Self-supervised learning (SSL) for multivariate time series mainly includes
two paradigms: contrastive methods that excel at instance discrimination and
generative approaches that model data distributions. While effective
individually, their complementary potential remains unexplored. We propose a
Contrastive Generative Time series framework (CoGenT), the first framework to
unify these paradigms through joint contrastive-generative optimization. CoGenT
addresses fundamental limitations of both approaches: it overcomes contrastive
learning's sensitivity to high intra-class similarity in temporal data while
reducing generative methods' dependence on large datasets. We evaluate CoGenT
on six diverse time series datasets. The results show consistent improvements,
with up to 59.2% and 14.27% F1 gains over standalone SimCLR and MAE,
respectively. Our analysis reveals that the hybrid objective preserves
discriminative power while acquiring generative robustness. These findings
establish a foundation for hybrid SSL in temporal domains. We will release the
code shortly.

</details>


### [178] [Open-Set Fault Diagnosis in Multimode Processes via Fine-Grained Deep Feature Representation](https://arxiv.org/abs/2508.09462)
*Guangqiang Li,M. Amine Atoui,Xiangshun Li*

Main category: cs.LG

TL;DR: 提出了一种名为FGCRN的新型开放集故障诊断模型，用于准确分类已知健康状态并识别未知故障。


<details>
  <summary>Details</summary>
Motivation: 解决多模式过程中同一健康状态样本分布复杂、难以构建紧凑决策边界的问题。

Method: 结合多尺度深度卷积、双向门控循环单元和时序注意力机制提取特征，设计基于距离的损失函数增强类内紧凑性，通过无监督学习构建细粒度特征表示。

Result: 实验表明该方法性能优越。

Conclusion: FGCRN能有效分类已知状态并识别未知故障，适用于多模式过程。

Abstract: A reliable fault diagnosis system should not only accurately classify known
health states but also effectively identify unknown faults. In multimode
processes, samples belonging to the same health state often show multiple
cluster distributions, making it difficult to construct compact and accurate
decision boundaries for that state. To address this challenge, a novel open-set
fault diagnosis model named fine-grained clustering and rejection network
(FGCRN) is proposed. It combines multiscale depthwise convolution,
bidirectional gated recurrent unit and temporal attention mechanism to capture
discriminative features. A distance-based loss function is designed to enhance
the intra-class compactness. Fine-grained feature representations are
constructed through unsupervised learning to uncover the intrinsic structures
of each health state. Extreme value theory is employed to model the distance
between sample features and their corresponding fine-grained representations,
enabling effective identification of unknown faults. Extensive experiments
demonstrate the superior performance of the proposed method.

</details>


### [179] [Learn to Explore: Meta NAS via Bayesian Optimization Guided Graph Generation](https://arxiv.org/abs/2508.09467)
*Zijun Sun,Yanning Shen*

Main category: cs.LG

TL;DR: GraB-NAS 是一种新型 Meta-NAS 框架，通过将神经网络架构建模为图并结合全局和局部搜索策略，显著提升泛化能力和搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有 Meta-NAS 方法存在泛化能力差、搜索空间有限或计算成本高的问题，GraB-NAS 旨在通过改进搜索策略解决这些问题。

Method: GraB-NAS 将架构建模为图，结合贝叶斯优化的全局搜索和梯度上升的局部探索，生成高性能任务感知架构。

Result: 实验表明，GraB-NAS 在泛化能力和搜索效率上优于现有 Meta-NAS 基线，甚至超越预定义搜索空间。

Conclusion: GraB-NAS 是一种高效且通用的 Meta-NAS 框架，解决了现有方法的局限性，展现出强大的性能潜力。

Abstract: Neural Architecture Search (NAS) automates the design of high-performing
neural networks but typically targets a single predefined task, thereby
restricting its real-world applicability. To address this, Meta Neural
Architecture Search (Meta-NAS) has emerged as a promising paradigm that
leverages prior knowledge across tasks to enable rapid adaptation to new ones.
Nevertheless, existing Meta-NAS methods often struggle with poor
generalization, limited search spaces, or high computational costs. In this
paper, we propose a novel Meta-NAS framework, GraB-NAS. Specifically, GraB-NAS
first models neural architectures as graphs, and then a hybrid search strategy
is developed to find and generate new graphs that lead to promising neural
architectures. The search strategy combines global architecture search via
Bayesian Optimization in the search space with local exploration for novel
neural networks via gradient ascent in the latent space. Such a hybrid search
strategy allows GraB-NAS to discover task-aware architectures with strong
performance, even beyond the predefined search space. Extensive experiments
demonstrate that GraB-NAS outperforms state-of-the-art Meta-NAS baselines,
achieving better generalization and search effectiveness.

</details>


### [180] [DeepFeatIoT: Unifying Deep Learned, Randomized, and LLM Features for Enhanced IoT Time Series Sensor Data Classification in Smart Industries](https://arxiv.org/abs/2508.09468)
*Muhammad Sakib Khan Inan,Kewen Liao*

Main category: cs.LG

TL;DR: 提出一种名为DeepFeatIoT的新型深度学习模型，通过结合学习与非学习特征，显著提升了物联网时间序列数据的分类效果。


<details>
  <summary>Details</summary>
Motivation: 物联网传感器数据由于元数据丢失、数据源异构、采样频率不一致等问题，难以直接用于智能系统的分析。

Method: 提出DeepFeatIoT模型，融合局部与全局学习特征、随机卷积核特征及大型语言模型特征。

Result: 在多种真实物联网数据集上表现优于现有基准模型，尤其在标记数据有限的情况下。

Conclusion: 该模型有助于推动物联网分析的发展，支持下一代智能系统的开发。

Abstract: Internet of Things (IoT) sensors are ubiquitous technologies deployed across
smart cities, industrial sites, and healthcare systems. They continuously
generate time series data that enable advanced analytics and automation in
industries. However, challenges such as the loss or ambiguity of sensor
metadata, heterogeneity in data sources, varying sampling frequencies,
inconsistent units of measurement, and irregular timestamps make raw IoT time
series data difficult to interpret, undermining the effectiveness of smart
systems. To address these challenges, we propose a novel deep learning model,
DeepFeatIoT, which integrates learned local and global features with
non-learned randomized convolutional kernel-based features and features from
large language models (LLMs). This straightforward yet unique fusion of diverse
learned and non-learned features significantly enhances IoT time series sensor
data classification, even in scenarios with limited labeled data. Our model's
effectiveness is demonstrated through its consistent and generalized
performance across multiple real-world IoT sensor datasets from diverse
critical application domains, outperforming state-of-the-art benchmark models.
These results highlight DeepFeatIoT's potential to drive significant
advancements in IoT analytics and support the development of next-generation
smart systems.

</details>


### [181] [EGGS-PTP: An Expander-Graph Guided Structured Post-training Pruning Method for Large Language Models](https://arxiv.org/abs/2508.09471)
*Omar Bazarbachi,Zijun Sun,Yanning Shen*

Main category: cs.LG

TL;DR: EGGS-PTP是一种基于扩展图理论的结构化剪枝方法，能有效减少大型语言模型的尺寸和计算需求。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型规模扩大，部署时的计算和内存挑战日益严重，亟需更高效的模型变体。

Method: 利用扩展图理论指导N:M结构化剪枝设计，确保剪枝网络中信息流动和功能保留。

Result: 实验显示EGGS-PTP在加速和内存节省方面表现突出，且精度优于现有结构化剪枝技术。

Conclusion: EGGS-PTP是解决大型语言模型部署挑战的有效方法，兼具高效性和准确性。

Abstract: As Large Language Models (LLMs) become more widely adopted and scale up in
size, the computational and memory challenges involved in deploying these
massive foundation models have grown increasingly severe. This underscores the
urgent need to develop more efficient model variants. Faced with this
challenge, the present work introduces EGGS-PTP: an Expander-Graph Guided
Structured Post-training Pruning method. The proposed approach leverages graph
theory to guide the design of N:M structured pruning, effectively reducing
model size and computational demands. By incorporating concepts from expander
graphs, EGGS-PTP ensures information flow within the pruned network, preserving
essential model functionality. Extensive numerical experiments demonstrate that
EGGS-PTP not only achieves significant acceleration and memory savings due to
structured sparsity but also outperforms existing structured pruning techniques
in terms of accuracy across various LLMs.

</details>


### [182] [NeuronTune: Fine-Grained Neuron Modulation for Balanced Safety-Utility Alignment in LLMs](https://arxiv.org/abs/2508.09473)
*Birong Pan,Mayi Xu,Qiankun Pi,Jianhao Chen,Yuanyuan Zhu,Ming Zhong,Tieyun Qian*

Main category: cs.LG

TL;DR: 论文提出NeuronTune框架，通过细粒度调节神经元活动实现LLM的安全与性能优化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在安全性与性能间存在矛盾，无法兼顾鲁棒安全和性能保持，需更精细的干预手段。

Method: NeuronTune动态调节稀疏神经元，结合归因和元学习优化安全与性能神经元活动。

Result: 实验表明NeuronTune在安全性和性能上均优于现有技术。

Conclusion: NeuronTune实现了安全性与性能的同步优化，为LLM部署提供了灵活方案。

Abstract: Ensuring robust safety alignment while preserving utility is critical for the
reliable deployment of Large Language Models (LLMs). However, current
techniques fundamentally suffer from intertwined deficiencies: insufficient
robustness against malicious attacks, frequent refusal of benign queries,
degradation in generated text quality and general task performance--the former
two reflecting deficits in robust safety and the latter constituting utility
impairment. We trace these limitations to the coarse-grained layer-wise
interventions in existing methods. To resolve this, we propose NeuronTune, a
fine-grained framework that dynamically modulates sparse neurons to achieve
simultaneous safety-utility optimization. Our approach first identifies
safety-critical and utility-preserving neurons across all layers via
attribution, then employs meta-learning to adaptively amplify safety-neuron
activations and suppress utility-neuron activations. Crucially, NeuronTune
enables tunable adjustment of intervention scope via neuron-count thresholds,
supporting flexible adaptation to security-critical or utility-priority
scenarios. Extensive experimental results demonstrate that our method
significantly outperforms existing state-of-the-art technologies, achieving
superior model safety while maintaining excellent utility.

</details>


### [183] [Large-Small Model Collaborative Framework for Federated Continual Learning](https://arxiv.org/abs/2508.09489)
*Hao Yu,Xin Yang,Boyang Fan,Xuemei Cao,Hanlin Gu,Lixin Fan,Qiang Yang*

Main category: cs.LG

TL;DR: 提出了一种用于联邦持续学习（FCL）的合作框架，利用轻量级本地模型动态适应新任务并增强大模型的实用性，解决了基础模型（FMs）在私有数据下性能不足和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 针对基础模型（FMs）在联邦持续学习中难以利用私有本地数据和防止遗忘的挑战，提出一种结合轻量级模型的方法，以提升性能和实用性。

Method: 提出合作框架，通过轻量级本地模型动态适应新任务；包含两个新组件：小模型持续微调以防止遗忘，以及一对一蒸馏在服务器上融合异构本地知识。

Result: 实验结果表明，该方法在客户端使用异构小模型时仍能表现出卓越性能。

Conclusion: 该框架成功解决了FCL中FMs的局限性，为异构环境下的大模型持续学习提供了一种有效解决方案。

Abstract: Continual learning (CL) for Foundation Models (FMs) is an essential yet
underexplored challenge, especially in Federated Continual Learning (FCL),
where each client learns from a private, evolving task stream under strict data
and communication constraints. Despite their powerful generalization abilities,
FMs often exhibit suboptimal performance on local downstream tasks, as they are
unable to utilize private local data. Furthermore, enabling FMs to learn new
tasks without forgetting prior knowledge is inherently a challenging problem,
primarily due to their immense parameter count and high model complexity. In
contrast, small models can be trained locally under resource-constrained
conditions and benefit from more mature CL techniques. To bridge the gap
between small models and FMs, we propose the first collaborative framework in
FCL, where lightweight local models act as a dynamic bridge, continually
adapting to new tasks while enhancing the utility of the large model. Two novel
components are also included: Small Model Continual Fine-tuning is for
preventing small models from temporal forgetting; One-by-One Distillation
performs personalized fusion of heterogeneous local knowledge on the server.
Experimental results demonstrate its superior performance, even when clients
utilize heterogeneous small models.

</details>


### [184] [MiCo: End-to-End Mixed Precision Neural Network Co-Exploration Framework for Edge AI](https://arxiv.org/abs/2508.09500)
*Zijun Jiang,Yangdi Lyu*

Main category: cs.LG

TL;DR: 该论文提出了MiCo框架，用于层混合精度量化（MPQ）的优化和部署，旨在减少精度损失并提高加速效果，适用于边缘AI应用。


<details>
  <summary>Details</summary>
Motivation: 当前MPQ方案在灵活性和效率上存在不足，且缺乏对量化后训练影响的深入理解，同时缺少端到端的优化与部署框架。

Method: 采用新型优化算法搜索满足延迟约束的最高精度量化方案，并为不同硬件目标构建硬件感知延迟模型。

Result: 框架实现了从PyTorch模型到裸机C代码的直接部署，以最小精度损失实现端到端加速。

Conclusion: MiCo为边缘AI应用提供了高效、灵活的MPQ优化和部署解决方案。

Abstract: Quantized Neural Networks (QNN) with extremely low-bitwidth data have proven
promising in efficient storage and computation on edge devices. To further
reduce the accuracy drop while increasing speedup, layer-wise mixed-precision
quantization (MPQ) becomes a popular solution. However, existing algorithms for
exploring MPQ schemes are limited in flexibility and efficiency. Comprehending
the complex impacts of different MPQ schemes on post-training quantization and
quantization-aware training results is a challenge for conventional methods.
Furthermore, an end-to-end framework for the optimization and deployment of MPQ
models is missing in existing work.
  In this paper, we propose the MiCo framework, a holistic MPQ exploration and
deployment framework for edge AI applications. The framework adopts a novel
optimization algorithm to search for optimal quantization schemes with the
highest accuracies while meeting latency constraints. Hardware-aware latency
models are built for different hardware targets to enable fast explorations.
After the exploration, the framework enables direct deployment from PyTorch MPQ
models to bare-metal C codes, leading to end-to-end speedup with minimal
accuracy drops.

</details>


### [185] [Causal Graph Profiling via Structural Divergence for Robust Anomaly Detection in Cyber-Physical Systems](https://arxiv.org/abs/2508.09504)
*Arun Vignesh Malarkkan,Haoyue Bai,Dongjie Wang,Yanjie Fu*

Main category: cs.LG

TL;DR: 论文提出了一种基于因果图的异常检测框架（CGAD），用于复杂网络攻击的检测，解决了传统方法在分布漂移和类别不平衡问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 面对针对关键基础设施的复杂网络攻击，传统异常检测方法因分布漂移和类别不平衡问题表现不佳，需要更鲁棒的解决方案。

Method: CGAD采用两阶段监督框架：1) 通过动态贝叶斯网络学习因果不变图结构；2) 通过因果图比较检测异常，评估拓扑偏差。

Result: CGAD在非平稳和不平衡时间序列环境中表现优于传统方法，F1和ROC-AUC得分显著提升。

Conclusion: CGAD通过因果结构提升了异常检测的鲁棒性和准确性，适用于复杂攻击场景。

Abstract: With the growing complexity of cyberattacks targeting critical
infrastructures such as water treatment networks, there is a pressing need for
robust anomaly detection strategies that account for both system
vulnerabilities and evolving attack patterns. Traditional methods --
statistical, density-based, and graph-based models struggle with distribution
shifts and class imbalance in multivariate time series, often leading to high
false positive rates. To address these challenges, we propose CGAD, a Causal
Graph-based Anomaly Detection framework designed for reliable cyberattack
detection in public infrastructure systems. CGAD follows a two-phase supervised
framework -- causal profiling and anomaly scoring. First, it learns causal
invariant graph structures representing the system's behavior under "Normal"
and "Attack" states using Dynamic Bayesian Networks. Second, it employs
structural divergence to detect anomalies via causal graph comparison by
evaluating topological deviations in causal graphs over time. By leveraging
causal structures, CGAD achieves superior adaptability and accuracy in
non-stationary and imbalanced time series environments compared to conventional
machine learning approaches. By uncovering causal structures beneath volatile
sensor data, our framework not only detects cyberattacks with markedly higher
precision but also redefines robustness in anomaly detection, proving
resilience where traditional models falter under imbalance and drift. Our
framework achieves substantial gains in F1 and ROC-AUC scores over
best-performing baselines across four industrial datasets, demonstrating robust
detection of delayed and structurally complex anomalies.

</details>


### [186] [Enhancing Memory Recall in LLMs with Gauss-Tin: A Hybrid Instructional and Gaussian Replay Approach](https://arxiv.org/abs/2508.09510)
*Iing Muttakhiroh,Thomas Fevens*

Main category: cs.LG

TL;DR: Gauss-Tin是一种结合回放策略与高斯混合模型的新方法，通过优化样本选择和指导生成，显著提升了大型语言模型（LLMs）的抗遗忘能力，实验结果显示其性能较传统方法提升6%。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）取得了显著进展，但灾难性遗忘问题仍然严重。持续学习（CL）策略中的回放方法被证明能有效保留已学知识，但需要进一步优化样本选择以提升效果。

Method: 提出了Gauss-Tin方法，整合回放策略与高斯混合模型，优化训练过程中的样本选择，并结合指导生成机制，以强化重要历史知识的学习。

Result: 实验表明，Gauss-Tin在保留指标上比传统方法提升了6%，证明了其在减轻LLMs灾难性遗忘方面的有效性。

Conclusion: Gauss-Tin展示了混合模型在提升LLMs动态学习环境中的鲁棒性和适应性方面的潜力。

Abstract: Despite the significant advancements in Large Language Models (LLMs),
catastrophic forgetting remains a substantial challenge, where models lose
previously acquired knowledge upon learning new information. Continual learning
(CL) strategies have emerged as a potential solution to this problem, with
replay-based techniques demonstrating superior performance in preserving
learned knowledge. In this context, we introduce Gauss-Tin, a novel approach
that integrates the replay strategy with a Gaussian mixture model to enhance
the quality of sample selection during training, supplemented by instructional
guidance to facilitate the generation of past learning. This method aims to
improve LLMs' retention capabilities by strategically reinforcing important
past learnings while accommodating new information. Our experimental results
indicate a promising 6\% improvement in retention metrics over traditional
methods, suggesting that Gauss-Tin is an effective strategy for mitigating
catastrophic forgetting in LLMs. This study underscores the potential of hybrid
models in enhancing the robustness and adaptability of LLMs in dynamic learning
environments.

</details>


### [187] [Time-Aware and Transition-Semantic Graph Neural Networks for Interpretable Predictive Business Process Monitoring](https://arxiv.org/abs/2508.09527)
*Fang Wang,Ernesto Damiani*

Main category: cs.LG

TL;DR: 提出了一个统一的、可解释的GNN框架，用于预测业务过程监控中的未来事件，解决了现有模型在架构、时间和语义上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于GNN的PBPM模型在捕捉时间相关性和转移语义方面表现不足，需要更先进的框架来提升预测性能。

Method: 比较基于前缀的GCN和全迹GAT，引入时间衰减注意力机制和转移类型语义嵌入，并结合多级可解释性模块。

Result: 在五个基准测试中取得了具有竞争力的Top-k准确率和DL分数，无需针对每个数据集进行调整。

Conclusion: 该框架为PBPM中的下一个事件预测提供了一个稳健、可推广且可解释的解决方案。

Abstract: Predictive Business Process Monitoring (PBPM) aims to forecast future events
in ongoing cases based on historical event logs. While Graph Neural Networks
(GNNs) are well suited to capture structural dependencies in process data,
existing GNN-based PBPM models remain underdeveloped. Most rely either on short
prefix subgraphs or global architectures that overlook temporal relevance and
transition semantics. We propose a unified, interpretable GNN framework that
advances the state of the art along three key axes. First, we compare
prefix-based Graph Convolutional Networks(GCNs) and full trace Graph Attention
Networks(GATs) to quantify the performance gap between localized and global
modeling. Second, we introduce a novel time decay attention mechanism that
constructs dynamic, prediction-centered windows, emphasizing temporally
relevant history and suppressing noise. Third, we embed transition type
semantics into edge features to enable fine grained reasoning over structurally
ambiguous traces. Our architecture includes multilevel interpretability
modules, offering diverse visualizations of attention behavior. Evaluated on
five benchmarks, the proposed models achieve competitive Top-k accuracy and DL
scores without per-dataset tuning. By addressing architectural, temporal, and
semantic gaps, this work presents a robust, generalizable, and explainable
solution for next event prediction in PBPM.

</details>


### [188] [Decentralized Rank Scheduling for Energy-Constrained Multi-Task Federated Fine-Tuning in Edge-Assisted IoV Networks](https://arxiv.org/abs/2508.09532)
*Bokeng Zheng,Jianqiang Zhong,Jiayi Liu,Xiaoxi Zhang*

Main category: cs.LG

TL;DR: 提出了一种层次化联邦微调框架，用于动态车联网环境中的多任务适应，结合低秩适应技术和新型UCB-DUAL算法，显著提升了效率和精度。


<details>
  <summary>Details</summary>
Motivation: 车联网系统中的客户端移动性、异构资源和间歇性连接使得多任务适应具有挑战性，需开发高效、低延迟的解决方案。

Method: 采用层次化联邦微调框架和低秩适应技术，设计了基于多臂老虎机问题的能效感知排名适应机制，并提出UCB-DUAL算法。

Result: 实验表明，该方法在延迟降低24%的同时，平均精度提升超过2.5%，优于所有基线方法。

Conclusion: 该框架在动态车联网场景下实现了资源感知和移动性鲁棒的学习，具有显著的性能优势。

Abstract: Federated fine-tuning has emerged as a promising approach for adapting
foundation models (FMs) to diverse downstream tasks in edge environments. In
Internet of Vehicles (IoV) systems, enabling efficient and low-latency
multi-task adaptation is particularly challenging due to client mobility,
heterogeneous resources, and intermittent connectivity. This paper proposes a
hierarchical federated fine-tuning framework that coordinates roadside units
(RSUs) and vehicles to support resource-aware and mobility-resilient learning
across dynamic IoV scenarios. Leveraging Low-Rank Adaptation (LoRA), we
introduce a decentralized, energy-aware rank adaptation mechanism formulated as
a constrained multi-armed bandit problem. A novel UCB-DUAL algorithm is
developed to enable adaptive exploration under per-task energy budgets,
achieving provable sublinear regret. To evaluate our method, we construct a
large-scale IoV simulator based on real-world trajectories, capturing dynamic
participation, RSU handoffs, and communication variability. Extensive
experiments show that our approach achieves the best accuracy-efficiency
trade-off among all baselines, reducing latency by over 24\% and improving
average accuracy by more than 2.5\%.

</details>


### [189] [SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification](https://arxiv.org/abs/2508.09544)
*Sasan Tavakkol,Lin Chen,Max Springer,Abigail Schantz,Blaž Bratanič,Vincent Cohen-Addad,MohammadHossein Bateni*

Main category: cs.LG

TL;DR: SYNAPSE-G是一种利用大型语言模型生成稀有事件分类的合成训练数据，并通过半监督标签传播扩展数据集的管道，解决了冷启动问题。实验表明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决标注数据稀缺，尤其是稀有事件分类中的冷启动问题。

Method: 利用LLMs生成合成数据作为种子，通过相似性图进行半监督标签传播，筛选候选正例并由人工或LLMs标注，最终训练分类器。

Result: 在SST2和MHS不平衡数据集上，SYNAPSE-G在寻找正标签方面优于基线方法。

Conclusion: SYNAPSE-G通过合成数据和半监督标签传播，有效解决了稀有事件分类中的数据稀缺问题。

Abstract: Scarcity of labeled data, especially for rare events, hinders training
effective machine learning models. This paper proposes SYNAPSE-G (Synthetic
Augmentation for Positive Sampling via Expansion on Graphs), a novel pipeline
leveraging Large Language Models (LLMs) to generate synthetic training data for
rare event classification, addressing the cold-start problem. This synthetic
data serve as seeds for semi-supervised label propagation on a similarity graph
constructed between the seeds and a large unlabeled dataset. This identifies
candidate positive examples, subsequently labeled by an oracle (human or LLM).
The expanded dataset then trains/fine-tunes a classifier. We theoretically
analyze how the quality (validity and diversity) of the synthetic data impacts
the precision and recall of our method. Experiments on the imbalanced SST2 and
MHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels,
outperforming baselines including nearest neighbor search.

</details>


### [190] [Edge General Intelligence Through World Models and Agentic AI: Fundamentals, Solutions, and Challenges](https://arxiv.org/abs/2508.09561)
*Changyuan Zhao,Guangyuan Liu,Ruichen Zhang,Yinqiu Liu,Jiacheng Wang,Jiawen Kang,Dusit Niyato,Zan Li,Xuemin,Shen,Zhu Han,Sumei Sun,Chau Yuen,Dong In Kim*

Main category: cs.LG

TL;DR: EGI通过世界模型实现边缘计算智能，涵盖感知、推理与自主行动，但无线边缘领域的应用仍需探索。本文综述其架构、应用场景及挑战。


<details>
  <summary>Details</summary>
Motivation: 探索世界模型在边缘通用智能（EGI）中的潜力，填补其在无线边缘领域应用的空白。

Method: 分析世界模型的架构基础（如潜在表示学习、动态建模），并展示其在车辆网络、无人机网络等场景的应用。

Result: 世界模型可作为EGI的认知核心，结合基础模型与数字孪生，优化延迟、能耗与隐私。

Conclusion: 世界模型为EGI提供理论与实践基础，未来需解决安全性、训练效率等挑战。

Abstract: Edge General Intelligence (EGI) represents a transformative evolution of edge
computing, where distributed agents possess the capability to perceive, reason,
and act autonomously across diverse, dynamic environments. Central to this
vision are world models, which act as proactive internal simulators that not
only predict but also actively imagine future trajectories, reason under
uncertainty, and plan multi-step actions with foresight. This proactive nature
allows agents to anticipate potential outcomes and optimize decisions ahead of
real-world interactions. While prior works in robotics and gaming have
showcased the potential of world models, their integration into the wireless
edge for EGI remains underexplored. This survey bridges this gap by offering a
comprehensive analysis of how world models can empower agentic artificial
intelligence (AI) systems at the edge. We first examine the architectural
foundations of world models, including latent representation learning, dynamics
modeling, and imagination-based planning. Building on these core capabilities,
we illustrate their proactive applications across EGI scenarios such as
vehicular networks, unmanned aerial vehicle (UAV) networks, the Internet of
Things (IoT) systems, and network functions virtualization, thereby
highlighting how they can enhance optimization under latency, energy, and
privacy constraints. We then explore their synergy with foundation models and
digital twins, positioning world models as the cognitive backbone of EGI.
Finally, we highlight open challenges, such as safety guarantees, efficient
training, and constrained deployment, and outline future research directions.
This survey provides both a conceptual foundation and a practical roadmap for
realizing the next generation of intelligent, autonomous edge systems.

</details>


### [191] [Online Prediction with Limited Selectivity](https://arxiv.org/abs/2508.09592)
*Licheng Liu,Mingda Qiao*

Main category: cs.LG

TL;DR: 论文研究了有限选择性预测（PLS）模型，探讨了在预测窗口受限的情况下如何优化预测误差，并提出了一个复杂度度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有的预测模型允许预测者自由选择预测窗口，而忽略了预测窗口受限的现实场景。

Method: 引入有限选择性预测（PLS）模型，分析实例和平均情况下的最优预测误差，并提出复杂度度量。

Result: 复杂度度量方法能提供实例相关的最优误差边界，且在随机生成的PLS实例中高概率匹配。

Conclusion: PLS模型为预测窗口受限的场景提供了理论支持，复杂度度量是有效的分析工具。

Abstract: Selective prediction [Dru13, QV19] models the scenario where a forecaster
freely decides on the prediction window that their forecast spans. Many data
statistics can be predicted to a non-trivial error rate without any
distributional assumptions or expert advice, yet these results rely on that the
forecaster may predict at any time. We introduce a model of Prediction with
Limited Selectivity (PLS) where the forecaster can start the prediction only on
a subset of the time horizon. We study the optimal prediction error both on an
instance-by-instance basis and via an average-case analysis. We introduce a
complexity measure that gives instance-dependent bounds on the optimal error.
For a randomly-generated PLS instance, these bounds match with high
probability.

</details>


### [192] [Goal Discovery with Causal Capacity for Efficient Reinforcement Learning](https://arxiv.org/abs/2508.09624)
*Yan Yu,Yaodong Yang,Zhengbo Lu,Chengdong Ma,Wengang Zhou,Houqiang Li*

Main category: cs.LG

TL;DR: 本文提出了一种名为GDCC的新框架，通过定义因果关系测量（因果容量）来指导强化学习中的高效探索。


<details>
  <summary>Details</summary>
Motivation: 因果推理对探索环境至关重要，但现有方法在复杂场景中难以衡量因果关系。

Method: 提出因果容量测量，并通过蒙特卡洛方法识别关键点作为子目标，优化探索策略。

Result: 实验表明高因果容量的状态与预期子目标一致，GDCC显著提升了任务成功率。

Conclusion: GDCC框架有效解决了强化学习中高效探索的问题，为未来研究提供了新方向。

Abstract: Causal inference is crucial for humans to explore the world, which can be
modeled to enable an agent to efficiently explore the environment in
reinforcement learning. Existing research indicates that establishing the
causality between action and state transition will enhance an agent to reason
how a policy affects its future trajectory, thereby promoting directed
exploration. However, it is challenging to measure the causality due to its
intractability in the vast state-action space of complex scenarios. In this
paper, we propose a novel Goal Discovery with Causal Capacity (GDCC) framework
for efficient environment exploration. Specifically, we first derive a
measurement of causality in state space, \emph{i.e.,} causal capacity, which
represents the highest influence of an agent's behavior on future trajectories.
After that, we present a Monte Carlo based method to identify critical points
in discrete state space and further optimize this method for continuous
high-dimensional environments. Those critical points are used to uncover where
the agent makes important decisions in the environment, which are then regarded
as our subgoals to guide the agent to make exploration more purposefully and
efficiently. Empirical results from multi-objective tasks demonstrate that
states with high causal capacity align with our expected subgoals, and our GDCC
achieves significant success rate improvements compared to baselines.

</details>


### [193] [Physics- and geometry-aware spatio-spectral graph neural operator for time-independent and time-dependent PDEs](https://arxiv.org/abs/2508.09627)
*Subhankar Sarkar,Souvik Chakraborty*

Main category: cs.LG

TL;DR: 提出了一种物理学和几何感知的空时谱图神经算子（πG-Sp²GNO），用于高效求解偏微分方程（PDE），并在多种基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 科学和工程中的PDE求解在复杂几何和有限标签数据情况下仍然是一个关键挑战，需要更高效和准确的解决方案。

Method: 在Sp²GNO基础上引入几何感知和物理约束，设计了多尺度学习结构和时间依赖问题的混合物理损失函数。

Result: 在常规和复杂域、几何变化以及时间独立/依赖问题上验证了方法的有效性，表现优于现有物理信息神经算子算法。

Conclusion: πG-Sp²GNO通过结合几何感知和物理约束，显著提升了PDE求解的准确性和效率，具有广泛的应用潜力。

Abstract: Solving partial differential equations (PDEs) efficiently and accurately
remains a cornerstone challenge in science and engineering, especially for
problems involving complex geometries and limited labeled data. We introduce a
Physics- and Geometry- Aware Spatio-Spectral Graph Neural Operator
($\pi$G-Sp$^2$GNO) for learning the solution operators of time-independent and
time-dependent PDEs. The proposed approach first improves upon the recently
developed Sp$^2$GNO by enabling geometry awareness and subsequently exploits
the governing physics to learn the underlying solution operator in a
simulation-free setup. While the spatio-spectral structure present in the
proposed architecture allows multiscale learning, two separate strategies for
enabling geometry awareness is introduced in this paper. For time dependent
problems, we also introduce a novel hybrid physics informed loss function that
combines higher-order time-marching scheme with upscaled theory inspired
stochastic projection scheme. This allows accurate integration of the
physics-information into the loss function. The performance of the proposed
approach is illustrated on number of benchmark examples involving regular and
complex domains, variation in geometry during inference, and time-independent
and time-dependent problems. The results obtained illustrate the efficacy of
the proposed approach as compared to the state-of-the-art physics-informed
neural operator algorithms in the literature.

</details>


### [194] [TimeMKG: Knowledge-Infused Causal Reasoning for Multivariate Time Series Modeling](https://arxiv.org/abs/2508.09630)
*Yifei Sun,Junming Liu,Ding Wang,Yirong Chen,Xuefeng Yan*

Main category: cs.LG

TL;DR: TimeMKG是一种多模态因果推理框架，通过结合变量语义和数值观测提升时间序列建模效果。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列模型忽略了变量名称和数据描述中的丰富语义信息，而这些信息对建模至关重要。

Method: 利用大语言模型解释变量语义，构建多元知识图谱，并通过双模态编码器和跨模态注意力融合语义与统计模式。

Result: 实验证明，加入变量级知识显著提升了预测性能和泛化能力。

Conclusion: TimeMKG框架为时间序列建模提供了可解释的因果先验，提升了模型效果。

Abstract: Multivariate time series data typically comprises two distinct modalities:
variable semantics and sampled numerical observations. Traditional time series
models treat variables as anonymous statistical signals, overlooking the rich
semantic information embedded in variable names and data descriptions. However,
these textual descriptors often encode critical domain knowledge that is
essential for robust and interpretable modeling. Here we present TimeMKG, a
multimodal causal reasoning framework that elevates time series modeling from
low-level signal processing to knowledge informed inference. TimeMKG employs
large language models to interpret variable semantics and constructs structured
Multivariate Knowledge Graphs that capture inter-variable relationships. A
dual-modality encoder separately models the semantic prompts, generated from
knowledge graph triplets, and the statistical patterns from historical time
series. Cross-modality attention aligns and fuses these representations at the
variable level, injecting causal priors into downstream tasks such as
forecasting and classification, providing explicit and interpretable priors to
guide model reasoning. The experiment in diverse datasets demonstrates that
incorporating variable-level knowledge significantly improves both predictive
performance and generalization.

</details>


### [195] [Thermal Tracks: A Gaussian process-based framework for universal melting curve analysis enabling unconstrained hit identification in thermal proteome profiling experiments](https://arxiv.org/abs/2508.09659)
*Johannes F. Hevler,Shivam Verma,Mirat Soijtra,Carolyn R. Bertozzi*

Main category: cs.LG

TL;DR: Thermal Tracks是一种基于Python的统计框架，用于分析蛋白质热稳定性数据，克服了现有热蛋白质组分析（TPP）方法的关键限制。


<details>
  <summary>Details</summary>
Motivation: 传统TPP方法假设熔解曲线为S型，并受经验性零分布的限制，可能导致遗漏生物学相关变化。Thermal Tracks旨在提供更灵活的模型和无偏的零分布。

Method: 采用高斯过程（GP）模型和平方指数核，灵活建模任何熔解曲线形状，同时通过核先验生成无偏零分布。

Result: 特别适合分析蛋白质组范围内的扰动（如途径抑制、遗传修饰或环境压力）以及非传统熔解曲线（如相分离蛋白和膜蛋白）。

Conclusion: Thermal Tracks是一个免费、灵活且易于使用的工具，适用于广泛的蛋白质组热稳定性研究。

Abstract: Thermal Tracks is a Python-based statistical framework for analyzing protein
thermal stability data that overcomes key limitations of existing thermal
proteome profiling (TPP) work-flows. Unlike standard approaches that assume
sigmoidal melting curves and are constrained by empirical null distributions
(limiting significant hits to approximately 5 % of data), Thermal Tracks uses
Gaussian Process (GP) models with squared-exponential kernels to flexibly model
any melting curve shape while generating unbiased null distributions through
kernel priors. This framework is particularly valuable for analyzing
proteome-wide perturbations that significantly alter protein thermal stability,
such as pathway inhibitions, genetic modifications, or environmental stresses,
where conventional TPP methods may miss biologically relevant changes due to
their statistical constraints. Furthermore, Thermal Tracks excels at analyzing
proteins with un-conventional melting profiles, including phase-separating
proteins and membrane proteins, which often exhibit complex, non-sigmoidal
thermal stability behaviors. Thermal Tracks is freely available from GitHub and
is implemented in Python, providing an accessible and flexible tool for
proteome-wide thermal profiling studies.

</details>


### [196] [Global Convergence Analysis of Vanilla Gradient Descent for Asymmetric Matrix Completion](https://arxiv.org/abs/2508.09685)
*Xu Zhang,Shuo Chen,Jinsheng Li,Xiangying Pang,Maoguo Gong*

Main category: cs.LG

TL;DR: 本文研究了非对称低秩矩阵补全问题，提出了一种无需正则项的梯度下降方法，并通过理论和实验验证其收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决传统梯度下降方法中正则项的必要性问题，探索更高效的矩阵补全算法。

Method: 采用谱初始化的纯梯度下降方法，结合留一法技术证明收敛性。

Result: 证明算法具有高概率线性收敛率，且计算成本更低。

Conclusion: 梯度下降在矩阵补全中具有隐式正则化特性，无需显式正则项即可高效收敛。

Abstract: This paper investigates the asymmetric low-rank matrix completion problem,
which can be formulated as an unconstrained non-convex optimization problem
with a nonlinear least-squares objective function, and is solved via gradient
descent methods. Previous gradient descent approaches typically incorporate
regularization terms into the objective function to guarantee convergence.
However, numerical experiments and theoretical analysis of the gradient flow
both demonstrate that the elimination of regularization terms in gradient
descent algorithms does not adversely affect convergence performance. By
introducing the leave-one-out technique, we inductively prove that the vanilla
gradient descent with spectral initialization achieves a linear convergence
rate with high probability. Besides, we demonstrate that the balancing
regularization term exhibits a small norm during iterations, which reveals the
implicit regularization property of gradient descent. Empirical results show
that our algorithm has a lower computational cost while maintaining comparable
completion performance compared to other gradient descent algorithms.

</details>


### [197] [Temporal Anchoring in Deepening Embedding Spaces: Event-Indexed Projections, Drift, Convergence, and an Internal Computational Architecture](https://arxiv.org/abs/2508.09693)
*Faruk Alpay,Bugra Kilictas,Hamdi Alakkad*

Main category: cs.LG

TL;DR: 该论文提出了一个算子理论框架，用于在嵌入空间中进行时间锚定，研究内容包括漂移映射、事件索引块和仿射投影，并提供了多项理论证明和应用分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为嵌入空间中的时间锚定问题提供一个统一的算子理论框架，并通过严格的理论证明验证其有效性和鲁棒性。

Method: 方法包括构建漂移映射与事件索引块的交错模型，提出变块收缩引理、漂移-投影收敛定理，并设计了一个纯由这些算子定义的内稿件计算机（MC）。

Result: 成果包括证明了多项理论结果（如Lipschitz性质、收敛性等），并应用于注意力层（如softmax的Lipschitz性质和非正交头的收缩条件）。

Conclusion: 结论是该框架为时间锚定问题提供了理论基础，并通过严格的数学证明和实际应用展示了其可行性和鲁棒性。

Abstract: We develop an operator-theoretic framework for temporal anchoring in
embedding spaces, modeled as drift maps interleaved with event-indexed blocks
culminating in affine projections. We provide complete proofs for a
variable-block contraction lemma (products of Lipschitz factors), a
drift--projection convergence theorem with explicit uniform-gap envelopes, and
ontological convergence under nested affine anchors with a robustness variant.
We formalize an internal Manuscript Computer (MC) whose computations are
defined purely by these operators and prove a rigorous finite-run equivalence
theorem (with perturbation bounds). For attention layers, we give a
self-contained proof that softmax is $1/2$-Lipschitz in $\ell_2$ and derive
sufficient layer-contraction conditions (orthogonal/non-orthogonal heads). All
floats are placed exactly where written; the manuscript uses only in-paper
pseudocode and appendix figures.

</details>


### [198] [Combating Noisy Labels via Dynamic Connection Masking](https://arxiv.org/abs/2508.09697)
*Xinlei Zhang,Fan Liu,Chuanyi Zhang,Fan Cheng,Yuhui Zheng*

Main category: cs.LG

TL;DR: 论文提出了一种动态连接掩码（DCM）机制，用于增强MLP和KAN分类器对噪声标签的鲁棒性。通过理论分析和实验验证，DCM在多种噪声鲁棒训练方法中表现优异，并首次揭示了KAN在真实噪声场景下的优越性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中噪声标签不可避免，而深度神经网络容易记住这些噪声标签，导致性能下降。现有研究主要集中在鲁棒损失函数和样本选择方面，对模型架构的正则化探索较少。

Method: 受KAN中稀疏正则化的启发，提出动态连接掩码（DCM）机制，通过评估边的重要性自适应地屏蔽不重要的连接，并理论上证明其减少梯度误差的有效性。

Result: 实验表明，DCM在合成和真实数据集上均优于现有方法，并且首次揭示了KAN在噪声场景中比MLP更鲁棒。

Conclusion: DCM机制可以无缝集成到多种噪声鲁棒训练方法中，为构建更鲁棒的深度网络提供了一种有效途径。

Abstract: Noisy labels are inevitable in real-world scenarios. Due to the strong
capacity of deep neural networks to memorize corrupted labels, these noisy
labels can cause significant performance degradation. Existing research on
mitigating the negative effects of noisy labels has mainly focused on robust
loss functions and sample selection, with comparatively limited exploration of
regularization in model architecture. Inspired by the sparsity regularization
used in Kolmogorov-Arnold Networks (KANs), we propose a Dynamic Connection
Masking (DCM) mechanism for both Multi-Layer Perceptron Networks (MLPs) and
KANs to enhance the robustness of classifiers against noisy labels. The
mechanism can adaptively mask less important edges during training by
evaluating their information-carrying capacity. Through theoretical analysis,
we demonstrate its efficiency in reducing gradient error. Our approach can be
seamlessly integrated into various noise-robust training methods to build more
robust deep networks, including robust loss functions, sample selection
strategies, and regularization techniques. Extensive experiments on both
synthetic and real-world benchmarks demonstrate that our method consistently
outperforms state-of-the-art (SOTA) approaches. Furthermore, we are also the
first to investigate KANs as classifiers against noisy labels, revealing their
superior noise robustness over MLPs in real-world noisy scenarios. Our code
will soon be publicly available.

</details>


### [199] [GraphTreeGen: Subtree-Centric Approach to Efficient and Supervised Graph Generation](https://arxiv.org/abs/2508.09710)
*Yitong Luo,Islem Rekik*

Main category: cs.LG

TL;DR: 论文提出了GraphTreeGen（GTG）框架，通过子树中心的生成方法解决了现有图生成模型在脑连接组生成中的局限性，实现了高效且准确的连接组合成。


<details>
  <summary>Details</summary>
Motivation: 现有的图生成模型在生成脑连接组时存在多种局限性，包括局部细节模糊、依赖稀有节点属性、忽视边权重预测以及计算成本高昂等，因此需要一种更高效且精确的生成方法。

Method: GTG将每个连接组分解为熵引导的k-hop子树，通过共享的GCN编码局部结构，并使用双分支解码器联合预测边的存在和权重，从而重建邻接矩阵。

Result: GTG在自监督任务中表现优于现有基线方法，在监督任务中保持竞争力，同时提供更高的结构保真度和更精确的权重预测，且内存消耗更低。

Conclusion: GTG通过其模块化设计，不仅解决了现有模型的局限性，还扩展了连接组超分辨率和跨模态合成的潜力。

Abstract: Brain connectomes, representing neural connectivity as graphs, are crucial
for understanding brain organization but costly and time-consuming to acquire,
motivating generative approaches. Recent advances in graph generative modeling
offer a data-driven alternative, enabling synthetic connectome generation and
reducing dependence on large neuroimaging datasets. However, current models
face key limitations: (i) compressing the whole graph into a single latent code
(e.g., VGAEs) blurs fine-grained local motifs; (ii) relying on rich node
attributes rarely available in connectomes reduces reconstruction quality;
(iii) edge-centric models emphasize topology but overlook accurate edge-weight
prediction, harming quantitative fidelity; and (iv) computationally expensive
designs (e.g., edge-conditioned convolutions) impose high memory demands,
limiting scalability. We propose GraphTreeGen (GTG), a subtree-centric
generative framework for efficient, accurate connectome synthesis. GTG
decomposes each connectome into entropy-guided k-hop trees capturing
informative local structure, encoded by a shared GCN. A bipartite
message-passing layer fuses subtree embeddings with global node features, while
a dual-branch decoder jointly predicts edge existence and weights to
reconstruct the adjacency matrix. GTG outperforms state-of-the-art baselines in
self-supervised tasks and remains competitive in supervised settings,
delivering higher structural fidelity and more precise weights with far less
memory. Its modular design enables extensions to connectome super-resolution
and cross-modality synthesis. Code: https://github.com/basiralab/GTG/

</details>


### [200] [Improving ARDS Diagnosis Through Context-Aware Concept Bottleneck Models](https://arxiv.org/abs/2508.09719)
*Anish Narain,Ritam Majumdar,Nikita Narayanan,Dominic Marshall,Sonali Parbhoo*

Main category: cs.LG

TL;DR: 论文探讨了如何利用临床数据集和AI工具改善疾病分类的准确性和可解释性，特别是在急性呼吸窘迫综合征（ARDS）的识别中，通过结合临床笔记的上下文信息，提升了概念瓶颈模型（CBM）的性能。


<details>
  <summary>Details</summary>
Motivation: 大型临床数据集为疾病异质性和个性化治疗提供了新资源，但数据不完整且缺乏标签。现有AI工具在分类疾病时存在可解释性不足的问题。

Method: 通过使用大型语言模型（LLM）处理临床笔记生成额外概念，改进概念瓶颈模型（CBM），提升其在ARDS识别中的性能。

Result: 结合临床笔记的上下文信息后，CBM性能提高了10%，并学习了更全面的概念，减少了信息泄漏和对虚假捷径的依赖。

Conclusion: 利用临床笔记的上下文信息可以有效提升CBM的准确性和可解释性，为疾病分类提供了更可靠的方法。

Abstract: Large, publicly available clinical datasets have emerged as a novel resource
for understanding disease heterogeneity and to explore personalization of
therapy. These datasets are derived from data not originally collected for
research purposes and, as a result, are often incomplete and lack critical
labels. Many AI tools have been developed to retrospectively label these
datasets, such as by performing disease classification; however, they often
suffer from limited interpretability. Previous work has attempted to explain
predictions using Concept Bottleneck Models (CBMs), which learn interpretable
concepts that map to higher-level clinical ideas, facilitating human
evaluation. However, these models often experience performance limitations when
the concepts fail to adequately explain or characterize the task. We use the
identification of Acute Respiratory Distress Syndrome (ARDS) as a challenging
test case to demonstrate the value of incorporating contextual information from
clinical notes to improve CBM performance. Our approach leverages a Large
Language Model (LLM) to process clinical notes and generate additional
concepts, resulting in a 10% performance gain over existing methods.
Additionally, it facilitates the learning of more comprehensive concepts,
thereby reducing the risk of information leakage and reliance on spurious
shortcuts, thus improving the characterization of ARDS.

</details>


### [201] [Generative Modeling with Multi-Instance Reward Learning for E-commerce Creative Optimization](https://arxiv.org/abs/2508.09730)
*Qiaolei Gu,Yu Li,DingYi Zeng,Lu Wang,Ming Pang,Changping Peng,Zhangang Lin,Ching Law,Jingping Shao*

Main category: cs.LG

TL;DR: 提出了一个名为GenCO的新框架，通过生成式建模与多实例奖励学习结合，优化电子商务广告创意组合选择，显著提升广告收入。


<details>
  <summary>Details</summary>
Motivation: 现有方法对创意组件单独评估，难以应对组合搜索空间的巨大挑战。

Method: 采用两阶段架构：1) 生成模型生成多样化创意组合；2) 多实例学习模型将组合级奖励（如点击）分配给单个创意元素。

Result: 在实际电商平台部署中显著增加了广告收入，并发布了工业级数据集。

Conclusion: GenCO通过高效组合生成与精准奖励反馈，解决了广告创意优化的难点。

Abstract: In e-commerce advertising, selecting the most compelling combination of
creative elements -- such as titles, images, and highlights -- is critical for
capturing user attention and driving conversions. However, existing methods
often evaluate creative components individually, failing to navigate the
exponentially large search space of possible combinations. To address this
challenge, we propose a novel framework named GenCO that integrates generative
modeling with multi-instance reward learning. Our unified two-stage
architecture first employs a generative model to efficiently produce a diverse
set of creative combinations. This generative process is optimized with
reinforcement learning, enabling the model to effectively explore and refine
its selections. Next, to overcome the challenge of sparse user feedback, a
multi-instance learning model attributes combination-level rewards, such as
clicks, to the individual creative elements. This allows the reward model to
provide a more accurate feedback signal, which in turn guides the generative
model toward creating more effective combinations. Deployed on a leading
e-commerce platform, our approach has significantly increased advertising
revenue, demonstrating its practical value. Additionally, we are releasing a
large-scale industrial dataset to facilitate further research in this important
domain.

</details>


### [202] [HKT: A Biologically Inspired Framework for Modular Hereditary Knowledge Transfer in Neural Networks](https://arxiv.org/abs/2508.09743)
*Yanick Chistian Tchenko,Felix Mohr,Hicham Hadj Abdelkader,Hedi Tabia*

Main category: cs.LG

TL;DR: 论文提出了一种名为HKT的生物启发框架，通过模块化和选择性特征转移优化小型可部署模型，显著提升性能并保持紧凑性。


<details>
  <summary>Details</summary>
Motivation: 针对深度神经网络在性能和效率之间的权衡问题，研究如何通过结构化知识继承提升小型模型的能力。

Method: 提出Hereditary Knowledge Transfer (HKT)框架，包含提取、转移和混合三个阶段，采用Genetic Attention机制选择性集成知识。

Result: 在多个视觉任务中验证了HKT的有效性，其性能优于传统蒸馏方法，且保持了模型的紧凑性。

Conclusion: HKT为资源受限环境提供了一种通用且可扩展的高性能神经网络部署方案。

Abstract: A prevailing trend in neural network research suggests that model performance
improves with increasing depth and capacity - often at the cost of
integrability and efficiency. In this paper, we propose a strategy to optimize
small, deployable models by enhancing their capabilities through structured
knowledge inheritance. We introduce Hereditary Knowledge Transfer (HKT), a
biologically inspired framework for modular and selective transfer of
task-relevant features from a larger, pretrained parent network to a smaller
child model. Unlike standard knowledge distillation, which enforces uniform
imitation of teacher outputs, HKT draws inspiration from biological inheritance
mechanisms - such as memory RNA transfer in planarians - to guide a multi-stage
process of feature transfer. Neural network blocks are treated as functional
carriers, and knowledge is transmitted through three biologically motivated
components: Extraction, Transfer, and Mixture (ETM). A novel Genetic Attention
(GA) mechanism governs the integration of inherited and native representations,
ensuring both alignment and selectivity. We evaluate HKT across diverse vision
tasks, including optical flow (Sintel, KITTI), image classification (CIFAR-10),
and semantic segmentation (LiTS), demonstrating that it significantly improves
child model performance while preserving its compactness. The results show that
HKT consistently outperforms conventional distillation approaches, offering a
general-purpose, interpretable, and scalable solution for deploying
high-performance neural networks in resource-constrained environments.

</details>


### [203] [A Machine Learning Approach to Predict Biological Age and its Longitudinal Drivers](https://arxiv.org/abs/2508.09747)
*Nazira Dunbayeva,Yulong Li,Yutong Xie,Imran Razzak*

Main category: cs.LG

TL;DR: 开发了一种基于纵向生物标志物变化的机器学习模型，显著提升年龄预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统模型仅依赖静态生物标志物，难以捕捉老化过程的动态特征，因此需要开发能反映健康轨迹的预测方法。

Method: 利用纵向队列数据（2019-2020和2021-2022），设计捕捉生物标志物变化率的新特征，训练LightGBM模型。

Result: 模型预测性能显著优于传统方法，在后续时间点上取得高准确度（男性R²=0.515，女性R²=0.498），斜率特征被证明是关键预测因子。

Conclusion: 动态健康轨迹是生物年龄的重要决定因素，此框架为临床工具开发提供了基础，支持个性化干预。

Abstract: Predicting an individual's aging trajectory is a central challenge in
preventative medicine and bioinformatics. While machine learning models can
predict chronological age from biomarkers, they often fail to capture the
dynamic, longitudinal nature of the aging process. In this work, we developed
and validated a machine learning pipeline to predict age using a longitudinal
cohort with data from two distinct time periods (2019-2020 and 2021-2022). We
demonstrate that a model using only static, cross-sectional biomarkers has
limited predictive power when generalizing to future time points. However, by
engineering novel features that explicitly capture the rate of change (slope)
of key biomarkers over time, we significantly improved model performance. Our
final LightGBM model, trained on the initial wave of data, successfully
predicted age in the subsequent wave with high accuracy ($R^2 = 0.515$ for
males, $R^2 = 0.498$ for females), significantly outperforming both traditional
linear models and other tree-based ensembles. SHAP analysis of our successful
model revealed that the engineered slope features were among the most important
predictors, highlighting that an individual's health trajectory, not just their
static health snapshot, is a key determinant of biological age. Our framework
paves the way for clinical tools that dynamically track patient health
trajectories, enabling early intervention and personalized prevention
strategies for age-related diseases.

</details>


### [204] [$μ$-Parametrization for Mixture of Experts](https://arxiv.org/abs/2508.09752)
*Jan Małaśnicki,Kamil Ciebiera,Mateusz Boruń,Maciej Pióro,Jan Ludziejewski,Maciej Stefaniak,Michał Krutul,Sebastian Jaszczur,Marek Cygan,Kamil Adamczewski,Jakub Krajewski*

Main category: cs.LG

TL;DR: 论文探讨了大型语言模型中的超参数调优技术μTransfer与混合专家架构MoE的结合，提出了μ参数化方法并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索μTransfer与MoE两种前沿技术结合的可能性，填补这一领域的空白。

Method: 方法包括理论推导μ参数化（μP）用于MoE，并实验验证其对学习率和专家规模的影响。

Result: 结果表明μ参数化在MoE中具有理论保证，并揭示了专家数量和粒度对最优学习率的影响。

Conclusion: 结论是通过μP方法实现了MoE的超参数优化，为大规模模型训练提供了新思路。

Abstract: Recent years have seen a growing interest and adoption of LLMs, with
$\mu$Transfer becoming a key technique for tuning hyperparameters in
large-scale training. Meanwhile, Mixture-of-Experts (MoE) has emerged as a
leading architecture in extremely large models. However, the intersection of
these two advancements has remained unexplored. In this work, we derive a
$\mu$-Parameterization ($\mu$P) for MoE, providing theoretical guarantees for
feature learning across model widths in both the router and experts. We
empirically validate our parameterization and further investigate how scaling
the number of experts and granularity affects the optimal learning rate.

</details>


### [205] [TriForecaster: A Mixture of Experts Framework for Multi-Region Electric Load Forecasting with Tri-dimensional Specialization](https://arxiv.org/abs/2508.09753)
*Zhaoyang Zhu,Zhipeng Zeng,Qiming Chen,Linxiao Yang,Peiyuan Liu,Weiqi Chen,Liang Sun*

Main category: cs.LG

TL;DR: 本文提出了一种名为TriForecaster的新框架，用于解决多区域电力负荷预测问题，通过动态合作和专家模型的专业化，显著降低了预测误差。


<details>
  <summary>Details</summary>
Motivation: 电力负荷预测对电力系统运营至关重要，智能电网的发展提供了更精细的负荷数据。观察到中国东部省份不同城市的负荷模式相似，本文致力于解决多区域短期负荷预测问题。

Method: 提出TriForecaster框架，结合混合专家（MoE）和多任务学习（MTL）方法，设计了RegionMixer和CTSpecializer层，以处理区域、上下文和时间的变化。

Result: 在四个真实数据集上的评估显示，TriForecaster平均降低预测误差22.4%，并在中国东部的eForecaster平台上成功部署，为17个城市提供服务。

Conclusion: TriForecaster展示了其灵活性和广泛适用性，为大规模电力负荷预测提供了实用解决方案。

Abstract: Electric load forecasting is pivotal for power system operation, planning and
decision-making. The rise of smart grids and meters has provided more detailed
and high-quality load data at multiple levels of granularity, from home to bus
and cities. Motivated by similar patterns of loads across different cities in a
province in eastern China, in this paper we focus on the Multi-Region Electric
Load Forecasting (MRELF) problem, targeting accurate short-term load
forecasting for multiple sub-regions within a large region. We identify three
challenges for MRELF, including regional variation, contextual variation, and
temporal variation. To address them, we propose TriForecaster, a new framework
leveraging the Mixture of Experts (MoE) approach within a Multi-Task Learning
(MTL) paradigm to overcome these challenges. TriForecaster features RegionMixer
and Context-Time Specializer (CTSpecializer) layers, enabling dynamic
cooperation and specialization of expert models across regional, contextual,
and temporal dimensions. Based on evaluation on four real-world MRELF datasets
with varied granularity, TriForecaster outperforms state-of-the-art models by
achieving an average forecast error reduction of 22.4\%, thereby demonstrating
its flexibility and broad applicability. In particular, the deployment of
TriForecaster on the eForecaster platform in eastern China exemplifies its
practical utility, effectively providing city-level, short-term load forecasts
for 17 cities, supporting a population exceeding 110 million and daily
electricity usage over 100 gigawatt-hours.

</details>


### [206] [Prototype Training with Dual Pseudo-Inverse and Optimized Hidden Activations](https://arxiv.org/abs/2508.09787)
*Mauro Tucci*

Main category: cs.LG

TL;DR: Proto-PINV+H是一种快速训练范式，结合闭式权重计算和梯度优化少量输入、软标签及隐藏激活。在MNIST和Fashion-MNIST上表现优异。


<details>
  <summary>Details</summary>
Motivation: 提出一种高效的训练方法，减少权重空间的自由度，提升训练速度和模型性能。

Method: 通过闭式权重计算和梯度优化（Adam）更新原型，将自由度转移到数据和激活空间。

Result: 在MNIST和Fashion-MNIST上分别达到97.8%和89.3%的测试准确率，训练速度快。

Conclusion: 方法在速度、规模和准确率之间取得良好平衡，优于现有技术。

Abstract: We present Proto-PINV+H, a fast training paradigm that combines closed-form
weight computation with gradient-based optimisation of a small set of synthetic
inputs, soft labels, and-crucially-hidden activations. At each iteration we
recompute all weight matrices in closed form via two (or more)
ridge-regularised pseudo-inverse solves, while updating only the prototypes
with Adam. The trainable degrees of freedom are thus shifted from weight space
to data/activation space. On MNIST (60k train, 10k test) and Fashion-MNIST (60k
train, 10k test), our method reaches 97.8% and 89.3% test accuracy on the
official 10k test sets, respectively, in 3.9s--4.5s using approximately 130k
trainable parameters and only 250 epochs on an RTX 5060 (16GB). We provide a
multi-layer extension (optimised activations at each hidden stage), learnable
ridge parameters, optional PCA/PLS projections, and theory linking the
condition number of prototype matrices to generalisation. The approach yields
favourable accuracy--speed--size trade-offs against ELM, random-feature ridge,
and shallow MLPs trained by back-propagation.

</details>


### [207] [Bayesian autoregression to optimize temporal Matérn kernel Gaussian process hyperparameters](https://arxiv.org/abs/2508.09792)
*Wouter M. Kouw*

Main category: cs.LG

TL;DR: 提出一种优化Matérn核时间高斯过程的方法，通过递归贝叶斯估计优化超参数，优于边际似然和哈密尔顿蒙特卡洛采样。


<details>
  <summary>Details</summary>
Motivation: 高斯过程是概率数值中的重要模型，但现有方法（如边际似然最大化）在超参数优化上效率不足。

Method: 将优化问题转化为自回归模型参数的递归贝叶斯估计，以优化Matérn核的协方差函数超参数。

Result: 该方法在运行时间和高斯过程回归的均方根误差上均优于边际似然和哈密尔顿蒙特卡洛采样。

Conclusion: 递归贝叶斯估计为高斯过程超参数优化提供了更高效的方法。

Abstract: Gaussian processes are important models in the field of probabilistic
numerics. We present a procedure for optimizing Mat\'ern kernel temporal
Gaussian processes with respect to the kernel covariance function's
hyperparameters. It is based on casting the optimization problem as a recursive
Bayesian estimation procedure for the parameters of an autoregressive model. We
demonstrate that the proposed procedure outperforms maximizing the marginal
likelihood as well as Hamiltonian Monte Carlo sampling, both in terms of
runtime and ultimate root mean square error in Gaussian process regression.

</details>


### [208] [Feature Impact Analysis on Top Long-Jump Performances with Quantile Random Forest and Explainable AI Techniques](https://arxiv.org/abs/2508.09810)
*Qi Gan,Stephan Clémençon,Mounîm A. El-Yacoubi,Sao Mai Nguyen,Eric Fenaux,Ons Jelassi*

Main category: cs.LG

TL;DR: 本研究利用机器学习模型分析跳远比赛中的生物力学特征，重点关注顶尖表现，揭示了男女运动员不同的关键特征。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以明确分析生物力学特征与运动员表现的关系，现代机器学习和统计方法为运动分析提供了新工具。

Method: 使用分位数回归模型结合SHAP、PDP和ICE图分析特征与跳远成绩的关系。

Result: 男性运动员的支撑腿膝盖角度和女性运动员的着地姿势及助跑技术是关键特征。

Conclusion: 研究为分析运动表现中的多特征影响提供了框架，尤其适用于顶尖表现。

Abstract: Biomechanical features have become important indicators for evaluating
athletes' techniques. Traditionally, experts propose significant features and
evaluate them using physics equations. However, the complexity of the human
body and its movements makes it challenging to explicitly analyze the
relationships between some features and athletes' final performance. With
advancements in modern machine learning and statistics, data analytics methods
have gained increasing importance in sports analytics. In this study, we
leverage machine learning models to analyze expert-proposed biomechanical
features from the finals of long jump competitions in the World Championships.
The objectives of the analysis include identifying the most important features
contributing to top-performing jumps and exploring the combined effects of
these key features. Using quantile regression, we model the relationship
between the biomechanical feature set and the target variable (effective
distance), with a particular focus on elite-level jumps. To interpret the
model, we apply SHapley Additive exPlanations (SHAP) alongside Partial
Dependence Plots (PDPs) and Individual Conditional Expectation (ICE) plots. The
findings reveal that, beyond the well-documented velocity-related features,
specific technical aspects also play a pivotal role. For male athletes, the
angle of the knee of the supporting leg before take-off is identified as a key
factor for achieving top 10% performance in our dataset, with angles greater
than 169{\deg}contributing significantly to jump performance. In contrast, for
female athletes, the landing pose and approach step technique emerge as the
most critical features influencing top 10% performances, alongside velocity.
This study establishes a framework for analyzing the impact of various features
on athletic performance, with a particular emphasis on top-performing events.

</details>


### [209] [Provable In-Context Vector Arithmetic via Retrieving Task Concepts](https://arxiv.org/abs/2508.09820)
*Dake Bu,Wei Huang,Andi Han,Atsushi Nitanda,Qingfu Zhang,Hau-San Wong,Taiji Suzuki*

Main category: cs.LG

TL;DR: 论文研究了LLMs在上下文学习（ICL）中如何通过潜在任务向量和残差流完成类似Word2Vec的向量运算，并提出了一种理论框架来解释其事实召回能力。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究指出LLMs在ICL中利用潜在任务向量和残差流，但对这一现象的理论解释仍缺失。本文旨在填补这一空白。

Method: 作者提出了一种基于分层概念建模的理论框架，并通过优化理论证明非线性残差Transformer如何通过梯度下降训练完成事实召回任务。

Result: 理论证明展示了0-1损失的收敛性，并表现出强泛化能力，包括对概念重组和分布变化的鲁棒性。实验模拟验证了理论结论。

Conclusion: 研究不仅揭示了Transformer相对于静态嵌入模型的优势，还为LLMs在ICL中的工作机制提供了理论支持。

Abstract: In-context learning (ICL) has garnered significant attention for its ability
to grasp functions/tasks from demonstrations. Recent studies suggest the
presence of a latent task/function vector in LLMs during ICL. Merullo et al.
(2024) showed that LLMs leverage this vector alongside the residual stream for
Word2Vec-like vector arithmetic, solving factual-recall ICL tasks.
Additionally, recent work empirically highlighted the key role of
Question-Answer data in enhancing factual-recall capabilities. Despite these
insights, a theoretical explanation remains elusive. To move one step forward,
we propose a theoretical framework building on empirically grounded
hierarchical concept modeling. We develop an optimization theory, showing how
nonlinear residual transformers trained via gradient descent on cross-entropy
loss perform factual-recall ICL tasks via vector arithmetic. We prove 0-1 loss
convergence and show the strong generalization, including robustness to concept
recombination and distribution shifts. These results elucidate the advantages
of transformers over static embedding predecessors. Empirical simulations
corroborate our theoretical insights.

</details>


### [210] [RankList -- A Listwise Preference Learning Framework for Predicting Subjective Preferences](https://arxiv.org/abs/2508.09826)
*Abinay Reddy Naini,Fernando Diaz,Carlos Busso*

Main category: cs.LG

TL;DR: 该论文提出了一种名为RankList的新型列表式偏好学习框架，扩展了RankNet以解决局部比较的局限性，并通过全局排序一致性提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有偏好学习框架（如RankNet）只能进行局部比较且难以捕捉全局排序一致性的问题。

Method: 提出RankList框架，通过列表级监督和概率框架显式建模局部和非局部排序约束，引入log-sum-exp近似以提高训练效率，并结合跳步比较增强全局排序保真度。

Result: 在多个基准数据集（MSP-Podcast、IEMOCAP、BIIC Podcast和艺术图像美学数据集）上，RankList在Kendall's Tau和排序准确性上表现优于基线方法。

Conclusion: RankList提供了一种统一且可扩展的方法，适用于主观学习场景中的有序偏好建模，并在跨域泛化中表现出色。

Abstract: Preference learning has gained significant attention in tasks involving
subjective human judgments, such as \emph{speech emotion recognition} (SER) and
image aesthetic assessment. While pairwise frameworks such as RankNet offer
robust modeling of relative preferences, they are inherently limited to local
comparisons and struggle to capture global ranking consistency. To address
these limitations, we propose RankList, a novel listwise preference learning
framework that generalizes RankNet to structured list-level supervision. Our
formulation explicitly models local and non-local ranking constraints within a
probabilistic framework. The paper introduces a log-sum-exp approximation to
improve training efficiency. We further extend RankList with skip-wise
comparisons, enabling progressive exposure to complex list structures and
enhancing global ranking fidelity. Extensive experiments demonstrate the
superiority of our method across diverse modalities. On benchmark SER datasets
(MSP-Podcast, IEMOCAP, BIIC Podcast), RankList achieves consistent improvements
in Kendall's Tau and ranking accuracy compared to standard listwise baselines.
We also validate our approach on aesthetic image ranking using the Artistic
Image Aesthetics dataset, highlighting its broad applicability. Through
ablation and cross-domain studies, we show that RankList not only improves
in-domain ranking but also generalizes better across datasets. Our framework
offers a unified, extensible approach for modeling ordered preferences in
subjective learning scenarios.

</details>


### [211] [FedShard: Federated Unlearning with Efficiency Fairness and Performance Fairness](https://arxiv.org/abs/2508.09866)
*Siyuan Wen,Meng Zhang,Yang Yang,Ningning Ding*

Main category: cs.LG

TL;DR: 论文提出了一种名为FedShard的联邦学习遗忘算法，旨在同时保证效率和性能公平性，解决了现有研究中未充分探索的公平性问题，并通过实验验证其优势。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习遗忘算法主要关注效率和效果，而忽略了效率和性能公平性，FedShard旨在填补这一空白。

Method: FedShard通过自适应解决收敛、遗忘效率和公平性之间的困境，并提出了两种定量评估公平性的新指标。

Result: 实验表明，FedShard比从头训练快1.3-6.2倍，比最先进的精确遗忘方法快4.9倍，且能应对不公平风险。

Conclusion: FedShard首次同时实现了效率和性能公平性，为联邦学习遗忘提供了更平衡和高效的解决方案。

Abstract: To protect clients' right to be forgotten in federated learning, federated
unlearning aims to remove the data contribution of leaving clients from the
global learned model. While current studies mainly focused on enhancing
unlearning efficiency and effectiveness, the crucial aspects of efficiency
fairness and performance fairness among decentralized clients during unlearning
have remained largely unexplored. In this study, we introduce FedShard, the
first federated unlearning algorithm designed to concurrently guarantee both
efficiency fairness and performance fairness. FedShard adaptively addresses the
challenges introduced by dilemmas among convergence, unlearning efficiency, and
unlearning fairness. Furthermore, we propose two novel metrics to
quantitatively assess the fairness of unlearning algorithms, which we prove to
satisfy well-known properties in other existing fairness measurements. Our
theoretical analysis and numerical evaluation validate FedShard's fairness in
terms of both unlearning performance and efficiency. We demonstrate that
FedShard mitigates unfairness risks such as cascaded leaving and poisoning
attacks and realizes more balanced unlearning costs among clients. Experimental
results indicate that FedShard accelerates the data unlearning process 1.3-6.2
times faster than retraining from scratch and 4.9 times faster than the
state-of-the-art exact unlearning methods.

</details>


### [212] [Beyond Scaling Law: A Data-Efficient Distillation Framework for Reasoning](https://arxiv.org/abs/2508.09883)
*Xiaojun Wu,Xiaoguang Jiang,Huiyang Li,Jucai Zhai,Dengfeng Liu,Qiaobo Hao,Huang Liu,Zhiguo Yang,Ji Xie,Ninglun Gu,Jin Yang,Kailai Zhang,Yelun Bao,Jun Wang*

Main category: cs.LG

TL;DR: 提出了一种数据高效的提炼框架（DED），通过选择最优教师模型、精心设计小规模语料库和多样化推理轨迹，提升了推理能力，同时在数学推理和代码生成任务中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在推理任务中表现出色，但现有方法通常依赖大量计算资源。本文旨在通过高效的数据利用和优化技术，提升推理能力而不增加计算成本。

Method: 提出的DED框架包括：(1) 选择最佳教师模型；(2) 使用小型但精心设计的语料库平衡领域内外能力；(3) 引入多样化的推理轨迹。

Result: 在数学推理（AIME 2024/2025, MATH-500）和代码生成（LiveCodeBench）任务中取得最佳性能，仅使用0.8k个精选示例。

Conclusion: DED提供了一种高效且实用的方法，通过优化数据使用和多样化策略，在推理任务中取得突破，同时保持模型的通用能力。

Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities in
tasks such as algorithmic coding and mathematical problem-solving. Recent
methods have improved reasoning through expanded corpus and multistage training
combining reinforcement learning and supervised fine-tuning. Although some
methods suggest that small but targeted dataset can incentivize reasoning via
only distillation, a reasoning scaling laws is still taking shape, increasing
computational costs. To address this, we propose a data-efficient distillation
framework (DED) that optimizes the Pareto frontier of reasoning distillation.
Inspired by the on-policy learning and diverse roll-out strategies of
reinforcement learning, the key idea of our approach is threefold: (1) We
identify that benchmark scores alone do not determine an effective teacher
model. Through comprehensive comparisons of leading reasoning LLMs, we develop
a method to select an optimal teacher model. (2) While scaling distillation can
enhance reasoning, it often degrades out-of-domain performance. A carefully
curated, smaller corpus achieves a balanced trade-off between in-domain and
out-of-domain capabilities. (3) Diverse reasoning trajectories encourage the
student model to develop robust reasoning skills. We validate our method
through evaluations on mathematical reasoning (AIME 2024/2025, MATH-500) and
code generation (LiveCodeBench), achieving state-of-the-art results with only
0.8k carefully curated examples, bypassing the need for extensive scaling. Our
systematic analysis demonstrates that DED outperforms existing methods by
considering factors beyond superficial hardness, token length, or teacher model
capability. This work offers a practical and efficient pathway to advanced
reasoning while preserving general capabilities.

</details>


### [213] [Modern Neural Networks for Small Tabular Datasets: The New Default for Field-Scale Digital Soil Mapping?](https://arxiv.org/abs/2508.09888)
*Viacheslav Barkov,Jonas Schmidinger,Robin Gebbers,Martin Atzmueller*

Main category: cs.LG

TL;DR: 现代人工神经网络在土壤属性预测中超越了传统机器学习方法，尤其是TabPFN表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探讨现代人工神经网络在基于小样本和高特征比的土壤光谱数据预测中的适用性。

Method: 对31个数据集进行综合基准测试，评估多种ANN架构的性能。

Result: 现代ANN（尤其是TabPFN）在多数任务中表现优于传统方法。

Conclusion: 现代ANN已足够成熟，推荐将其作为土壤预测建模的默认选择。

Abstract: In the field of pedometrics, tabular machine learning is the predominant
method for predicting soil properties from remote and proximal soil sensing
data, forming a central component of digital soil mapping. At the field-scale,
this predictive soil modeling (PSM) task is typically constrained by small
training sample sizes and high feature-to-sample ratios in soil spectroscopy.
Traditionally, these conditions have proven challenging for conventional deep
learning methods. Classical machine learning algorithms, particularly
tree-based models like Random Forest and linear models such as Partial Least
Squares Regression, have long been the default choice for field-scale PSM.
Recent advances in artificial neural networks (ANN) for tabular data challenge
this view, yet their suitability for field-scale PSM has not been proven. We
introduce a comprehensive benchmark that evaluates state-of-the-art ANN
architectures, including the latest multilayer perceptron (MLP)-based models
(TabM, RealMLP), attention-based transformer variants (FT-Transformer,
ExcelFormer, T2G-Former, AMFormer), retrieval-augmented approaches (TabR,
ModernNCA), and an in-context learning foundation model (TabPFN). Our
evaluation encompasses 31 field- and farm-scale datasets containing 30 to 460
samples and three critical soil properties: soil organic matter or soil organic
carbon, pH, and clay content. Our results reveal that modern ANNs consistently
outperform classical methods on the majority of tasks, demonstrating that deep
learning has matured sufficiently to overcome the long-standing dominance of
classical machine learning for PSM. Notably, TabPFN delivers the strongest
overall performance, showing robustness across varying conditions. We therefore
recommend the adoption of modern ANNs for field-scale PSM and propose TabPFN as
the new default choice in the toolkit of every pedometrician.

</details>


### [214] [Rare anomalies require large datasets: About proving the existence of anomalies](https://arxiv.org/abs/2508.09894)
*Simon Klüttermann,Emmanuel Müller*

Main category: cs.LG

TL;DR: 本文探讨了在数据集大小、污染率和算法依赖常数αₐₗgₒ之间的关系，提出了确认异常存在所需样本数量的下限条件。


<details>
  <summary>Details</summary>
Motivation: 异常检测中确认异常的存在是核心问题，但当前研究不足，本文旨在填补这一空白。

Method: 通过超过三百万次统计测试，分析不同异常检测任务和算法，确定N≥αₐₗgₒ/ν²的条件。

Result: 研究结果表明，当数据集大小满足条件时，可以确认异常的存在，否则因异常过稀有而无法验证。

Conclusion: 本文为异常检测提供了理论支持，明确了确认异常存在的样本数量阈值及其限制条件。

Abstract: Detecting whether any anomalies exist within a dataset is crucial for
effective anomaly detection, yet it remains surprisingly underexplored in
anomaly detection literature. This paper presents a comprehensive study that
addresses the fundamental question: When can we conclusively determine that
anomalies are present? Through extensive experimentation involving over three
million statistical tests across various anomaly detection tasks and
algorithms, we identify a relationship between the dataset size, contamination
rate, and an algorithm-dependent constant $ \alpha_{\text{algo}} $. Our results
demonstrate that, for an unlabeled dataset of size $ N $ and contamination rate
$ \nu $, the condition $ N \ge \frac{\alpha_{\text{algo}}}{\nu^2} $ represents
a lower bound on the number of samples required to confirm anomaly existence.
This threshold implies a limit to how rare anomalies can be before proving
their existence becomes infeasible.

</details>


### [215] [Beyond Naïve Prompting: Strategies for Improved Zero-shot Context-aided Forecasting with LLMs](https://arxiv.org/abs/2508.09904)
*Arjun Ashok,Andrew Robert Williams,Vincent Zhihao Zheng,Irina Rish,Nicolas Chapados,Étienne Marcotte,Valentina Zantedeschi,Alexandre Drouin*

Main category: cs.LG

TL;DR: 论文提出了四种策略（ReDP、CorDP、IC-DP、RouteDP），以提升大语言模型（LLM）在上下文辅助预测任务中的零样本能力，分别针对解释性、预测改进、提示嵌入和资源优化。


<details>
  <summary>Details</summary>
Motivation: 探索如何更有效地利用大语言模型（LLM）整合上下文信息进行预测，弥补现有直接提示方法的不足。

Method: 提出四种策略：ReDP（提升解释性）、CorDP（改进预测）、IC-DP（嵌入历史示例）、RouteDP（优化资源分配）。

Result: 在CiK基准测试中，这些策略在不同规模和家族的LLM上均优于直接提示方法。

Conclusion: 研究展示了简单而有效的方法可以显著提升LLM在上下文辅助预测任务中的表现，为未来改进提供了方向。

Abstract: Forecasting in real-world settings requires models to integrate not only
historical data but also relevant contextual information, often available in
textual form. While recent work has shown that large language models (LLMs) can
be effective context-aided forecasters via na\"ive direct prompting, their full
potential remains underexplored. We address this gap with 4 strategies,
providing new insights into the zero-shot capabilities of LLMs in this setting.
ReDP improves interpretability by eliciting explicit reasoning traces, allowing
us to assess the model's reasoning over the context independently from its
forecast accuracy. CorDP leverages LLMs solely to refine existing forecasts
with context, enhancing their applicability in real-world forecasting
pipelines. IC-DP proposes embedding historical examples of context-aided
forecasting tasks in the prompt, substantially improving accuracy even for the
largest models. Finally, RouteDP optimizes resource efficiency by using LLMs to
estimate task difficulty, and routing the most challenging tasks to larger
models. Evaluated on different kinds of context-aided forecasting tasks from
the CiK benchmark, our strategies demonstrate distinct benefits over na\"ive
prompting across LLMs of different sizes and families. These results open the
door to further simple yet effective improvements in LLM-based context-aided
forecasting.

</details>


### [216] [Prototype-Guided Diffusion: Visual Conditioning without External Memory](https://arxiv.org/abs/2508.09922)
*Bilal Faye,Hanane Azzag,Mustapha Lebbah*

Main category: cs.LG

TL;DR: 该论文提出了原型扩散模型（PDM），通过将原型学习直接集成到扩散过程中，实现了高效且自适应的视觉条件生成，无需外部存储。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在高质量图像生成方面表现优异，但计算成本高，尤其是在迭代去噪过程中。现有方法如检索增强扩散模型（RDM）虽然提高了效率，但依赖外部存储和检索基础设施，且缺乏训练时的适应性。

Method: PDM利用对比学习从干净图像特征中构建动态的紧凑视觉原型集合，通过语义对齐引导去噪步骤。

Result: 实验表明，PDM在保持高质量生成的同时，显著降低了计算和存储开销。

Conclusion: PDM为扩散模型提供了一种无需检索的可扩展条件生成方法，具有较高的实用价值。

Abstract: Diffusion models have emerged as a leading framework for high-quality image
generation, offering stable training and strong performance across diverse
domains. However, they remain computationally intensive, particularly during
the iterative denoising process. Latent-space models like Stable Diffusion
alleviate some of this cost by operating in compressed representations, though
at the expense of fine-grained detail. More recent approaches such as
Retrieval-Augmented Diffusion Models (RDM) address efficiency by conditioning
denoising on similar examples retrieved from large external memory banks. While
effective, these methods introduce drawbacks: they require costly storage and
retrieval infrastructure, depend on static vision-language models like CLIP for
similarity, and lack adaptability during training. We propose the Prototype
Diffusion Model (PDM), a method that integrates prototype learning directly
into the diffusion process for efficient and adaptive visual conditioning -
without external memory. Instead of retrieving reference samples, PDM
constructs a dynamic set of compact visual prototypes from clean image features
using contrastive learning. These prototypes guide the denoising steps by
aligning noisy representations with semantically relevant visual patterns,
enabling efficient generation with strong semantic grounding. Experiments show
that PDM maintains high generation quality while reducing computational and
storage overhead, offering a scalable alternative to retrieval-based
conditioning in diffusion models.

</details>


### [217] [Residual Reservoir Memory Networks](https://arxiv.org/abs/2508.09925)
*Matteo Pinna,Andrea Ceni,Claudio Gallicchio*

Main category: cs.LG

TL;DR: 介绍了一种新型的未训练RNN模型ResRMN，结合线性记忆储层和基于残差正交连接的非线性储层，提升长期输入传播。


<details>
  <summary>Details</summary>
Motivation: 探索通过残差正交连接增强时间维度上的长期输入传播，以改进RC模型的性能。

Method: 结合线性记忆储层和非线性储层，通过残差正交连接优化时间维度上的状态动态。

Result: 实验表明，ResRMN在时间序列和像素级1-D分类任务上优于传统RC模型。

Conclusion: ResRMN通过独特的储层设计有效提升了RC模型的性能。

Abstract: We introduce a novel class of untrained Recurrent Neural Networks (RNNs)
within the Reservoir Computing (RC) paradigm, called Residual Reservoir Memory
Networks (ResRMNs). ResRMN combines a linear memory reservoir with a non-linear
reservoir, where the latter is based on residual orthogonal connections along
the temporal dimension for enhanced long-term propagation of the input. The
resulting reservoir state dynamics are studied through the lens of linear
stability analysis, and we investigate diverse configurations for the temporal
residual connections. The proposed approach is empirically assessed on
time-series and pixel-level 1-D classification tasks. Our experimental results
highlight the advantages of the proposed approach over other conventional RC
models.

</details>


### [218] [Noise Hypernetworks: Amortizing Test-Time Compute in Diffusion Models](https://arxiv.org/abs/2508.09968)
*Luca Eyring,Shyamgopal Karthik,Alexey Dosovitskiy,Nataniel Ruiz,Zeynep Akata*

Main category: cs.LG

TL;DR: 提出了一种通过噪声超网络替代奖励引导的测试时噪声优化的方法，以减少扩散模型中的计算开销，同时保留测试时扩展的优势。


<details>
  <summary>Details</summary>
Motivation: 测试时扩展方法在大型语言模型和生成视觉模型中取得了显著进展，但其计算时间大幅增加，导致速度慢且不实用。研究旨在保留其优点的同时减少推理开销。

Method: 在训练后阶段，用噪声超网络调制初始输入噪声，替代奖励引导的测试时噪声优化。提出了一个理论框架，通过可处理的噪声空间目标学习这种奖励倾斜的分布。

Result: 该方法能够以极低的计算成本，恢复显著部分的测试时优化质量增益。

Conclusion: 通过噪声超网络方法，成功地解决了测试时扩展的计算开销问题，同时保持了其优势。

Abstract: The new paradigm of test-time scaling has yielded remarkable breakthroughs in
Large Language Models (LLMs) (e.g. reasoning models) and in generative vision
models, allowing models to allocate additional computation during inference to
effectively tackle increasingly complex problems. Despite the improvements of
this approach, an important limitation emerges: the substantial increase in
computation time makes the process slow and impractical for many applications.
Given the success of this paradigm and its growing usage, we seek to preserve
its benefits while eschewing the inference overhead. In this work we propose
one solution to the critical problem of integrating test-time scaling knowledge
into a model during post-training. Specifically, we replace reward guided
test-time noise optimization in diffusion models with a Noise Hypernetwork that
modulates initial input noise. We propose a theoretically grounded framework
for learning this reward-tilted distribution for distilled generators, through
a tractable noise-space objective that maintains fidelity to the base model
while optimizing for desired characteristics. We show that our approach
recovers a substantial portion of the quality gains from explicit test-time
optimization at a fraction of the computational cost. Code is available at
https://github.com/ExplainableML/HyperNoise

</details>


### [219] [Dynamic Mixture-of-Experts for Incremental Graph Learning](https://arxiv.org/abs/2508.09974)
*Lecheng Kong,Theodore Vasiloudis,Seongjun Yun,Han Xie,Xiang Song*

Main category: cs.LG

TL;DR: 提出了动态专家混合（DyMoE）方法解决图增量学习中的灾难性遗忘问题，并通过稀疏MoE降低计算成本，实验显示性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统图机器学习方法在增量学习中存在灾难性遗忘问题，且未考虑不同时间段知识对新任务的不同贡献。

Method: DyMoE通过动态添加专家网络和定制正则化损失，稀疏MoE选择最相关专家以减少计算开销。

Result: 模型在类别增量学习上相对基线准确率提升4.92%，计算效率高。

Conclusion: DyMoE方法有效缓解灾难性遗忘，兼具高性能和计算效率，适合增量学习场景。

Abstract: Graph incremental learning is a learning paradigm that aims to adapt trained
models to continuously incremented graphs and data over time without the need
for retraining on the full dataset. However, regular graph machine learning
methods suffer from catastrophic forgetting when applied to incremental
learning settings, where previously learned knowledge is overridden by new
knowledge. Previous approaches have tried to address this by treating the
previously trained model as an inseparable unit and using techniques to
maintain old behaviors while learning new knowledge. These approaches, however,
do not account for the fact that previously acquired knowledge at different
timestamps contributes differently to learning new tasks. Some prior patterns
can be transferred to help learn new data, while others may deviate from the
new data distribution and be detrimental. To address this, we propose a dynamic
mixture-of-experts (DyMoE) approach for incremental learning. Specifically, a
DyMoE GNN layer adds new expert networks specialized in modeling the incoming
data blocks. We design a customized regularization loss that utilizes data
sequence information so existing experts can maintain their ability to solve
old tasks while helping the new expert learn the new data effectively. As the
number of data blocks grows over time, the computational cost of the full
mixture-of-experts (MoE) model increases. To address this, we introduce a
sparse MoE approach, where only the top-$k$ most relevant experts make
predictions, significantly reducing the computation time. Our model achieved
4.92\% relative accuracy increase compared to the best baselines on class
incremental learning, showing the model's exceptional power.

</details>
